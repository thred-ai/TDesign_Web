{"ast":null,"code":"'use strict';\n\nvar tslib = require('tslib');\n\nvar util = require('@firebase/util');\n\nvar logger = require('@firebase/logger');\n\nvar util$1 = require('util');\n\nvar crypto = require('crypto');\n\nvar grpcJs = require('@grpc/grpc-js');\n\nvar package_json = require('@grpc/grpc-js/package.json');\n\nvar path = require('path');\n\nvar protoLoader = require('@grpc/proto-loader');\n\nvar version = \"8.8.1\";\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\nvar SDK_VERSION = version;\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * `ListenSequence` is a monotonic sequence. It is initialized with a minimum value to\r\n * exceed. All subsequent calls to next will return increasing values. If provided with a\r\n * `SequenceNumberSyncer`, it will additionally bump its next value when told of a new value, as\r\n * well as write out sequence numbers that it produces via `next()`.\r\n */\n\nvar ListenSequence =\n/** @class */\nfunction () {\n  function ListenSequence(previousValue, sequenceNumberSyncer) {\n    var _this = this;\n\n    this.previousValue = previousValue;\n\n    if (sequenceNumberSyncer) {\n      sequenceNumberSyncer.sequenceNumberHandler = function (sequenceNumber) {\n        return _this.setPreviousValue(sequenceNumber);\n      };\n\n      this.writeNewSequenceNumber = function (sequenceNumber) {\n        return sequenceNumberSyncer.writeSequenceNumber(sequenceNumber);\n      };\n    }\n  }\n\n  ListenSequence.prototype.setPreviousValue = function (externalPreviousValue) {\n    this.previousValue = Math.max(externalPreviousValue, this.previousValue);\n    return this.previousValue;\n  };\n\n  ListenSequence.prototype.next = function () {\n    var nextValue = ++this.previousValue;\n\n    if (this.writeNewSequenceNumber) {\n      this.writeNewSequenceNumber(nextValue);\n    }\n\n    return nextValue;\n  };\n\n  return ListenSequence;\n}();\n\nListenSequence.INVALID = -1;\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Formats an object as a JSON string, suitable for logging. */\n\nfunction formatJSON(value) {\n  // util.inspect() results in much more readable output than JSON.stringify()\n  return util$1.inspect(value, {\n    depth: 100\n  });\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar logClient = new logger.Logger('@firebase/firestore'); // Helper methods are needed because variables can't be exported as read/write\n\nfunction getLogLevel() {\n  return logClient.logLevel;\n}\n/**\r\n * Sets the verbosity of Cloud Firestore logs (debug, error, or silent).\r\n *\r\n * @param logLevel - The verbosity you set for activity and error logging. Can\r\n *   be any of the following values:\r\n *\r\n *   <ul>\r\n *     <li>`debug` for the most verbose logging level, primarily for\r\n *     debugging.</li>\r\n *     <li>`error` to log errors only.</li>\r\n *     <li><code>`silent` to turn off logging.</li>\r\n *   </ul>\r\n */\n\n\nfunction setLogLevel$1(logLevel) {\n  logClient.setLogLevel(logLevel);\n}\n\nfunction logDebug(msg) {\n  var obj = [];\n\n  for (var _i = 1; _i < arguments.length; _i++) {\n    obj[_i - 1] = arguments[_i];\n  }\n\n  if (logClient.logLevel <= logger.LogLevel.DEBUG) {\n    var args = obj.map(argToString);\n    logClient.debug.apply(logClient, tslib.__spreadArray([\"Firestore (\" + SDK_VERSION + \"): \" + msg], args));\n  }\n}\n\nfunction logError(msg) {\n  var obj = [];\n\n  for (var _i = 1; _i < arguments.length; _i++) {\n    obj[_i - 1] = arguments[_i];\n  }\n\n  if (logClient.logLevel <= logger.LogLevel.ERROR) {\n    var args = obj.map(argToString);\n    logClient.error.apply(logClient, tslib.__spreadArray([\"Firestore (\" + SDK_VERSION + \"): \" + msg], args));\n  }\n}\n\nfunction logWarn(msg) {\n  var obj = [];\n\n  for (var _i = 1; _i < arguments.length; _i++) {\n    obj[_i - 1] = arguments[_i];\n  }\n\n  if (logClient.logLevel <= logger.LogLevel.WARN) {\n    var args = obj.map(argToString);\n    logClient.warn.apply(logClient, tslib.__spreadArray([\"Firestore (\" + SDK_VERSION + \"): \" + msg], args));\n  }\n}\n/**\r\n * Converts an additional log parameter to a string representation.\r\n */\n\n\nfunction argToString(obj) {\n  if (typeof obj === 'string') {\n    return obj;\n  } else {\n    try {\n      return formatJSON(obj);\n    } catch (e) {\n      // Converting to JSON failed, just log the object directly\n      return obj;\n    }\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Unconditionally fails, throwing an Error with the given message.\r\n * Messages are stripped in production builds.\r\n *\r\n * Returns `never` and can be used in expressions:\r\n * @example\r\n * let futureVar = fail('not implemented yet');\r\n */\n\n\nfunction fail(failure) {\n  if (failure === void 0) {\n    failure = 'Unexpected state';\n  } // Log the failure in addition to throw an exception, just in case the\n  // exception is swallowed.\n\n\n  var message = \"FIRESTORE (\" + SDK_VERSION + \") INTERNAL ASSERTION FAILED: \" + failure;\n  logError(message); // NOTE: We don't use FirestoreError here because these are internal failures\n  // that cannot be handled by the user. (Also it would create a circular\n  // dependency between the error and assert modules which doesn't work.)\n\n  throw new Error(message);\n}\n/**\r\n * Fails if the given assertion condition is false, throwing an Error with the\r\n * given message if it did.\r\n *\r\n * Messages are stripped in production builds.\r\n */\n\n\nfunction hardAssert(assertion, message) {\n  if (!assertion) {\n    fail();\n  }\n}\n/**\r\n * Casts `obj` to `T`. In non-production builds, verifies that `obj` is an\r\n * instance of `T` before casting.\r\n */\n\n\nfunction debugCast(obj, // eslint-disable-next-line @typescript-eslint/no-explicit-any\nconstructor) {\n  return obj;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar Code = {\n  // Causes are copied from:\n  // https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\n\n  /** Not an error; returned on success. */\n  OK: 'ok',\n\n  /** The operation was cancelled (typically by the caller). */\n  CANCELLED: 'cancelled',\n\n  /** Unknown error or an error from a different error domain. */\n  UNKNOWN: 'unknown',\n\n  /**\r\n   * Client specified an invalid argument. Note that this differs from\r\n   * FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are\r\n   * problematic regardless of the state of the system (e.g., a malformed file\r\n   * name).\r\n   */\n  INVALID_ARGUMENT: 'invalid-argument',\n\n  /**\r\n   * Deadline expired before operation could complete. For operations that\r\n   * change the state of the system, this error may be returned even if the\r\n   * operation has completed successfully. For example, a successful response\r\n   * from a server could have been delayed long enough for the deadline to\r\n   * expire.\r\n   */\n  DEADLINE_EXCEEDED: 'deadline-exceeded',\n\n  /** Some requested entity (e.g., file or directory) was not found. */\n  NOT_FOUND: 'not-found',\n\n  /**\r\n   * Some entity that we attempted to create (e.g., file or directory) already\r\n   * exists.\r\n   */\n  ALREADY_EXISTS: 'already-exists',\n\n  /**\r\n   * The caller does not have permission to execute the specified operation.\r\n   * PERMISSION_DENIED must not be used for rejections caused by exhausting\r\n   * some resource (use RESOURCE_EXHAUSTED instead for those errors).\r\n   * PERMISSION_DENIED must not be used if the caller can not be identified\r\n   * (use UNAUTHENTICATED instead for those errors).\r\n   */\n  PERMISSION_DENIED: 'permission-denied',\n\n  /**\r\n   * The request does not have valid authentication credentials for the\r\n   * operation.\r\n   */\n  UNAUTHENTICATED: 'unauthenticated',\n\n  /**\r\n   * Some resource has been exhausted, perhaps a per-user quota, or perhaps the\r\n   * entire file system is out of space.\r\n   */\n  RESOURCE_EXHAUSTED: 'resource-exhausted',\n\n  /**\r\n   * Operation was rejected because the system is not in a state required for\r\n   * the operation's execution. For example, directory to be deleted may be\r\n   * non-empty, an rmdir operation is applied to a non-directory, etc.\r\n   *\r\n   * A litmus test that may help a service implementor in deciding\r\n   * between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:\r\n   *  (a) Use UNAVAILABLE if the client can retry just the failing call.\r\n   *  (b) Use ABORTED if the client should retry at a higher-level\r\n   *      (e.g., restarting a read-modify-write sequence).\r\n   *  (c) Use FAILED_PRECONDITION if the client should not retry until\r\n   *      the system state has been explicitly fixed. E.g., if an \"rmdir\"\r\n   *      fails because the directory is non-empty, FAILED_PRECONDITION\r\n   *      should be returned since the client should not retry unless\r\n   *      they have first fixed up the directory by deleting files from it.\r\n   *  (d) Use FAILED_PRECONDITION if the client performs conditional\r\n   *      REST Get/Update/Delete on a resource and the resource on the\r\n   *      server does not match the condition. E.g., conflicting\r\n   *      read-modify-write on the same resource.\r\n   */\n  FAILED_PRECONDITION: 'failed-precondition',\n\n  /**\r\n   * The operation was aborted, typically due to a concurrency issue like\r\n   * sequencer check failures, transaction aborts, etc.\r\n   *\r\n   * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\r\n   * and UNAVAILABLE.\r\n   */\n  ABORTED: 'aborted',\n\n  /**\r\n   * Operation was attempted past the valid range. E.g., seeking or reading\r\n   * past end of file.\r\n   *\r\n   * Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed\r\n   * if the system state changes. For example, a 32-bit file system will\r\n   * generate INVALID_ARGUMENT if asked to read at an offset that is not in the\r\n   * range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from\r\n   * an offset past the current file size.\r\n   *\r\n   * There is a fair bit of overlap between FAILED_PRECONDITION and\r\n   * OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error)\r\n   * when it applies so that callers who are iterating through a space can\r\n   * easily look for an OUT_OF_RANGE error to detect when they are done.\r\n   */\n  OUT_OF_RANGE: 'out-of-range',\n\n  /** Operation is not implemented or not supported/enabled in this service. */\n  UNIMPLEMENTED: 'unimplemented',\n\n  /**\r\n   * Internal errors. Means some invariants expected by underlying System has\r\n   * been broken. If you see one of these errors, Something is very broken.\r\n   */\n  INTERNAL: 'internal',\n\n  /**\r\n   * The service is currently unavailable. This is a most likely a transient\r\n   * condition and may be corrected by retrying with a backoff.\r\n   *\r\n   * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\r\n   * and UNAVAILABLE.\r\n   */\n  UNAVAILABLE: 'unavailable',\n\n  /** Unrecoverable data loss or corruption. */\n  DATA_LOSS: 'data-loss'\n};\n/** An error returned by a Firestore operation. */\n\nvar FirestoreError =\n/** @class */\nfunction (_super) {\n  tslib.__extends(FirestoreError, _super);\n  /** @hideconstructor */\n\n\n  function FirestoreError(\n  /**\r\n   * The backend error code associated with this error.\r\n   */\n  code,\n  /**\r\n   * A custom error description.\r\n   */\n  message) {\n    var _this = _super.call(this, message) || this;\n\n    _this.code = code;\n    _this.message = message;\n    /** The custom name for all FirestoreErrors. */\n\n    _this.name = 'FirebaseError'; // HACK: We write a toString property directly because Error is not a real\n    // class and so inheritance does not work correctly. We could alternatively\n    // do the same \"back-door inheritance\" trick that FirebaseError does.\n\n    _this.toString = function () {\n      return _this.name + \": [code=\" + _this.code + \"]: \" + _this.message;\n    };\n\n    return _this;\n  }\n\n  return FirestoreError;\n}(Error);\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar DOCUMENT_KEY_NAME = '__name__';\n/**\r\n * Path represents an ordered sequence of string segments.\r\n */\n\nvar BasePath =\n/** @class */\nfunction () {\n  function BasePath(segments, offset, length) {\n    if (offset === undefined) {\n      offset = 0;\n    } else if (offset > segments.length) {\n      fail();\n    }\n\n    if (length === undefined) {\n      length = segments.length - offset;\n    } else if (length > segments.length - offset) {\n      fail();\n    }\n\n    this.segments = segments;\n    this.offset = offset;\n    this.len = length;\n  }\n\n  Object.defineProperty(BasePath.prototype, \"length\", {\n    get: function () {\n      return this.len;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  BasePath.prototype.isEqual = function (other) {\n    return BasePath.comparator(this, other) === 0;\n  };\n\n  BasePath.prototype.child = function (nameOrPath) {\n    var segments = this.segments.slice(this.offset, this.limit());\n\n    if (nameOrPath instanceof BasePath) {\n      nameOrPath.forEach(function (segment) {\n        segments.push(segment);\n      });\n    } else {\n      segments.push(nameOrPath);\n    }\n\n    return this.construct(segments);\n  };\n  /** The index of one past the last segment of the path. */\n\n\n  BasePath.prototype.limit = function () {\n    return this.offset + this.length;\n  };\n\n  BasePath.prototype.popFirst = function (size) {\n    size = size === undefined ? 1 : size;\n    return this.construct(this.segments, this.offset + size, this.length - size);\n  };\n\n  BasePath.prototype.popLast = function () {\n    return this.construct(this.segments, this.offset, this.length - 1);\n  };\n\n  BasePath.prototype.firstSegment = function () {\n    return this.segments[this.offset];\n  };\n\n  BasePath.prototype.lastSegment = function () {\n    return this.get(this.length - 1);\n  };\n\n  BasePath.prototype.get = function (index) {\n    return this.segments[this.offset + index];\n  };\n\n  BasePath.prototype.isEmpty = function () {\n    return this.length === 0;\n  };\n\n  BasePath.prototype.isPrefixOf = function (other) {\n    if (other.length < this.length) {\n      return false;\n    }\n\n    for (var i = 0; i < this.length; i++) {\n      if (this.get(i) !== other.get(i)) {\n        return false;\n      }\n    }\n\n    return true;\n  };\n\n  BasePath.prototype.isImmediateParentOf = function (potentialChild) {\n    if (this.length + 1 !== potentialChild.length) {\n      return false;\n    }\n\n    for (var i = 0; i < this.length; i++) {\n      if (this.get(i) !== potentialChild.get(i)) {\n        return false;\n      }\n    }\n\n    return true;\n  };\n\n  BasePath.prototype.forEach = function (fn) {\n    for (var i = this.offset, end = this.limit(); i < end; i++) {\n      fn(this.segments[i]);\n    }\n  };\n\n  BasePath.prototype.toArray = function () {\n    return this.segments.slice(this.offset, this.limit());\n  };\n\n  BasePath.comparator = function (p1, p2) {\n    var len = Math.min(p1.length, p2.length);\n\n    for (var i = 0; i < len; i++) {\n      var left = p1.get(i);\n      var right = p2.get(i);\n\n      if (left < right) {\n        return -1;\n      }\n\n      if (left > right) {\n        return 1;\n      }\n    }\n\n    if (p1.length < p2.length) {\n      return -1;\n    }\n\n    if (p1.length > p2.length) {\n      return 1;\n    }\n\n    return 0;\n  };\n\n  return BasePath;\n}();\n/**\r\n * A slash-separated path for navigating resources (documents and collections)\r\n * within Firestore.\r\n */\n\n\nvar ResourcePath =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ResourcePath, _super);\n\n  function ResourcePath() {\n    return _super !== null && _super.apply(this, arguments) || this;\n  }\n\n  ResourcePath.prototype.construct = function (segments, offset, length) {\n    return new ResourcePath(segments, offset, length);\n  };\n\n  ResourcePath.prototype.canonicalString = function () {\n    // NOTE: The client is ignorant of any path segments containing escape\n    // sequences (e.g. __id123__) and just passes them through raw (they exist\n    // for legacy reasons and should not be used frequently).\n    return this.toArray().join('/');\n  };\n\n  ResourcePath.prototype.toString = function () {\n    return this.canonicalString();\n  };\n  /**\r\n   * Creates a resource path from the given slash-delimited string. If multiple\r\n   * arguments are provided, all components are combined. Leading and trailing\r\n   * slashes from all components are ignored.\r\n   */\n\n\n  ResourcePath.fromString = function () {\n    var pathComponents = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      pathComponents[_i] = arguments[_i];\n    } // NOTE: The client is ignorant of any path segments containing escape\n    // sequences (e.g. __id123__) and just passes them through raw (they exist\n    // for legacy reasons and should not be used frequently).\n\n\n    var segments = [];\n\n    for (var _d = 0, pathComponents_1 = pathComponents; _d < pathComponents_1.length; _d++) {\n      var path = pathComponents_1[_d];\n\n      if (path.indexOf('//') >= 0) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid segment (\" + path + \"). Paths must not contain // in them.\");\n      } // Strip leading and traling slashed.\n\n\n      segments.push.apply(segments, path.split('/').filter(function (segment) {\n        return segment.length > 0;\n      }));\n    }\n\n    return new ResourcePath(segments);\n  };\n\n  ResourcePath.emptyPath = function () {\n    return new ResourcePath([]);\n  };\n\n  return ResourcePath;\n}(BasePath);\n\nvar identifierRegExp = /^[_a-zA-Z][_a-zA-Z0-9]*$/;\n/** A dot-separated path for navigating sub-objects within a document. */\n\nvar FieldPath$1 =\n/** @class */\nfunction (_super) {\n  tslib.__extends(FieldPath$1, _super);\n\n  function FieldPath$1() {\n    return _super !== null && _super.apply(this, arguments) || this;\n  }\n\n  FieldPath$1.prototype.construct = function (segments, offset, length) {\n    return new FieldPath$1(segments, offset, length);\n  };\n  /**\r\n   * Returns true if the string could be used as a segment in a field path\r\n   * without escaping.\r\n   */\n\n\n  FieldPath$1.isValidIdentifier = function (segment) {\n    return identifierRegExp.test(segment);\n  };\n\n  FieldPath$1.prototype.canonicalString = function () {\n    return this.toArray().map(function (str) {\n      str = str.replace(/\\\\/g, '\\\\\\\\').replace(/`/g, '\\\\`');\n\n      if (!FieldPath$1.isValidIdentifier(str)) {\n        str = '`' + str + '`';\n      }\n\n      return str;\n    }).join('.');\n  };\n\n  FieldPath$1.prototype.toString = function () {\n    return this.canonicalString();\n  };\n  /**\r\n   * Returns true if this field references the key of a document.\r\n   */\n\n\n  FieldPath$1.prototype.isKeyField = function () {\n    return this.length === 1 && this.get(0) === DOCUMENT_KEY_NAME;\n  };\n  /**\r\n   * The field designating the key of a document.\r\n   */\n\n\n  FieldPath$1.keyField = function () {\n    return new FieldPath$1([DOCUMENT_KEY_NAME]);\n  };\n  /**\r\n   * Parses a field string from the given server-formatted string.\r\n   *\r\n   * - Splitting the empty string is not allowed (for now at least).\r\n   * - Empty segments within the string (e.g. if there are two consecutive\r\n   *   separators) are not allowed.\r\n   *\r\n   * TODO(b/37244157): we should make this more strict. Right now, it allows\r\n   * non-identifier path components, even if they aren't escaped.\r\n   */\n\n\n  FieldPath$1.fromServerFormat = function (path) {\n    var segments = [];\n    var current = '';\n    var i = 0;\n\n    var addCurrentSegment = function () {\n      if (current.length === 0) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid field path (\" + path + \"). Paths must not be empty, begin \" + \"with '.', end with '.', or contain '..'\");\n      }\n\n      segments.push(current);\n      current = '';\n    };\n\n    var inBackticks = false;\n\n    while (i < path.length) {\n      var c = path[i];\n\n      if (c === '\\\\') {\n        if (i + 1 === path.length) {\n          throw new FirestoreError(Code.INVALID_ARGUMENT, 'Path has trailing escape character: ' + path);\n        }\n\n        var next = path[i + 1];\n\n        if (!(next === '\\\\' || next === '.' || next === '`')) {\n          throw new FirestoreError(Code.INVALID_ARGUMENT, 'Path has invalid escape sequence: ' + path);\n        }\n\n        current += next;\n        i += 2;\n      } else if (c === '`') {\n        inBackticks = !inBackticks;\n        i++;\n      } else if (c === '.' && !inBackticks) {\n        addCurrentSegment();\n        i++;\n      } else {\n        current += c;\n        i++;\n      }\n    }\n\n    addCurrentSegment();\n\n    if (inBackticks) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Unterminated ` in path: ' + path);\n    }\n\n    return new FieldPath$1(segments);\n  };\n\n  FieldPath$1.emptyPath = function () {\n    return new FieldPath$1([]);\n  };\n\n  return FieldPath$1;\n}(BasePath);\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar escapeChar = '\\u0001';\nvar encodedSeparatorChar = '\\u0001';\nvar encodedNul = '\\u0010';\nvar encodedEscape = '\\u0011';\n/**\r\n * Encodes a resource path into a IndexedDb-compatible string form.\r\n */\n\nfunction encodeResourcePath(path) {\n  var result = '';\n\n  for (var i = 0; i < path.length; i++) {\n    if (result.length > 0) {\n      result = encodeSeparator(result);\n    }\n\n    result = encodeSegment(path.get(i), result);\n  }\n\n  return encodeSeparator(result);\n}\n/** Encodes a single segment of a resource path into the given result */\n\n\nfunction encodeSegment(segment, resultBuf) {\n  var result = resultBuf;\n  var length = segment.length;\n\n  for (var i = 0; i < length; i++) {\n    var c = segment.charAt(i);\n\n    switch (c) {\n      case '\\0':\n        result += escapeChar + encodedNul;\n        break;\n\n      case escapeChar:\n        result += escapeChar + encodedEscape;\n        break;\n\n      default:\n        result += c;\n    }\n  }\n\n  return result;\n}\n/** Encodes a path separator into the given result */\n\n\nfunction encodeSeparator(result) {\n  return result + escapeChar + encodedSeparatorChar;\n}\n/**\r\n * Decodes the given IndexedDb-compatible string form of a resource path into\r\n * a ResourcePath instance. Note that this method is not suitable for use with\r\n * decoding resource names from the server; those are One Platform format\r\n * strings.\r\n */\n\n\nfunction decodeResourcePath(path) {\n  // Event the empty path must encode as a path of at least length 2. A path\n  // with exactly 2 must be the empty path.\n  var length = path.length;\n  hardAssert(length >= 2);\n\n  if (length === 2) {\n    hardAssert(path.charAt(0) === escapeChar && path.charAt(1) === encodedSeparatorChar);\n    return ResourcePath.emptyPath();\n  } // Escape characters cannot exist past the second-to-last position in the\n  // source value.\n\n\n  var lastReasonableEscapeIndex = length - 2;\n  var segments = [];\n  var segmentBuilder = '';\n\n  for (var start = 0; start < length;) {\n    // The last two characters of a valid encoded path must be a separator, so\n    // there must be an end to this segment.\n    var end = path.indexOf(escapeChar, start);\n\n    if (end < 0 || end > lastReasonableEscapeIndex) {\n      fail();\n    }\n\n    var next = path.charAt(end + 1);\n\n    switch (next) {\n      case encodedSeparatorChar:\n        var currentPiece = path.substring(start, end);\n        var segment = void 0;\n\n        if (segmentBuilder.length === 0) {\n          // Avoid copying for the common case of a segment that excludes \\0\n          // and \\001\n          segment = currentPiece;\n        } else {\n          segmentBuilder += currentPiece;\n          segment = segmentBuilder;\n          segmentBuilder = '';\n        }\n\n        segments.push(segment);\n        break;\n\n      case encodedNul:\n        segmentBuilder += path.substring(start, end);\n        segmentBuilder += '\\0';\n        break;\n\n      case encodedEscape:\n        // The escape character can be used in the output to encode itself.\n        segmentBuilder += path.substring(start, end + 1);\n        break;\n\n      default:\n        fail();\n    }\n\n    start = end + 2;\n  }\n\n  return new ResourcePath(segments);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Schema Version for the Web client:\r\n * 1.  Initial version including Mutation Queue, Query Cache, and Remote\r\n *     Document Cache\r\n * 2.  Used to ensure a targetGlobal object exists and add targetCount to it. No\r\n *     longer required because migration 3 unconditionally clears it.\r\n * 3.  Dropped and re-created Query Cache to deal with cache corruption related\r\n *     to limbo resolution. Addresses\r\n *     https://github.com/firebase/firebase-ios-sdk/issues/1548\r\n * 4.  Multi-Tab Support.\r\n * 5.  Removal of held write acks.\r\n * 6.  Create document global for tracking document cache size.\r\n * 7.  Ensure every cached document has a sentinel row with a sequence number.\r\n * 8.  Add collection-parent index for Collection Group queries.\r\n * 9.  Change RemoteDocumentChanges store to be keyed by readTime rather than\r\n *     an auto-incrementing ID. This is required for Index-Free queries.\r\n * 10. Rewrite the canonical IDs to the explicit Protobuf-based format.\r\n * 11. Add bundles and named_queries for bundle support.\r\n */\n\n\nvar SCHEMA_VERSION = 11;\n/**\r\n * Wrapper class to store timestamps (seconds and nanos) in IndexedDb objects.\r\n */\n\nvar DbTimestamp =\n/** @class */\nfunction () {\n  function DbTimestamp(seconds, nanoseconds) {\n    this.seconds = seconds;\n    this.nanoseconds = nanoseconds;\n  }\n\n  return DbTimestamp;\n}();\n/**\r\n * A singleton object to be stored in the 'owner' store in IndexedDb.\r\n *\r\n * A given database can have a single primary tab assigned at a given time. That\r\n * tab must validate that it is still holding the primary lease before every\r\n * operation that requires locked access. The primary tab should regularly\r\n * write an updated timestamp to this lease to prevent other tabs from\r\n * \"stealing\" the primary lease\r\n */\n\n\nvar DbPrimaryClient =\n/** @class */\nfunction () {\n  function DbPrimaryClient(ownerId,\n  /** Whether to allow shared access from multiple tabs. */\n  allowTabSynchronization, leaseTimestampMs) {\n    this.ownerId = ownerId;\n    this.allowTabSynchronization = allowTabSynchronization;\n    this.leaseTimestampMs = leaseTimestampMs;\n  }\n\n  return DbPrimaryClient;\n}();\n/**\r\n * Name of the IndexedDb object store.\r\n *\r\n * Note that the name 'owner' is chosen to ensure backwards compatibility with\r\n * older clients that only supported single locked access to the persistence\r\n * layer.\r\n */\n\n\nDbPrimaryClient.store = 'owner';\n/**\r\n * The key string used for the single object that exists in the\r\n * DbPrimaryClient store.\r\n */\n\nDbPrimaryClient.key = 'owner';\n/**\r\n * An object to be stored in the 'mutationQueues' store in IndexedDb.\r\n *\r\n * Each user gets a single queue of MutationBatches to apply to the server.\r\n * DbMutationQueue tracks the metadata about the queue.\r\n */\n\nvar DbMutationQueue =\n/** @class */\nfunction () {\n  function DbMutationQueue(\n  /**\r\n   * The normalized user ID to which this queue belongs.\r\n   */\n  userId,\n  /**\r\n   * An identifier for the highest numbered batch that has been acknowledged\r\n   * by the server. All MutationBatches in this queue with batchIds less\r\n   * than or equal to this value are considered to have been acknowledged by\r\n   * the server.\r\n   *\r\n   * NOTE: this is deprecated and no longer used by the code.\r\n   */\n  lastAcknowledgedBatchId,\n  /**\r\n   * A stream token that was previously sent by the server.\r\n   *\r\n   * See StreamingWriteRequest in datastore.proto for more details about\r\n   * usage.\r\n   *\r\n   * After sending this token, earlier tokens may not be used anymore so\r\n   * only a single stream token is retained.\r\n   *\r\n   * NOTE: this is deprecated and no longer used by the code.\r\n   */\n  lastStreamToken) {\n    this.userId = userId;\n    this.lastAcknowledgedBatchId = lastAcknowledgedBatchId;\n    this.lastStreamToken = lastStreamToken;\n  }\n\n  return DbMutationQueue;\n}();\n/** Name of the IndexedDb object store.  */\n\n\nDbMutationQueue.store = 'mutationQueues';\n/** Keys are automatically assigned via the userId property. */\n\nDbMutationQueue.keyPath = 'userId';\n/**\r\n * An object to be stored in the 'mutations' store in IndexedDb.\r\n *\r\n * Represents a batch of user-level mutations intended to be sent to the server\r\n * in a single write. Each user-level batch gets a separate DbMutationBatch\r\n * with a new batchId.\r\n */\n\nvar DbMutationBatch =\n/** @class */\nfunction () {\n  function DbMutationBatch(\n  /**\r\n   * The normalized user ID to which this batch belongs.\r\n   */\n  userId,\n  /**\r\n   * An identifier for this batch, allocated using an auto-generated key.\r\n   */\n  batchId,\n  /**\r\n   * The local write time of the batch, stored as milliseconds since the\r\n   * epoch.\r\n   */\n  localWriteTimeMs,\n  /**\r\n   * A list of \"mutations\" that represent a partial base state from when this\r\n   * write batch was initially created. During local application of the write\r\n   * batch, these baseMutations are applied prior to the real writes in order\r\n   * to override certain document fields from the remote document cache. This\r\n   * is necessary in the case of non-idempotent writes (e.g. `increment()`\r\n   * transforms) to make sure that the local view of the modified documents\r\n   * doesn't flicker if the remote document cache receives the result of the\r\n   * non-idempotent write before the write is removed from the queue.\r\n   *\r\n   * These mutations are never sent to the backend.\r\n   */\n  baseMutations,\n  /**\r\n   * A list of mutations to apply. All mutations will be applied atomically.\r\n   *\r\n   * Mutations are serialized via toMutation().\r\n   */\n  mutations) {\n    this.userId = userId;\n    this.batchId = batchId;\n    this.localWriteTimeMs = localWriteTimeMs;\n    this.baseMutations = baseMutations;\n    this.mutations = mutations;\n  }\n\n  return DbMutationBatch;\n}();\n/** Name of the IndexedDb object store.  */\n\n\nDbMutationBatch.store = 'mutations';\n/** Keys are automatically assigned via the userId, batchId properties. */\n\nDbMutationBatch.keyPath = 'batchId';\n/** The index name for lookup of mutations by user. */\n\nDbMutationBatch.userMutationsIndex = 'userMutationsIndex';\n/** The user mutations index is keyed by [userId, batchId] pairs. */\n\nDbMutationBatch.userMutationsKeyPath = ['userId', 'batchId'];\n/**\r\n * An object to be stored in the 'documentMutations' store in IndexedDb.\r\n *\r\n * A manually maintained index of all the mutation batches that affect a given\r\n * document key. The rows in this table are references based on the contents of\r\n * DbMutationBatch.mutations.\r\n */\n\nvar DbDocumentMutation =\n/** @class */\nfunction () {\n  function DbDocumentMutation() {}\n  /**\r\n   * Creates a [userId] key for use in the DbDocumentMutations index to iterate\r\n   * over all of a user's document mutations.\r\n   */\n\n\n  DbDocumentMutation.prefixForUser = function (userId) {\n    return [userId];\n  };\n  /**\r\n   * Creates a [userId, encodedPath] key for use in the DbDocumentMutations\r\n   * index to iterate over all at document mutations for a given path or lower.\r\n   */\n\n\n  DbDocumentMutation.prefixForPath = function (userId, path) {\n    return [userId, encodeResourcePath(path)];\n  };\n  /**\r\n   * Creates a full index key of [userId, encodedPath, batchId] for inserting\r\n   * and deleting into the DbDocumentMutations index.\r\n   */\n\n\n  DbDocumentMutation.key = function (userId, path, batchId) {\n    return [userId, encodeResourcePath(path), batchId];\n  };\n\n  return DbDocumentMutation;\n}();\n\nDbDocumentMutation.store = 'documentMutations';\n/**\r\n * Because we store all the useful information for this store in the key,\r\n * there is no useful information to store as the value. The raw (unencoded)\r\n * path cannot be stored because IndexedDb doesn't store prototype\r\n * information.\r\n */\n\nDbDocumentMutation.PLACEHOLDER = new DbDocumentMutation();\n/**\r\n * Represents the known absence of a document at a particular version.\r\n * Stored in IndexedDb as part of a DbRemoteDocument object.\r\n */\n\nvar DbNoDocument =\n/** @class */\nfunction () {\n  function DbNoDocument(path, readTime) {\n    this.path = path;\n    this.readTime = readTime;\n  }\n\n  return DbNoDocument;\n}();\n/**\r\n * Represents a document that is known to exist but whose data is unknown.\r\n * Stored in IndexedDb as part of a DbRemoteDocument object.\r\n */\n\n\nvar DbUnknownDocument =\n/** @class */\nfunction () {\n  function DbUnknownDocument(path, version) {\n    this.path = path;\n    this.version = version;\n  }\n\n  return DbUnknownDocument;\n}();\n/**\r\n * An object to be stored in the 'remoteDocuments' store in IndexedDb.\r\n * It represents either:\r\n *\r\n * - A complete document.\r\n * - A \"no document\" representing a document that is known not to exist (at\r\n * some version).\r\n * - An \"unknown document\" representing a document that is known to exist (at\r\n * some version) but whose contents are unknown.\r\n *\r\n * Note: This is the persisted equivalent of a MaybeDocument and could perhaps\r\n * be made more general if necessary.\r\n */\n\n\nvar DbRemoteDocument =\n/** @class */\nfunction () {\n  // TODO: We are currently storing full document keys almost three times\n  // (once as part of the primary key, once - partly - as `parentPath` and once\n  // inside the encoded documents). During our next migration, we should\n  // rewrite the primary key as parentPath + document ID which would allow us\n  // to drop one value.\n  function DbRemoteDocument(\n  /**\r\n   * Set to an instance of DbUnknownDocument if the data for a document is\r\n   * not known, but it is known that a document exists at the specified\r\n   * version (e.g. it had a successful update applied to it)\r\n   */\n  unknownDocument,\n  /**\r\n   * Set to an instance of a DbNoDocument if it is known that no document\r\n   * exists.\r\n   */\n  noDocument,\n  /**\r\n   * Set to an instance of a Document if there's a cached version of the\r\n   * document.\r\n   */\n  document,\n  /**\r\n   * Documents that were written to the remote document store based on\r\n   * a write acknowledgment are marked with `hasCommittedMutations`. These\r\n   * documents are potentially inconsistent with the backend's copy and use\r\n   * the write's commit version as their document version.\r\n   */\n  hasCommittedMutations,\n  /**\r\n   * When the document was read from the backend. Undefined for data written\r\n   * prior to schema version 9.\r\n   */\n  readTime,\n  /**\r\n   * The path of the collection this document is part of. Undefined for data\r\n   * written prior to schema version 9.\r\n   */\n  parentPath) {\n    this.unknownDocument = unknownDocument;\n    this.noDocument = noDocument;\n    this.document = document;\n    this.hasCommittedMutations = hasCommittedMutations;\n    this.readTime = readTime;\n    this.parentPath = parentPath;\n  }\n\n  return DbRemoteDocument;\n}();\n\nDbRemoteDocument.store = 'remoteDocuments';\n/**\r\n * An index that provides access to all entries sorted by read time (which\r\n * corresponds to the last modification time of each row).\r\n *\r\n * This index is used to provide a changelog for Multi-Tab.\r\n */\n\nDbRemoteDocument.readTimeIndex = 'readTimeIndex';\nDbRemoteDocument.readTimeIndexPath = 'readTime';\n/**\r\n * An index that provides access to documents in a collection sorted by read\r\n * time.\r\n *\r\n * This index is used to allow the RemoteDocumentCache to fetch newly changed\r\n * documents in a collection.\r\n */\n\nDbRemoteDocument.collectionReadTimeIndex = 'collectionReadTimeIndex';\nDbRemoteDocument.collectionReadTimeIndexPath = ['parentPath', 'readTime'];\n/**\r\n * Contains a single entry that has metadata about the remote document cache.\r\n */\n\nvar DbRemoteDocumentGlobal =\n/** @class */\nfunction () {\n  /**\r\n   * @param byteSize - Approximately the total size in bytes of all the\r\n   * documents in the document cache.\r\n   */\n  function DbRemoteDocumentGlobal(byteSize) {\n    this.byteSize = byteSize;\n  }\n\n  return DbRemoteDocumentGlobal;\n}();\n\nDbRemoteDocumentGlobal.store = 'remoteDocumentGlobal';\nDbRemoteDocumentGlobal.key = 'remoteDocumentGlobalKey';\n/**\r\n * An object to be stored in the 'targets' store in IndexedDb.\r\n *\r\n * This is based on and should be kept in sync with the proto used in the iOS\r\n * client.\r\n *\r\n * Each query the client listens to against the server is tracked on disk so\r\n * that the query can be efficiently resumed on restart.\r\n */\n\nvar DbTarget =\n/** @class */\nfunction () {\n  function DbTarget(\n  /**\r\n   * An auto-generated sequential numeric identifier for the query.\r\n   *\r\n   * Queries are stored using their canonicalId as the key, but these\r\n   * canonicalIds can be quite long so we additionally assign a unique\r\n   * queryId which can be used by referenced data structures (e.g.\r\n   * indexes) to minimize the on-disk cost.\r\n   */\n  targetId,\n  /**\r\n   * The canonical string representing this query. This is not unique.\r\n   */\n  canonicalId,\n  /**\r\n   * The last readTime received from the Watch Service for this query.\r\n   *\r\n   * This is the same value as TargetChange.read_time in the protos.\r\n   */\n  readTime,\n  /**\r\n   * An opaque, server-assigned token that allows watching a query to be\r\n   * resumed after disconnecting without retransmitting all the data\r\n   * that matches the query. The resume token essentially identifies a\r\n   * point in time from which the server should resume sending results.\r\n   *\r\n   * This is related to the snapshotVersion in that the resumeToken\r\n   * effectively also encodes that value, but the resumeToken is opaque\r\n   * and sometimes encodes additional information.\r\n   *\r\n   * A consequence of this is that the resumeToken should be used when\r\n   * asking the server to reason about where this client is in the watch\r\n   * stream, but the client should use the snapshotVersion for its own\r\n   * purposes.\r\n   *\r\n   * This is the same value as TargetChange.resume_token in the protos.\r\n   */\n  resumeToken,\n  /**\r\n   * A sequence number representing the last time this query was\r\n   * listened to, used for garbage collection purposes.\r\n   *\r\n   * Conventionally this would be a timestamp value, but device-local\r\n   * clocks are unreliable and they must be able to create new listens\r\n   * even while disconnected. Instead this should be a monotonically\r\n   * increasing number that's incremented on each listen call.\r\n   *\r\n   * This is different from the queryId since the queryId is an\r\n   * immutable identifier assigned to the Query on first use while\r\n   * lastListenSequenceNumber is updated every time the query is\r\n   * listened to.\r\n   */\n  lastListenSequenceNumber,\n  /**\r\n   * Denotes the maximum snapshot version at which the associated query view\r\n   * contained no limbo documents.  Undefined for data written prior to\r\n   * schema version 9.\r\n   */\n  lastLimboFreeSnapshotVersion,\n  /**\r\n   * The query for this target.\r\n   *\r\n   * Because canonical ids are not unique we must store the actual query. We\r\n   * use the proto to have an object we can persist without having to\r\n   * duplicate translation logic to and from a `Query` object.\r\n   */\n  query) {\n    this.targetId = targetId;\n    this.canonicalId = canonicalId;\n    this.readTime = readTime;\n    this.resumeToken = resumeToken;\n    this.lastListenSequenceNumber = lastListenSequenceNumber;\n    this.lastLimboFreeSnapshotVersion = lastLimboFreeSnapshotVersion;\n    this.query = query;\n  }\n\n  return DbTarget;\n}();\n\nDbTarget.store = 'targets';\n/** Keys are automatically assigned via the targetId property. */\n\nDbTarget.keyPath = 'targetId';\n/** The name of the queryTargets index. */\n\nDbTarget.queryTargetsIndexName = 'queryTargetsIndex';\n/**\r\n * The index of all canonicalIds to the targets that they match. This is not\r\n * a unique mapping because canonicalId does not promise a unique name for all\r\n * possible queries, so we append the targetId to make the mapping unique.\r\n */\n\nDbTarget.queryTargetsKeyPath = ['canonicalId', 'targetId'];\n/**\r\n * An object representing an association between a target and a document, or a\r\n * sentinel row marking the last sequence number at which a document was used.\r\n * Each document cached must have a corresponding sentinel row before lru\r\n * garbage collection is enabled.\r\n *\r\n * The target associations and sentinel rows are co-located so that orphaned\r\n * documents and their sequence numbers can be identified efficiently via a scan\r\n * of this store.\r\n */\n\nvar DbTargetDocument =\n/** @class */\nfunction () {\n  function DbTargetDocument(\n  /**\r\n   * The targetId identifying a target or 0 for a sentinel row.\r\n   */\n  targetId,\n  /**\r\n   * The path to the document, as encoded in the key.\r\n   */\n  path,\n  /**\r\n   * If this is a sentinel row, this should be the sequence number of the last\r\n   * time the document specified by `path` was used. Otherwise, it should be\r\n   * `undefined`.\r\n   */\n  sequenceNumber) {\n    this.targetId = targetId;\n    this.path = path;\n    this.sequenceNumber = sequenceNumber;\n  }\n\n  return DbTargetDocument;\n}();\n/** Name of the IndexedDb object store.  */\n\n\nDbTargetDocument.store = 'targetDocuments';\n/** Keys are automatically assigned via the targetId, path properties. */\n\nDbTargetDocument.keyPath = ['targetId', 'path'];\n/** The index name for the reverse index. */\n\nDbTargetDocument.documentTargetsIndex = 'documentTargetsIndex';\n/** We also need to create the reverse index for these properties. */\n\nDbTargetDocument.documentTargetsKeyPath = ['path', 'targetId'];\n/**\r\n * A record of global state tracked across all Targets, tracked separately\r\n * to avoid the need for extra indexes.\r\n *\r\n * This should be kept in-sync with the proto used in the iOS client.\r\n */\n\nvar DbTargetGlobal =\n/** @class */\nfunction () {\n  function DbTargetGlobal(\n  /**\r\n   * The highest numbered target id across all targets.\r\n   *\r\n   * See DbTarget.targetId.\r\n   */\n  highestTargetId,\n  /**\r\n   * The highest numbered lastListenSequenceNumber across all targets.\r\n   *\r\n   * See DbTarget.lastListenSequenceNumber.\r\n   */\n  highestListenSequenceNumber,\n  /**\r\n   * A global snapshot version representing the last consistent snapshot we\r\n   * received from the backend. This is monotonically increasing and any\r\n   * snapshots received from the backend prior to this version (e.g. for\r\n   * targets resumed with a resumeToken) should be suppressed (buffered)\r\n   * until the backend has caught up to this snapshot version again. This\r\n   * prevents our cache from ever going backwards in time.\r\n   */\n  lastRemoteSnapshotVersion,\n  /**\r\n   * The number of targets persisted.\r\n   */\n  targetCount) {\n    this.highestTargetId = highestTargetId;\n    this.highestListenSequenceNumber = highestListenSequenceNumber;\n    this.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion;\n    this.targetCount = targetCount;\n  }\n\n  return DbTargetGlobal;\n}();\n/**\r\n * The key string used for the single object that exists in the\r\n * DbTargetGlobal store.\r\n */\n\n\nDbTargetGlobal.key = 'targetGlobalKey';\nDbTargetGlobal.store = 'targetGlobal';\n/**\r\n * An object representing an association between a Collection id (e.g. 'messages')\r\n * to a parent path (e.g. '/chats/123') that contains it as a (sub)collection.\r\n * This is used to efficiently find all collections to query when performing\r\n * a Collection Group query.\r\n */\n\nvar DbCollectionParent =\n/** @class */\nfunction () {\n  function DbCollectionParent(\n  /**\r\n   * The collectionId (e.g. 'messages')\r\n   */\n  collectionId,\n  /**\r\n   * The path to the parent (either a document location or an empty path for\r\n   * a root-level collection).\r\n   */\n  parent) {\n    this.collectionId = collectionId;\n    this.parent = parent;\n  }\n\n  return DbCollectionParent;\n}();\n/** Name of the IndexedDb object store. */\n\n\nDbCollectionParent.store = 'collectionParents';\n/** Keys are automatically assigned via the collectionId, parent properties. */\n\nDbCollectionParent.keyPath = ['collectionId', 'parent'];\n/**\r\n * A record of the metadata state of each client.\r\n *\r\n * PORTING NOTE: This is used to synchronize multi-tab state and does not need\r\n * to be ported to iOS or Android.\r\n */\n\nvar DbClientMetadata =\n/** @class */\nfunction () {\n  function DbClientMetadata( // Note: Previous schema versions included a field\n  // \"lastProcessedDocumentChangeId\". Don't use anymore.\n\n  /** The auto-generated client id assigned at client startup. */\n  clientId,\n  /** The last time this state was updated. */\n  updateTimeMs,\n  /** Whether the client's network connection is enabled. */\n  networkEnabled,\n  /** Whether this client is running in a foreground tab. */\n  inForeground) {\n    this.clientId = clientId;\n    this.updateTimeMs = updateTimeMs;\n    this.networkEnabled = networkEnabled;\n    this.inForeground = inForeground;\n  }\n\n  return DbClientMetadata;\n}();\n/** Name of the IndexedDb object store. */\n\n\nDbClientMetadata.store = 'clientMetadata';\n/** Keys are automatically assigned via the clientId properties. */\n\nDbClientMetadata.keyPath = 'clientId';\n/**\r\n * A object representing a bundle loaded by the SDK.\r\n */\n\nvar DbBundle =\n/** @class */\nfunction () {\n  function DbBundle(\n  /** The ID of the loaded bundle. */\n  bundleId,\n  /** The create time of the loaded bundle. */\n  createTime,\n  /** The schema version of the loaded bundle. */\n  version) {\n    this.bundleId = bundleId;\n    this.createTime = createTime;\n    this.version = version;\n  }\n\n  return DbBundle;\n}();\n/** Name of the IndexedDb object store. */\n\n\nDbBundle.store = 'bundles';\nDbBundle.keyPath = 'bundleId';\n/**\r\n * A object representing a named query loaded by the SDK via a bundle.\r\n */\n\nvar DbNamedQuery =\n/** @class */\nfunction () {\n  function DbNamedQuery(\n  /** The name of the query. */\n  name,\n  /** The read time of the results saved in the bundle from the named query. */\n  readTime,\n  /** The query saved in the bundle. */\n  bundledQuery) {\n    this.name = name;\n    this.readTime = readTime;\n    this.bundledQuery = bundledQuery;\n  }\n\n  return DbNamedQuery;\n}();\n/** Name of the IndexedDb object store. */\n\n\nDbNamedQuery.store = 'namedQueries';\nDbNamedQuery.keyPath = 'name'; // Visible for testing\n\nvar V1_STORES = [DbMutationQueue.store, DbMutationBatch.store, DbDocumentMutation.store, DbRemoteDocument.store, DbTarget.store, DbPrimaryClient.store, DbTargetGlobal.store, DbTargetDocument.store]; // V2 is no longer usable (see comment at top of file)\n// Visible for testing\n\nvar V3_STORES = V1_STORES; // Visible for testing\n// Note: DbRemoteDocumentChanges is no longer used and dropped with v9.\n\nvar V4_STORES = tslib.__spreadArray(tslib.__spreadArray([], V3_STORES), [DbClientMetadata.store]); // V5 does not change the set of stores.\n\n\nvar V6_STORES = tslib.__spreadArray(tslib.__spreadArray([], V4_STORES), [DbRemoteDocumentGlobal.store]); // V7 does not change the set of stores.\n\n\nvar V8_STORES = tslib.__spreadArray(tslib.__spreadArray([], V6_STORES), [DbCollectionParent.store]); // V9 does not change the set of stores.\n// V10 does not change the set of stores.\n\n\nvar V11_STORES = tslib.__spreadArray(tslib.__spreadArray([], V8_STORES), [DbBundle.store, DbNamedQuery.store]);\n/**\r\n * The list of all default IndexedDB stores used throughout the SDK. This is\r\n * used when creating transactions so that access across all stores is done\r\n * atomically.\r\n */\n\n\nvar ALL_STORES = V11_STORES;\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\nvar PRIMARY_LEASE_LOST_ERROR_MSG = 'The current tab is not in the required state to perform this operation. ' + 'It might be necessary to refresh the browser tab.';\n/**\r\n * A base class representing a persistence transaction, encapsulating both the\r\n * transaction's sequence numbers as well as a list of onCommitted listeners.\r\n *\r\n * When you call Persistence.runTransaction(), it will create a transaction and\r\n * pass it to your callback. You then pass it to any method that operates\r\n * on persistence.\r\n */\n\nvar PersistenceTransaction =\n/** @class */\nfunction () {\n  function PersistenceTransaction() {\n    this.onCommittedListeners = [];\n  }\n\n  PersistenceTransaction.prototype.addOnCommittedListener = function (listener) {\n    this.onCommittedListeners.push(listener);\n  };\n\n  PersistenceTransaction.prototype.raiseOnCommittedEvent = function () {\n    this.onCommittedListeners.forEach(function (listener) {\n      return listener();\n    });\n  };\n\n  return PersistenceTransaction;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar Deferred =\n/** @class */\nfunction () {\n  function Deferred() {\n    var _this = this;\n\n    this.promise = new Promise(function (resolve, reject) {\n      _this.resolve = resolve;\n      _this.reject = reject;\n    });\n  }\n\n  return Deferred;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * PersistencePromise is essentially a re-implementation of Promise except\r\n * it has a .next() method instead of .then() and .next() and .catch() callbacks\r\n * are executed synchronously when a PersistencePromise resolves rather than\r\n * asynchronously (Promise implementations use setImmediate() or similar).\r\n *\r\n * This is necessary to interoperate with IndexedDB which will automatically\r\n * commit transactions if control is returned to the event loop without\r\n * synchronously initiating another operation on the transaction.\r\n *\r\n * NOTE: .then() and .catch() only allow a single consumer, unlike normal\r\n * Promises.\r\n */\n\n\nvar PersistencePromise =\n/** @class */\nfunction () {\n  function PersistencePromise(callback) {\n    var _this = this; // NOTE: next/catchCallback will always point to our own wrapper functions,\n    // not the user's raw next() or catch() callbacks.\n\n\n    this.nextCallback = null;\n    this.catchCallback = null; // When the operation resolves, we'll set result or error and mark isDone.\n\n    this.result = undefined;\n    this.error = undefined;\n    this.isDone = false; // Set to true when .then() or .catch() are called and prevents additional\n    // chaining.\n\n    this.callbackAttached = false;\n    callback(function (value) {\n      _this.isDone = true;\n      _this.result = value;\n\n      if (_this.nextCallback) {\n        // value should be defined unless T is Void, but we can't express\n        // that in the type system.\n        _this.nextCallback(value);\n      }\n    }, function (error) {\n      _this.isDone = true;\n      _this.error = error;\n\n      if (_this.catchCallback) {\n        _this.catchCallback(error);\n      }\n    });\n  }\n\n  PersistencePromise.prototype.catch = function (fn) {\n    return this.next(undefined, fn);\n  };\n\n  PersistencePromise.prototype.next = function (nextFn, catchFn) {\n    var _this = this;\n\n    if (this.callbackAttached) {\n      fail();\n    }\n\n    this.callbackAttached = true;\n\n    if (this.isDone) {\n      if (!this.error) {\n        return this.wrapSuccess(nextFn, this.result);\n      } else {\n        return this.wrapFailure(catchFn, this.error);\n      }\n    } else {\n      return new PersistencePromise(function (resolve, reject) {\n        _this.nextCallback = function (value) {\n          _this.wrapSuccess(nextFn, value).next(resolve, reject);\n        };\n\n        _this.catchCallback = function (error) {\n          _this.wrapFailure(catchFn, error).next(resolve, reject);\n        };\n      });\n    }\n  };\n\n  PersistencePromise.prototype.toPromise = function () {\n    var _this = this;\n\n    return new Promise(function (resolve, reject) {\n      _this.next(resolve, reject);\n    });\n  };\n\n  PersistencePromise.prototype.wrapUserFunction = function (fn) {\n    try {\n      var result = fn();\n\n      if (result instanceof PersistencePromise) {\n        return result;\n      } else {\n        return PersistencePromise.resolve(result);\n      }\n    } catch (e) {\n      return PersistencePromise.reject(e);\n    }\n  };\n\n  PersistencePromise.prototype.wrapSuccess = function (nextFn, value) {\n    if (nextFn) {\n      return this.wrapUserFunction(function () {\n        return nextFn(value);\n      });\n    } else {\n      // If there's no nextFn, then R must be the same as T\n      return PersistencePromise.resolve(value);\n    }\n  };\n\n  PersistencePromise.prototype.wrapFailure = function (catchFn, error) {\n    if (catchFn) {\n      return this.wrapUserFunction(function () {\n        return catchFn(error);\n      });\n    } else {\n      return PersistencePromise.reject(error);\n    }\n  };\n\n  PersistencePromise.resolve = function (result) {\n    return new PersistencePromise(function (resolve, reject) {\n      resolve(result);\n    });\n  };\n\n  PersistencePromise.reject = function (error) {\n    return new PersistencePromise(function (resolve, reject) {\n      reject(error);\n    });\n  };\n\n  PersistencePromise.waitFor = function ( // Accept all Promise types in waitFor().\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  all) {\n    return new PersistencePromise(function (resolve, reject) {\n      var expectedCount = 0;\n      var resolvedCount = 0;\n      var done = false;\n      all.forEach(function (element) {\n        ++expectedCount;\n        element.next(function () {\n          ++resolvedCount;\n\n          if (done && resolvedCount === expectedCount) {\n            resolve();\n          }\n        }, function (err) {\n          return reject(err);\n        });\n      });\n      done = true;\n\n      if (resolvedCount === expectedCount) {\n        resolve();\n      }\n    });\n  };\n  /**\r\n   * Given an array of predicate functions that asynchronously evaluate to a\r\n   * boolean, implements a short-circuiting `or` between the results. Predicates\r\n   * will be evaluated until one of them returns `true`, then stop. The final\r\n   * result will be whether any of them returned `true`.\r\n   */\n\n\n  PersistencePromise.or = function (predicates) {\n    var p = PersistencePromise.resolve(false);\n\n    var _loop_1 = function (predicate) {\n      p = p.next(function (isTrue) {\n        if (isTrue) {\n          return PersistencePromise.resolve(isTrue);\n        } else {\n          return predicate();\n        }\n      });\n    };\n\n    for (var _i = 0, predicates_1 = predicates; _i < predicates_1.length; _i++) {\n      var predicate = predicates_1[_i];\n\n      _loop_1(predicate);\n    }\n\n    return p;\n  };\n\n  PersistencePromise.forEach = function (collection, f) {\n    var _this = this;\n\n    var promises = [];\n    collection.forEach(function (r, s) {\n      promises.push(f.call(_this, r, s));\n    });\n    return this.waitFor(promises);\n  };\n\n  return PersistencePromise;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// References to `window` are guarded by SimpleDb.isAvailable()\n\n/* eslint-disable no-restricted-globals */\n\n\nvar LOG_TAG$g = 'SimpleDb';\n/**\r\n * The maximum number of retry attempts for an IndexedDb transaction that fails\r\n * with a DOMException.\r\n */\n\nvar TRANSACTION_RETRY_COUNT = 3;\n/**\r\n * Wraps an IDBTransaction and exposes a store() method to get a handle to a\r\n * specific object store.\r\n */\n\nvar SimpleDbTransaction =\n/** @class */\nfunction () {\n  function SimpleDbTransaction(action, transaction) {\n    var _this = this;\n\n    this.action = action;\n    this.transaction = transaction;\n    this.aborted = false;\n    /**\r\n     * A promise that resolves with the result of the IndexedDb transaction.\r\n     */\n\n    this.completionDeferred = new Deferred();\n\n    this.transaction.oncomplete = function () {\n      _this.completionDeferred.resolve();\n    };\n\n    this.transaction.onabort = function () {\n      if (transaction.error) {\n        _this.completionDeferred.reject(new IndexedDbTransactionError(action, transaction.error));\n      } else {\n        _this.completionDeferred.resolve();\n      }\n    };\n\n    this.transaction.onerror = function (event) {\n      var error = checkForAndReportiOSError(event.target.error);\n\n      _this.completionDeferred.reject(new IndexedDbTransactionError(action, error));\n    };\n  }\n\n  SimpleDbTransaction.open = function (db, action, mode, objectStoreNames) {\n    try {\n      return new SimpleDbTransaction(action, db.transaction(objectStoreNames, mode));\n    } catch (e) {\n      throw new IndexedDbTransactionError(action, e);\n    }\n  };\n\n  Object.defineProperty(SimpleDbTransaction.prototype, \"completionPromise\", {\n    get: function () {\n      return this.completionDeferred.promise;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  SimpleDbTransaction.prototype.abort = function (error) {\n    if (error) {\n      this.completionDeferred.reject(error);\n    }\n\n    if (!this.aborted) {\n      logDebug(LOG_TAG$g, 'Aborting transaction:', error ? error.message : 'Client-initiated abort');\n      this.aborted = true;\n      this.transaction.abort();\n    }\n  };\n  /**\r\n   * Returns a SimpleDbStore<KeyType, ValueType> for the specified store. All\r\n   * operations performed on the SimpleDbStore happen within the context of this\r\n   * transaction and it cannot be used anymore once the transaction is\r\n   * completed.\r\n   *\r\n   * Note that we can't actually enforce that the KeyType and ValueType are\r\n   * correct, but they allow type safety through the rest of the consuming code.\r\n   */\n\n\n  SimpleDbTransaction.prototype.store = function (storeName) {\n    var store = this.transaction.objectStore(storeName);\n    return new SimpleDbStore(store);\n  };\n\n  return SimpleDbTransaction;\n}();\n/**\r\n * Provides a wrapper around IndexedDb with a simplified interface that uses\r\n * Promise-like return values to chain operations. Real promises cannot be used\r\n * since .then() continuations are executed asynchronously (e.g. via\r\n * .setImmediate), which would cause IndexedDB to end the transaction.\r\n * See PersistencePromise for more details.\r\n */\n\n\nvar SimpleDb =\n/** @class */\nfunction () {\n  /*\r\n   * Creates a new SimpleDb wrapper for IndexedDb database `name`.\r\n   *\r\n   * Note that `version` must not be a downgrade. IndexedDB does not support\r\n   * downgrading the schema version. We currently do not support any way to do\r\n   * versioning outside of IndexedDB's versioning mechanism, as only\r\n   * version-upgrade transactions are allowed to do things like create\r\n   * objectstores.\r\n   */\n  function SimpleDb(name, version, schemaConverter) {\n    this.name = name;\n    this.version = version;\n    this.schemaConverter = schemaConverter;\n    var iOSVersion = SimpleDb.getIOSVersion(util.getUA()); // NOTE: According to https://bugs.webkit.org/show_bug.cgi?id=197050, the\n    // bug we're checking for should exist in iOS >= 12.2 and < 13, but for\n    // whatever reason it's much harder to hit after 12.2 so we only proactively\n    // log on 12.2.\n\n    if (iOSVersion === 12.2) {\n      logError('Firestore persistence suffers from a bug in iOS 12.2 ' + 'Safari that may cause your app to stop working. See ' + 'https://stackoverflow.com/q/56496296/110915 for details ' + 'and a potential workaround.');\n    }\n  }\n  /** Deletes the specified database. */\n\n\n  SimpleDb.delete = function (name) {\n    logDebug(LOG_TAG$g, 'Removing database:', name);\n    return wrapRequest(window.indexedDB.deleteDatabase(name)).toPromise();\n  };\n  /** Returns true if IndexedDB is available in the current environment. */\n\n\n  SimpleDb.isAvailable = function () {\n    if (typeof indexedDB === 'undefined') {\n      return false;\n    }\n\n    if (SimpleDb.isMockPersistence()) {\n      return true;\n    } // We extensively use indexed array values and compound keys,\n    // which IE and Edge do not support. However, they still have indexedDB\n    // defined on the window, so we need to check for them here and make sure\n    // to return that persistence is not enabled for those browsers.\n    // For tracking support of this feature, see here:\n    // https://developer.microsoft.com/en-us/microsoft-edge/platform/status/indexeddbarraysandmultientrysupport/\n    // Check the UA string to find out the browser.\n\n\n    var ua = util.getUA(); // IE 10\n    // ua = 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Trident/6.0)';\n    // IE 11\n    // ua = 'Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko';\n    // Edge\n    // ua = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML,\n    // like Gecko) Chrome/39.0.2171.71 Safari/537.36 Edge/12.0';\n    // iOS Safari: Disable for users running iOS version < 10.\n\n    var iOSVersion = SimpleDb.getIOSVersion(ua);\n    var isUnsupportedIOS = 0 < iOSVersion && iOSVersion < 10; // Android browser: Disable for userse running version < 4.5.\n\n    var androidVersion = SimpleDb.getAndroidVersion(ua);\n    var isUnsupportedAndroid = 0 < androidVersion && androidVersion < 4.5;\n\n    if (ua.indexOf('MSIE ') > 0 || ua.indexOf('Trident/') > 0 || ua.indexOf('Edge/') > 0 || isUnsupportedIOS || isUnsupportedAndroid) {\n      return false;\n    } else {\n      return true;\n    }\n  };\n  /**\r\n   * Returns true if the backing IndexedDB store is the Node IndexedDBShim\r\n   * (see https://github.com/axemclion/IndexedDBShim).\r\n   */\n\n\n  SimpleDb.isMockPersistence = function () {\n    var _a;\n\n    return typeof process !== 'undefined' && ((_a = process.env) === null || _a === void 0 ? void 0 : _a.USE_MOCK_PERSISTENCE) === 'YES';\n  };\n  /** Helper to get a typed SimpleDbStore from a transaction. */\n\n\n  SimpleDb.getStore = function (txn, store) {\n    return txn.store(store);\n  }; // visible for testing\n\n  /** Parse User Agent to determine iOS version. Returns -1 if not found. */\n\n\n  SimpleDb.getIOSVersion = function (ua) {\n    var iOSVersionRegex = ua.match(/i(?:phone|pad|pod) os ([\\d_]+)/i);\n    var version = iOSVersionRegex ? iOSVersionRegex[1].split('_').slice(0, 2).join('.') : '-1';\n    return Number(version);\n  }; // visible for testing\n\n  /** Parse User Agent to determine Android version. Returns -1 if not found. */\n\n\n  SimpleDb.getAndroidVersion = function (ua) {\n    var androidVersionRegex = ua.match(/Android ([\\d.]+)/i);\n    var version = androidVersionRegex ? androidVersionRegex[1].split('.').slice(0, 2).join('.') : '-1';\n    return Number(version);\n  };\n  /**\r\n   * Opens the specified database, creating or upgrading it if necessary.\r\n   */\n\n\n  SimpleDb.prototype.ensureDb = function (action) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var _d;\n\n      var _this = this;\n\n      return tslib.__generator(this, function (_e) {\n        switch (_e.label) {\n          case 0:\n            if (!!this.db) return [3\n            /*break*/\n            , 2];\n            logDebug(LOG_TAG$g, 'Opening database:', this.name);\n            _d = this;\n            return [4\n            /*yield*/\n            , new Promise(function (resolve, reject) {\n              // TODO(mikelehen): Investigate browser compatibility.\n              // https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB\n              // suggests IE9 and older WebKit browsers handle upgrade\n              // differently. They expect setVersion, as described here:\n              // https://developer.mozilla.org/en-US/docs/Web/API/IDBVersionChangeRequest/setVersion\n              var request = indexedDB.open(_this.name, _this.version);\n\n              request.onsuccess = function (event) {\n                var db = event.target.result;\n                resolve(db);\n              };\n\n              request.onblocked = function () {\n                reject(new IndexedDbTransactionError(action, 'Cannot upgrade IndexedDB schema while another tab is open. ' + 'Close all tabs that access Firestore and reload this page to proceed.'));\n              };\n\n              request.onerror = function (event) {\n                var error = event.target.error;\n\n                if (error.name === 'VersionError') {\n                  reject(new FirestoreError(Code.FAILED_PRECONDITION, 'A newer version of the Firestore SDK was previously used and so the persisted ' + 'data is not compatible with the version of the SDK you are now using. The SDK ' + 'will operate with persistence disabled. If you need persistence, please ' + 're-upgrade to a newer version of the SDK or else clear the persisted IndexedDB ' + 'data for your app to start fresh.'));\n                } else {\n                  reject(new IndexedDbTransactionError(action, error));\n                }\n              };\n\n              request.onupgradeneeded = function (event) {\n                logDebug(LOG_TAG$g, 'Database \"' + _this.name + '\" requires upgrade from version:', event.oldVersion);\n                var db = event.target.result;\n\n                _this.schemaConverter.createOrUpgrade(db, request.transaction, event.oldVersion, _this.version).next(function () {\n                  logDebug(LOG_TAG$g, 'Database upgrade to version ' + _this.version + ' complete');\n                });\n              };\n            })];\n\n          case 1:\n            _d.db = _e.sent();\n            _e.label = 2;\n\n          case 2:\n            if (this.versionchangelistener) {\n              this.db.onversionchange = function (event) {\n                return _this.versionchangelistener(event);\n              };\n            }\n\n            return [2\n            /*return*/\n            , this.db];\n        }\n      });\n    });\n  };\n\n  SimpleDb.prototype.setVersionChangeListener = function (versionChangeListener) {\n    this.versionchangelistener = versionChangeListener;\n\n    if (this.db) {\n      this.db.onversionchange = function (event) {\n        return versionChangeListener(event);\n      };\n    }\n  };\n\n  SimpleDb.prototype.runTransaction = function (action, mode, objectStores, transactionFn) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var readonly, attemptNumber, _loop_2, this_1, state_1;\n\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            readonly = mode === 'readonly';\n            attemptNumber = 0;\n\n            _loop_2 = function () {\n              var transaction_1, transactionFnResult, error_1, retryable;\n              return tslib.__generator(this, function (_e) {\n                switch (_e.label) {\n                  case 0:\n                    ++attemptNumber;\n                    _e.label = 1;\n\n                  case 1:\n                    _e.trys.push([1, 4,, 5]);\n\n                    return [4\n                    /*yield*/\n                    , this_1.ensureDb(action)];\n\n                  case 2:\n                    this_1.db = _e.sent();\n                    transaction_1 = SimpleDbTransaction.open(this_1.db, action, readonly ? 'readonly' : 'readwrite', objectStores);\n                    transactionFnResult = transactionFn(transaction_1).catch(function (error) {\n                      // Abort the transaction if there was an error.\n                      transaction_1.abort(error); // We cannot actually recover, and calling `abort()` will cause the transaction's\n                      // completion promise to be rejected. This in turn means that we won't use\n                      // `transactionFnResult` below. We return a rejection here so that we don't add the\n                      // possibility of returning `void` to the type of `transactionFnResult`.\n\n                      return PersistencePromise.reject(error);\n                    }).toPromise(); // As noted above, errors are propagated by aborting the transaction. So\n                    // we swallow any error here to avoid the browser logging it as unhandled.\n\n                    transactionFnResult.catch(function () {}); // Wait for the transaction to complete (i.e. IndexedDb's onsuccess event to\n                    // fire), but still return the original transactionFnResult back to the\n                    // caller.\n\n                    return [4\n                    /*yield*/\n                    , transaction_1.completionPromise];\n\n                  case 3:\n                    // Wait for the transaction to complete (i.e. IndexedDb's onsuccess event to\n                    // fire), but still return the original transactionFnResult back to the\n                    // caller.\n                    _e.sent();\n\n                    return [2\n                    /*return*/\n                    , {\n                      value: transactionFnResult\n                    }];\n\n                  case 4:\n                    error_1 = _e.sent();\n                    retryable = error_1.name !== 'FirebaseError' && attemptNumber < TRANSACTION_RETRY_COUNT;\n                    logDebug(LOG_TAG$g, 'Transaction failed with error:', error_1.message, 'Retrying:', retryable);\n                    this_1.close();\n\n                    if (!retryable) {\n                      return [2\n                      /*return*/\n                      , {\n                        value: Promise.reject(error_1)\n                      }];\n                    }\n\n                    return [3\n                    /*break*/\n                    , 5];\n\n                  case 5:\n                    return [2\n                    /*return*/\n                    ];\n                }\n              });\n            };\n\n            this_1 = this;\n            _d.label = 1;\n\n          case 1:\n            return [5\n            /*yield**/\n            , _loop_2()];\n\n          case 2:\n            state_1 = _d.sent();\n            if (typeof state_1 === \"object\") return [2\n            /*return*/\n            , state_1.value];\n            return [3\n            /*break*/\n            , 1];\n\n          case 3:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  SimpleDb.prototype.close = function () {\n    if (this.db) {\n      this.db.close();\n    }\n\n    this.db = undefined;\n  };\n\n  return SimpleDb;\n}();\n/**\r\n * A controller for iterating over a key range or index. It allows an iterate\r\n * callback to delete the currently-referenced object, or jump to a new key\r\n * within the key range or index.\r\n */\n\n\nvar IterationController =\n/** @class */\nfunction () {\n  function IterationController(dbCursor) {\n    this.dbCursor = dbCursor;\n    this.shouldStop = false;\n    this.nextKey = null;\n  }\n\n  Object.defineProperty(IterationController.prototype, \"isDone\", {\n    get: function () {\n      return this.shouldStop;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(IterationController.prototype, \"skipToKey\", {\n    get: function () {\n      return this.nextKey;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(IterationController.prototype, \"cursor\", {\n    set: function (value) {\n      this.dbCursor = value;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * This function can be called to stop iteration at any point.\r\n   */\n\n  IterationController.prototype.done = function () {\n    this.shouldStop = true;\n  };\n  /**\r\n   * This function can be called to skip to that next key, which could be\r\n   * an index or a primary key.\r\n   */\n\n\n  IterationController.prototype.skip = function (key) {\n    this.nextKey = key;\n  };\n  /**\r\n   * Delete the current cursor value from the object store.\r\n   *\r\n   * NOTE: You CANNOT do this with a keysOnly query.\r\n   */\n\n\n  IterationController.prototype.delete = function () {\n    return wrapRequest(this.dbCursor.delete());\n  };\n\n  return IterationController;\n}();\n/** An error that wraps exceptions that thrown during IndexedDB execution. */\n\n\nvar IndexedDbTransactionError =\n/** @class */\nfunction (_super) {\n  tslib.__extends(IndexedDbTransactionError, _super);\n\n  function IndexedDbTransactionError(actionName, cause) {\n    var _this = _super.call(this, Code.UNAVAILABLE, \"IndexedDB transaction '\" + actionName + \"' failed: \" + cause) || this;\n\n    _this.name = 'IndexedDbTransactionError';\n    return _this;\n  }\n\n  return IndexedDbTransactionError;\n}(FirestoreError);\n/** Verifies whether `e` is an IndexedDbTransactionError. */\n\n\nfunction isIndexedDbTransactionError(e) {\n  // Use name equality, as instanceof checks on errors don't work with errors\n  // that wrap other errors.\n  return e.name === 'IndexedDbTransactionError';\n}\n/**\r\n * A wrapper around an IDBObjectStore providing an API that:\r\n *\r\n * 1) Has generic KeyType / ValueType parameters to provide strongly-typed\r\n * methods for acting against the object store.\r\n * 2) Deals with IndexedDB's onsuccess / onerror event callbacks, making every\r\n * method return a PersistencePromise instead.\r\n * 3) Provides a higher-level API to avoid needing to do excessive wrapping of\r\n * intermediate IndexedDB types (IDBCursorWithValue, etc.)\r\n */\n\n\nvar SimpleDbStore =\n/** @class */\nfunction () {\n  function SimpleDbStore(store) {\n    this.store = store;\n  }\n\n  SimpleDbStore.prototype.put = function (keyOrValue, value) {\n    var request;\n\n    if (value !== undefined) {\n      logDebug(LOG_TAG$g, 'PUT', this.store.name, keyOrValue, value);\n      request = this.store.put(value, keyOrValue);\n    } else {\n      logDebug(LOG_TAG$g, 'PUT', this.store.name, '<auto-key>', keyOrValue);\n      request = this.store.put(keyOrValue);\n    }\n\n    return wrapRequest(request);\n  };\n  /**\r\n   * Adds a new value into an Object Store and returns the new key. Similar to\r\n   * IndexedDb's `add()`, this method will fail on primary key collisions.\r\n   *\r\n   * @param value - The object to write.\r\n   * @returns The key of the value to add.\r\n   */\n\n\n  SimpleDbStore.prototype.add = function (value) {\n    logDebug(LOG_TAG$g, 'ADD', this.store.name, value, value);\n    var request = this.store.add(value);\n    return wrapRequest(request);\n  };\n  /**\r\n   * Gets the object with the specified key from the specified store, or null\r\n   * if no object exists with the specified key.\r\n   *\r\n   * @key The key of the object to get.\r\n   * @returns The object with the specified key or null if no object exists.\r\n   */\n\n\n  SimpleDbStore.prototype.get = function (key) {\n    var _this = this;\n\n    var request = this.store.get(key); // We're doing an unsafe cast to ValueType.\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n    return wrapRequest(request).next(function (result) {\n      // Normalize nonexistence to null.\n      if (result === undefined) {\n        result = null;\n      }\n\n      logDebug(LOG_TAG$g, 'GET', _this.store.name, key, result);\n      return result;\n    });\n  };\n\n  SimpleDbStore.prototype.delete = function (key) {\n    logDebug(LOG_TAG$g, 'DELETE', this.store.name, key);\n    var request = this.store.delete(key);\n    return wrapRequest(request);\n  };\n  /**\r\n   * If we ever need more of the count variants, we can add overloads. For now,\r\n   * all we need is to count everything in a store.\r\n   *\r\n   * Returns the number of rows in the store.\r\n   */\n\n\n  SimpleDbStore.prototype.count = function () {\n    logDebug(LOG_TAG$g, 'COUNT', this.store.name);\n    var request = this.store.count();\n    return wrapRequest(request);\n  };\n\n  SimpleDbStore.prototype.loadAll = function (indexOrRange, range) {\n    var cursor = this.cursor(this.options(indexOrRange, range));\n    var results = [];\n    return this.iterateCursor(cursor, function (key, value) {\n      results.push(value);\n    }).next(function () {\n      return results;\n    });\n  };\n\n  SimpleDbStore.prototype.deleteAll = function (indexOrRange, range) {\n    logDebug(LOG_TAG$g, 'DELETE ALL', this.store.name);\n    var options = this.options(indexOrRange, range);\n    options.keysOnly = false;\n    var cursor = this.cursor(options);\n    return this.iterateCursor(cursor, function (key, value, control) {\n      // NOTE: Calling delete() on a cursor is documented as more efficient than\n      // calling delete() on an object store with a single key\n      // (https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/delete),\n      // however, this requires us *not* to use a keysOnly cursor\n      // (https://developer.mozilla.org/en-US/docs/Web/API/IDBCursor/delete). We\n      // may want to compare the performance of each method.\n      return control.delete();\n    });\n  };\n\n  SimpleDbStore.prototype.iterate = function (optionsOrCallback, callback) {\n    var options;\n\n    if (!callback) {\n      options = {};\n      callback = optionsOrCallback;\n    } else {\n      options = optionsOrCallback;\n    }\n\n    var cursor = this.cursor(options);\n    return this.iterateCursor(cursor, callback);\n  };\n  /**\r\n   * Iterates over a store, but waits for the given callback to complete for\r\n   * each entry before iterating the next entry. This allows the callback to do\r\n   * asynchronous work to determine if this iteration should continue.\r\n   *\r\n   * The provided callback should return `true` to continue iteration, and\r\n   * `false` otherwise.\r\n   */\n\n\n  SimpleDbStore.prototype.iterateSerial = function (callback) {\n    var cursorRequest = this.cursor({});\n    return new PersistencePromise(function (resolve, reject) {\n      cursorRequest.onerror = function (event) {\n        var error = checkForAndReportiOSError(event.target.error);\n        reject(error);\n      };\n\n      cursorRequest.onsuccess = function (event) {\n        var cursor = event.target.result;\n\n        if (!cursor) {\n          resolve();\n          return;\n        }\n\n        callback(cursor.primaryKey, cursor.value).next(function (shouldContinue) {\n          if (shouldContinue) {\n            cursor.continue();\n          } else {\n            resolve();\n          }\n        });\n      };\n    });\n  };\n\n  SimpleDbStore.prototype.iterateCursor = function (cursorRequest, fn) {\n    var results = [];\n    return new PersistencePromise(function (resolve, reject) {\n      cursorRequest.onerror = function (event) {\n        reject(event.target.error);\n      };\n\n      cursorRequest.onsuccess = function (event) {\n        var cursor = event.target.result;\n\n        if (!cursor) {\n          resolve();\n          return;\n        }\n\n        var controller = new IterationController(cursor);\n        var userResult = fn(cursor.primaryKey, cursor.value, controller);\n\n        if (userResult instanceof PersistencePromise) {\n          var userPromise = userResult.catch(function (err) {\n            controller.done();\n            return PersistencePromise.reject(err);\n          });\n          results.push(userPromise);\n        }\n\n        if (controller.isDone) {\n          resolve();\n        } else if (controller.skipToKey === null) {\n          cursor.continue();\n        } else {\n          cursor.continue(controller.skipToKey);\n        }\n      };\n    }).next(function () {\n      return PersistencePromise.waitFor(results);\n    });\n  };\n\n  SimpleDbStore.prototype.options = function (indexOrRange, range) {\n    var indexName = undefined;\n\n    if (indexOrRange !== undefined) {\n      if (typeof indexOrRange === 'string') {\n        indexName = indexOrRange;\n      } else {\n        range = indexOrRange;\n      }\n    }\n\n    return {\n      index: indexName,\n      range: range\n    };\n  };\n\n  SimpleDbStore.prototype.cursor = function (options) {\n    var direction = 'next';\n\n    if (options.reverse) {\n      direction = 'prev';\n    }\n\n    if (options.index) {\n      var index = this.store.index(options.index);\n\n      if (options.keysOnly) {\n        return index.openKeyCursor(options.range, direction);\n      } else {\n        return index.openCursor(options.range, direction);\n      }\n    } else {\n      return this.store.openCursor(options.range, direction);\n    }\n  };\n\n  return SimpleDbStore;\n}();\n/**\r\n * Wraps an IDBRequest in a PersistencePromise, using the onsuccess / onerror\r\n * handlers to resolve / reject the PersistencePromise as appropriate.\r\n */\n\n\nfunction wrapRequest(request) {\n  return new PersistencePromise(function (resolve, reject) {\n    request.onsuccess = function (event) {\n      var result = event.target.result;\n      resolve(result);\n    };\n\n    request.onerror = function (event) {\n      var error = checkForAndReportiOSError(event.target.error);\n      reject(error);\n    };\n  });\n} // Guard so we only report the error once.\n\n\nvar reportedIOSError = false;\n\nfunction checkForAndReportiOSError(error) {\n  var iOSVersion = SimpleDb.getIOSVersion(util.getUA());\n\n  if (iOSVersion >= 12.2 && iOSVersion < 13) {\n    var IOS_ERROR = 'An internal error was encountered in the Indexed Database server';\n\n    if (error.message.indexOf(IOS_ERROR) >= 0) {\n      // Wrap error in a more descriptive one.\n      var newError_1 = new FirestoreError('internal', \"IOS_INDEXEDDB_BUG1: IndexedDb has thrown '\" + IOS_ERROR + \"'. This is likely \" + \"due to an unavoidable bug in iOS. See https://stackoverflow.com/q/56496296/110915 \" + \"for details and a potential workaround.\");\n\n      if (!reportedIOSError) {\n        reportedIOSError = true; // Throw a global exception outside of this promise chain, for the user to\n        // potentially catch.\n\n        setTimeout(function () {\n          throw newError_1;\n        }, 0);\n      }\n\n      return newError_1;\n    }\n  }\n\n  return error;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar IndexedDbTransaction =\n/** @class */\nfunction (_super) {\n  tslib.__extends(IndexedDbTransaction, _super);\n\n  function IndexedDbTransaction(simpleDbTransaction, currentSequenceNumber) {\n    var _this = _super.call(this) || this;\n\n    _this.simpleDbTransaction = simpleDbTransaction;\n    _this.currentSequenceNumber = currentSequenceNumber;\n    return _this;\n  }\n\n  return IndexedDbTransaction;\n}(PersistenceTransaction);\n\nfunction getStore(txn, store) {\n  var indexedDbTransaction = debugCast(txn);\n  return SimpleDb.getStore(indexedDbTransaction.simpleDbTransaction, store);\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Generates `nBytes` of random bytes.\r\n *\r\n * If `nBytes < 0` , an error will be thrown.\r\n */\n\n\nfunction randomBytes(nBytes) {\n  return crypto.randomBytes(nBytes);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar AutoId =\n/** @class */\nfunction () {\n  function AutoId() {}\n\n  AutoId.newId = function () {\n    // Alphanumeric characters\n    var chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789'; // The largest byte value that is a multiple of `char.length`.\n\n    var maxMultiple = Math.floor(256 / chars.length) * chars.length;\n    var autoId = '';\n    var targetLength = 20;\n\n    while (autoId.length < targetLength) {\n      var bytes = randomBytes(40);\n\n      for (var i = 0; i < bytes.length; ++i) {\n        // Only accept values that are [0, maxMultiple), this ensures they can\n        // be evenly mapped to indices of `chars` via a modulo operation.\n        if (autoId.length < targetLength && bytes[i] < maxMultiple) {\n          autoId += chars.charAt(bytes[i] % chars.length);\n        }\n      }\n    }\n\n    return autoId;\n  };\n\n  return AutoId;\n}();\n\nfunction primitiveComparator(left, right) {\n  if (left < right) {\n    return -1;\n  }\n\n  if (left > right) {\n    return 1;\n  }\n\n  return 0;\n}\n/** Helper to compare arrays using isEqual(). */\n\n\nfunction arrayEquals(left, right, comparator) {\n  if (left.length !== right.length) {\n    return false;\n  }\n\n  return left.every(function (value, index) {\n    return comparator(value, right[index]);\n  });\n}\n/**\r\n * Returns the immediate lexicographically-following string. This is useful to\r\n * construct an inclusive range for indexeddb iterators.\r\n */\n\n\nfunction immediateSuccessor(s) {\n  // Return the input string, with an additional NUL byte appended.\n  return s + '\\0';\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// The earliest date supported by Firestore timestamps (0001-01-01T00:00:00Z).\n\n\nvar MIN_SECONDS = -62135596800; // Number of nanoseconds in a millisecond.\n\nvar MS_TO_NANOS = 1e6;\n/**\r\n * A `Timestamp` represents a point in time independent of any time zone or\r\n * calendar, represented as seconds and fractions of seconds at nanosecond\r\n * resolution in UTC Epoch time.\r\n *\r\n * It is encoded using the Proleptic Gregorian Calendar which extends the\r\n * Gregorian calendar backwards to year one. It is encoded assuming all minutes\r\n * are 60 seconds long, i.e. leap seconds are \"smeared\" so that no leap second\r\n * table is needed for interpretation. Range is from 0001-01-01T00:00:00Z to\r\n * 9999-12-31T23:59:59.999999999Z.\r\n *\r\n * For examples and further specifications, refer to the\r\n * {@link https://github.com/google/protobuf/blob/master/src/google/protobuf/timestamp.proto | Timestamp definition}.\r\n */\n\nvar Timestamp =\n/** @class */\nfunction () {\n  /**\r\n   * Creates a new timestamp.\r\n   *\r\n   * @param seconds - The number of seconds of UTC time since Unix epoch\r\n   *     1970-01-01T00:00:00Z. Must be from 0001-01-01T00:00:00Z to\r\n   *     9999-12-31T23:59:59Z inclusive.\r\n   * @param nanoseconds - The non-negative fractions of a second at nanosecond\r\n   *     resolution. Negative second values with fractions must still have\r\n   *     non-negative nanoseconds values that count forward in time. Must be\r\n   *     from 0 to 999,999,999 inclusive.\r\n   */\n  function Timestamp(\n  /**\r\n   * The number of seconds of UTC time since Unix epoch 1970-01-01T00:00:00Z.\r\n   */\n  seconds,\n  /**\r\n   * The fractions of a second at nanosecond resolution.*\r\n   */\n  nanoseconds) {\n    this.seconds = seconds;\n    this.nanoseconds = nanoseconds;\n\n    if (nanoseconds < 0) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp nanoseconds out of range: ' + nanoseconds);\n    }\n\n    if (nanoseconds >= 1e9) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp nanoseconds out of range: ' + nanoseconds);\n    }\n\n    if (seconds < MIN_SECONDS) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp seconds out of range: ' + seconds);\n    } // This will break in the year 10,000.\n\n\n    if (seconds >= 253402300800) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Timestamp seconds out of range: ' + seconds);\n    }\n  }\n  /**\r\n   * Creates a new timestamp with the current date, with millisecond precision.\r\n   *\r\n   * @returns a new timestamp representing the current date.\r\n   */\n\n\n  Timestamp.now = function () {\n    return Timestamp.fromMillis(Date.now());\n  };\n  /**\r\n   * Creates a new timestamp from the given date.\r\n   *\r\n   * @param date - The date to initialize the `Timestamp` from.\r\n   * @returns A new `Timestamp` representing the same point in time as the given\r\n   *     date.\r\n   */\n\n\n  Timestamp.fromDate = function (date) {\n    return Timestamp.fromMillis(date.getTime());\n  };\n  /**\r\n   * Creates a new timestamp from the given number of milliseconds.\r\n   *\r\n   * @param milliseconds - Number of milliseconds since Unix epoch\r\n   *     1970-01-01T00:00:00Z.\r\n   * @returns A new `Timestamp` representing the same point in time as the given\r\n   *     number of milliseconds.\r\n   */\n\n\n  Timestamp.fromMillis = function (milliseconds) {\n    var seconds = Math.floor(milliseconds / 1000);\n    var nanos = Math.floor((milliseconds - seconds * 1000) * MS_TO_NANOS);\n    return new Timestamp(seconds, nanos);\n  };\n  /**\r\n   * Converts a `Timestamp` to a JavaScript `Date` object. This conversion\r\n   * causes a loss of precision since `Date` objects only support millisecond\r\n   * precision.\r\n   *\r\n   * @returns JavaScript `Date` object representing the same point in time as\r\n   *     this `Timestamp`, with millisecond precision.\r\n   */\n\n\n  Timestamp.prototype.toDate = function () {\n    return new Date(this.toMillis());\n  };\n  /**\r\n   * Converts a `Timestamp` to a numeric timestamp (in milliseconds since\r\n   * epoch). This operation causes a loss of precision.\r\n   *\r\n   * @returns The point in time corresponding to this timestamp, represented as\r\n   *     the number of milliseconds since Unix epoch 1970-01-01T00:00:00Z.\r\n   */\n\n\n  Timestamp.prototype.toMillis = function () {\n    return this.seconds * 1000 + this.nanoseconds / MS_TO_NANOS;\n  };\n\n  Timestamp.prototype._compareTo = function (other) {\n    if (this.seconds === other.seconds) {\n      return primitiveComparator(this.nanoseconds, other.nanoseconds);\n    }\n\n    return primitiveComparator(this.seconds, other.seconds);\n  };\n  /**\r\n   * Returns true if this `Timestamp` is equal to the provided one.\r\n   *\r\n   * @param other - The `Timestamp` to compare against.\r\n   * @returns true if this `Timestamp` is equal to the provided one.\r\n   */\n\n\n  Timestamp.prototype.isEqual = function (other) {\n    return other.seconds === this.seconds && other.nanoseconds === this.nanoseconds;\n  };\n  /** Returns a textual representation of this Timestamp. */\n\n\n  Timestamp.prototype.toString = function () {\n    return 'Timestamp(seconds=' + this.seconds + ', nanoseconds=' + this.nanoseconds + ')';\n  };\n  /** Returns a JSON-serializable representation of this Timestamp. */\n\n\n  Timestamp.prototype.toJSON = function () {\n    return {\n      seconds: this.seconds,\n      nanoseconds: this.nanoseconds\n    };\n  };\n  /**\r\n   * Converts this object to a primitive string, which allows Timestamp objects\r\n   * to be compared using the `>`, `<=`, `>=` and `>` operators.\r\n   */\n\n\n  Timestamp.prototype.valueOf = function () {\n    // This method returns a string of the form <seconds>.<nanoseconds> where\n    // <seconds> is translated to have a non-negative value and both <seconds>\n    // and <nanoseconds> are left-padded with zeroes to be a consistent length.\n    // Strings with this format then have a lexiographical ordering that matches\n    // the expected ordering. The <seconds> translation is done to avoid having\n    // a leading negative sign (i.e. a leading '-' character) in its string\n    // representation, which would affect its lexiographical ordering.\n    var adjustedSeconds = this.seconds - MIN_SECONDS; // Note: Up to 12 decimal digits are required to represent all valid\n    // 'seconds' values.\n\n    var formattedSeconds = String(adjustedSeconds).padStart(12, '0');\n    var formattedNanoseconds = String(this.nanoseconds).padStart(9, '0');\n    return formattedSeconds + '.' + formattedNanoseconds;\n  };\n\n  return Timestamp;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A version of a document in Firestore. This corresponds to the version\r\n * timestamp, such as update_time or read_time.\r\n */\n\n\nvar SnapshotVersion =\n/** @class */\nfunction () {\n  function SnapshotVersion(timestamp) {\n    this.timestamp = timestamp;\n  }\n\n  SnapshotVersion.fromTimestamp = function (value) {\n    return new SnapshotVersion(value);\n  };\n\n  SnapshotVersion.min = function () {\n    return new SnapshotVersion(new Timestamp(0, 0));\n  };\n\n  SnapshotVersion.prototype.compareTo = function (other) {\n    return this.timestamp._compareTo(other.timestamp);\n  };\n\n  SnapshotVersion.prototype.isEqual = function (other) {\n    return this.timestamp.isEqual(other.timestamp);\n  };\n  /** Returns a number representation of the version for use in spec tests. */\n\n\n  SnapshotVersion.prototype.toMicroseconds = function () {\n    // Convert to microseconds.\n    return this.timestamp.seconds * 1e6 + this.timestamp.nanoseconds / 1000;\n  };\n\n  SnapshotVersion.prototype.toString = function () {\n    return 'SnapshotVersion(' + this.timestamp.toString() + ')';\n  };\n\n  SnapshotVersion.prototype.toTimestamp = function () {\n    return this.timestamp;\n  };\n\n  return SnapshotVersion;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction objectSize(obj) {\n  var count = 0;\n\n  for (var key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      count++;\n    }\n  }\n\n  return count;\n}\n\nfunction forEach(obj, fn) {\n  for (var key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      fn(key, obj[key]);\n    }\n  }\n}\n\nfunction isEmpty(obj) {\n  for (var key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      return false;\n    }\n  }\n\n  return true;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Provides a set of fields that can be used to partially patch a document.\r\n * FieldMask is used in conjunction with ObjectValue.\r\n * Examples:\r\n *   foo - Overwrites foo entirely with the provided value. If foo is not\r\n *         present in the companion ObjectValue, the field is deleted.\r\n *   foo.bar - Overwrites only the field bar of the object foo.\r\n *             If foo is not an object, foo is replaced with an object\r\n *             containing foo\r\n */\n\n\nvar FieldMask =\n/** @class */\nfunction () {\n  function FieldMask(fields) {\n    this.fields = fields; // TODO(dimond): validation of FieldMask\n    // Sort the field mask to support `FieldMask.isEqual()` and assert below.\n\n    fields.sort(FieldPath$1.comparator);\n  }\n  /**\r\n   * Verifies that `fieldPath` is included by at least one field in this field\r\n   * mask.\r\n   *\r\n   * This is an O(n) operation, where `n` is the size of the field mask.\r\n   */\n\n\n  FieldMask.prototype.covers = function (fieldPath) {\n    for (var _i = 0, _d = this.fields; _i < _d.length; _i++) {\n      var fieldMaskPath = _d[_i];\n\n      if (fieldMaskPath.isPrefixOf(fieldPath)) {\n        return true;\n      }\n    }\n\n    return false;\n  };\n\n  FieldMask.prototype.isEqual = function (other) {\n    return arrayEquals(this.fields, other.fields, function (l, r) {\n      return l.isEqual(r);\n    });\n  };\n\n  return FieldMask;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction decodeBase64(encoded) {\n  // Node actually doesn't validate base64 strings.\n  // A quick sanity check that is not a fool-proof validation\n  if (/[^-A-Za-z0-9+/=]/.test(encoded)) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Not a valid Base64 string: ' + encoded);\n  }\n\n  return new Buffer(encoded, 'base64').toString('binary');\n}\n/** Converts a binary string to a Base64 encoded string. */\n\n\nfunction encodeBase64(raw) {\n  return new Buffer(raw, 'binary').toString('base64');\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Immutable class that represents a \"proto\" byte string.\r\n *\r\n * Proto byte strings can either be Base64-encoded strings or Uint8Arrays when\r\n * sent on the wire. This class abstracts away this differentiation by holding\r\n * the proto byte string in a common class that must be converted into a string\r\n * before being sent as a proto.\r\n */\n\n\nvar ByteString =\n/** @class */\nfunction () {\n  function ByteString(binaryString) {\n    this.binaryString = binaryString;\n  }\n\n  ByteString.fromBase64String = function (base64) {\n    var binaryString = decodeBase64(base64);\n    return new ByteString(binaryString);\n  };\n\n  ByteString.fromUint8Array = function (array) {\n    var binaryString = binaryStringFromUint8Array(array);\n    return new ByteString(binaryString);\n  };\n\n  ByteString.prototype.toBase64 = function () {\n    return encodeBase64(this.binaryString);\n  };\n\n  ByteString.prototype.toUint8Array = function () {\n    return uint8ArrayFromBinaryString(this.binaryString);\n  };\n\n  ByteString.prototype.approximateByteSize = function () {\n    return this.binaryString.length * 2;\n  };\n\n  ByteString.prototype.compareTo = function (other) {\n    return primitiveComparator(this.binaryString, other.binaryString);\n  };\n\n  ByteString.prototype.isEqual = function (other) {\n    return this.binaryString === other.binaryString;\n  };\n\n  return ByteString;\n}();\n\nByteString.EMPTY_BYTE_STRING = new ByteString('');\n/**\r\n * Helper function to convert an Uint8array to a binary string.\r\n */\n\nfunction binaryStringFromUint8Array(array) {\n  var binaryString = '';\n\n  for (var i = 0; i < array.length; ++i) {\n    binaryString += String.fromCharCode(array[i]);\n  }\n\n  return binaryString;\n}\n/**\r\n * Helper function to convert a binary string to an Uint8Array.\r\n */\n\n\nfunction uint8ArrayFromBinaryString(binaryString) {\n  var buffer = new Uint8Array(binaryString.length);\n\n  for (var i = 0; i < binaryString.length; i++) {\n    buffer[i] = binaryString.charCodeAt(i);\n  }\n\n  return buffer;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// A RegExp matching ISO 8601 UTC timestamps with optional fraction.\n\n\nvar ISO_TIMESTAMP_REG_EXP = new RegExp(/^\\d{4}-\\d\\d-\\d\\dT\\d\\d:\\d\\d:\\d\\d(?:\\.(\\d+))?Z$/);\n/**\r\n * Converts the possible Proto values for a timestamp value into a \"seconds and\r\n * nanos\" representation.\r\n */\n\nfunction normalizeTimestamp(date) {\n  hardAssert(!!date); // The json interface (for the browser) will return an iso timestamp string,\n  // while the proto js library (for node) will return a\n  // google.protobuf.Timestamp instance.\n\n  if (typeof date === 'string') {\n    // The date string can have higher precision (nanos) than the Date class\n    // (millis), so we do some custom parsing here.\n    // Parse the nanos right out of the string.\n    var nanos = 0;\n    var fraction = ISO_TIMESTAMP_REG_EXP.exec(date);\n    hardAssert(!!fraction);\n\n    if (fraction[1]) {\n      // Pad the fraction out to 9 digits (nanos).\n      var nanoStr = fraction[1];\n      nanoStr = (nanoStr + '000000000').substr(0, 9);\n      nanos = Number(nanoStr);\n    } // Parse the date to get the seconds.\n\n\n    var parsedDate = new Date(date);\n    var seconds = Math.floor(parsedDate.getTime() / 1000);\n    return {\n      seconds: seconds,\n      nanos: nanos\n    };\n  } else {\n    // TODO(b/37282237): Use strings for Proto3 timestamps\n    // assert(!this.options.useProto3Json,\n    //   'The timestamp instance format requires Proto JS.');\n    var seconds = normalizeNumber(date.seconds);\n    var nanos = normalizeNumber(date.nanos);\n    return {\n      seconds: seconds,\n      nanos: nanos\n    };\n  }\n}\n/**\r\n * Converts the possible Proto types for numbers into a JavaScript number.\r\n * Returns 0 if the value is not numeric.\r\n */\n\n\nfunction normalizeNumber(value) {\n  // TODO(bjornick): Handle int64 greater than 53 bits.\n  if (typeof value === 'number') {\n    return value;\n  } else if (typeof value === 'string') {\n    return Number(value);\n  } else {\n    return 0;\n  }\n}\n/** Converts the possible Proto types for Blobs into a ByteString. */\n\n\nfunction normalizeByteString(blob) {\n  if (typeof blob === 'string') {\n    return ByteString.fromBase64String(blob);\n  } else {\n    return ByteString.fromUint8Array(blob);\n  }\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Represents a locally-applied ServerTimestamp.\r\n *\r\n * Server Timestamps are backed by MapValues that contain an internal field\r\n * `__type__` with a value of `server_timestamp`. The previous value and local\r\n * write time are stored in its `__previous_value__` and `__local_write_time__`\r\n * fields respectively.\r\n *\r\n * Notes:\r\n * - ServerTimestampValue instances are created as the result of applying a\r\n *   transform. They can only exist in the local view of a document. Therefore\r\n *   they do not need to be parsed or serialized.\r\n * - When evaluated locally (e.g. for snapshot.data()), they by default\r\n *   evaluate to `null`. This behavior can be configured by passing custom\r\n *   FieldValueOptions to value().\r\n * - With respect to other ServerTimestampValues, they sort by their\r\n *   localWriteTime.\r\n */\n\n\nvar SERVER_TIMESTAMP_SENTINEL = 'server_timestamp';\nvar TYPE_KEY = '__type__';\nvar PREVIOUS_VALUE_KEY = '__previous_value__';\nvar LOCAL_WRITE_TIME_KEY = '__local_write_time__';\n\nfunction isServerTimestamp(value) {\n  var _a, _b;\n\n  var type = (_b = (((_a = value === null || value === void 0 ? void 0 : value.mapValue) === null || _a === void 0 ? void 0 : _a.fields) || {})[TYPE_KEY]) === null || _b === void 0 ? void 0 : _b.stringValue;\n  return type === SERVER_TIMESTAMP_SENTINEL;\n}\n/**\r\n * Creates a new ServerTimestamp proto value (using the internal format).\r\n */\n\n\nfunction serverTimestamp(localWriteTime, previousValue) {\n  var _d;\n\n  var mapValue = {\n    fields: (_d = {}, _d[TYPE_KEY] = {\n      stringValue: SERVER_TIMESTAMP_SENTINEL\n    }, _d[LOCAL_WRITE_TIME_KEY] = {\n      timestampValue: {\n        seconds: localWriteTime.seconds,\n        nanos: localWriteTime.nanoseconds\n      }\n    }, _d)\n  };\n\n  if (previousValue) {\n    mapValue.fields[PREVIOUS_VALUE_KEY] = previousValue;\n  }\n\n  return {\n    mapValue: mapValue\n  };\n}\n/**\r\n * Returns the value of the field before this ServerTimestamp was set.\r\n *\r\n * Preserving the previous values allows the user to display the last resoled\r\n * value until the backend responds with the timestamp.\r\n */\n\n\nfunction getPreviousValue(value) {\n  var previousValue = value.mapValue.fields[PREVIOUS_VALUE_KEY];\n\n  if (isServerTimestamp(previousValue)) {\n    return getPreviousValue(previousValue);\n  }\n\n  return previousValue;\n}\n/**\r\n * Returns the local time at which this timestamp was first set.\r\n */\n\n\nfunction getLocalWriteTime(value) {\n  var localWriteTime = normalizeTimestamp(value.mapValue.fields[LOCAL_WRITE_TIME_KEY].timestampValue);\n  return new Timestamp(localWriteTime.seconds, localWriteTime.nanos);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Sentinel value that sorts before any Mutation Batch ID. */\n\n\nvar BATCHID_UNKNOWN = -1;\n/**\r\n * Returns whether a variable is either undefined or null.\r\n */\n\nfunction isNullOrUndefined(value) {\n  return value === null || value === undefined;\n}\n/** Returns whether the value represents -0. */\n\n\nfunction isNegativeZero(value) {\n  // Detect if the value is -0.0. Based on polyfill from\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\n  return value === 0 && 1 / value === 1 / -0;\n}\n/**\r\n * Returns whether a value is an integer and in the safe integer range\r\n * @param value - The value to test for being an integer and in the safe range\r\n */\n\n\nfunction isSafeInteger(value) {\n  return typeof value === 'number' && Number.isInteger(value) && !isNegativeZero(value) && value <= Number.MAX_SAFE_INTEGER && value >= Number.MIN_SAFE_INTEGER;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar DocumentKey =\n/** @class */\nfunction () {\n  function DocumentKey(path) {\n    this.path = path;\n  }\n\n  DocumentKey.fromPath = function (path) {\n    return new DocumentKey(ResourcePath.fromString(path));\n  };\n\n  DocumentKey.fromName = function (name) {\n    return new DocumentKey(ResourcePath.fromString(name).popFirst(5));\n  };\n  /** Returns true if the document is in the specified collectionId. */\n\n\n  DocumentKey.prototype.hasCollectionId = function (collectionId) {\n    return this.path.length >= 2 && this.path.get(this.path.length - 2) === collectionId;\n  };\n\n  DocumentKey.prototype.isEqual = function (other) {\n    return other !== null && ResourcePath.comparator(this.path, other.path) === 0;\n  };\n\n  DocumentKey.prototype.toString = function () {\n    return this.path.toString();\n  };\n\n  DocumentKey.comparator = function (k1, k2) {\n    return ResourcePath.comparator(k1.path, k2.path);\n  };\n\n  DocumentKey.isDocumentKey = function (path) {\n    return path.length % 2 === 0;\n  };\n  /**\r\n   * Creates and returns a new document key with the given segments.\r\n   *\r\n   * @param segments - The segments of the path to the document\r\n   * @returns A new instance of DocumentKey\r\n   */\n\n\n  DocumentKey.fromSegments = function (segments) {\n    return new DocumentKey(new ResourcePath(segments.slice()));\n  };\n\n  return DocumentKey;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Extracts the backend's type order for the provided value. */\n\n\nfunction typeOrder(value) {\n  if ('nullValue' in value) {\n    return 0\n    /* NullValue */\n    ;\n  } else if ('booleanValue' in value) {\n    return 1\n    /* BooleanValue */\n    ;\n  } else if ('integerValue' in value || 'doubleValue' in value) {\n    return 2\n    /* NumberValue */\n    ;\n  } else if ('timestampValue' in value) {\n    return 3\n    /* TimestampValue */\n    ;\n  } else if ('stringValue' in value) {\n    return 5\n    /* StringValue */\n    ;\n  } else if ('bytesValue' in value) {\n    return 6\n    /* BlobValue */\n    ;\n  } else if ('referenceValue' in value) {\n    return 7\n    /* RefValue */\n    ;\n  } else if ('geoPointValue' in value) {\n    return 8\n    /* GeoPointValue */\n    ;\n  } else if ('arrayValue' in value) {\n    return 9\n    /* ArrayValue */\n    ;\n  } else if ('mapValue' in value) {\n    if (isServerTimestamp(value)) {\n      return 4\n      /* ServerTimestampValue */\n      ;\n    }\n\n    return 10\n    /* ObjectValue */\n    ;\n  } else {\n    return fail();\n  }\n}\n/** Tests `left` and `right` for equality based on the backend semantics. */\n\n\nfunction valueEquals(left, right) {\n  var leftType = typeOrder(left);\n  var rightType = typeOrder(right);\n\n  if (leftType !== rightType) {\n    return false;\n  }\n\n  switch (leftType) {\n    case 0\n    /* NullValue */\n    :\n      return true;\n\n    case 1\n    /* BooleanValue */\n    :\n      return left.booleanValue === right.booleanValue;\n\n    case 4\n    /* ServerTimestampValue */\n    :\n      return getLocalWriteTime(left).isEqual(getLocalWriteTime(right));\n\n    case 3\n    /* TimestampValue */\n    :\n      return timestampEquals(left, right);\n\n    case 5\n    /* StringValue */\n    :\n      return left.stringValue === right.stringValue;\n\n    case 6\n    /* BlobValue */\n    :\n      return blobEquals(left, right);\n\n    case 7\n    /* RefValue */\n    :\n      return left.referenceValue === right.referenceValue;\n\n    case 8\n    /* GeoPointValue */\n    :\n      return geoPointEquals(left, right);\n\n    case 2\n    /* NumberValue */\n    :\n      return numberEquals(left, right);\n\n    case 9\n    /* ArrayValue */\n    :\n      return arrayEquals(left.arrayValue.values || [], right.arrayValue.values || [], valueEquals);\n\n    case 10\n    /* ObjectValue */\n    :\n      return objectEquals(left, right);\n\n    default:\n      return fail();\n  }\n}\n\nfunction timestampEquals(left, right) {\n  if (typeof left.timestampValue === 'string' && typeof right.timestampValue === 'string' && left.timestampValue.length === right.timestampValue.length) {\n    // Use string equality for ISO 8601 timestamps\n    return left.timestampValue === right.timestampValue;\n  }\n\n  var leftTimestamp = normalizeTimestamp(left.timestampValue);\n  var rightTimestamp = normalizeTimestamp(right.timestampValue);\n  return leftTimestamp.seconds === rightTimestamp.seconds && leftTimestamp.nanos === rightTimestamp.nanos;\n}\n\nfunction geoPointEquals(left, right) {\n  return normalizeNumber(left.geoPointValue.latitude) === normalizeNumber(right.geoPointValue.latitude) && normalizeNumber(left.geoPointValue.longitude) === normalizeNumber(right.geoPointValue.longitude);\n}\n\nfunction blobEquals(left, right) {\n  return normalizeByteString(left.bytesValue).isEqual(normalizeByteString(right.bytesValue));\n}\n\nfunction numberEquals(left, right) {\n  if ('integerValue' in left && 'integerValue' in right) {\n    return normalizeNumber(left.integerValue) === normalizeNumber(right.integerValue);\n  } else if ('doubleValue' in left && 'doubleValue' in right) {\n    var n1 = normalizeNumber(left.doubleValue);\n    var n2 = normalizeNumber(right.doubleValue);\n\n    if (n1 === n2) {\n      return isNegativeZero(n1) === isNegativeZero(n2);\n    } else {\n      return isNaN(n1) && isNaN(n2);\n    }\n  }\n\n  return false;\n}\n\nfunction objectEquals(left, right) {\n  var leftMap = left.mapValue.fields || {};\n  var rightMap = right.mapValue.fields || {};\n\n  if (objectSize(leftMap) !== objectSize(rightMap)) {\n    return false;\n  }\n\n  for (var key in leftMap) {\n    if (leftMap.hasOwnProperty(key)) {\n      if (rightMap[key] === undefined || !valueEquals(leftMap[key], rightMap[key])) {\n        return false;\n      }\n    }\n  }\n\n  return true;\n}\n/** Returns true if the ArrayValue contains the specified element. */\n\n\nfunction arrayValueContains(haystack, needle) {\n  return (haystack.values || []).find(function (v) {\n    return valueEquals(v, needle);\n  }) !== undefined;\n}\n\nfunction valueCompare(left, right) {\n  var leftType = typeOrder(left);\n  var rightType = typeOrder(right);\n\n  if (leftType !== rightType) {\n    return primitiveComparator(leftType, rightType);\n  }\n\n  switch (leftType) {\n    case 0\n    /* NullValue */\n    :\n      return 0;\n\n    case 1\n    /* BooleanValue */\n    :\n      return primitiveComparator(left.booleanValue, right.booleanValue);\n\n    case 2\n    /* NumberValue */\n    :\n      return compareNumbers(left, right);\n\n    case 3\n    /* TimestampValue */\n    :\n      return compareTimestamps(left.timestampValue, right.timestampValue);\n\n    case 4\n    /* ServerTimestampValue */\n    :\n      return compareTimestamps(getLocalWriteTime(left), getLocalWriteTime(right));\n\n    case 5\n    /* StringValue */\n    :\n      return primitiveComparator(left.stringValue, right.stringValue);\n\n    case 6\n    /* BlobValue */\n    :\n      return compareBlobs(left.bytesValue, right.bytesValue);\n\n    case 7\n    /* RefValue */\n    :\n      return compareReferences(left.referenceValue, right.referenceValue);\n\n    case 8\n    /* GeoPointValue */\n    :\n      return compareGeoPoints(left.geoPointValue, right.geoPointValue);\n\n    case 9\n    /* ArrayValue */\n    :\n      return compareArrays(left.arrayValue, right.arrayValue);\n\n    case 10\n    /* ObjectValue */\n    :\n      return compareMaps(left.mapValue, right.mapValue);\n\n    default:\n      throw fail();\n  }\n}\n\nfunction compareNumbers(left, right) {\n  var leftNumber = normalizeNumber(left.integerValue || left.doubleValue);\n  var rightNumber = normalizeNumber(right.integerValue || right.doubleValue);\n\n  if (leftNumber < rightNumber) {\n    return -1;\n  } else if (leftNumber > rightNumber) {\n    return 1;\n  } else if (leftNumber === rightNumber) {\n    return 0;\n  } else {\n    // one or both are NaN.\n    if (isNaN(leftNumber)) {\n      return isNaN(rightNumber) ? 0 : -1;\n    } else {\n      return 1;\n    }\n  }\n}\n\nfunction compareTimestamps(left, right) {\n  if (typeof left === 'string' && typeof right === 'string' && left.length === right.length) {\n    return primitiveComparator(left, right);\n  }\n\n  var leftTimestamp = normalizeTimestamp(left);\n  var rightTimestamp = normalizeTimestamp(right);\n  var comparison = primitiveComparator(leftTimestamp.seconds, rightTimestamp.seconds);\n\n  if (comparison !== 0) {\n    return comparison;\n  }\n\n  return primitiveComparator(leftTimestamp.nanos, rightTimestamp.nanos);\n}\n\nfunction compareReferences(leftPath, rightPath) {\n  var leftSegments = leftPath.split('/');\n  var rightSegments = rightPath.split('/');\n\n  for (var i = 0; i < leftSegments.length && i < rightSegments.length; i++) {\n    var comparison = primitiveComparator(leftSegments[i], rightSegments[i]);\n\n    if (comparison !== 0) {\n      return comparison;\n    }\n  }\n\n  return primitiveComparator(leftSegments.length, rightSegments.length);\n}\n\nfunction compareGeoPoints(left, right) {\n  var comparison = primitiveComparator(normalizeNumber(left.latitude), normalizeNumber(right.latitude));\n\n  if (comparison !== 0) {\n    return comparison;\n  }\n\n  return primitiveComparator(normalizeNumber(left.longitude), normalizeNumber(right.longitude));\n}\n\nfunction compareBlobs(left, right) {\n  var leftBytes = normalizeByteString(left);\n  var rightBytes = normalizeByteString(right);\n  return leftBytes.compareTo(rightBytes);\n}\n\nfunction compareArrays(left, right) {\n  var leftArray = left.values || [];\n  var rightArray = right.values || [];\n\n  for (var i = 0; i < leftArray.length && i < rightArray.length; ++i) {\n    var compare = valueCompare(leftArray[i], rightArray[i]);\n\n    if (compare) {\n      return compare;\n    }\n  }\n\n  return primitiveComparator(leftArray.length, rightArray.length);\n}\n\nfunction compareMaps(left, right) {\n  var leftMap = left.fields || {};\n  var leftKeys = Object.keys(leftMap);\n  var rightMap = right.fields || {};\n  var rightKeys = Object.keys(rightMap); // Even though MapValues are likely sorted correctly based on their insertion\n  // order (e.g. when received from the backend), local modifications can bring\n  // elements out of order. We need to re-sort the elements to ensure that\n  // canonical IDs are independent of insertion order.\n\n  leftKeys.sort();\n  rightKeys.sort();\n\n  for (var i = 0; i < leftKeys.length && i < rightKeys.length; ++i) {\n    var keyCompare = primitiveComparator(leftKeys[i], rightKeys[i]);\n\n    if (keyCompare !== 0) {\n      return keyCompare;\n    }\n\n    var compare = valueCompare(leftMap[leftKeys[i]], rightMap[rightKeys[i]]);\n\n    if (compare !== 0) {\n      return compare;\n    }\n  }\n\n  return primitiveComparator(leftKeys.length, rightKeys.length);\n}\n/**\r\n * Generates the canonical ID for the provided field value (as used in Target\r\n * serialization).\r\n */\n\n\nfunction canonicalId(value) {\n  return canonifyValue(value);\n}\n\nfunction canonifyValue(value) {\n  if ('nullValue' in value) {\n    return 'null';\n  } else if ('booleanValue' in value) {\n    return '' + value.booleanValue;\n  } else if ('integerValue' in value) {\n    return '' + value.integerValue;\n  } else if ('doubleValue' in value) {\n    return '' + value.doubleValue;\n  } else if ('timestampValue' in value) {\n    return canonifyTimestamp(value.timestampValue);\n  } else if ('stringValue' in value) {\n    return value.stringValue;\n  } else if ('bytesValue' in value) {\n    return canonifyByteString(value.bytesValue);\n  } else if ('referenceValue' in value) {\n    return canonifyReference(value.referenceValue);\n  } else if ('geoPointValue' in value) {\n    return canonifyGeoPoint(value.geoPointValue);\n  } else if ('arrayValue' in value) {\n    return canonifyArray(value.arrayValue);\n  } else if ('mapValue' in value) {\n    return canonifyMap(value.mapValue);\n  } else {\n    return fail();\n  }\n}\n\nfunction canonifyByteString(byteString) {\n  return normalizeByteString(byteString).toBase64();\n}\n\nfunction canonifyTimestamp(timestamp) {\n  var normalizedTimestamp = normalizeTimestamp(timestamp);\n  return \"time(\" + normalizedTimestamp.seconds + \",\" + normalizedTimestamp.nanos + \")\";\n}\n\nfunction canonifyGeoPoint(geoPoint) {\n  return \"geo(\" + geoPoint.latitude + \",\" + geoPoint.longitude + \")\";\n}\n\nfunction canonifyReference(referenceValue) {\n  return DocumentKey.fromName(referenceValue).toString();\n}\n\nfunction canonifyMap(mapValue) {\n  // Iteration order in JavaScript is not guaranteed. To ensure that we generate\n  // matching canonical IDs for identical maps, we need to sort the keys.\n  var sortedKeys = Object.keys(mapValue.fields || {}).sort();\n  var result = '{';\n  var first = true;\n\n  for (var _i = 0, sortedKeys_1 = sortedKeys; _i < sortedKeys_1.length; _i++) {\n    var key = sortedKeys_1[_i];\n\n    if (!first) {\n      result += ',';\n    } else {\n      first = false;\n    }\n\n    result += key + \":\" + canonifyValue(mapValue.fields[key]);\n  }\n\n  return result + '}';\n}\n\nfunction canonifyArray(arrayValue) {\n  var result = '[';\n  var first = true;\n\n  for (var _i = 0, _d = arrayValue.values || []; _i < _d.length; _i++) {\n    var value = _d[_i];\n\n    if (!first) {\n      result += ',';\n    } else {\n      first = false;\n    }\n\n    result += canonifyValue(value);\n  }\n\n  return result + ']';\n}\n/** Returns a reference value for the provided database and key. */\n\n\nfunction refValue(databaseId, key) {\n  return {\n    referenceValue: \"projects/\" + databaseId.projectId + \"/databases/\" + databaseId.database + \"/documents/\" + key.path.canonicalString()\n  };\n}\n/** Returns true if `value` is an IntegerValue . */\n\n\nfunction isInteger(value) {\n  return !!value && 'integerValue' in value;\n}\n/** Returns true if `value` is a DoubleValue. */\n\n\nfunction isDouble(value) {\n  return !!value && 'doubleValue' in value;\n}\n/** Returns true if `value` is either an IntegerValue or a DoubleValue. */\n\n\nfunction isNumber(value) {\n  return isInteger(value) || isDouble(value);\n}\n/** Returns true if `value` is an ArrayValue. */\n\n\nfunction isArray(value) {\n  return !!value && 'arrayValue' in value;\n}\n/** Returns true if `value` is a NullValue. */\n\n\nfunction isNullValue(value) {\n  return !!value && 'nullValue' in value;\n}\n/** Returns true if `value` is NaN. */\n\n\nfunction isNanValue(value) {\n  return !!value && 'doubleValue' in value && isNaN(Number(value.doubleValue));\n}\n/** Returns true if `value` is a MapValue. */\n\n\nfunction isMapValue(value) {\n  return !!value && 'mapValue' in value;\n}\n/** Creates a deep copy of `source`. */\n\n\nfunction deepClone(source) {\n  if (source.geoPointValue) {\n    return {\n      geoPointValue: Object.assign({}, source.geoPointValue)\n    };\n  } else if (source.timestampValue && typeof source.timestampValue === 'object') {\n    return {\n      timestampValue: Object.assign({}, source.timestampValue)\n    };\n  } else if (source.mapValue) {\n    var target_1 = {\n      mapValue: {\n        fields: {}\n      }\n    };\n    forEach(source.mapValue.fields, function (key, val) {\n      return target_1.mapValue.fields[key] = deepClone(val);\n    });\n    return target_1;\n  } else if (source.arrayValue) {\n    var target = {\n      arrayValue: {\n        values: []\n      }\n    };\n\n    for (var i = 0; i < (source.arrayValue.values || []).length; ++i) {\n      target.arrayValue.values[i] = deepClone(source.arrayValue.values[i]);\n    }\n\n    return target;\n  } else {\n    return Object.assign({}, source);\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An ObjectValue represents a MapValue in the Firestore Proto and offers the\r\n * ability to add and remove fields (via the ObjectValueBuilder).\r\n */\n\n\nvar ObjectValue =\n/** @class */\nfunction () {\n  function ObjectValue(value) {\n    this.value = value;\n  }\n\n  ObjectValue.empty = function () {\n    return new ObjectValue({\n      mapValue: {}\n    });\n  };\n  /**\r\n   * Returns the value at the given path or null.\r\n   *\r\n   * @param path - the path to search\r\n   * @returns The value at the path or null if the path is not set.\r\n   */\n\n\n  ObjectValue.prototype.field = function (path) {\n    if (path.isEmpty()) {\n      return this.value;\n    } else {\n      var currentLevel = this.value;\n\n      for (var i = 0; i < path.length - 1; ++i) {\n        currentLevel = (currentLevel.mapValue.fields || {})[path.get(i)];\n\n        if (!isMapValue(currentLevel)) {\n          return null;\n        }\n      }\n\n      currentLevel = (currentLevel.mapValue.fields || {})[path.lastSegment()];\n      return currentLevel || null;\n    }\n  };\n  /**\r\n   * Sets the field to the provided value.\r\n   *\r\n   * @param path - The field path to set.\r\n   * @param value - The value to set.\r\n   */\n\n\n  ObjectValue.prototype.set = function (path, value) {\n    var fieldsMap = this.getFieldsMap(path.popLast());\n    fieldsMap[path.lastSegment()] = deepClone(value);\n  };\n  /**\r\n   * Sets the provided fields to the provided values.\r\n   *\r\n   * @param data - A map of fields to values (or null for deletes).\r\n   */\n\n\n  ObjectValue.prototype.setAll = function (data) {\n    var _this = this;\n\n    var parent = FieldPath$1.emptyPath();\n    var upserts = {};\n    var deletes = [];\n    data.forEach(function (value, path) {\n      if (!parent.isImmediateParentOf(path)) {\n        // Insert the accumulated changes at this parent location\n        var fieldsMap_1 = _this.getFieldsMap(parent);\n\n        _this.applyChanges(fieldsMap_1, upserts, deletes);\n\n        upserts = {};\n        deletes = [];\n        parent = path.popLast();\n      }\n\n      if (value) {\n        upserts[path.lastSegment()] = deepClone(value);\n      } else {\n        deletes.push(path.lastSegment());\n      }\n    });\n    var fieldsMap = this.getFieldsMap(parent);\n    this.applyChanges(fieldsMap, upserts, deletes);\n  };\n  /**\r\n   * Removes the field at the specified path. If there is no field at the\r\n   * specified path, nothing is changed.\r\n   *\r\n   * @param path - The field path to remove.\r\n   */\n\n\n  ObjectValue.prototype.delete = function (path) {\n    var nestedValue = this.field(path.popLast());\n\n    if (isMapValue(nestedValue) && nestedValue.mapValue.fields) {\n      delete nestedValue.mapValue.fields[path.lastSegment()];\n    }\n  };\n\n  ObjectValue.prototype.isEqual = function (other) {\n    return valueEquals(this.value, other.value);\n  };\n  /**\r\n   * Returns the map that contains the leaf element of `path`. If the parent\r\n   * entry does not yet exist, or if it is not a map, a new map will be created.\r\n   */\n\n\n  ObjectValue.prototype.getFieldsMap = function (path) {\n    var current = this.value;\n\n    if (!current.mapValue.fields) {\n      current.mapValue = {\n        fields: {}\n      };\n    }\n\n    for (var i = 0; i < path.length; ++i) {\n      var next = current.mapValue.fields[path.get(i)];\n\n      if (!isMapValue(next) || !next.mapValue.fields) {\n        next = {\n          mapValue: {\n            fields: {}\n          }\n        };\n        current.mapValue.fields[path.get(i)] = next;\n      }\n\n      current = next;\n    }\n\n    return current.mapValue.fields;\n  };\n  /**\r\n   * Modifies `fieldsMap` by adding, replacing or deleting the specified\r\n   * entries.\r\n   */\n\n\n  ObjectValue.prototype.applyChanges = function (fieldsMap, inserts, deletes) {\n    forEach(inserts, function (key, val) {\n      return fieldsMap[key] = val;\n    });\n\n    for (var _i = 0, deletes_1 = deletes; _i < deletes_1.length; _i++) {\n      var field = deletes_1[_i];\n      delete fieldsMap[field];\n    }\n  };\n\n  ObjectValue.prototype.clone = function () {\n    return new ObjectValue(deepClone(this.value));\n  };\n\n  return ObjectValue;\n}();\n/**\r\n * Returns a FieldMask built from all fields in a MapValue.\r\n */\n\n\nfunction extractFieldMask(value) {\n  var fields = [];\n  forEach(value.fields, function (key, value) {\n    var currentPath = new FieldPath$1([key]);\n\n    if (isMapValue(value)) {\n      var nestedMask = extractFieldMask(value.mapValue);\n      var nestedFields = nestedMask.fields;\n\n      if (nestedFields.length === 0) {\n        // Preserve the empty map by adding it to the FieldMask.\n        fields.push(currentPath);\n      } else {\n        // For nested and non-empty ObjectValues, add the FieldPath of the\n        // leaf nodes.\n        for (var _i = 0, nestedFields_1 = nestedFields; _i < nestedFields_1.length; _i++) {\n          var nestedPath = nestedFields_1[_i];\n          fields.push(currentPath.child(nestedPath));\n        }\n      }\n    } else {\n      // For nested and non-empty ObjectValues, add the FieldPath of the leaf\n      // nodes.\n      fields.push(currentPath);\n    }\n  });\n  return new FieldMask(fields);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Represents a document in Firestore with a key, version, data and whether it\r\n * has local mutations applied to it.\r\n *\r\n * Documents can transition between states via `convertToFoundDocument()`,\r\n * `convertToNoDocument()` and `convertToUnknownDocument()`. If a document does\r\n * not transition to one of these states even after all mutations have been\r\n * applied, `isValidDocument()` returns false and the document should be removed\r\n * from all views.\r\n */\n\n\nvar MutableDocument =\n/** @class */\nfunction () {\n  function MutableDocument(key, documentType, version, data, documentState) {\n    this.key = key;\n    this.documentType = documentType;\n    this.version = version;\n    this.data = data;\n    this.documentState = documentState;\n  }\n  /**\r\n   * Creates a document with no known version or data, but which can serve as\r\n   * base document for mutations.\r\n   */\n\n\n  MutableDocument.newInvalidDocument = function (documentKey) {\n    return new MutableDocument(documentKey, 0\n    /* INVALID */\n    , SnapshotVersion.min(), ObjectValue.empty(), 0\n    /* SYNCED */\n    );\n  };\n  /**\r\n   * Creates a new document that is known to exist with the given data at the\r\n   * given version.\r\n   */\n\n\n  MutableDocument.newFoundDocument = function (documentKey, version, value) {\n    return new MutableDocument(documentKey, 1\n    /* FOUND_DOCUMENT */\n    , version, value, 0\n    /* SYNCED */\n    );\n  };\n  /** Creates a new document that is known to not exist at the given version. */\n\n\n  MutableDocument.newNoDocument = function (documentKey, version) {\n    return new MutableDocument(documentKey, 2\n    /* NO_DOCUMENT */\n    , version, ObjectValue.empty(), 0\n    /* SYNCED */\n    );\n  };\n  /**\r\n   * Creates a new document that is known to exist at the given version but\r\n   * whose data is not known (e.g. a document that was updated without a known\r\n   * base document).\r\n   */\n\n\n  MutableDocument.newUnknownDocument = function (documentKey, version) {\n    return new MutableDocument(documentKey, 3\n    /* UNKNOWN_DOCUMENT */\n    , version, ObjectValue.empty(), 2\n    /* HAS_COMMITTED_MUTATIONS */\n    );\n  };\n  /**\r\n   * Changes the document type to indicate that it exists and that its version\r\n   * and data are known.\r\n   */\n\n\n  MutableDocument.prototype.convertToFoundDocument = function (version, value) {\n    this.version = version;\n    this.documentType = 1\n    /* FOUND_DOCUMENT */\n    ;\n    this.data = value;\n    this.documentState = 0\n    /* SYNCED */\n    ;\n    return this;\n  };\n  /**\r\n   * Changes the document type to indicate that it doesn't exist at the given\r\n   * version.\r\n   */\n\n\n  MutableDocument.prototype.convertToNoDocument = function (version) {\n    this.version = version;\n    this.documentType = 2\n    /* NO_DOCUMENT */\n    ;\n    this.data = ObjectValue.empty();\n    this.documentState = 0\n    /* SYNCED */\n    ;\n    return this;\n  };\n  /**\r\n   * Changes the document type to indicate that it exists at a given version but\r\n   * that its data is not known (e.g. a document that was updated without a known\r\n   * base document).\r\n   */\n\n\n  MutableDocument.prototype.convertToUnknownDocument = function (version) {\n    this.version = version;\n    this.documentType = 3\n    /* UNKNOWN_DOCUMENT */\n    ;\n    this.data = ObjectValue.empty();\n    this.documentState = 2\n    /* HAS_COMMITTED_MUTATIONS */\n    ;\n    return this;\n  };\n\n  MutableDocument.prototype.setHasCommittedMutations = function () {\n    this.documentState = 2\n    /* HAS_COMMITTED_MUTATIONS */\n    ;\n    return this;\n  };\n\n  MutableDocument.prototype.setHasLocalMutations = function () {\n    this.documentState = 1\n    /* HAS_LOCAL_MUTATIONS */\n    ;\n    return this;\n  };\n\n  Object.defineProperty(MutableDocument.prototype, \"hasLocalMutations\", {\n    get: function () {\n      return this.documentState === 1\n      /* HAS_LOCAL_MUTATIONS */\n      ;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(MutableDocument.prototype, \"hasCommittedMutations\", {\n    get: function () {\n      return this.documentState === 2\n      /* HAS_COMMITTED_MUTATIONS */\n      ;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(MutableDocument.prototype, \"hasPendingWrites\", {\n    get: function () {\n      return this.hasLocalMutations || this.hasCommittedMutations;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  MutableDocument.prototype.isValidDocument = function () {\n    return this.documentType !== 0\n    /* INVALID */\n    ;\n  };\n\n  MutableDocument.prototype.isFoundDocument = function () {\n    return this.documentType === 1\n    /* FOUND_DOCUMENT */\n    ;\n  };\n\n  MutableDocument.prototype.isNoDocument = function () {\n    return this.documentType === 2\n    /* NO_DOCUMENT */\n    ;\n  };\n\n  MutableDocument.prototype.isUnknownDocument = function () {\n    return this.documentType === 3\n    /* UNKNOWN_DOCUMENT */\n    ;\n  };\n\n  MutableDocument.prototype.isEqual = function (other) {\n    return other instanceof MutableDocument && this.key.isEqual(other.key) && this.version.isEqual(other.version) && this.documentType === other.documentType && this.documentState === other.documentState && this.data.isEqual(other.data);\n  };\n\n  MutableDocument.prototype.clone = function () {\n    return new MutableDocument(this.key, this.documentType, this.version, this.data.clone(), this.documentState);\n  };\n\n  MutableDocument.prototype.toString = function () {\n    return \"Document(\" + this.key + \", \" + this.version + \", \" + JSON.stringify(this.data.value) + \", \" + (\"{documentType: \" + this.documentType + \"}), \") + (\"{documentState: \" + this.documentState + \"})\");\n  };\n\n  return MutableDocument;\n}();\n/**\r\n * Compares the value for field `field` in the provided documents. Throws if\r\n * the field does not exist in both documents.\r\n */\n\n\nfunction compareDocumentsByField(field, d1, d2) {\n  var v1 = d1.data.field(field);\n  var v2 = d2.data.field(field);\n\n  if (v1 !== null && v2 !== null) {\n    return valueCompare(v1, v2);\n  } else {\n    return fail();\n  }\n}\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// Visible for testing\n\n\nvar TargetImpl =\n/** @class */\nfunction () {\n  function TargetImpl(path, collectionGroup, orderBy, filters, limit, startAt, endAt) {\n    if (collectionGroup === void 0) {\n      collectionGroup = null;\n    }\n\n    if (orderBy === void 0) {\n      orderBy = [];\n    }\n\n    if (filters === void 0) {\n      filters = [];\n    }\n\n    if (limit === void 0) {\n      limit = null;\n    }\n\n    if (startAt === void 0) {\n      startAt = null;\n    }\n\n    if (endAt === void 0) {\n      endAt = null;\n    }\n\n    this.path = path;\n    this.collectionGroup = collectionGroup;\n    this.orderBy = orderBy;\n    this.filters = filters;\n    this.limit = limit;\n    this.startAt = startAt;\n    this.endAt = endAt;\n    this.memoizedCanonicalId = null;\n  }\n\n  return TargetImpl;\n}();\n/**\r\n * Initializes a Target with a path and optional additional query constraints.\r\n * Path must currently be empty if this is a collection group query.\r\n *\r\n * NOTE: you should always construct `Target` from `Query.toTarget` instead of\r\n * using this factory method, because `Query` provides an implicit `orderBy`\r\n * property.\r\n */\n\n\nfunction newTarget(path, collectionGroup, orderBy, filters, limit, startAt, endAt) {\n  if (collectionGroup === void 0) {\n    collectionGroup = null;\n  }\n\n  if (orderBy === void 0) {\n    orderBy = [];\n  }\n\n  if (filters === void 0) {\n    filters = [];\n  }\n\n  if (limit === void 0) {\n    limit = null;\n  }\n\n  if (startAt === void 0) {\n    startAt = null;\n  }\n\n  if (endAt === void 0) {\n    endAt = null;\n  }\n\n  return new TargetImpl(path, collectionGroup, orderBy, filters, limit, startAt, endAt);\n}\n\nfunction canonifyTarget(target) {\n  var targetImpl = debugCast(target);\n\n  if (targetImpl.memoizedCanonicalId === null) {\n    var canonicalId_1 = targetImpl.path.canonicalString();\n\n    if (targetImpl.collectionGroup !== null) {\n      canonicalId_1 += '|cg:' + targetImpl.collectionGroup;\n    }\n\n    canonicalId_1 += '|f:';\n    canonicalId_1 += targetImpl.filters.map(function (f) {\n      return canonifyFilter(f);\n    }).join(',');\n    canonicalId_1 += '|ob:';\n    canonicalId_1 += targetImpl.orderBy.map(function (o) {\n      return canonifyOrderBy(o);\n    }).join(',');\n\n    if (!isNullOrUndefined(targetImpl.limit)) {\n      canonicalId_1 += '|l:';\n      canonicalId_1 += targetImpl.limit;\n    }\n\n    if (targetImpl.startAt) {\n      canonicalId_1 += '|lb:';\n      canonicalId_1 += canonifyBound(targetImpl.startAt);\n    }\n\n    if (targetImpl.endAt) {\n      canonicalId_1 += '|ub:';\n      canonicalId_1 += canonifyBound(targetImpl.endAt);\n    }\n\n    targetImpl.memoizedCanonicalId = canonicalId_1;\n  }\n\n  return targetImpl.memoizedCanonicalId;\n}\n\nfunction stringifyTarget(target) {\n  var str = target.path.canonicalString();\n\n  if (target.collectionGroup !== null) {\n    str += ' collectionGroup=' + target.collectionGroup;\n  }\n\n  if (target.filters.length > 0) {\n    str += \", filters: [\" + target.filters.map(function (f) {\n      return stringifyFilter(f);\n    }).join(', ') + \"]\";\n  }\n\n  if (!isNullOrUndefined(target.limit)) {\n    str += ', limit: ' + target.limit;\n  }\n\n  if (target.orderBy.length > 0) {\n    str += \", orderBy: [\" + target.orderBy.map(function (o) {\n      return stringifyOrderBy(o);\n    }).join(', ') + \"]\";\n  }\n\n  if (target.startAt) {\n    str += ', startAt: ' + canonifyBound(target.startAt);\n  }\n\n  if (target.endAt) {\n    str += ', endAt: ' + canonifyBound(target.endAt);\n  }\n\n  return \"Target(\" + str + \")\";\n}\n\nfunction targetEquals(left, right) {\n  if (left.limit !== right.limit) {\n    return false;\n  }\n\n  if (left.orderBy.length !== right.orderBy.length) {\n    return false;\n  }\n\n  for (var i = 0; i < left.orderBy.length; i++) {\n    if (!orderByEquals(left.orderBy[i], right.orderBy[i])) {\n      return false;\n    }\n  }\n\n  if (left.filters.length !== right.filters.length) {\n    return false;\n  }\n\n  for (var i = 0; i < left.filters.length; i++) {\n    if (!filterEquals(left.filters[i], right.filters[i])) {\n      return false;\n    }\n  }\n\n  if (left.collectionGroup !== right.collectionGroup) {\n    return false;\n  }\n\n  if (!left.path.isEqual(right.path)) {\n    return false;\n  }\n\n  if (!boundEquals(left.startAt, right.startAt)) {\n    return false;\n  }\n\n  return boundEquals(left.endAt, right.endAt);\n}\n\nfunction isDocumentTarget(target) {\n  return DocumentKey.isDocumentKey(target.path) && target.collectionGroup === null && target.filters.length === 0;\n}\n\nvar Filter =\n/** @class */\nfunction () {\n  function Filter() {}\n\n  return Filter;\n}();\n\nvar FieldFilter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(FieldFilter, _super);\n\n  function FieldFilter(field, op, value) {\n    var _this = _super.call(this) || this;\n\n    _this.field = field;\n    _this.op = op;\n    _this.value = value;\n    return _this;\n  }\n  /**\r\n   * Creates a filter based on the provided arguments.\r\n   */\n\n\n  FieldFilter.create = function (field, op, value) {\n    if (field.isKeyField()) {\n      if (op === \"in\"\n      /* IN */\n      || op === \"not-in\"\n      /* NOT_IN */\n      ) {\n          return this.createKeyFieldInFilter(field, op, value);\n        } else {\n        return new KeyFieldFilter(field, op, value);\n      }\n    } else if (op === \"array-contains\"\n    /* ARRAY_CONTAINS */\n    ) {\n        return new ArrayContainsFilter(field, value);\n      } else if (op === \"in\"\n    /* IN */\n    ) {\n        return new InFilter(field, value);\n      } else if (op === \"not-in\"\n    /* NOT_IN */\n    ) {\n        return new NotInFilter(field, value);\n      } else if (op === \"array-contains-any\"\n    /* ARRAY_CONTAINS_ANY */\n    ) {\n        return new ArrayContainsAnyFilter(field, value);\n      } else {\n      return new FieldFilter(field, op, value);\n    }\n  };\n\n  FieldFilter.createKeyFieldInFilter = function (field, op, value) {\n    return op === \"in\"\n    /* IN */\n    ? new KeyFieldInFilter(field, value) : new KeyFieldNotInFilter(field, value);\n  };\n\n  FieldFilter.prototype.matches = function (doc) {\n    var other = doc.data.field(this.field); // Types do not have to match in NOT_EQUAL filters.\n\n    if (this.op === \"!=\"\n    /* NOT_EQUAL */\n    ) {\n        return other !== null && this.matchesComparison(valueCompare(other, this.value));\n      } // Only compare types with matching backend order (such as double and int).\n\n\n    return other !== null && typeOrder(this.value) === typeOrder(other) && this.matchesComparison(valueCompare(other, this.value));\n  };\n\n  FieldFilter.prototype.matchesComparison = function (comparison) {\n    switch (this.op) {\n      case \"<\"\n      /* LESS_THAN */\n      :\n        return comparison < 0;\n\n      case \"<=\"\n      /* LESS_THAN_OR_EQUAL */\n      :\n        return comparison <= 0;\n\n      case \"==\"\n      /* EQUAL */\n      :\n        return comparison === 0;\n\n      case \"!=\"\n      /* NOT_EQUAL */\n      :\n        return comparison !== 0;\n\n      case \">\"\n      /* GREATER_THAN */\n      :\n        return comparison > 0;\n\n      case \">=\"\n      /* GREATER_THAN_OR_EQUAL */\n      :\n        return comparison >= 0;\n\n      default:\n        return fail();\n    }\n  };\n\n  FieldFilter.prototype.isInequality = function () {\n    return [\"<\"\n    /* LESS_THAN */\n    , \"<=\"\n    /* LESS_THAN_OR_EQUAL */\n    , \">\"\n    /* GREATER_THAN */\n    , \">=\"\n    /* GREATER_THAN_OR_EQUAL */\n    , \"!=\"\n    /* NOT_EQUAL */\n    , \"not-in\"\n    /* NOT_IN */\n    ].indexOf(this.op) >= 0;\n  };\n\n  return FieldFilter;\n}(Filter);\n\nfunction canonifyFilter(filter) {\n  // TODO(b/29183165): Technically, this won't be unique if two values have\n  // the same description, such as the int 3 and the string \"3\". So we should\n  // add the types in here somehow, too.\n  return filter.field.canonicalString() + filter.op.toString() + canonicalId(filter.value);\n}\n\nfunction filterEquals(f1, f2) {\n  return f1.op === f2.op && f1.field.isEqual(f2.field) && valueEquals(f1.value, f2.value);\n}\n/** Returns a debug description for `filter`. */\n\n\nfunction stringifyFilter(filter) {\n  return filter.field.canonicalString() + \" \" + filter.op + \" \" + canonicalId(filter.value);\n}\n/** Filter that matches on key fields (i.e. '__name__'). */\n\n\nvar KeyFieldFilter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(KeyFieldFilter, _super);\n\n  function KeyFieldFilter(field, op, value) {\n    var _this = _super.call(this, field, op, value) || this;\n\n    _this.key = DocumentKey.fromName(value.referenceValue);\n    return _this;\n  }\n\n  KeyFieldFilter.prototype.matches = function (doc) {\n    var comparison = DocumentKey.comparator(doc.key, this.key);\n    return this.matchesComparison(comparison);\n  };\n\n  return KeyFieldFilter;\n}(FieldFilter);\n/** Filter that matches on key fields within an array. */\n\n\nvar KeyFieldInFilter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(KeyFieldInFilter, _super);\n\n  function KeyFieldInFilter(field, value) {\n    var _this = _super.call(this, field, \"in\"\n    /* IN */\n    , value) || this;\n\n    _this.keys = extractDocumentKeysFromArrayValue(\"in\"\n    /* IN */\n    , value);\n    return _this;\n  }\n\n  KeyFieldInFilter.prototype.matches = function (doc) {\n    return this.keys.some(function (key) {\n      return key.isEqual(doc.key);\n    });\n  };\n\n  return KeyFieldInFilter;\n}(FieldFilter);\n/** Filter that matches on key fields not present within an array. */\n\n\nvar KeyFieldNotInFilter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(KeyFieldNotInFilter, _super);\n\n  function KeyFieldNotInFilter(field, value) {\n    var _this = _super.call(this, field, \"not-in\"\n    /* NOT_IN */\n    , value) || this;\n\n    _this.keys = extractDocumentKeysFromArrayValue(\"not-in\"\n    /* NOT_IN */\n    , value);\n    return _this;\n  }\n\n  KeyFieldNotInFilter.prototype.matches = function (doc) {\n    return !this.keys.some(function (key) {\n      return key.isEqual(doc.key);\n    });\n  };\n\n  return KeyFieldNotInFilter;\n}(FieldFilter);\n\nfunction extractDocumentKeysFromArrayValue(op, value) {\n  var _a;\n\n  return (((_a = value.arrayValue) === null || _a === void 0 ? void 0 : _a.values) || []).map(function (v) {\n    return DocumentKey.fromName(v.referenceValue);\n  });\n}\n/** A Filter that implements the array-contains operator. */\n\n\nvar ArrayContainsFilter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ArrayContainsFilter, _super);\n\n  function ArrayContainsFilter(field, value) {\n    return _super.call(this, field, \"array-contains\"\n    /* ARRAY_CONTAINS */\n    , value) || this;\n  }\n\n  ArrayContainsFilter.prototype.matches = function (doc) {\n    var other = doc.data.field(this.field);\n    return isArray(other) && arrayValueContains(other.arrayValue, this.value);\n  };\n\n  return ArrayContainsFilter;\n}(FieldFilter);\n/** A Filter that implements the IN operator. */\n\n\nvar InFilter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(InFilter, _super);\n\n  function InFilter(field, value) {\n    return _super.call(this, field, \"in\"\n    /* IN */\n    , value) || this;\n  }\n\n  InFilter.prototype.matches = function (doc) {\n    var other = doc.data.field(this.field);\n    return other !== null && arrayValueContains(this.value.arrayValue, other);\n  };\n\n  return InFilter;\n}(FieldFilter);\n/** A Filter that implements the not-in operator. */\n\n\nvar NotInFilter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(NotInFilter, _super);\n\n  function NotInFilter(field, value) {\n    return _super.call(this, field, \"not-in\"\n    /* NOT_IN */\n    , value) || this;\n  }\n\n  NotInFilter.prototype.matches = function (doc) {\n    if (arrayValueContains(this.value.arrayValue, {\n      nullValue: 'NULL_VALUE'\n    })) {\n      return false;\n    }\n\n    var other = doc.data.field(this.field);\n    return other !== null && !arrayValueContains(this.value.arrayValue, other);\n  };\n\n  return NotInFilter;\n}(FieldFilter);\n/** A Filter that implements the array-contains-any operator. */\n\n\nvar ArrayContainsAnyFilter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ArrayContainsAnyFilter, _super);\n\n  function ArrayContainsAnyFilter(field, value) {\n    return _super.call(this, field, \"array-contains-any\"\n    /* ARRAY_CONTAINS_ANY */\n    , value) || this;\n  }\n\n  ArrayContainsAnyFilter.prototype.matches = function (doc) {\n    var _this = this;\n\n    var other = doc.data.field(this.field);\n\n    if (!isArray(other) || !other.arrayValue.values) {\n      return false;\n    }\n\n    return other.arrayValue.values.some(function (val) {\n      return arrayValueContains(_this.value.arrayValue, val);\n    });\n  };\n\n  return ArrayContainsAnyFilter;\n}(FieldFilter);\n/**\r\n * Represents a bound of a query.\r\n *\r\n * The bound is specified with the given components representing a position and\r\n * whether it's just before or just after the position (relative to whatever the\r\n * query order is).\r\n *\r\n * The position represents a logical index position for a query. It's a prefix\r\n * of values for the (potentially implicit) order by clauses of a query.\r\n *\r\n * Bound provides a function to determine whether a document comes before or\r\n * after a bound. This is influenced by whether the position is just before or\r\n * just after the provided values.\r\n */\n\n\nvar Bound =\n/** @class */\nfunction () {\n  function Bound(position, before) {\n    this.position = position;\n    this.before = before;\n  }\n\n  return Bound;\n}();\n\nfunction canonifyBound(bound) {\n  // TODO(b/29183165): Make this collision robust.\n  return (bound.before ? 'b' : 'a') + \":\" + bound.position.map(function (p) {\n    return canonicalId(p);\n  }).join(',');\n}\n/**\r\n * An ordering on a field, in some Direction. Direction defaults to ASCENDING.\r\n */\n\n\nvar OrderBy =\n/** @class */\nfunction () {\n  function OrderBy(field, dir\n  /* ASCENDING */\n  ) {\n    if (dir === void 0) {\n      dir = \"asc\";\n    }\n\n    this.field = field;\n    this.dir = dir;\n  }\n\n  return OrderBy;\n}();\n\nfunction canonifyOrderBy(orderBy) {\n  // TODO(b/29183165): Make this collision robust.\n  return orderBy.field.canonicalString() + orderBy.dir;\n}\n\nfunction stringifyOrderBy(orderBy) {\n  return orderBy.field.canonicalString() + \" (\" + orderBy.dir + \")\";\n}\n\nfunction orderByEquals(left, right) {\n  return left.dir === right.dir && left.field.isEqual(right.field);\n}\n/**\r\n * Returns true if a document sorts before a bound using the provided sort\r\n * order.\r\n */\n\n\nfunction sortsBeforeDocument(bound, orderBy, doc) {\n  var comparison = 0;\n\n  for (var i = 0; i < bound.position.length; i++) {\n    var orderByComponent = orderBy[i];\n    var component = bound.position[i];\n\n    if (orderByComponent.field.isKeyField()) {\n      comparison = DocumentKey.comparator(DocumentKey.fromName(component.referenceValue), doc.key);\n    } else {\n      var docValue = doc.data.field(orderByComponent.field);\n      comparison = valueCompare(component, docValue);\n    }\n\n    if (orderByComponent.dir === \"desc\"\n    /* DESCENDING */\n    ) {\n        comparison = comparison * -1;\n      }\n\n    if (comparison !== 0) {\n      break;\n    }\n  }\n\n  return bound.before ? comparison <= 0 : comparison < 0;\n}\n\nfunction boundEquals(left, right) {\n  if (left === null) {\n    return right === null;\n  } else if (right === null) {\n    return false;\n  }\n\n  if (left.before !== right.before || left.position.length !== right.position.length) {\n    return false;\n  }\n\n  for (var i = 0; i < left.position.length; i++) {\n    var leftPosition = left.position[i];\n    var rightPosition = right.position[i];\n\n    if (!valueEquals(leftPosition, rightPosition)) {\n      return false;\n    }\n  }\n\n  return true;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Query encapsulates all the query attributes we support in the SDK. It can\r\n * be run against the LocalStore, as well as be converted to a `Target` to\r\n * query the RemoteStore results.\r\n *\r\n * Visible for testing.\r\n */\n\n\nvar QueryImpl =\n/** @class */\nfunction () {\n  /**\r\n   * Initializes a Query with a path and optional additional query constraints.\r\n   * Path must currently be empty if this is a collection group query.\r\n   */\n  function QueryImpl(path, collectionGroup, explicitOrderBy, filters, limit, limitType\n  /* First */\n  , startAt, endAt) {\n    if (collectionGroup === void 0) {\n      collectionGroup = null;\n    }\n\n    if (explicitOrderBy === void 0) {\n      explicitOrderBy = [];\n    }\n\n    if (filters === void 0) {\n      filters = [];\n    }\n\n    if (limit === void 0) {\n      limit = null;\n    }\n\n    if (limitType === void 0) {\n      limitType = \"F\";\n    }\n\n    if (startAt === void 0) {\n      startAt = null;\n    }\n\n    if (endAt === void 0) {\n      endAt = null;\n    }\n\n    this.path = path;\n    this.collectionGroup = collectionGroup;\n    this.explicitOrderBy = explicitOrderBy;\n    this.filters = filters;\n    this.limit = limit;\n    this.limitType = limitType;\n    this.startAt = startAt;\n    this.endAt = endAt;\n    this.memoizedOrderBy = null; // The corresponding `Target` of this `Query` instance.\n\n    this.memoizedTarget = null;\n    if (this.startAt) ;\n    if (this.endAt) ;\n  }\n\n  return QueryImpl;\n}();\n/** Creates a new Query instance with the options provided. */\n\n\nfunction newQuery(path, collectionGroup, explicitOrderBy, filters, limit, limitType, startAt, endAt) {\n  return new QueryImpl(path, collectionGroup, explicitOrderBy, filters, limit, limitType, startAt, endAt);\n}\n/** Creates a new Query for a query that matches all documents at `path` */\n\n\nfunction newQueryForPath(path) {\n  return new QueryImpl(path);\n}\n/**\r\n * Helper to convert a collection group query into a collection query at a\r\n * specific path. This is used when executing collection group queries, since\r\n * we have to split the query into a set of collection queries at multiple\r\n * paths.\r\n */\n\n\nfunction asCollectionQueryAtPath(query, path) {\n  return new QueryImpl(path,\n  /*collectionGroup=*/\n  null, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, query.startAt, query.endAt);\n}\n/**\r\n * Returns true if this query does not specify any query constraints that\r\n * could remove results.\r\n */\n\n\nfunction matchesAllDocuments(query) {\n  return query.filters.length === 0 && query.limit === null && query.startAt == null && query.endAt == null && (query.explicitOrderBy.length === 0 || query.explicitOrderBy.length === 1 && query.explicitOrderBy[0].field.isKeyField());\n}\n\nfunction hasLimitToFirst(query) {\n  return !isNullOrUndefined(query.limit) && query.limitType === \"F\"\n  /* First */\n  ;\n}\n\nfunction hasLimitToLast(query) {\n  return !isNullOrUndefined(query.limit) && query.limitType === \"L\"\n  /* Last */\n  ;\n}\n\nfunction getFirstOrderByField(query) {\n  return query.explicitOrderBy.length > 0 ? query.explicitOrderBy[0].field : null;\n}\n\nfunction getInequalityFilterField(query) {\n  for (var _i = 0, _d = query.filters; _i < _d.length; _i++) {\n    var filter = _d[_i];\n\n    if (filter.isInequality()) {\n      return filter.field;\n    }\n  }\n\n  return null;\n}\n/**\r\n * Checks if any of the provided Operators are included in the query and\r\n * returns the first one that is, or null if none are.\r\n */\n\n\nfunction findFilterOperator(query, operators) {\n  for (var _i = 0, _d = query.filters; _i < _d.length; _i++) {\n    var filter = _d[_i];\n\n    if (operators.indexOf(filter.op) >= 0) {\n      return filter.op;\n    }\n  }\n\n  return null;\n}\n/**\r\n * Creates a new Query for a collection group query that matches all documents\r\n * within the provided collection group.\r\n */\n\n\nfunction newQueryForCollectionGroup(collectionId) {\n  return new QueryImpl(ResourcePath.emptyPath(), collectionId);\n}\n/**\r\n * Returns whether the query matches a single document by path (rather than a\r\n * collection).\r\n */\n\n\nfunction isDocumentQuery$1(query) {\n  return DocumentKey.isDocumentKey(query.path) && query.collectionGroup === null && query.filters.length === 0;\n}\n/**\r\n * Returns whether the query matches a collection group rather than a specific\r\n * collection.\r\n */\n\n\nfunction isCollectionGroupQuery(query) {\n  return query.collectionGroup !== null;\n}\n/**\r\n * Returns the implicit order by constraint that is used to execute the Query,\r\n * which can be different from the order by constraints the user provided (e.g.\r\n * the SDK and backend always orders by `__name__`).\r\n */\n\n\nfunction queryOrderBy(query) {\n  var queryImpl = debugCast(query);\n\n  if (queryImpl.memoizedOrderBy === null) {\n    queryImpl.memoizedOrderBy = [];\n    var inequalityField = getInequalityFilterField(queryImpl);\n    var firstOrderByField = getFirstOrderByField(queryImpl);\n\n    if (inequalityField !== null && firstOrderByField === null) {\n      // In order to implicitly add key ordering, we must also add the\n      // inequality filter field for it to be a valid query.\n      // Note that the default inequality field and key ordering is ascending.\n      if (!inequalityField.isKeyField()) {\n        queryImpl.memoizedOrderBy.push(new OrderBy(inequalityField));\n      }\n\n      queryImpl.memoizedOrderBy.push(new OrderBy(FieldPath$1.keyField(), \"asc\"\n      /* ASCENDING */\n      ));\n    } else {\n      var foundKeyOrdering = false;\n\n      for (var _i = 0, _d = queryImpl.explicitOrderBy; _i < _d.length; _i++) {\n        var orderBy_1 = _d[_i];\n        queryImpl.memoizedOrderBy.push(orderBy_1);\n\n        if (orderBy_1.field.isKeyField()) {\n          foundKeyOrdering = true;\n        }\n      }\n\n      if (!foundKeyOrdering) {\n        // The order of the implicit key ordering always matches the last\n        // explicit order by\n        var lastDirection = queryImpl.explicitOrderBy.length > 0 ? queryImpl.explicitOrderBy[queryImpl.explicitOrderBy.length - 1].dir : \"asc\"\n        /* ASCENDING */\n        ;\n        queryImpl.memoizedOrderBy.push(new OrderBy(FieldPath$1.keyField(), lastDirection));\n      }\n    }\n  }\n\n  return queryImpl.memoizedOrderBy;\n}\n/**\r\n * Converts this `Query` instance to it's corresponding `Target` representation.\r\n */\n\n\nfunction queryToTarget(query) {\n  var queryImpl = debugCast(query);\n\n  if (!queryImpl.memoizedTarget) {\n    if (queryImpl.limitType === \"F\"\n    /* First */\n    ) {\n        queryImpl.memoizedTarget = newTarget(queryImpl.path, queryImpl.collectionGroup, queryOrderBy(queryImpl), queryImpl.filters, queryImpl.limit, queryImpl.startAt, queryImpl.endAt);\n      } else {\n      // Flip the orderBy directions since we want the last results\n      var orderBys = [];\n\n      for (var _i = 0, _d = queryOrderBy(queryImpl); _i < _d.length; _i++) {\n        var orderBy_2 = _d[_i];\n        var dir = orderBy_2.dir === \"desc\"\n        /* DESCENDING */\n        ? \"asc\"\n        /* ASCENDING */\n        : \"desc\"\n        /* DESCENDING */\n        ;\n        orderBys.push(new OrderBy(orderBy_2.field, dir));\n      } // We need to swap the cursors to match the now-flipped query ordering.\n\n\n      var startAt_1 = queryImpl.endAt ? new Bound(queryImpl.endAt.position, !queryImpl.endAt.before) : null;\n      var endAt_1 = queryImpl.startAt ? new Bound(queryImpl.startAt.position, !queryImpl.startAt.before) : null; // Now return as a LimitType.First query.\n\n      queryImpl.memoizedTarget = newTarget(queryImpl.path, queryImpl.collectionGroup, orderBys, queryImpl.filters, queryImpl.limit, startAt_1, endAt_1);\n    }\n  }\n\n  return queryImpl.memoizedTarget;\n}\n\nfunction queryWithAddedFilter(query, filter) {\n  var newFilters = query.filters.concat([filter]);\n  return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), newFilters, query.limit, query.limitType, query.startAt, query.endAt);\n}\n\nfunction queryWithAddedOrderBy(query, orderBy) {\n  // TODO(dimond): validate that orderBy does not list the same key twice.\n  var newOrderBy = query.explicitOrderBy.concat([orderBy]);\n  return new QueryImpl(query.path, query.collectionGroup, newOrderBy, query.filters.slice(), query.limit, query.limitType, query.startAt, query.endAt);\n}\n\nfunction queryWithLimit(query, limit, limitType) {\n  return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), limit, limitType, query.startAt, query.endAt);\n}\n\nfunction queryWithStartAt(query, bound) {\n  return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, bound, query.endAt);\n}\n\nfunction queryWithEndAt(query, bound) {\n  return new QueryImpl(query.path, query.collectionGroup, query.explicitOrderBy.slice(), query.filters.slice(), query.limit, query.limitType, query.startAt, bound);\n}\n\nfunction queryEquals(left, right) {\n  return targetEquals(queryToTarget(left), queryToTarget(right)) && left.limitType === right.limitType;\n} // TODO(b/29183165): This is used to get a unique string from a query to, for\n// example, use as a dictionary key, but the implementation is subject to\n// collisions. Make it collision-free.\n\n\nfunction canonifyQuery(query) {\n  return canonifyTarget(queryToTarget(query)) + \"|lt:\" + query.limitType;\n}\n\nfunction stringifyQuery(query) {\n  return \"Query(target=\" + stringifyTarget(queryToTarget(query)) + \"; limitType=\" + query.limitType + \")\";\n}\n/** Returns whether `doc` matches the constraints of `query`. */\n\n\nfunction queryMatches(query, doc) {\n  return doc.isFoundDocument() && queryMatchesPathAndCollectionGroup(query, doc) && queryMatchesOrderBy(query, doc) && queryMatchesFilters(query, doc) && queryMatchesBounds(query, doc);\n}\n\nfunction queryMatchesPathAndCollectionGroup(query, doc) {\n  var docPath = doc.key.path;\n\n  if (query.collectionGroup !== null) {\n    // NOTE: this.path is currently always empty since we don't expose Collection\n    // Group queries rooted at a document path yet.\n    return doc.key.hasCollectionId(query.collectionGroup) && query.path.isPrefixOf(docPath);\n  } else if (DocumentKey.isDocumentKey(query.path)) {\n    // exact match for document queries\n    return query.path.isEqual(docPath);\n  } else {\n    // shallow ancestor queries by default\n    return query.path.isImmediateParentOf(docPath);\n  }\n}\n/**\r\n * A document must have a value for every ordering clause in order to show up\r\n * in the results.\r\n */\n\n\nfunction queryMatchesOrderBy(query, doc) {\n  for (var _i = 0, _d = query.explicitOrderBy; _i < _d.length; _i++) {\n    var orderBy_3 = _d[_i]; // order by key always matches\n\n    if (!orderBy_3.field.isKeyField() && doc.data.field(orderBy_3.field) === null) {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nfunction queryMatchesFilters(query, doc) {\n  for (var _i = 0, _d = query.filters; _i < _d.length; _i++) {\n    var filter = _d[_i];\n\n    if (!filter.matches(doc)) {\n      return false;\n    }\n  }\n\n  return true;\n}\n/** Makes sure a document is within the bounds, if provided. */\n\n\nfunction queryMatchesBounds(query, doc) {\n  if (query.startAt && !sortsBeforeDocument(query.startAt, queryOrderBy(query), doc)) {\n    return false;\n  }\n\n  if (query.endAt && sortsBeforeDocument(query.endAt, queryOrderBy(query), doc)) {\n    return false;\n  }\n\n  return true;\n}\n/**\r\n * Returns a new comparator function that can be used to compare two documents\r\n * based on the Query's ordering constraint.\r\n */\n\n\nfunction newQueryComparator(query) {\n  return function (d1, d2) {\n    var comparedOnKeyField = false;\n\n    for (var _i = 0, _d = queryOrderBy(query); _i < _d.length; _i++) {\n      var orderBy_4 = _d[_i];\n      var comp = compareDocs(orderBy_4, d1, d2);\n\n      if (comp !== 0) {\n        return comp;\n      }\n\n      comparedOnKeyField = comparedOnKeyField || orderBy_4.field.isKeyField();\n    }\n\n    return 0;\n  };\n}\n\nfunction compareDocs(orderBy, d1, d2) {\n  var comparison = orderBy.field.isKeyField() ? DocumentKey.comparator(d1.key, d2.key) : compareDocumentsByField(orderBy.field, d1, d2);\n\n  switch (orderBy.dir) {\n    case \"asc\"\n    /* ASCENDING */\n    :\n      return comparison;\n\n    case \"desc\"\n    /* DESCENDING */\n    :\n      return -1 * comparison;\n\n    default:\n      return fail();\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// An immutable sorted map implementation, based on a Left-leaning Red-Black\n// tree.\n\n\nvar SortedMap =\n/** @class */\nfunction () {\n  function SortedMap(comparator, root) {\n    this.comparator = comparator;\n    this.root = root ? root : LLRBNode.EMPTY;\n  } // Returns a copy of the map, with the specified key/value added or replaced.\n\n\n  SortedMap.prototype.insert = function (key, value) {\n    return new SortedMap(this.comparator, this.root.insert(key, value, this.comparator).copy(null, null, LLRBNode.BLACK, null, null));\n  }; // Returns a copy of the map, with the specified key removed.\n\n\n  SortedMap.prototype.remove = function (key) {\n    return new SortedMap(this.comparator, this.root.remove(key, this.comparator).copy(null, null, LLRBNode.BLACK, null, null));\n  }; // Returns the value of the node with the given key, or null.\n\n\n  SortedMap.prototype.get = function (key) {\n    var node = this.root;\n\n    while (!node.isEmpty()) {\n      var cmp = this.comparator(key, node.key);\n\n      if (cmp === 0) {\n        return node.value;\n      } else if (cmp < 0) {\n        node = node.left;\n      } else if (cmp > 0) {\n        node = node.right;\n      }\n    }\n\n    return null;\n  }; // Returns the index of the element in this sorted map, or -1 if it doesn't\n  // exist.\n\n\n  SortedMap.prototype.indexOf = function (key) {\n    // Number of nodes that were pruned when descending right\n    var prunedNodes = 0;\n    var node = this.root;\n\n    while (!node.isEmpty()) {\n      var cmp = this.comparator(key, node.key);\n\n      if (cmp === 0) {\n        return prunedNodes + node.left.size;\n      } else if (cmp < 0) {\n        node = node.left;\n      } else {\n        // Count all nodes left of the node plus the node itself\n        prunedNodes += node.left.size + 1;\n        node = node.right;\n      }\n    } // Node not found\n\n\n    return -1;\n  };\n\n  SortedMap.prototype.isEmpty = function () {\n    return this.root.isEmpty();\n  };\n\n  Object.defineProperty(SortedMap.prototype, \"size\", {\n    // Returns the total number of nodes in the map.\n    get: function () {\n      return this.root.size;\n    },\n    enumerable: false,\n    configurable: true\n  }); // Returns the minimum key in the map.\n\n  SortedMap.prototype.minKey = function () {\n    return this.root.minKey();\n  }; // Returns the maximum key in the map.\n\n\n  SortedMap.prototype.maxKey = function () {\n    return this.root.maxKey();\n  }; // Traverses the map in key order and calls the specified action function\n  // for each key/value pair. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n\n\n  SortedMap.prototype.inorderTraversal = function (action) {\n    return this.root.inorderTraversal(action);\n  };\n\n  SortedMap.prototype.forEach = function (fn) {\n    this.inorderTraversal(function (k, v) {\n      fn(k, v);\n      return false;\n    });\n  };\n\n  SortedMap.prototype.toString = function () {\n    var descriptions = [];\n    this.inorderTraversal(function (k, v) {\n      descriptions.push(k + \":\" + v);\n      return false;\n    });\n    return \"{\" + descriptions.join(', ') + \"}\";\n  }; // Traverses the map in reverse key order and calls the specified action\n  // function for each key/value pair. If action returns true, traversal is\n  // aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n\n\n  SortedMap.prototype.reverseTraversal = function (action) {\n    return this.root.reverseTraversal(action);\n  }; // Returns an iterator over the SortedMap.\n\n\n  SortedMap.prototype.getIterator = function () {\n    return new SortedMapIterator(this.root, null, this.comparator, false);\n  };\n\n  SortedMap.prototype.getIteratorFrom = function (key) {\n    return new SortedMapIterator(this.root, key, this.comparator, false);\n  };\n\n  SortedMap.prototype.getReverseIterator = function () {\n    return new SortedMapIterator(this.root, null, this.comparator, true);\n  };\n\n  SortedMap.prototype.getReverseIteratorFrom = function (key) {\n    return new SortedMapIterator(this.root, key, this.comparator, true);\n  };\n\n  return SortedMap;\n}(); // end SortedMap\n// An iterator over an LLRBNode.\n\n\nvar SortedMapIterator =\n/** @class */\nfunction () {\n  function SortedMapIterator(node, startKey, comparator, isReverse) {\n    this.isReverse = isReverse;\n    this.nodeStack = [];\n    var cmp = 1;\n\n    while (!node.isEmpty()) {\n      cmp = startKey ? comparator(node.key, startKey) : 1; // flip the comparison if we're going in reverse\n\n      if (isReverse) {\n        cmp *= -1;\n      }\n\n      if (cmp < 0) {\n        // This node is less than our start key. ignore it\n        if (this.isReverse) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      } else if (cmp === 0) {\n        // This node is exactly equal to our start key. Push it on the stack,\n        // but stop iterating;\n        this.nodeStack.push(node);\n        break;\n      } else {\n        // This node is greater than our start key, add it to the stack and move\n        // to the next one\n        this.nodeStack.push(node);\n\n        if (this.isReverse) {\n          node = node.right;\n        } else {\n          node = node.left;\n        }\n      }\n    }\n  }\n\n  SortedMapIterator.prototype.getNext = function () {\n    var node = this.nodeStack.pop();\n    var result = {\n      key: node.key,\n      value: node.value\n    };\n\n    if (this.isReverse) {\n      node = node.left;\n\n      while (!node.isEmpty()) {\n        this.nodeStack.push(node);\n        node = node.right;\n      }\n    } else {\n      node = node.right;\n\n      while (!node.isEmpty()) {\n        this.nodeStack.push(node);\n        node = node.left;\n      }\n    }\n\n    return result;\n  };\n\n  SortedMapIterator.prototype.hasNext = function () {\n    return this.nodeStack.length > 0;\n  };\n\n  SortedMapIterator.prototype.peek = function () {\n    if (this.nodeStack.length === 0) {\n      return null;\n    }\n\n    var node = this.nodeStack[this.nodeStack.length - 1];\n    return {\n      key: node.key,\n      value: node.value\n    };\n  };\n\n  return SortedMapIterator;\n}(); // end SortedMapIterator\n// Represents a node in a Left-leaning Red-Black tree.\n\n\nvar LLRBNode =\n/** @class */\nfunction () {\n  function LLRBNode(key, value, color, left, right) {\n    this.key = key;\n    this.value = value;\n    this.color = color != null ? color : LLRBNode.RED;\n    this.left = left != null ? left : LLRBNode.EMPTY;\n    this.right = right != null ? right : LLRBNode.EMPTY;\n    this.size = this.left.size + 1 + this.right.size;\n  } // Returns a copy of the current node, optionally replacing pieces of it.\n\n\n  LLRBNode.prototype.copy = function (key, value, color, left, right) {\n    return new LLRBNode(key != null ? key : this.key, value != null ? value : this.value, color != null ? color : this.color, left != null ? left : this.left, right != null ? right : this.right);\n  };\n\n  LLRBNode.prototype.isEmpty = function () {\n    return false;\n  }; // Traverses the tree in key order and calls the specified action function\n  // for each node. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n\n\n  LLRBNode.prototype.inorderTraversal = function (action) {\n    return this.left.inorderTraversal(action) || action(this.key, this.value) || this.right.inorderTraversal(action);\n  }; // Traverses the tree in reverse key order and calls the specified action\n  // function for each node. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n\n\n  LLRBNode.prototype.reverseTraversal = function (action) {\n    return this.right.reverseTraversal(action) || action(this.key, this.value) || this.left.reverseTraversal(action);\n  }; // Returns the minimum node in the tree.\n\n\n  LLRBNode.prototype.min = function () {\n    if (this.left.isEmpty()) {\n      return this;\n    } else {\n      return this.left.min();\n    }\n  }; // Returns the maximum key in the tree.\n\n\n  LLRBNode.prototype.minKey = function () {\n    return this.min().key;\n  }; // Returns the maximum key in the tree.\n\n\n  LLRBNode.prototype.maxKey = function () {\n    if (this.right.isEmpty()) {\n      return this.key;\n    } else {\n      return this.right.maxKey();\n    }\n  }; // Returns new tree, with the key/value added.\n\n\n  LLRBNode.prototype.insert = function (key, value, comparator) {\n    var n = this;\n    var cmp = comparator(key, n.key);\n\n    if (cmp < 0) {\n      n = n.copy(null, null, null, n.left.insert(key, value, comparator), null);\n    } else if (cmp === 0) {\n      n = n.copy(null, value, null, null, null);\n    } else {\n      n = n.copy(null, null, null, null, n.right.insert(key, value, comparator));\n    }\n\n    return n.fixUp();\n  };\n\n  LLRBNode.prototype.removeMin = function () {\n    if (this.left.isEmpty()) {\n      return LLRBNode.EMPTY;\n    }\n\n    var n = this;\n\n    if (!n.left.isRed() && !n.left.left.isRed()) {\n      n = n.moveRedLeft();\n    }\n\n    n = n.copy(null, null, null, n.left.removeMin(), null);\n    return n.fixUp();\n  }; // Returns new tree, with the specified item removed.\n\n\n  LLRBNode.prototype.remove = function (key, comparator) {\n    var smallest;\n    var n = this;\n\n    if (comparator(key, n.key) < 0) {\n      if (!n.left.isEmpty() && !n.left.isRed() && !n.left.left.isRed()) {\n        n = n.moveRedLeft();\n      }\n\n      n = n.copy(null, null, null, n.left.remove(key, comparator), null);\n    } else {\n      if (n.left.isRed()) {\n        n = n.rotateRight();\n      }\n\n      if (!n.right.isEmpty() && !n.right.isRed() && !n.right.left.isRed()) {\n        n = n.moveRedRight();\n      }\n\n      if (comparator(key, n.key) === 0) {\n        if (n.right.isEmpty()) {\n          return LLRBNode.EMPTY;\n        } else {\n          smallest = n.right.min();\n          n = n.copy(smallest.key, smallest.value, null, null, n.right.removeMin());\n        }\n      }\n\n      n = n.copy(null, null, null, null, n.right.remove(key, comparator));\n    }\n\n    return n.fixUp();\n  };\n\n  LLRBNode.prototype.isRed = function () {\n    return this.color;\n  }; // Returns new tree after performing any needed rotations.\n\n\n  LLRBNode.prototype.fixUp = function () {\n    var n = this;\n\n    if (n.right.isRed() && !n.left.isRed()) {\n      n = n.rotateLeft();\n    }\n\n    if (n.left.isRed() && n.left.left.isRed()) {\n      n = n.rotateRight();\n    }\n\n    if (n.left.isRed() && n.right.isRed()) {\n      n = n.colorFlip();\n    }\n\n    return n;\n  };\n\n  LLRBNode.prototype.moveRedLeft = function () {\n    var n = this.colorFlip();\n\n    if (n.right.left.isRed()) {\n      n = n.copy(null, null, null, null, n.right.rotateRight());\n      n = n.rotateLeft();\n      n = n.colorFlip();\n    }\n\n    return n;\n  };\n\n  LLRBNode.prototype.moveRedRight = function () {\n    var n = this.colorFlip();\n\n    if (n.left.left.isRed()) {\n      n = n.rotateRight();\n      n = n.colorFlip();\n    }\n\n    return n;\n  };\n\n  LLRBNode.prototype.rotateLeft = function () {\n    var nl = this.copy(null, null, LLRBNode.RED, null, this.right.left);\n    return this.right.copy(null, null, this.color, nl, null);\n  };\n\n  LLRBNode.prototype.rotateRight = function () {\n    var nr = this.copy(null, null, LLRBNode.RED, this.left.right, null);\n    return this.left.copy(null, null, this.color, null, nr);\n  };\n\n  LLRBNode.prototype.colorFlip = function () {\n    var left = this.left.copy(null, null, !this.left.color, null, null);\n    var right = this.right.copy(null, null, !this.right.color, null, null);\n    return this.copy(null, null, !this.color, left, right);\n  }; // For testing.\n\n\n  LLRBNode.prototype.checkMaxDepth = function () {\n    var blackDepth = this.check();\n\n    if (Math.pow(2.0, blackDepth) <= this.size + 1) {\n      return true;\n    } else {\n      return false;\n    }\n  }; // In a balanced RB tree, the black-depth (number of black nodes) from root to\n  // leaves is equal on both sides.  This function verifies that or asserts.\n\n\n  LLRBNode.prototype.check = function () {\n    if (this.isRed() && this.left.isRed()) {\n      throw fail();\n    }\n\n    if (this.right.isRed()) {\n      throw fail();\n    }\n\n    var blackDepth = this.left.check();\n\n    if (blackDepth !== this.right.check()) {\n      throw fail();\n    } else {\n      return blackDepth + (this.isRed() ? 0 : 1);\n    }\n  };\n\n  return LLRBNode;\n}(); // end LLRBNode\n// Empty node is shared between all LLRB trees.\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n\nLLRBNode.EMPTY = null;\nLLRBNode.RED = true;\nLLRBNode.BLACK = false; // Represents an empty node (a leaf node in the Red-Black Tree).\n\nvar LLRBEmptyNode =\n/** @class */\nfunction () {\n  function LLRBEmptyNode() {\n    this.size = 0;\n  }\n\n  Object.defineProperty(LLRBEmptyNode.prototype, \"key\", {\n    get: function () {\n      throw fail();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(LLRBEmptyNode.prototype, \"value\", {\n    get: function () {\n      throw fail();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(LLRBEmptyNode.prototype, \"color\", {\n    get: function () {\n      throw fail();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(LLRBEmptyNode.prototype, \"left\", {\n    get: function () {\n      throw fail();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(LLRBEmptyNode.prototype, \"right\", {\n    get: function () {\n      throw fail();\n    },\n    enumerable: false,\n    configurable: true\n  }); // Returns a copy of the current node.\n\n  LLRBEmptyNode.prototype.copy = function (key, value, color, left, right) {\n    return this;\n  }; // Returns a copy of the tree, with the specified key/value added.\n\n\n  LLRBEmptyNode.prototype.insert = function (key, value, comparator) {\n    return new LLRBNode(key, value);\n  }; // Returns a copy of the tree, with the specified key removed.\n\n\n  LLRBEmptyNode.prototype.remove = function (key, comparator) {\n    return this;\n  };\n\n  LLRBEmptyNode.prototype.isEmpty = function () {\n    return true;\n  };\n\n  LLRBEmptyNode.prototype.inorderTraversal = function (action) {\n    return false;\n  };\n\n  LLRBEmptyNode.prototype.reverseTraversal = function (action) {\n    return false;\n  };\n\n  LLRBEmptyNode.prototype.minKey = function () {\n    return null;\n  };\n\n  LLRBEmptyNode.prototype.maxKey = function () {\n    return null;\n  };\n\n  LLRBEmptyNode.prototype.isRed = function () {\n    return false;\n  }; // For testing.\n\n\n  LLRBEmptyNode.prototype.checkMaxDepth = function () {\n    return true;\n  };\n\n  LLRBEmptyNode.prototype.check = function () {\n    return 0;\n  };\n\n  return LLRBEmptyNode;\n}(); // end LLRBEmptyNode\n\n\nLLRBNode.EMPTY = new LLRBEmptyNode();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * SortedSet is an immutable (copy-on-write) collection that holds elements\r\n * in order specified by the provided comparator.\r\n *\r\n * NOTE: if provided comparator returns 0 for two elements, we consider them to\r\n * be equal!\r\n */\n\nvar SortedSet =\n/** @class */\nfunction () {\n  function SortedSet(comparator) {\n    this.comparator = comparator;\n    this.data = new SortedMap(this.comparator);\n  }\n\n  SortedSet.prototype.has = function (elem) {\n    return this.data.get(elem) !== null;\n  };\n\n  SortedSet.prototype.first = function () {\n    return this.data.minKey();\n  };\n\n  SortedSet.prototype.last = function () {\n    return this.data.maxKey();\n  };\n\n  Object.defineProperty(SortedSet.prototype, \"size\", {\n    get: function () {\n      return this.data.size;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  SortedSet.prototype.indexOf = function (elem) {\n    return this.data.indexOf(elem);\n  };\n  /** Iterates elements in order defined by \"comparator\" */\n\n\n  SortedSet.prototype.forEach = function (cb) {\n    this.data.inorderTraversal(function (k, v) {\n      cb(k);\n      return false;\n    });\n  };\n  /** Iterates over `elem`s such that: range[0] &lt;= elem &lt; range[1]. */\n\n\n  SortedSet.prototype.forEachInRange = function (range, cb) {\n    var iter = this.data.getIteratorFrom(range[0]);\n\n    while (iter.hasNext()) {\n      var elem = iter.getNext();\n\n      if (this.comparator(elem.key, range[1]) >= 0) {\n        return;\n      }\n\n      cb(elem.key);\n    }\n  };\n  /**\r\n   * Iterates over `elem`s such that: start &lt;= elem until false is returned.\r\n   */\n\n\n  SortedSet.prototype.forEachWhile = function (cb, start) {\n    var iter;\n\n    if (start !== undefined) {\n      iter = this.data.getIteratorFrom(start);\n    } else {\n      iter = this.data.getIterator();\n    }\n\n    while (iter.hasNext()) {\n      var elem = iter.getNext();\n      var result = cb(elem.key);\n\n      if (!result) {\n        return;\n      }\n    }\n  };\n  /** Finds the least element greater than or equal to `elem`. */\n\n\n  SortedSet.prototype.firstAfterOrEqual = function (elem) {\n    var iter = this.data.getIteratorFrom(elem);\n    return iter.hasNext() ? iter.getNext().key : null;\n  };\n\n  SortedSet.prototype.getIterator = function () {\n    return new SortedSetIterator(this.data.getIterator());\n  };\n\n  SortedSet.prototype.getIteratorFrom = function (key) {\n    return new SortedSetIterator(this.data.getIteratorFrom(key));\n  };\n  /** Inserts or updates an element */\n\n\n  SortedSet.prototype.add = function (elem) {\n    return this.copy(this.data.remove(elem).insert(elem, true));\n  };\n  /** Deletes an element */\n\n\n  SortedSet.prototype.delete = function (elem) {\n    if (!this.has(elem)) {\n      return this;\n    }\n\n    return this.copy(this.data.remove(elem));\n  };\n\n  SortedSet.prototype.isEmpty = function () {\n    return this.data.isEmpty();\n  };\n\n  SortedSet.prototype.unionWith = function (other) {\n    var result = this; // Make sure `result` always refers to the larger one of the two sets.\n\n    if (result.size < other.size) {\n      result = other;\n      other = this;\n    }\n\n    other.forEach(function (elem) {\n      result = result.add(elem);\n    });\n    return result;\n  };\n\n  SortedSet.prototype.isEqual = function (other) {\n    if (!(other instanceof SortedSet)) {\n      return false;\n    }\n\n    if (this.size !== other.size) {\n      return false;\n    }\n\n    var thisIt = this.data.getIterator();\n    var otherIt = other.data.getIterator();\n\n    while (thisIt.hasNext()) {\n      var thisElem = thisIt.getNext().key;\n      var otherElem = otherIt.getNext().key;\n\n      if (this.comparator(thisElem, otherElem) !== 0) {\n        return false;\n      }\n    }\n\n    return true;\n  };\n\n  SortedSet.prototype.toArray = function () {\n    var res = [];\n    this.forEach(function (targetId) {\n      res.push(targetId);\n    });\n    return res;\n  };\n\n  SortedSet.prototype.toString = function () {\n    var result = [];\n    this.forEach(function (elem) {\n      return result.push(elem);\n    });\n    return 'SortedSet(' + result.toString() + ')';\n  };\n\n  SortedSet.prototype.copy = function (data) {\n    var result = new SortedSet(this.comparator);\n    result.data = data;\n    return result;\n  };\n\n  return SortedSet;\n}();\n\nvar SortedSetIterator =\n/** @class */\nfunction () {\n  function SortedSetIterator(iter) {\n    this.iter = iter;\n  }\n\n  SortedSetIterator.prototype.getNext = function () {\n    return this.iter.getNext().key;\n  };\n\n  SortedSetIterator.prototype.hasNext = function () {\n    return this.iter.hasNext();\n  };\n\n  return SortedSetIterator;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar EMPTY_MUTABLE_DOCUMENT_MAP = new SortedMap(DocumentKey.comparator);\n\nfunction mutableDocumentMap() {\n  return EMPTY_MUTABLE_DOCUMENT_MAP;\n}\n\nvar EMPTY_DOCUMENT_MAP = new SortedMap(DocumentKey.comparator);\n\nfunction documentMap() {\n  return EMPTY_DOCUMENT_MAP;\n}\n\nvar EMPTY_DOCUMENT_VERSION_MAP = new SortedMap(DocumentKey.comparator);\n\nfunction documentVersionMap() {\n  return EMPTY_DOCUMENT_VERSION_MAP;\n}\n\nvar EMPTY_DOCUMENT_KEY_SET = new SortedSet(DocumentKey.comparator);\n\nfunction documentKeySet() {\n  var keys = [];\n\n  for (var _i = 0; _i < arguments.length; _i++) {\n    keys[_i] = arguments[_i];\n  }\n\n  var set = EMPTY_DOCUMENT_KEY_SET;\n\n  for (var _d = 0, keys_1 = keys; _d < keys_1.length; _d++) {\n    var key = keys_1[_d];\n    set = set.add(key);\n  }\n\n  return set;\n}\n\nvar EMPTY_TARGET_ID_SET = new SortedSet(primitiveComparator);\n\nfunction targetIdSet() {\n  return EMPTY_TARGET_ID_SET;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Returns an DoubleValue for `value` that is encoded based the serializer's\r\n * `useProto3Json` setting.\r\n */\n\n\nfunction toDouble(serializer, value) {\n  if (serializer.useProto3Json) {\n    if (isNaN(value)) {\n      return {\n        doubleValue: 'NaN'\n      };\n    } else if (value === Infinity) {\n      return {\n        doubleValue: 'Infinity'\n      };\n    } else if (value === -Infinity) {\n      return {\n        doubleValue: '-Infinity'\n      };\n    }\n  }\n\n  return {\n    doubleValue: isNegativeZero(value) ? '-0' : value\n  };\n}\n/**\r\n * Returns an IntegerValue for `value`.\r\n */\n\n\nfunction toInteger(value) {\n  return {\n    integerValue: '' + value\n  };\n}\n/**\r\n * Returns a value for a number that's appropriate to put into a proto.\r\n * The return value is an IntegerValue if it can safely represent the value,\r\n * otherwise a DoubleValue is returned.\r\n */\n\n\nfunction toNumber(serializer, value) {\n  return isSafeInteger(value) ? toInteger(value) : toDouble(serializer, value);\n}\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Used to represent a field transform on a mutation. */\n\n\nvar TransformOperation =\n/** @class */\nfunction () {\n  function TransformOperation() {\n    // Make sure that the structural type of `TransformOperation` is unique.\n    // See https://github.com/microsoft/TypeScript/issues/5451\n    this._ = undefined;\n  }\n\n  return TransformOperation;\n}();\n/**\r\n * Computes the local transform result against the provided `previousValue`,\r\n * optionally using the provided localWriteTime.\r\n */\n\n\nfunction applyTransformOperationToLocalView(transform, previousValue, localWriteTime) {\n  if (transform instanceof ServerTimestampTransform) {\n    return serverTimestamp(localWriteTime, previousValue);\n  } else if (transform instanceof ArrayUnionTransformOperation) {\n    return applyArrayUnionTransformOperation(transform, previousValue);\n  } else if (transform instanceof ArrayRemoveTransformOperation) {\n    return applyArrayRemoveTransformOperation(transform, previousValue);\n  } else {\n    return applyNumericIncrementTransformOperationToLocalView(transform, previousValue);\n  }\n}\n/**\r\n * Computes a final transform result after the transform has been acknowledged\r\n * by the server, potentially using the server-provided transformResult.\r\n */\n\n\nfunction applyTransformOperationToRemoteDocument(transform, previousValue, transformResult) {\n  // The server just sends null as the transform result for array operations,\n  // so we have to calculate a result the same as we do for local\n  // applications.\n  if (transform instanceof ArrayUnionTransformOperation) {\n    return applyArrayUnionTransformOperation(transform, previousValue);\n  } else if (transform instanceof ArrayRemoveTransformOperation) {\n    return applyArrayRemoveTransformOperation(transform, previousValue);\n  }\n\n  return transformResult;\n}\n/**\r\n * If this transform operation is not idempotent, returns the base value to\r\n * persist for this transform. If a base value is returned, the transform\r\n * operation is always applied to this base value, even if document has\r\n * already been updated.\r\n *\r\n * Base values provide consistent behavior for non-idempotent transforms and\r\n * allow us to return the same latency-compensated value even if the backend\r\n * has already applied the transform operation. The base value is null for\r\n * idempotent transforms, as they can be re-played even if the backend has\r\n * already applied them.\r\n *\r\n * @returns a base value to store along with the mutation, or null for\r\n * idempotent transforms.\r\n */\n\n\nfunction computeTransformOperationBaseValue(transform, previousValue) {\n  if (transform instanceof NumericIncrementTransformOperation) {\n    return isNumber(previousValue) ? previousValue : {\n      integerValue: 0\n    };\n  }\n\n  return null;\n}\n\nfunction transformOperationEquals(left, right) {\n  if (left instanceof ArrayUnionTransformOperation && right instanceof ArrayUnionTransformOperation) {\n    return arrayEquals(left.elements, right.elements, valueEquals);\n  } else if (left instanceof ArrayRemoveTransformOperation && right instanceof ArrayRemoveTransformOperation) {\n    return arrayEquals(left.elements, right.elements, valueEquals);\n  } else if (left instanceof NumericIncrementTransformOperation && right instanceof NumericIncrementTransformOperation) {\n    return valueEquals(left.operand, right.operand);\n  }\n\n  return left instanceof ServerTimestampTransform && right instanceof ServerTimestampTransform;\n}\n/** Transforms a value into a server-generated timestamp. */\n\n\nvar ServerTimestampTransform =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ServerTimestampTransform, _super);\n\n  function ServerTimestampTransform() {\n    return _super !== null && _super.apply(this, arguments) || this;\n  }\n\n  return ServerTimestampTransform;\n}(TransformOperation);\n/** Transforms an array value via a union operation. */\n\n\nvar ArrayUnionTransformOperation =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ArrayUnionTransformOperation, _super);\n\n  function ArrayUnionTransformOperation(elements) {\n    var _this = _super.call(this) || this;\n\n    _this.elements = elements;\n    return _this;\n  }\n\n  return ArrayUnionTransformOperation;\n}(TransformOperation);\n\nfunction applyArrayUnionTransformOperation(transform, previousValue) {\n  var values = coercedFieldValuesArray(previousValue);\n\n  var _loop_3 = function (toUnion) {\n    if (!values.some(function (element) {\n      return valueEquals(element, toUnion);\n    })) {\n      values.push(toUnion);\n    }\n  };\n\n  for (var _i = 0, _d = transform.elements; _i < _d.length; _i++) {\n    var toUnion = _d[_i];\n\n    _loop_3(toUnion);\n  }\n\n  return {\n    arrayValue: {\n      values: values\n    }\n  };\n}\n/** Transforms an array value via a remove operation. */\n\n\nvar ArrayRemoveTransformOperation =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ArrayRemoveTransformOperation, _super);\n\n  function ArrayRemoveTransformOperation(elements) {\n    var _this = _super.call(this) || this;\n\n    _this.elements = elements;\n    return _this;\n  }\n\n  return ArrayRemoveTransformOperation;\n}(TransformOperation);\n\nfunction applyArrayRemoveTransformOperation(transform, previousValue) {\n  var values = coercedFieldValuesArray(previousValue);\n\n  var _loop_4 = function (toRemove) {\n    values = values.filter(function (element) {\n      return !valueEquals(element, toRemove);\n    });\n  };\n\n  for (var _i = 0, _d = transform.elements; _i < _d.length; _i++) {\n    var toRemove = _d[_i];\n\n    _loop_4(toRemove);\n  }\n\n  return {\n    arrayValue: {\n      values: values\n    }\n  };\n}\n/**\r\n * Implements the backend semantics for locally computed NUMERIC_ADD (increment)\r\n * transforms. Converts all field values to integers or doubles, but unlike the\r\n * backend does not cap integer values at 2^63. Instead, JavaScript number\r\n * arithmetic is used and precision loss can occur for values greater than 2^53.\r\n */\n\n\nvar NumericIncrementTransformOperation =\n/** @class */\nfunction (_super) {\n  tslib.__extends(NumericIncrementTransformOperation, _super);\n\n  function NumericIncrementTransformOperation(serializer, operand) {\n    var _this = _super.call(this) || this;\n\n    _this.serializer = serializer;\n    _this.operand = operand;\n    return _this;\n  }\n\n  return NumericIncrementTransformOperation;\n}(TransformOperation);\n\nfunction applyNumericIncrementTransformOperationToLocalView(transform, previousValue) {\n  // PORTING NOTE: Since JavaScript's integer arithmetic is limited to 53 bit\n  // precision and resolves overflows by reducing precision, we do not\n  // manually cap overflows at 2^63.\n  var baseValue = computeTransformOperationBaseValue(transform, previousValue);\n  var sum = asNumber(baseValue) + asNumber(transform.operand);\n\n  if (isInteger(baseValue) && isInteger(transform.operand)) {\n    return toInteger(sum);\n  } else {\n    return toDouble(transform.serializer, sum);\n  }\n}\n\nfunction asNumber(value) {\n  return normalizeNumber(value.integerValue || value.doubleValue);\n}\n\nfunction coercedFieldValuesArray(value) {\n  return isArray(value) && value.arrayValue.values ? value.arrayValue.values.slice() : [];\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** A field path and the TransformOperation to perform upon it. */\n\n\nvar FieldTransform =\n/** @class */\nfunction () {\n  function FieldTransform(field, transform) {\n    this.field = field;\n    this.transform = transform;\n  }\n\n  return FieldTransform;\n}();\n\nfunction fieldTransformEquals(left, right) {\n  return left.field.isEqual(right.field) && transformOperationEquals(left.transform, right.transform);\n}\n\nfunction fieldTransformsAreEqual(left, right) {\n  if (left === undefined && right === undefined) {\n    return true;\n  }\n\n  if (left && right) {\n    return arrayEquals(left, right, function (l, r) {\n      return fieldTransformEquals(l, r);\n    });\n  }\n\n  return false;\n}\n/** The result of successfully applying a mutation to the backend. */\n\n\nvar MutationResult =\n/** @class */\nfunction () {\n  function MutationResult(\n  /**\r\n   * The version at which the mutation was committed:\r\n   *\r\n   * - For most operations, this is the updateTime in the WriteResult.\r\n   * - For deletes, the commitTime of the WriteResponse (because deletes are\r\n   *   not stored and have no updateTime).\r\n   *\r\n   * Note that these versions can be different: No-op writes will not change\r\n   * the updateTime even though the commitTime advances.\r\n   */\n  version,\n  /**\r\n   * The resulting fields returned from the backend after a mutation\r\n   * containing field transforms has been committed. Contains one FieldValue\r\n   * for each FieldTransform that was in the mutation.\r\n   *\r\n   * Will be empty if the mutation did not contain any field transforms.\r\n   */\n  transformResults) {\n    this.version = version;\n    this.transformResults = transformResults;\n  }\n\n  return MutationResult;\n}();\n/**\r\n * Encodes a precondition for a mutation. This follows the model that the\r\n * backend accepts with the special case of an explicit \"empty\" precondition\r\n * (meaning no precondition).\r\n */\n\n\nvar Precondition =\n/** @class */\nfunction () {\n  function Precondition(updateTime, exists) {\n    this.updateTime = updateTime;\n    this.exists = exists;\n  }\n  /** Creates a new empty Precondition. */\n\n\n  Precondition.none = function () {\n    return new Precondition();\n  };\n  /** Creates a new Precondition with an exists flag. */\n\n\n  Precondition.exists = function (exists) {\n    return new Precondition(undefined, exists);\n  };\n  /** Creates a new Precondition based on a version a document exists at. */\n\n\n  Precondition.updateTime = function (version) {\n    return new Precondition(version);\n  };\n\n  Object.defineProperty(Precondition.prototype, \"isNone\", {\n    /** Returns whether this Precondition is empty. */\n    get: function () {\n      return this.updateTime === undefined && this.exists === undefined;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  Precondition.prototype.isEqual = function (other) {\n    return this.exists === other.exists && (this.updateTime ? !!other.updateTime && this.updateTime.isEqual(other.updateTime) : !other.updateTime);\n  };\n\n  return Precondition;\n}();\n/** Returns true if the preconditions is valid for the given document. */\n\n\nfunction preconditionIsValidForDocument(precondition, document) {\n  if (precondition.updateTime !== undefined) {\n    return document.isFoundDocument() && document.version.isEqual(precondition.updateTime);\n  } else if (precondition.exists !== undefined) {\n    return precondition.exists === document.isFoundDocument();\n  } else {\n    return true;\n  }\n}\n/**\r\n * A mutation describes a self-contained change to a document. Mutations can\r\n * create, replace, delete, and update subsets of documents.\r\n *\r\n * Mutations not only act on the value of the document but also its version.\r\n *\r\n * For local mutations (mutations that haven't been committed yet), we preserve\r\n * the existing version for Set and Patch mutations. For Delete mutations, we\r\n * reset the version to 0.\r\n *\r\n * Here's the expected transition table.\r\n *\r\n * MUTATION           APPLIED TO            RESULTS IN\r\n *\r\n * SetMutation        Document(v3)          Document(v3)\r\n * SetMutation        NoDocument(v3)        Document(v0)\r\n * SetMutation        InvalidDocument(v0)   Document(v0)\r\n * PatchMutation      Document(v3)          Document(v3)\r\n * PatchMutation      NoDocument(v3)        NoDocument(v3)\r\n * PatchMutation      InvalidDocument(v0)   UnknownDocument(v3)\r\n * DeleteMutation     Document(v3)          NoDocument(v0)\r\n * DeleteMutation     NoDocument(v3)        NoDocument(v0)\r\n * DeleteMutation     InvalidDocument(v0)   NoDocument(v0)\r\n *\r\n * For acknowledged mutations, we use the updateTime of the WriteResponse as\r\n * the resulting version for Set and Patch mutations. As deletes have no\r\n * explicit update time, we use the commitTime of the WriteResponse for\r\n * Delete mutations.\r\n *\r\n * If a mutation is acknowledged by the backend but fails the precondition check\r\n * locally, we transition to an `UnknownDocument` and rely on Watch to send us\r\n * the updated version.\r\n *\r\n * Field transforms are used only with Patch and Set Mutations. We use the\r\n * `updateTransforms` message to store transforms, rather than the `transforms`s\r\n * messages.\r\n *\r\n * ## Subclassing Notes\r\n *\r\n * Every type of mutation needs to implement its own applyToRemoteDocument() and\r\n * applyToLocalView() to implement the actual behavior of applying the mutation\r\n * to some source document (see `applySetMutationToRemoteDocument()` for an\r\n * example).\r\n */\n\n\nvar Mutation =\n/** @class */\nfunction () {\n  function Mutation() {}\n\n  return Mutation;\n}();\n/**\r\n * Applies this mutation to the given document for the purposes of computing a\r\n * new remote document. If the input document doesn't match the expected state\r\n * (e.g. it is invalid or outdated), the document type may transition to\r\n * unknown.\r\n *\r\n * @param mutation - The mutation to apply.\r\n * @param document - The document to mutate. The input document can be an\r\n *     invalid document if the client has no knowledge of the pre-mutation state\r\n *     of the document.\r\n * @param mutationResult - The result of applying the mutation from the backend.\r\n */\n\n\nfunction applyMutationToRemoteDocument(mutation, document, mutationResult) {\n  if (mutation instanceof SetMutation) {\n    applySetMutationToRemoteDocument(mutation, document, mutationResult);\n  } else if (mutation instanceof PatchMutation) {\n    applyPatchMutationToRemoteDocument(mutation, document, mutationResult);\n  } else {\n    applyDeleteMutationToRemoteDocument(mutation, document, mutationResult);\n  }\n}\n/**\r\n * Applies this mutation to the given document for the purposes of computing\r\n * the new local view of a document. If the input document doesn't match the\r\n * expected state, the document is not modified.\r\n *\r\n * @param mutation - The mutation to apply.\r\n * @param document - The document to mutate. The input document can be an\r\n *     invalid document if the client has no knowledge of the pre-mutation state\r\n *     of the document.\r\n * @param localWriteTime - A timestamp indicating the local write time of the\r\n *     batch this mutation is a part of.\r\n */\n\n\nfunction applyMutationToLocalView(mutation, document, localWriteTime) {\n  if (mutation instanceof SetMutation) {\n    applySetMutationToLocalView(mutation, document, localWriteTime);\n  } else if (mutation instanceof PatchMutation) {\n    applyPatchMutationToLocalView(mutation, document, localWriteTime);\n  } else {\n    applyDeleteMutationToLocalView(mutation, document);\n  }\n}\n/**\r\n * If this mutation is not idempotent, returns the base value to persist with\r\n * this mutation. If a base value is returned, the mutation is always applied\r\n * to this base value, even if document has already been updated.\r\n *\r\n * The base value is a sparse object that consists of only the document\r\n * fields for which this mutation contains a non-idempotent transformation\r\n * (e.g. a numeric increment). The provided value guarantees consistent\r\n * behavior for non-idempotent transforms and allow us to return the same\r\n * latency-compensated value even if the backend has already applied the\r\n * mutation. The base value is null for idempotent mutations, as they can be\r\n * re-played even if the backend has already applied them.\r\n *\r\n * @returns a base value to store along with the mutation, or null for\r\n * idempotent mutations.\r\n */\n\n\nfunction extractMutationBaseValue(mutation, document) {\n  var baseObject = null;\n\n  for (var _i = 0, _d = mutation.fieldTransforms; _i < _d.length; _i++) {\n    var fieldTransform = _d[_i];\n    var existingValue = document.data.field(fieldTransform.field);\n    var coercedValue = computeTransformOperationBaseValue(fieldTransform.transform, existingValue || null);\n\n    if (coercedValue != null) {\n      if (baseObject == null) {\n        baseObject = ObjectValue.empty();\n      }\n\n      baseObject.set(fieldTransform.field, coercedValue);\n    }\n  }\n\n  return baseObject ? baseObject : null;\n}\n\nfunction mutationEquals(left, right) {\n  if (left.type !== right.type) {\n    return false;\n  }\n\n  if (!left.key.isEqual(right.key)) {\n    return false;\n  }\n\n  if (!left.precondition.isEqual(right.precondition)) {\n    return false;\n  }\n\n  if (!fieldTransformsAreEqual(left.fieldTransforms, right.fieldTransforms)) {\n    return false;\n  }\n\n  if (left.type === 0\n  /* Set */\n  ) {\n      return left.value.isEqual(right.value);\n    }\n\n  if (left.type === 1\n  /* Patch */\n  ) {\n      return left.data.isEqual(right.data) && left.fieldMask.isEqual(right.fieldMask);\n    }\n\n  return true;\n}\n/**\r\n * Returns the version from the given document for use as the result of a\r\n * mutation. Mutations are defined to return the version of the base document\r\n * only if it is an existing document. Deleted and unknown documents have a\r\n * post-mutation version of SnapshotVersion.min().\r\n */\n\n\nfunction getPostMutationVersion(document) {\n  return document.isFoundDocument() ? document.version : SnapshotVersion.min();\n}\n/**\r\n * A mutation that creates or replaces the document at the given key with the\r\n * object value contents.\r\n */\n\n\nvar SetMutation =\n/** @class */\nfunction (_super) {\n  tslib.__extends(SetMutation, _super);\n\n  function SetMutation(key, value, precondition, fieldTransforms) {\n    if (fieldTransforms === void 0) {\n      fieldTransforms = [];\n    }\n\n    var _this = _super.call(this) || this;\n\n    _this.key = key;\n    _this.value = value;\n    _this.precondition = precondition;\n    _this.fieldTransforms = fieldTransforms;\n    _this.type = 0\n    /* Set */\n    ;\n    return _this;\n  }\n\n  return SetMutation;\n}(Mutation);\n\nfunction applySetMutationToRemoteDocument(mutation, document, mutationResult) {\n  // Unlike applySetMutationToLocalView, if we're applying a mutation to a\n  // remote document the server has accepted the mutation so the precondition\n  // must have held.\n  var newData = mutation.value.clone();\n  var transformResults = serverTransformResults(mutation.fieldTransforms, document, mutationResult.transformResults);\n  newData.setAll(transformResults);\n  document.convertToFoundDocument(mutationResult.version, newData).setHasCommittedMutations();\n}\n\nfunction applySetMutationToLocalView(mutation, document, localWriteTime) {\n  if (!preconditionIsValidForDocument(mutation.precondition, document)) {\n    // The mutation failed to apply (e.g. a document ID created with add()\n    // caused a name collision).\n    return;\n  }\n\n  var newData = mutation.value.clone();\n  var transformResults = localTransformResults(mutation.fieldTransforms, localWriteTime, document);\n  newData.setAll(transformResults);\n  document.convertToFoundDocument(getPostMutationVersion(document), newData).setHasLocalMutations();\n}\n/**\r\n * A mutation that modifies fields of the document at the given key with the\r\n * given values. The values are applied through a field mask:\r\n *\r\n *  * When a field is in both the mask and the values, the corresponding field\r\n *    is updated.\r\n *  * When a field is in neither the mask nor the values, the corresponding\r\n *    field is unmodified.\r\n *  * When a field is in the mask but not in the values, the corresponding field\r\n *    is deleted.\r\n *  * When a field is not in the mask but is in the values, the values map is\r\n *    ignored.\r\n */\n\n\nvar PatchMutation =\n/** @class */\nfunction (_super) {\n  tslib.__extends(PatchMutation, _super);\n\n  function PatchMutation(key, data, fieldMask, precondition, fieldTransforms) {\n    if (fieldTransforms === void 0) {\n      fieldTransforms = [];\n    }\n\n    var _this = _super.call(this) || this;\n\n    _this.key = key;\n    _this.data = data;\n    _this.fieldMask = fieldMask;\n    _this.precondition = precondition;\n    _this.fieldTransforms = fieldTransforms;\n    _this.type = 1\n    /* Patch */\n    ;\n    return _this;\n  }\n\n  return PatchMutation;\n}(Mutation);\n\nfunction applyPatchMutationToRemoteDocument(mutation, document, mutationResult) {\n  if (!preconditionIsValidForDocument(mutation.precondition, document)) {\n    // Since the mutation was not rejected, we know that the precondition\n    // matched on the backend. We therefore must not have the expected version\n    // of the document in our cache and convert to an UnknownDocument with a\n    // known updateTime.\n    document.convertToUnknownDocument(mutationResult.version);\n    return;\n  }\n\n  var transformResults = serverTransformResults(mutation.fieldTransforms, document, mutationResult.transformResults);\n  var newData = document.data;\n  newData.setAll(getPatch(mutation));\n  newData.setAll(transformResults);\n  document.convertToFoundDocument(mutationResult.version, newData).setHasCommittedMutations();\n}\n\nfunction applyPatchMutationToLocalView(mutation, document, localWriteTime) {\n  if (!preconditionIsValidForDocument(mutation.precondition, document)) {\n    return;\n  }\n\n  var transformResults = localTransformResults(mutation.fieldTransforms, localWriteTime, document);\n  var newData = document.data;\n  newData.setAll(getPatch(mutation));\n  newData.setAll(transformResults);\n  document.convertToFoundDocument(getPostMutationVersion(document), newData).setHasLocalMutations();\n}\n/**\r\n * Returns a FieldPath/Value map with the content of the PatchMutation.\r\n */\n\n\nfunction getPatch(mutation) {\n  var result = new Map();\n  mutation.fieldMask.fields.forEach(function (fieldPath) {\n    if (!fieldPath.isEmpty()) {\n      var newValue = mutation.data.field(fieldPath);\n      result.set(fieldPath, newValue);\n    }\n  });\n  return result;\n}\n/**\r\n * Creates a list of \"transform results\" (a transform result is a field value\r\n * representing the result of applying a transform) for use after a mutation\r\n * containing transforms has been acknowledged by the server.\r\n *\r\n * @param fieldTransforms - The field transforms to apply the result to.\r\n * @param mutableDocument - The current state of the document after applying all\r\n * previous mutations.\r\n * @param serverTransformResults - The transform results received by the server.\r\n * @returns The transform results list.\r\n */\n\n\nfunction serverTransformResults(fieldTransforms, mutableDocument, serverTransformResults) {\n  var transformResults = new Map();\n  hardAssert(fieldTransforms.length === serverTransformResults.length);\n\n  for (var i = 0; i < serverTransformResults.length; i++) {\n    var fieldTransform = fieldTransforms[i];\n    var transform = fieldTransform.transform;\n    var previousValue = mutableDocument.data.field(fieldTransform.field);\n    transformResults.set(fieldTransform.field, applyTransformOperationToRemoteDocument(transform, previousValue, serverTransformResults[i]));\n  }\n\n  return transformResults;\n}\n/**\r\n * Creates a list of \"transform results\" (a transform result is a field value\r\n * representing the result of applying a transform) for use when applying a\r\n * transform locally.\r\n *\r\n * @param fieldTransforms - The field transforms to apply the result to.\r\n * @param localWriteTime - The local time of the mutation (used to\r\n *     generate ServerTimestampValues).\r\n * @param mutableDocument - The current state of the document after applying all\r\n *     previous mutations.\r\n * @returns The transform results list.\r\n */\n\n\nfunction localTransformResults(fieldTransforms, localWriteTime, mutableDocument) {\n  var transformResults = new Map();\n\n  for (var _i = 0, fieldTransforms_1 = fieldTransforms; _i < fieldTransforms_1.length; _i++) {\n    var fieldTransform = fieldTransforms_1[_i];\n    var transform = fieldTransform.transform;\n    var previousValue = mutableDocument.data.field(fieldTransform.field);\n    transformResults.set(fieldTransform.field, applyTransformOperationToLocalView(transform, previousValue, localWriteTime));\n  }\n\n  return transformResults;\n}\n/** A mutation that deletes the document at the given key. */\n\n\nvar DeleteMutation =\n/** @class */\nfunction (_super) {\n  tslib.__extends(DeleteMutation, _super);\n\n  function DeleteMutation(key, precondition) {\n    var _this = _super.call(this) || this;\n\n    _this.key = key;\n    _this.precondition = precondition;\n    _this.type = 2\n    /* Delete */\n    ;\n    _this.fieldTransforms = [];\n    return _this;\n  }\n\n  return DeleteMutation;\n}(Mutation);\n\nfunction applyDeleteMutationToRemoteDocument(mutation, document, mutationResult) {\n  // Unlike applyToLocalView, if we're applying a mutation to a remote\n  // document the server has accepted the mutation so the precondition must\n  // have held.\n  document.convertToNoDocument(mutationResult.version).setHasCommittedMutations();\n}\n\nfunction applyDeleteMutationToLocalView(mutation, document) {\n  if (preconditionIsValidForDocument(mutation.precondition, document)) {\n    // We don't call `setHasLocalMutations()` since we want to be backwards\n    // compatible with the existing SDK behavior.\n    document.convertToNoDocument(SnapshotVersion.min());\n  }\n}\n/**\r\n * A mutation that verifies the existence of the document at the given key with\r\n * the provided precondition.\r\n *\r\n * The `verify` operation is only used in Transactions, and this class serves\r\n * primarily to facilitate serialization into protos.\r\n */\n\n\nvar VerifyMutation =\n/** @class */\nfunction (_super) {\n  tslib.__extends(VerifyMutation, _super);\n\n  function VerifyMutation(key, precondition) {\n    var _this = _super.call(this) || this;\n\n    _this.key = key;\n    _this.precondition = precondition;\n    _this.type = 3\n    /* Verify */\n    ;\n    _this.fieldTransforms = [];\n    return _this;\n  }\n\n  return VerifyMutation;\n}(Mutation);\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A batch of mutations that will be sent as one unit to the backend.\r\n */\n\n\nvar MutationBatch =\n/** @class */\nfunction () {\n  /**\r\n   * @param batchId - The unique ID of this mutation batch.\r\n   * @param localWriteTime - The original write time of this mutation.\r\n   * @param baseMutations - Mutations that are used to populate the base\r\n   * values when this mutation is applied locally. This can be used to locally\r\n   * overwrite values that are persisted in the remote document cache. Base\r\n   * mutations are never sent to the backend.\r\n   * @param mutations - The user-provided mutations in this mutation batch.\r\n   * User-provided mutations are applied both locally and remotely on the\r\n   * backend.\r\n   */\n  function MutationBatch(batchId, localWriteTime, baseMutations, mutations) {\n    this.batchId = batchId;\n    this.localWriteTime = localWriteTime;\n    this.baseMutations = baseMutations;\n    this.mutations = mutations;\n  }\n  /**\r\n   * Applies all the mutations in this MutationBatch to the specified document\r\n   * to compute the state of the remote document\r\n   *\r\n   * @param document - The document to apply mutations to.\r\n   * @param batchResult - The result of applying the MutationBatch to the\r\n   * backend.\r\n   */\n\n\n  MutationBatch.prototype.applyToRemoteDocument = function (document, batchResult) {\n    var mutationResults = batchResult.mutationResults;\n\n    for (var i = 0; i < this.mutations.length; i++) {\n      var mutation = this.mutations[i];\n\n      if (mutation.key.isEqual(document.key)) {\n        var mutationResult = mutationResults[i];\n        applyMutationToRemoteDocument(mutation, document, mutationResult);\n      }\n    }\n  };\n  /**\r\n   * Computes the local view of a document given all the mutations in this\r\n   * batch.\r\n   *\r\n   * @param document - The document to apply mutations to.\r\n   */\n\n\n  MutationBatch.prototype.applyToLocalView = function (document) {\n    // First, apply the base state. This allows us to apply non-idempotent\n    // transform against a consistent set of values.\n    for (var _i = 0, _d = this.baseMutations; _i < _d.length; _i++) {\n      var mutation = _d[_i];\n\n      if (mutation.key.isEqual(document.key)) {\n        applyMutationToLocalView(mutation, document, this.localWriteTime);\n      }\n    } // Second, apply all user-provided mutations.\n\n\n    for (var _e = 0, _f = this.mutations; _e < _f.length; _e++) {\n      var mutation = _f[_e];\n\n      if (mutation.key.isEqual(document.key)) {\n        applyMutationToLocalView(mutation, document, this.localWriteTime);\n      }\n    }\n  };\n  /**\r\n   * Computes the local view for all provided documents given the mutations in\r\n   * this batch.\r\n   */\n\n\n  MutationBatch.prototype.applyToLocalDocumentSet = function (documentMap) {\n    var _this = this; // TODO(mrschmidt): This implementation is O(n^2). If we apply the mutations\n    // directly (as done in `applyToLocalView()`), we can reduce the complexity\n    // to O(n).\n\n\n    this.mutations.forEach(function (m) {\n      var document = documentMap.get(m.key); // TODO(mutabledocuments): This method should take a MutableDocumentMap\n      // and we should remove this cast.\n\n      var mutableDocument = document;\n\n      _this.applyToLocalView(mutableDocument);\n\n      if (!document.isValidDocument()) {\n        mutableDocument.convertToNoDocument(SnapshotVersion.min());\n      }\n    });\n  };\n\n  MutationBatch.prototype.keys = function () {\n    return this.mutations.reduce(function (keys, m) {\n      return keys.add(m.key);\n    }, documentKeySet());\n  };\n\n  MutationBatch.prototype.isEqual = function (other) {\n    return this.batchId === other.batchId && arrayEquals(this.mutations, other.mutations, function (l, r) {\n      return mutationEquals(l, r);\n    }) && arrayEquals(this.baseMutations, other.baseMutations, function (l, r) {\n      return mutationEquals(l, r);\n    });\n  };\n\n  return MutationBatch;\n}();\n/** The result of applying a mutation batch to the backend. */\n\n\nvar MutationBatchResult =\n/** @class */\nfunction () {\n  function MutationBatchResult(batch, commitVersion, mutationResults,\n  /**\r\n   * A pre-computed mapping from each mutated document to the resulting\r\n   * version.\r\n   */\n  docVersions) {\n    this.batch = batch;\n    this.commitVersion = commitVersion;\n    this.mutationResults = mutationResults;\n    this.docVersions = docVersions;\n  }\n  /**\r\n   * Creates a new MutationBatchResult for the given batch and results. There\r\n   * must be one result for each mutation in the batch. This static factory\r\n   * caches a document=&gt;version mapping (docVersions).\r\n   */\n\n\n  MutationBatchResult.from = function (batch, commitVersion, results) {\n    hardAssert(batch.mutations.length === results.length);\n    var versionMap = documentVersionMap();\n    var mutations = batch.mutations;\n\n    for (var i = 0; i < mutations.length; i++) {\n      versionMap = versionMap.insert(mutations[i].key, results[i].version);\n    }\n\n    return new MutationBatchResult(batch, commitVersion, results, versionMap);\n  };\n\n  return MutationBatchResult;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar ExistenceFilter =\n/** @class */\nfunction () {\n  // TODO(b/33078163): just use simplest form of existence filter for now\n  function ExistenceFilter(count) {\n    this.count = count;\n  }\n\n  return ExistenceFilter;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Error Codes describing the different ways GRPC can fail. These are copied\r\n * directly from GRPC's sources here:\r\n *\r\n * https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\r\n *\r\n * Important! The names of these identifiers matter because the string forms\r\n * are used for reverse lookups from the webchannel stream. Do NOT change the\r\n * names of these identifiers or change this into a const enum.\r\n */\n\n\nvar RpcCode;\n\n(function (RpcCode) {\n  RpcCode[RpcCode[\"OK\"] = 0] = \"OK\";\n  RpcCode[RpcCode[\"CANCELLED\"] = 1] = \"CANCELLED\";\n  RpcCode[RpcCode[\"UNKNOWN\"] = 2] = \"UNKNOWN\";\n  RpcCode[RpcCode[\"INVALID_ARGUMENT\"] = 3] = \"INVALID_ARGUMENT\";\n  RpcCode[RpcCode[\"DEADLINE_EXCEEDED\"] = 4] = \"DEADLINE_EXCEEDED\";\n  RpcCode[RpcCode[\"NOT_FOUND\"] = 5] = \"NOT_FOUND\";\n  RpcCode[RpcCode[\"ALREADY_EXISTS\"] = 6] = \"ALREADY_EXISTS\";\n  RpcCode[RpcCode[\"PERMISSION_DENIED\"] = 7] = \"PERMISSION_DENIED\";\n  RpcCode[RpcCode[\"UNAUTHENTICATED\"] = 16] = \"UNAUTHENTICATED\";\n  RpcCode[RpcCode[\"RESOURCE_EXHAUSTED\"] = 8] = \"RESOURCE_EXHAUSTED\";\n  RpcCode[RpcCode[\"FAILED_PRECONDITION\"] = 9] = \"FAILED_PRECONDITION\";\n  RpcCode[RpcCode[\"ABORTED\"] = 10] = \"ABORTED\";\n  RpcCode[RpcCode[\"OUT_OF_RANGE\"] = 11] = \"OUT_OF_RANGE\";\n  RpcCode[RpcCode[\"UNIMPLEMENTED\"] = 12] = \"UNIMPLEMENTED\";\n  RpcCode[RpcCode[\"INTERNAL\"] = 13] = \"INTERNAL\";\n  RpcCode[RpcCode[\"UNAVAILABLE\"] = 14] = \"UNAVAILABLE\";\n  RpcCode[RpcCode[\"DATA_LOSS\"] = 15] = \"DATA_LOSS\";\n})(RpcCode || (RpcCode = {}));\n/**\r\n * Determines whether an error code represents a permanent error when received\r\n * in response to a non-write operation.\r\n *\r\n * See isPermanentWriteError for classifying write errors.\r\n */\n\n\nfunction isPermanentError(code) {\n  switch (code) {\n    case Code.OK:\n      return fail();\n\n    case Code.CANCELLED:\n    case Code.UNKNOWN:\n    case Code.DEADLINE_EXCEEDED:\n    case Code.RESOURCE_EXHAUSTED:\n    case Code.INTERNAL:\n    case Code.UNAVAILABLE: // Unauthenticated means something went wrong with our token and we need\n    // to retry with new credentials which will happen automatically.\n\n    case Code.UNAUTHENTICATED:\n      return false;\n\n    case Code.INVALID_ARGUMENT:\n    case Code.NOT_FOUND:\n    case Code.ALREADY_EXISTS:\n    case Code.PERMISSION_DENIED:\n    case Code.FAILED_PRECONDITION: // Aborted might be retried in some scenarios, but that is dependant on\n    // the context and should handled individually by the calling code.\n    // See https://cloud.google.com/apis/design/errors.\n\n    case Code.ABORTED:\n    case Code.OUT_OF_RANGE:\n    case Code.UNIMPLEMENTED:\n    case Code.DATA_LOSS:\n      return true;\n\n    default:\n      return fail();\n  }\n}\n/**\r\n * Determines whether an error code represents a permanent error when received\r\n * in response to a write operation.\r\n *\r\n * Write operations must be handled specially because as of b/119437764, ABORTED\r\n * errors on the write stream should be retried too (even though ABORTED errors\r\n * are not generally retryable).\r\n *\r\n * Note that during the initial handshake on the write stream an ABORTED error\r\n * signals that we should discard our stream token (i.e. it is permanent). This\r\n * means a handshake error should be classified with isPermanentError, above.\r\n */\n\n\nfunction isPermanentWriteError(code) {\n  return isPermanentError(code) && code !== Code.ABORTED;\n}\n/**\r\n * Maps an error Code from GRPC status code number, like 0, 1, or 14. These\r\n * are not the same as HTTP status codes.\r\n *\r\n * @returns The Code equivalent to the given GRPC status code. Fails if there\r\n *     is no match.\r\n */\n\n\nfunction mapCodeFromRpcCode(code) {\n  if (code === undefined) {\n    // This shouldn't normally happen, but in certain error cases (like trying\n    // to send invalid proto messages) we may get an error with no GRPC code.\n    logError('GRPC error has no .code');\n    return Code.UNKNOWN;\n  }\n\n  switch (code) {\n    case RpcCode.OK:\n      return Code.OK;\n\n    case RpcCode.CANCELLED:\n      return Code.CANCELLED;\n\n    case RpcCode.UNKNOWN:\n      return Code.UNKNOWN;\n\n    case RpcCode.DEADLINE_EXCEEDED:\n      return Code.DEADLINE_EXCEEDED;\n\n    case RpcCode.RESOURCE_EXHAUSTED:\n      return Code.RESOURCE_EXHAUSTED;\n\n    case RpcCode.INTERNAL:\n      return Code.INTERNAL;\n\n    case RpcCode.UNAVAILABLE:\n      return Code.UNAVAILABLE;\n\n    case RpcCode.UNAUTHENTICATED:\n      return Code.UNAUTHENTICATED;\n\n    case RpcCode.INVALID_ARGUMENT:\n      return Code.INVALID_ARGUMENT;\n\n    case RpcCode.NOT_FOUND:\n      return Code.NOT_FOUND;\n\n    case RpcCode.ALREADY_EXISTS:\n      return Code.ALREADY_EXISTS;\n\n    case RpcCode.PERMISSION_DENIED:\n      return Code.PERMISSION_DENIED;\n\n    case RpcCode.FAILED_PRECONDITION:\n      return Code.FAILED_PRECONDITION;\n\n    case RpcCode.ABORTED:\n      return Code.ABORTED;\n\n    case RpcCode.OUT_OF_RANGE:\n      return Code.OUT_OF_RANGE;\n\n    case RpcCode.UNIMPLEMENTED:\n      return Code.UNIMPLEMENTED;\n\n    case RpcCode.DATA_LOSS:\n      return Code.DATA_LOSS;\n\n    default:\n      return fail();\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An event from the RemoteStore. It is split into targetChanges (changes to the\r\n * state or the set of documents in our watched targets) and documentUpdates\r\n * (changes to the actual documents).\r\n */\n\n\nvar RemoteEvent =\n/** @class */\nfunction () {\n  function RemoteEvent(\n  /**\r\n   * The snapshot version this event brings us up to, or MIN if not set.\r\n   */\n  snapshotVersion,\n  /**\r\n   * A map from target to changes to the target. See TargetChange.\r\n   */\n  targetChanges,\n  /**\r\n   * A set of targets that is known to be inconsistent. Listens for these\r\n   * targets should be re-established without resume tokens.\r\n   */\n  targetMismatches,\n  /**\r\n   * A set of which documents have changed or been deleted, along with the\r\n   * doc's new values (if not deleted).\r\n   */\n  documentUpdates,\n  /**\r\n   * A set of which document updates are due only to limbo resolution targets.\r\n   */\n  resolvedLimboDocuments) {\n    this.snapshotVersion = snapshotVersion;\n    this.targetChanges = targetChanges;\n    this.targetMismatches = targetMismatches;\n    this.documentUpdates = documentUpdates;\n    this.resolvedLimboDocuments = resolvedLimboDocuments;\n  }\n  /**\r\n   * HACK: Views require RemoteEvents in order to determine whether the view is\r\n   * CURRENT, but secondary tabs don't receive remote events. So this method is\r\n   * used to create a synthesized RemoteEvent that can be used to apply a\r\n   * CURRENT status change to a View, for queries executed in a different tab.\r\n   */\n  // PORTING NOTE: Multi-tab only\n\n\n  RemoteEvent.createSynthesizedRemoteEventForCurrentChange = function (targetId, current) {\n    var targetChanges = new Map();\n    targetChanges.set(targetId, TargetChange.createSynthesizedTargetChangeForCurrentChange(targetId, current));\n    return new RemoteEvent(SnapshotVersion.min(), targetChanges, targetIdSet(), mutableDocumentMap(), documentKeySet());\n  };\n\n  return RemoteEvent;\n}();\n/**\r\n * A TargetChange specifies the set of changes for a specific target as part of\r\n * a RemoteEvent. These changes track which documents are added, modified or\r\n * removed, as well as the target's resume token and whether the target is\r\n * marked CURRENT.\r\n * The actual changes *to* documents are not part of the TargetChange since\r\n * documents may be part of multiple targets.\r\n */\n\n\nvar TargetChange =\n/** @class */\nfunction () {\n  function TargetChange(\n  /**\r\n   * An opaque, server-assigned token that allows watching a query to be resumed\r\n   * after disconnecting without retransmitting all the data that matches the\r\n   * query. The resume token essentially identifies a point in time from which\r\n   * the server should resume sending results.\r\n   */\n  resumeToken,\n  /**\r\n   * The \"current\" (synced) status of this target. Note that \"current\"\r\n   * has special meaning in the RPC protocol that implies that a target is\r\n   * both up-to-date and consistent with the rest of the watch stream.\r\n   */\n  current,\n  /**\r\n   * The set of documents that were newly assigned to this target as part of\r\n   * this remote event.\r\n   */\n  addedDocuments,\n  /**\r\n   * The set of documents that were already assigned to this target but received\r\n   * an update during this remote event.\r\n   */\n  modifiedDocuments,\n  /**\r\n   * The set of documents that were removed from this target as part of this\r\n   * remote event.\r\n   */\n  removedDocuments) {\n    this.resumeToken = resumeToken;\n    this.current = current;\n    this.addedDocuments = addedDocuments;\n    this.modifiedDocuments = modifiedDocuments;\n    this.removedDocuments = removedDocuments;\n  }\n  /**\r\n   * This method is used to create a synthesized TargetChanges that can be used to\r\n   * apply a CURRENT status change to a View (for queries executed in a different\r\n   * tab) or for new queries (to raise snapshots with correct CURRENT status).\r\n   */\n\n\n  TargetChange.createSynthesizedTargetChangeForCurrentChange = function (targetId, current) {\n    return new TargetChange(ByteString.EMPTY_BYTE_STRING, current, documentKeySet(), documentKeySet(), documentKeySet());\n  };\n\n  return TargetChange;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Represents a changed document and a list of target ids to which this change\r\n * applies.\r\n *\r\n * If document has been deleted NoDocument will be provided.\r\n */\n\n\nvar DocumentWatchChange =\n/** @class */\nfunction () {\n  function DocumentWatchChange(\n  /** The new document applies to all of these targets. */\n  updatedTargetIds,\n  /** The new document is removed from all of these targets. */\n  removedTargetIds,\n  /** The key of the document for this change. */\n  key,\n  /**\r\n   * The new document or NoDocument if it was deleted. Is null if the\r\n   * document went out of view without the server sending a new document.\r\n   */\n  newDoc) {\n    this.updatedTargetIds = updatedTargetIds;\n    this.removedTargetIds = removedTargetIds;\n    this.key = key;\n    this.newDoc = newDoc;\n  }\n\n  return DocumentWatchChange;\n}();\n\nvar ExistenceFilterChange =\n/** @class */\nfunction () {\n  function ExistenceFilterChange(targetId, existenceFilter) {\n    this.targetId = targetId;\n    this.existenceFilter = existenceFilter;\n  }\n\n  return ExistenceFilterChange;\n}();\n\nvar WatchTargetChange =\n/** @class */\nfunction () {\n  function WatchTargetChange(\n  /** What kind of change occurred to the watch target. */\n  state,\n  /** The target IDs that were added/removed/set. */\n  targetIds,\n  /**\r\n   * An opaque, server-assigned token that allows watching a target to be\r\n   * resumed after disconnecting without retransmitting all the data that\r\n   * matches the target. The resume token essentially identifies a point in\r\n   * time from which the server should resume sending results.\r\n   */\n  resumeToken,\n  /** An RPC error indicating why the watch failed. */\n  cause) {\n    if (resumeToken === void 0) {\n      resumeToken = ByteString.EMPTY_BYTE_STRING;\n    }\n\n    if (cause === void 0) {\n      cause = null;\n    }\n\n    this.state = state;\n    this.targetIds = targetIds;\n    this.resumeToken = resumeToken;\n    this.cause = cause;\n  }\n\n  return WatchTargetChange;\n}();\n/** Tracks the internal state of a Watch target. */\n\n\nvar TargetState =\n/** @class */\nfunction () {\n  function TargetState() {\n    /**\r\n     * The number of pending responses (adds or removes) that we are waiting on.\r\n     * We only consider targets active that have no pending responses.\r\n     */\n    this.pendingResponses = 0;\n    /**\r\n     * Keeps track of the document changes since the last raised snapshot.\r\n     *\r\n     * These changes are continuously updated as we receive document updates and\r\n     * always reflect the current set of changes against the last issued snapshot.\r\n     */\n\n    this.documentChanges = snapshotChangesMap();\n    /** See public getters for explanations of these fields. */\n\n    this._resumeToken = ByteString.EMPTY_BYTE_STRING;\n    this._current = false;\n    /**\r\n     * Whether this target state should be included in the next snapshot. We\r\n     * initialize to true so that newly-added targets are included in the next\r\n     * RemoteEvent.\r\n     */\n\n    this._hasPendingChanges = true;\n  }\n\n  Object.defineProperty(TargetState.prototype, \"current\", {\n    /**\r\n     * Whether this target has been marked 'current'.\r\n     *\r\n     * 'Current' has special meaning in the RPC protocol: It implies that the\r\n     * Watch backend has sent us all changes up to the point at which the target\r\n     * was added and that the target is consistent with the rest of the watch\r\n     * stream.\r\n     */\n    get: function () {\n      return this._current;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(TargetState.prototype, \"resumeToken\", {\n    /** The last resume token sent to us for this target. */\n    get: function () {\n      return this._resumeToken;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(TargetState.prototype, \"isPending\", {\n    /** Whether this target has pending target adds or target removes. */\n    get: function () {\n      return this.pendingResponses !== 0;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(TargetState.prototype, \"hasPendingChanges\", {\n    /** Whether we have modified any state that should trigger a snapshot. */\n    get: function () {\n      return this._hasPendingChanges;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Applies the resume token to the TargetChange, but only when it has a new\r\n   * value. Empty resumeTokens are discarded.\r\n   */\n\n  TargetState.prototype.updateResumeToken = function (resumeToken) {\n    if (resumeToken.approximateByteSize() > 0) {\n      this._hasPendingChanges = true;\n      this._resumeToken = resumeToken;\n    }\n  };\n  /**\r\n   * Creates a target change from the current set of changes.\r\n   *\r\n   * To reset the document changes after raising this snapshot, call\r\n   * `clearPendingChanges()`.\r\n   */\n\n\n  TargetState.prototype.toTargetChange = function () {\n    var addedDocuments = documentKeySet();\n    var modifiedDocuments = documentKeySet();\n    var removedDocuments = documentKeySet();\n    this.documentChanges.forEach(function (key, changeType) {\n      switch (changeType) {\n        case 0\n        /* Added */\n        :\n          addedDocuments = addedDocuments.add(key);\n          break;\n\n        case 2\n        /* Modified */\n        :\n          modifiedDocuments = modifiedDocuments.add(key);\n          break;\n\n        case 1\n        /* Removed */\n        :\n          removedDocuments = removedDocuments.add(key);\n          break;\n\n        default:\n          fail();\n      }\n    });\n    return new TargetChange(this._resumeToken, this._current, addedDocuments, modifiedDocuments, removedDocuments);\n  };\n  /**\r\n   * Resets the document changes and sets `hasPendingChanges` to false.\r\n   */\n\n\n  TargetState.prototype.clearPendingChanges = function () {\n    this._hasPendingChanges = false;\n    this.documentChanges = snapshotChangesMap();\n  };\n\n  TargetState.prototype.addDocumentChange = function (key, changeType) {\n    this._hasPendingChanges = true;\n    this.documentChanges = this.documentChanges.insert(key, changeType);\n  };\n\n  TargetState.prototype.removeDocumentChange = function (key) {\n    this._hasPendingChanges = true;\n    this.documentChanges = this.documentChanges.remove(key);\n  };\n\n  TargetState.prototype.recordPendingTargetRequest = function () {\n    this.pendingResponses += 1;\n  };\n\n  TargetState.prototype.recordTargetResponse = function () {\n    this.pendingResponses -= 1;\n  };\n\n  TargetState.prototype.markCurrent = function () {\n    this._hasPendingChanges = true;\n    this._current = true;\n  };\n\n  return TargetState;\n}();\n\nvar LOG_TAG$f = 'WatchChangeAggregator';\n/**\r\n * A helper class to accumulate watch changes into a RemoteEvent.\r\n */\n\nvar WatchChangeAggregator =\n/** @class */\nfunction () {\n  function WatchChangeAggregator(metadataProvider) {\n    this.metadataProvider = metadataProvider;\n    /** The internal state of all tracked targets. */\n\n    this.targetStates = new Map();\n    /** Keeps track of the documents to update since the last raised snapshot. */\n\n    this.pendingDocumentUpdates = mutableDocumentMap();\n    /** A mapping of document keys to their set of target IDs. */\n\n    this.pendingDocumentTargetMapping = documentTargetMap();\n    /**\r\n     * A list of targets with existence filter mismatches. These targets are\r\n     * known to be inconsistent and their listens needs to be re-established by\r\n     * RemoteStore.\r\n     */\n\n    this.pendingTargetResets = new SortedSet(primitiveComparator);\n  }\n  /**\r\n   * Processes and adds the DocumentWatchChange to the current set of changes.\r\n   */\n\n\n  WatchChangeAggregator.prototype.handleDocumentChange = function (docChange) {\n    for (var _i = 0, _d = docChange.updatedTargetIds; _i < _d.length; _i++) {\n      var targetId = _d[_i];\n\n      if (docChange.newDoc && docChange.newDoc.isFoundDocument()) {\n        this.addDocumentToTarget(targetId, docChange.newDoc);\n      } else {\n        this.removeDocumentFromTarget(targetId, docChange.key, docChange.newDoc);\n      }\n    }\n\n    for (var _e = 0, _f = docChange.removedTargetIds; _e < _f.length; _e++) {\n      var targetId = _f[_e];\n      this.removeDocumentFromTarget(targetId, docChange.key, docChange.newDoc);\n    }\n  };\n  /** Processes and adds the WatchTargetChange to the current set of changes. */\n\n\n  WatchChangeAggregator.prototype.handleTargetChange = function (targetChange) {\n    var _this = this;\n\n    this.forEachTarget(targetChange, function (targetId) {\n      var targetState = _this.ensureTargetState(targetId);\n\n      switch (targetChange.state) {\n        case 0\n        /* NoChange */\n        :\n          if (_this.isActiveTarget(targetId)) {\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n\n          break;\n\n        case 1\n        /* Added */\n        :\n          // We need to decrement the number of pending acks needed from watch\n          // for this targetId.\n          targetState.recordTargetResponse();\n\n          if (!targetState.isPending) {\n            // We have a freshly added target, so we need to reset any state\n            // that we had previously. This can happen e.g. when remove and add\n            // back a target for existence filter mismatches.\n            targetState.clearPendingChanges();\n          }\n\n          targetState.updateResumeToken(targetChange.resumeToken);\n          break;\n\n        case 2\n        /* Removed */\n        :\n          // We need to keep track of removed targets to we can post-filter and\n          // remove any target changes.\n          // We need to decrement the number of pending acks needed from watch\n          // for this targetId.\n          targetState.recordTargetResponse();\n\n          if (!targetState.isPending) {\n            _this.removeTarget(targetId);\n          }\n\n          break;\n\n        case 3\n        /* Current */\n        :\n          if (_this.isActiveTarget(targetId)) {\n            targetState.markCurrent();\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n\n          break;\n\n        case 4\n        /* Reset */\n        :\n          if (_this.isActiveTarget(targetId)) {\n            // Reset the target and synthesizes removes for all existing\n            // documents. The backend will re-add any documents that still\n            // match the target before it sends the next global snapshot.\n            _this.resetTarget(targetId);\n\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n\n          break;\n\n        default:\n          fail();\n      }\n    });\n  };\n  /**\r\n   * Iterates over all targetIds that the watch change applies to: either the\r\n   * targetIds explicitly listed in the change or the targetIds of all currently\r\n   * active targets.\r\n   */\n\n\n  WatchChangeAggregator.prototype.forEachTarget = function (targetChange, fn) {\n    var _this = this;\n\n    if (targetChange.targetIds.length > 0) {\n      targetChange.targetIds.forEach(fn);\n    } else {\n      this.targetStates.forEach(function (_, targetId) {\n        if (_this.isActiveTarget(targetId)) {\n          fn(targetId);\n        }\n      });\n    }\n  };\n  /**\r\n   * Handles existence filters and synthesizes deletes for filter mismatches.\r\n   * Targets that are invalidated by filter mismatches are added to\r\n   * `pendingTargetResets`.\r\n   */\n\n\n  WatchChangeAggregator.prototype.handleExistenceFilter = function (watchChange) {\n    var targetId = watchChange.targetId;\n    var expectedCount = watchChange.existenceFilter.count;\n    var targetData = this.targetDataForActiveTarget(targetId);\n\n    if (targetData) {\n      var target = targetData.target;\n\n      if (isDocumentTarget(target)) {\n        if (expectedCount === 0) {\n          // The existence filter told us the document does not exist. We deduce\n          // that this document does not exist and apply a deleted document to\n          // our updates. Without applying this deleted document there might be\n          // another query that will raise this document as part of a snapshot\n          // until it is resolved, essentially exposing inconsistency between\n          // queries.\n          var key = new DocumentKey(target.path);\n          this.removeDocumentFromTarget(targetId, key, MutableDocument.newNoDocument(key, SnapshotVersion.min()));\n        } else {\n          hardAssert(expectedCount === 1);\n        }\n      } else {\n        var currentSize = this.getCurrentDocumentCountForTarget(targetId);\n\n        if (currentSize !== expectedCount) {\n          // Existence filter mismatch: We reset the mapping and raise a new\n          // snapshot with `isFromCache:true`.\n          this.resetTarget(targetId);\n          this.pendingTargetResets = this.pendingTargetResets.add(targetId);\n        }\n      }\n    }\n  };\n  /**\r\n   * Converts the currently accumulated state into a remote event at the\r\n   * provided snapshot version. Resets the accumulated changes before returning.\r\n   */\n\n\n  WatchChangeAggregator.prototype.createRemoteEvent = function (snapshotVersion) {\n    var _this = this;\n\n    var targetChanges = new Map();\n    this.targetStates.forEach(function (targetState, targetId) {\n      var targetData = _this.targetDataForActiveTarget(targetId);\n\n      if (targetData) {\n        if (targetState.current && isDocumentTarget(targetData.target)) {\n          // Document queries for document that don't exist can produce an empty\n          // result set. To update our local cache, we synthesize a document\n          // delete if we have not previously received the document. This\n          // resolves the limbo state of the document, removing it from\n          // limboDocumentRefs.\n          //\n          // TODO(dimond): Ideally we would have an explicit lookup target\n          // instead resulting in an explicit delete message and we could\n          // remove this special logic.\n          var key = new DocumentKey(targetData.target.path);\n\n          if (_this.pendingDocumentUpdates.get(key) === null && !_this.targetContainsDocument(targetId, key)) {\n            _this.removeDocumentFromTarget(targetId, key, MutableDocument.newNoDocument(key, snapshotVersion));\n          }\n        }\n\n        if (targetState.hasPendingChanges) {\n          targetChanges.set(targetId, targetState.toTargetChange());\n          targetState.clearPendingChanges();\n        }\n      }\n    });\n    var resolvedLimboDocuments = documentKeySet(); // We extract the set of limbo-only document updates as the GC logic\n    // special-cases documents that do not appear in the target cache.\n    //\n    // TODO(gsoltis): Expand on this comment once GC is available in the JS\n    // client.\n\n    this.pendingDocumentTargetMapping.forEach(function (key, targets) {\n      var isOnlyLimboTarget = true;\n      targets.forEachWhile(function (targetId) {\n        var targetData = _this.targetDataForActiveTarget(targetId);\n\n        if (targetData && targetData.purpose !== 2\n        /* LimboResolution */\n        ) {\n            isOnlyLimboTarget = false;\n            return false;\n          }\n\n        return true;\n      });\n\n      if (isOnlyLimboTarget) {\n        resolvedLimboDocuments = resolvedLimboDocuments.add(key);\n      }\n    });\n    var remoteEvent = new RemoteEvent(snapshotVersion, targetChanges, this.pendingTargetResets, this.pendingDocumentUpdates, resolvedLimboDocuments);\n    this.pendingDocumentUpdates = mutableDocumentMap();\n    this.pendingDocumentTargetMapping = documentTargetMap();\n    this.pendingTargetResets = new SortedSet(primitiveComparator);\n    return remoteEvent;\n  };\n  /**\r\n   * Adds the provided document to the internal list of document updates and\r\n   * its document key to the given target's mapping.\r\n   */\n  // Visible for testing.\n\n\n  WatchChangeAggregator.prototype.addDocumentToTarget = function (targetId, document) {\n    if (!this.isActiveTarget(targetId)) {\n      return;\n    }\n\n    var changeType = this.targetContainsDocument(targetId, document.key) ? 2\n    /* Modified */\n    : 0\n    /* Added */\n    ;\n    var targetState = this.ensureTargetState(targetId);\n    targetState.addDocumentChange(document.key, changeType);\n    this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(document.key, document);\n    this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(document.key, this.ensureDocumentTargetMapping(document.key).add(targetId));\n  };\n  /**\r\n   * Removes the provided document from the target mapping. If the\r\n   * document no longer matches the target, but the document's state is still\r\n   * known (e.g. we know that the document was deleted or we received the change\r\n   * that caused the filter mismatch), the new document can be provided\r\n   * to update the remote document cache.\r\n   */\n  // Visible for testing.\n\n\n  WatchChangeAggregator.prototype.removeDocumentFromTarget = function (targetId, key, updatedDocument) {\n    if (!this.isActiveTarget(targetId)) {\n      return;\n    }\n\n    var targetState = this.ensureTargetState(targetId);\n\n    if (this.targetContainsDocument(targetId, key)) {\n      targetState.addDocumentChange(key, 1\n      /* Removed */\n      );\n    } else {\n      // The document may have entered and left the target before we raised a\n      // snapshot, so we can just ignore the change.\n      targetState.removeDocumentChange(key);\n    }\n\n    this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(key, this.ensureDocumentTargetMapping(key).delete(targetId));\n\n    if (updatedDocument) {\n      this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(key, updatedDocument);\n    }\n  };\n\n  WatchChangeAggregator.prototype.removeTarget = function (targetId) {\n    this.targetStates.delete(targetId);\n  };\n  /**\r\n   * Returns the current count of documents in the target. This includes both\r\n   * the number of documents that the LocalStore considers to be part of the\r\n   * target as well as any accumulated changes.\r\n   */\n\n\n  WatchChangeAggregator.prototype.getCurrentDocumentCountForTarget = function (targetId) {\n    var targetState = this.ensureTargetState(targetId);\n    var targetChange = targetState.toTargetChange();\n    return this.metadataProvider.getRemoteKeysForTarget(targetId).size + targetChange.addedDocuments.size - targetChange.removedDocuments.size;\n  };\n  /**\r\n   * Increment the number of acks needed from watch before we can consider the\r\n   * server to be 'in-sync' with the client's active targets.\r\n   */\n\n\n  WatchChangeAggregator.prototype.recordPendingTargetRequest = function (targetId) {\n    // For each request we get we need to record we need a response for it.\n    var targetState = this.ensureTargetState(targetId);\n    targetState.recordPendingTargetRequest();\n  };\n\n  WatchChangeAggregator.prototype.ensureTargetState = function (targetId) {\n    var result = this.targetStates.get(targetId);\n\n    if (!result) {\n      result = new TargetState();\n      this.targetStates.set(targetId, result);\n    }\n\n    return result;\n  };\n\n  WatchChangeAggregator.prototype.ensureDocumentTargetMapping = function (key) {\n    var targetMapping = this.pendingDocumentTargetMapping.get(key);\n\n    if (!targetMapping) {\n      targetMapping = new SortedSet(primitiveComparator);\n      this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(key, targetMapping);\n    }\n\n    return targetMapping;\n  };\n  /**\r\n   * Verifies that the user is still interested in this target (by calling\r\n   * `getTargetDataForTarget()`) and that we are not waiting for pending ADDs\r\n   * from watch.\r\n   */\n\n\n  WatchChangeAggregator.prototype.isActiveTarget = function (targetId) {\n    var targetActive = this.targetDataForActiveTarget(targetId) !== null;\n\n    if (!targetActive) {\n      logDebug(LOG_TAG$f, 'Detected inactive target', targetId);\n    }\n\n    return targetActive;\n  };\n  /**\r\n   * Returns the TargetData for an active target (i.e. a target that the user\r\n   * is still interested in that has no outstanding target change requests).\r\n   */\n\n\n  WatchChangeAggregator.prototype.targetDataForActiveTarget = function (targetId) {\n    var targetState = this.targetStates.get(targetId);\n    return targetState && targetState.isPending ? null : this.metadataProvider.getTargetDataForTarget(targetId);\n  };\n  /**\r\n   * Resets the state of a Watch target to its initial state (e.g. sets\r\n   * 'current' to false, clears the resume token and removes its target mapping\r\n   * from all documents).\r\n   */\n\n\n  WatchChangeAggregator.prototype.resetTarget = function (targetId) {\n    var _this = this;\n\n    this.targetStates.set(targetId, new TargetState()); // Trigger removal for any documents currently mapped to this target.\n    // These removals will be part of the initial snapshot if Watch does not\n    // resend these documents.\n\n    var existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\n    existingKeys.forEach(function (key) {\n      _this.removeDocumentFromTarget(targetId, key,\n      /*updatedDocument=*/\n      null);\n    });\n  };\n  /**\r\n   * Returns whether the LocalStore considers the document to be part of the\r\n   * specified target.\r\n   */\n\n\n  WatchChangeAggregator.prototype.targetContainsDocument = function (targetId, key) {\n    var existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\n    return existingKeys.has(key);\n  };\n\n  return WatchChangeAggregator;\n}();\n\nfunction documentTargetMap() {\n  return new SortedMap(DocumentKey.comparator);\n}\n\nfunction snapshotChangesMap() {\n  return new SortedMap(DocumentKey.comparator);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar DIRECTIONS = function () {\n  var dirs = {};\n  dirs[\"asc\"\n  /* ASCENDING */\n  ] = 'ASCENDING';\n  dirs[\"desc\"\n  /* DESCENDING */\n  ] = 'DESCENDING';\n  return dirs;\n}();\n\nvar OPERATORS = function () {\n  var ops = {};\n  ops[\"<\"\n  /* LESS_THAN */\n  ] = 'LESS_THAN';\n  ops[\"<=\"\n  /* LESS_THAN_OR_EQUAL */\n  ] = 'LESS_THAN_OR_EQUAL';\n  ops[\">\"\n  /* GREATER_THAN */\n  ] = 'GREATER_THAN';\n  ops[\">=\"\n  /* GREATER_THAN_OR_EQUAL */\n  ] = 'GREATER_THAN_OR_EQUAL';\n  ops[\"==\"\n  /* EQUAL */\n  ] = 'EQUAL';\n  ops[\"!=\"\n  /* NOT_EQUAL */\n  ] = 'NOT_EQUAL';\n  ops[\"array-contains\"\n  /* ARRAY_CONTAINS */\n  ] = 'ARRAY_CONTAINS';\n  ops[\"in\"\n  /* IN */\n  ] = 'IN';\n  ops[\"not-in\"\n  /* NOT_IN */\n  ] = 'NOT_IN';\n  ops[\"array-contains-any\"\n  /* ARRAY_CONTAINS_ANY */\n  ] = 'ARRAY_CONTAINS_ANY';\n  return ops;\n}();\n\nfunction assertPresent(value, description) {}\n/**\r\n * This class generates JsonObject values for the Datastore API suitable for\r\n * sending to either GRPC stub methods or via the JSON/HTTP REST API.\r\n *\r\n * The serializer supports both Protobuf.js and Proto3 JSON formats. By\r\n * setting `useProto3Json` to true, the serializer will use the Proto3 JSON\r\n * format.\r\n *\r\n * For a description of the Proto3 JSON format check\r\n * https://developers.google.com/protocol-buffers/docs/proto3#json\r\n *\r\n * TODO(klimt): We can remove the databaseId argument if we keep the full\r\n * resource name in documents.\r\n */\n\n\nvar JsonProtoSerializer =\n/** @class */\nfunction () {\n  function JsonProtoSerializer(databaseId, useProto3Json) {\n    this.databaseId = databaseId;\n    this.useProto3Json = useProto3Json;\n  }\n\n  return JsonProtoSerializer;\n}();\n\nfunction fromRpcStatus(status) {\n  var code = status.code === undefined ? Code.UNKNOWN : mapCodeFromRpcCode(status.code);\n  return new FirestoreError(code, status.message || '');\n}\n/**\r\n * Returns a value for a number (or null) that's appropriate to put into\r\n * a google.protobuf.Int32Value proto.\r\n * DO NOT USE THIS FOR ANYTHING ELSE.\r\n * This method cheats. It's typed as returning \"number\" because that's what\r\n * our generated proto interfaces say Int32Value must be. But GRPC actually\r\n * expects a { value: <number> } struct.\r\n */\n\n\nfunction toInt32Proto(serializer, val) {\n  if (serializer.useProto3Json || isNullOrUndefined(val)) {\n    return val;\n  } else {\n    return {\n      value: val\n    };\n  }\n}\n/**\r\n * Returns a number (or null) from a google.protobuf.Int32Value proto.\r\n */\n\n\nfunction fromInt32Proto(val) {\n  var result;\n\n  if (typeof val === 'object') {\n    result = val.value;\n  } else {\n    result = val;\n  }\n\n  return isNullOrUndefined(result) ? null : result;\n}\n/**\r\n * Returns a value for a Date that's appropriate to put into a proto.\r\n */\n\n\nfunction toTimestamp(serializer, timestamp) {\n  if (serializer.useProto3Json) {\n    // Serialize to ISO-8601 date format, but with full nano resolution.\n    // Since JS Date has only millis, let's only use it for the seconds and\n    // then manually add the fractions to the end.\n    var jsDateStr = new Date(timestamp.seconds * 1000).toISOString(); // Remove .xxx frac part and Z in the end.\n\n    var strUntilSeconds = jsDateStr.replace(/\\.\\d*/, '').replace('Z', ''); // Pad the fraction out to 9 digits (nanos).\n\n    var nanoStr = ('000000000' + timestamp.nanoseconds).slice(-9);\n    return strUntilSeconds + \".\" + nanoStr + \"Z\";\n  } else {\n    return {\n      seconds: '' + timestamp.seconds,\n      nanos: timestamp.nanoseconds // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n    };\n  }\n}\n\nfunction fromTimestamp(date) {\n  var timestamp = normalizeTimestamp(date);\n  return new Timestamp(timestamp.seconds, timestamp.nanos);\n}\n/**\r\n * Returns a value for bytes that's appropriate to put in a proto.\r\n *\r\n * Visible for testing.\r\n */\n\n\nfunction toBytes(serializer, bytes) {\n  if (serializer.useProto3Json) {\n    return bytes.toBase64();\n  } else {\n    return bytes.toUint8Array();\n  }\n}\n/**\r\n * Returns a ByteString based on the proto string value.\r\n */\n\n\nfunction fromBytes(serializer, value) {\n  if (serializer.useProto3Json) {\n    hardAssert(value === undefined || typeof value === 'string');\n    return ByteString.fromBase64String(value ? value : '');\n  } else {\n    hardAssert(value === undefined || value instanceof Uint8Array);\n    return ByteString.fromUint8Array(value ? value : new Uint8Array());\n  }\n}\n\nfunction toVersion(serializer, version) {\n  return toTimestamp(serializer, version.toTimestamp());\n}\n\nfunction fromVersion(version) {\n  hardAssert(!!version);\n  return SnapshotVersion.fromTimestamp(fromTimestamp(version));\n}\n\nfunction toResourceName(databaseId, path) {\n  return fullyQualifiedPrefixPath(databaseId).child('documents').child(path).canonicalString();\n}\n\nfunction fromResourceName(name) {\n  var resource = ResourcePath.fromString(name);\n  hardAssert(isValidResourceName(resource));\n  return resource;\n}\n\nfunction toName(serializer, key) {\n  return toResourceName(serializer.databaseId, key.path);\n}\n\nfunction fromName(serializer, name) {\n  var resource = fromResourceName(name);\n\n  if (resource.get(1) !== serializer.databaseId.projectId) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Tried to deserialize key from different project: ' + resource.get(1) + ' vs ' + serializer.databaseId.projectId);\n  }\n\n  if (resource.get(3) !== serializer.databaseId.database) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Tried to deserialize key from different database: ' + resource.get(3) + ' vs ' + serializer.databaseId.database);\n  }\n\n  return new DocumentKey(extractLocalPathFromResourceName(resource));\n}\n\nfunction toQueryPath(serializer, path) {\n  return toResourceName(serializer.databaseId, path);\n}\n\nfunction fromQueryPath(name) {\n  var resourceName = fromResourceName(name); // In v1beta1 queries for collections at the root did not have a trailing\n  // \"/documents\". In v1 all resource paths contain \"/documents\". Preserve the\n  // ability to read the v1beta1 form for compatibility with queries persisted\n  // in the local target cache.\n\n  if (resourceName.length === 4) {\n    return ResourcePath.emptyPath();\n  }\n\n  return extractLocalPathFromResourceName(resourceName);\n}\n\nfunction getEncodedDatabaseId(serializer) {\n  var path = new ResourcePath(['projects', serializer.databaseId.projectId, 'databases', serializer.databaseId.database]);\n  return path.canonicalString();\n}\n\nfunction fullyQualifiedPrefixPath(databaseId) {\n  return new ResourcePath(['projects', databaseId.projectId, 'databases', databaseId.database]);\n}\n\nfunction extractLocalPathFromResourceName(resourceName) {\n  hardAssert(resourceName.length > 4 && resourceName.get(4) === 'documents');\n  return resourceName.popFirst(5);\n}\n/** Creates a Document proto from key and fields (but no create/update time) */\n\n\nfunction toMutationDocument(serializer, key, fields) {\n  return {\n    name: toName(serializer, key),\n    fields: fields.value.mapValue.fields\n  };\n}\n\nfunction toDocument(serializer, document) {\n  return {\n    name: toName(serializer, document.key),\n    fields: document.data.value.mapValue.fields,\n    updateTime: toTimestamp(serializer, document.version.toTimestamp())\n  };\n}\n\nfunction fromDocument(serializer, document, hasCommittedMutations) {\n  var key = fromName(serializer, document.name);\n  var version = fromVersion(document.updateTime);\n  var data = new ObjectValue({\n    mapValue: {\n      fields: document.fields\n    }\n  });\n  var result = MutableDocument.newFoundDocument(key, version, data);\n\n  if (hasCommittedMutations) {\n    result.setHasCommittedMutations();\n  }\n\n  return hasCommittedMutations ? result.setHasCommittedMutations() : result;\n}\n\nfunction fromFound(serializer, doc) {\n  hardAssert(!!doc.found);\n  assertPresent(doc.found.name);\n  assertPresent(doc.found.updateTime);\n  var key = fromName(serializer, doc.found.name);\n  var version = fromVersion(doc.found.updateTime);\n  var data = new ObjectValue({\n    mapValue: {\n      fields: doc.found.fields\n    }\n  });\n  return MutableDocument.newFoundDocument(key, version, data);\n}\n\nfunction fromMissing(serializer, result) {\n  hardAssert(!!result.missing);\n  hardAssert(!!result.readTime);\n  var key = fromName(serializer, result.missing);\n  var version = fromVersion(result.readTime);\n  return MutableDocument.newNoDocument(key, version);\n}\n\nfunction fromBatchGetDocumentsResponse(serializer, result) {\n  if ('found' in result) {\n    return fromFound(serializer, result);\n  } else if ('missing' in result) {\n    return fromMissing(serializer, result);\n  }\n\n  return fail();\n}\n\nfunction fromWatchChange(serializer, change) {\n  var watchChange;\n\n  if ('targetChange' in change) {\n    assertPresent(change.targetChange); // proto3 default value is unset in JSON (undefined), so use 'NO_CHANGE'\n    // if unset\n\n    var state = fromWatchTargetChangeState(change.targetChange.targetChangeType || 'NO_CHANGE');\n    var targetIds = change.targetChange.targetIds || [];\n    var resumeToken = fromBytes(serializer, change.targetChange.resumeToken);\n    var causeProto = change.targetChange.cause;\n    var cause = causeProto && fromRpcStatus(causeProto);\n    watchChange = new WatchTargetChange(state, targetIds, resumeToken, cause || null);\n  } else if ('documentChange' in change) {\n    assertPresent(change.documentChange);\n    var entityChange = change.documentChange;\n    assertPresent(entityChange.document);\n    assertPresent(entityChange.document.name);\n    assertPresent(entityChange.document.updateTime);\n    var key = fromName(serializer, entityChange.document.name);\n    var version_1 = fromVersion(entityChange.document.updateTime);\n    var data = new ObjectValue({\n      mapValue: {\n        fields: entityChange.document.fields\n      }\n    });\n    var doc_1 = MutableDocument.newFoundDocument(key, version_1, data);\n    var updatedTargetIds = entityChange.targetIds || [];\n    var removedTargetIds = entityChange.removedTargetIds || [];\n    watchChange = new DocumentWatchChange(updatedTargetIds, removedTargetIds, doc_1.key, doc_1);\n  } else if ('documentDelete' in change) {\n    assertPresent(change.documentDelete);\n    var docDelete = change.documentDelete;\n    assertPresent(docDelete.document);\n    var key = fromName(serializer, docDelete.document);\n    var version_2 = docDelete.readTime ? fromVersion(docDelete.readTime) : SnapshotVersion.min();\n    var doc_2 = MutableDocument.newNoDocument(key, version_2);\n    var removedTargetIds = docDelete.removedTargetIds || [];\n    watchChange = new DocumentWatchChange([], removedTargetIds, doc_2.key, doc_2);\n  } else if ('documentRemove' in change) {\n    assertPresent(change.documentRemove);\n    var docRemove = change.documentRemove;\n    assertPresent(docRemove.document);\n    var key = fromName(serializer, docRemove.document);\n    var removedTargetIds = docRemove.removedTargetIds || [];\n    watchChange = new DocumentWatchChange([], removedTargetIds, key, null);\n  } else if ('filter' in change) {\n    // TODO(dimond): implement existence filter parsing with strategy.\n    assertPresent(change.filter);\n    var filter = change.filter;\n    assertPresent(filter.targetId);\n    var count = filter.count || 0;\n    var existenceFilter = new ExistenceFilter(count);\n    var targetId = filter.targetId;\n    watchChange = new ExistenceFilterChange(targetId, existenceFilter);\n  } else {\n    return fail();\n  }\n\n  return watchChange;\n}\n\nfunction fromWatchTargetChangeState(state) {\n  if (state === 'NO_CHANGE') {\n    return 0\n    /* NoChange */\n    ;\n  } else if (state === 'ADD') {\n    return 1\n    /* Added */\n    ;\n  } else if (state === 'REMOVE') {\n    return 2\n    /* Removed */\n    ;\n  } else if (state === 'CURRENT') {\n    return 3\n    /* Current */\n    ;\n  } else if (state === 'RESET') {\n    return 4\n    /* Reset */\n    ;\n  } else {\n    return fail();\n  }\n}\n\nfunction versionFromListenResponse(change) {\n  // We have only reached a consistent snapshot for the entire stream if there\n  // is a read_time set and it applies to all targets (i.e. the list of\n  // targets is empty). The backend is guaranteed to send such responses.\n  if (!('targetChange' in change)) {\n    return SnapshotVersion.min();\n  }\n\n  var targetChange = change.targetChange;\n\n  if (targetChange.targetIds && targetChange.targetIds.length) {\n    return SnapshotVersion.min();\n  }\n\n  if (!targetChange.readTime) {\n    return SnapshotVersion.min();\n  }\n\n  return fromVersion(targetChange.readTime);\n}\n\nfunction toMutation(serializer, mutation) {\n  var result;\n\n  if (mutation instanceof SetMutation) {\n    result = {\n      update: toMutationDocument(serializer, mutation.key, mutation.value)\n    };\n  } else if (mutation instanceof DeleteMutation) {\n    result = {\n      delete: toName(serializer, mutation.key)\n    };\n  } else if (mutation instanceof PatchMutation) {\n    result = {\n      update: toMutationDocument(serializer, mutation.key, mutation.data),\n      updateMask: toDocumentMask(mutation.fieldMask)\n    };\n  } else if (mutation instanceof VerifyMutation) {\n    result = {\n      verify: toName(serializer, mutation.key)\n    };\n  } else {\n    return fail();\n  }\n\n  if (mutation.fieldTransforms.length > 0) {\n    result.updateTransforms = mutation.fieldTransforms.map(function (transform) {\n      return toFieldTransform(serializer, transform);\n    });\n  }\n\n  if (!mutation.precondition.isNone) {\n    result.currentDocument = toPrecondition(serializer, mutation.precondition);\n  }\n\n  return result;\n}\n\nfunction fromMutation(serializer, proto) {\n  var precondition = proto.currentDocument ? fromPrecondition(proto.currentDocument) : Precondition.none();\n  var fieldTransforms = proto.updateTransforms ? proto.updateTransforms.map(function (transform) {\n    return fromFieldTransform(serializer, transform);\n  }) : [];\n\n  if (proto.update) {\n    assertPresent(proto.update.name);\n    var key = fromName(serializer, proto.update.name);\n    var value = new ObjectValue({\n      mapValue: {\n        fields: proto.update.fields\n      }\n    });\n\n    if (proto.updateMask) {\n      var fieldMask = fromDocumentMask(proto.updateMask);\n      return new PatchMutation(key, value, fieldMask, precondition, fieldTransforms);\n    } else {\n      return new SetMutation(key, value, precondition, fieldTransforms);\n    }\n  } else if (proto.delete) {\n    var key = fromName(serializer, proto.delete);\n    return new DeleteMutation(key, precondition);\n  } else if (proto.verify) {\n    var key = fromName(serializer, proto.verify);\n    return new VerifyMutation(key, precondition);\n  } else {\n    return fail();\n  }\n}\n\nfunction toPrecondition(serializer, precondition) {\n  if (precondition.updateTime !== undefined) {\n    return {\n      updateTime: toVersion(serializer, precondition.updateTime)\n    };\n  } else if (precondition.exists !== undefined) {\n    return {\n      exists: precondition.exists\n    };\n  } else {\n    return fail();\n  }\n}\n\nfunction fromPrecondition(precondition) {\n  if (precondition.updateTime !== undefined) {\n    return Precondition.updateTime(fromVersion(precondition.updateTime));\n  } else if (precondition.exists !== undefined) {\n    return Precondition.exists(precondition.exists);\n  } else {\n    return Precondition.none();\n  }\n}\n\nfunction fromWriteResult(proto, commitTime) {\n  // NOTE: Deletes don't have an updateTime.\n  var version = proto.updateTime ? fromVersion(proto.updateTime) : fromVersion(commitTime);\n\n  if (version.isEqual(SnapshotVersion.min())) {\n    // The Firestore Emulator currently returns an update time of 0 for\n    // deletes of non-existing documents (rather than null). This breaks the\n    // test \"get deleted doc while offline with source=cache\" as NoDocuments\n    // with version 0 are filtered by IndexedDb's RemoteDocumentCache.\n    // TODO(#2149): Remove this when Emulator is fixed\n    version = fromVersion(commitTime);\n  }\n\n  return new MutationResult(version, proto.transformResults || []);\n}\n\nfunction fromWriteResults(protos, commitTime) {\n  if (protos && protos.length > 0) {\n    hardAssert(commitTime !== undefined);\n    return protos.map(function (proto) {\n      return fromWriteResult(proto, commitTime);\n    });\n  } else {\n    return [];\n  }\n}\n\nfunction toFieldTransform(serializer, fieldTransform) {\n  var transform = fieldTransform.transform;\n\n  if (transform instanceof ServerTimestampTransform) {\n    return {\n      fieldPath: fieldTransform.field.canonicalString(),\n      setToServerValue: 'REQUEST_TIME'\n    };\n  } else if (transform instanceof ArrayUnionTransformOperation) {\n    return {\n      fieldPath: fieldTransform.field.canonicalString(),\n      appendMissingElements: {\n        values: transform.elements\n      }\n    };\n  } else if (transform instanceof ArrayRemoveTransformOperation) {\n    return {\n      fieldPath: fieldTransform.field.canonicalString(),\n      removeAllFromArray: {\n        values: transform.elements\n      }\n    };\n  } else if (transform instanceof NumericIncrementTransformOperation) {\n    return {\n      fieldPath: fieldTransform.field.canonicalString(),\n      increment: transform.operand\n    };\n  } else {\n    throw fail();\n  }\n}\n\nfunction fromFieldTransform(serializer, proto) {\n  var transform = null;\n\n  if ('setToServerValue' in proto) {\n    hardAssert(proto.setToServerValue === 'REQUEST_TIME');\n    transform = new ServerTimestampTransform();\n  } else if ('appendMissingElements' in proto) {\n    var values = proto.appendMissingElements.values || [];\n    transform = new ArrayUnionTransformOperation(values);\n  } else if ('removeAllFromArray' in proto) {\n    var values = proto.removeAllFromArray.values || [];\n    transform = new ArrayRemoveTransformOperation(values);\n  } else if ('increment' in proto) {\n    transform = new NumericIncrementTransformOperation(serializer, proto.increment);\n  } else {\n    fail();\n  }\n\n  var fieldPath = FieldPath$1.fromServerFormat(proto.fieldPath);\n  return new FieldTransform(fieldPath, transform);\n}\n\nfunction toDocumentsTarget(serializer, target) {\n  return {\n    documents: [toQueryPath(serializer, target.path)]\n  };\n}\n\nfunction fromDocumentsTarget(documentsTarget) {\n  var count = documentsTarget.documents.length;\n  hardAssert(count === 1);\n  var name = documentsTarget.documents[0];\n  return queryToTarget(newQueryForPath(fromQueryPath(name)));\n}\n\nfunction toQueryTarget(serializer, target) {\n  // Dissect the path into parent, collectionId, and optional key filter.\n  var result = {\n    structuredQuery: {}\n  };\n  var path = target.path;\n\n  if (target.collectionGroup !== null) {\n    result.parent = toQueryPath(serializer, path);\n    result.structuredQuery.from = [{\n      collectionId: target.collectionGroup,\n      allDescendants: true\n    }];\n  } else {\n    result.parent = toQueryPath(serializer, path.popLast());\n    result.structuredQuery.from = [{\n      collectionId: path.lastSegment()\n    }];\n  }\n\n  var where = toFilter(target.filters);\n\n  if (where) {\n    result.structuredQuery.where = where;\n  }\n\n  var orderBy = toOrder(target.orderBy);\n\n  if (orderBy) {\n    result.structuredQuery.orderBy = orderBy;\n  }\n\n  var limit = toInt32Proto(serializer, target.limit);\n\n  if (limit !== null) {\n    result.structuredQuery.limit = limit;\n  }\n\n  if (target.startAt) {\n    result.structuredQuery.startAt = toCursor(target.startAt);\n  }\n\n  if (target.endAt) {\n    result.structuredQuery.endAt = toCursor(target.endAt);\n  }\n\n  return result;\n}\n\nfunction convertQueryTargetToQuery(target) {\n  var path = fromQueryPath(target.parent);\n  var query = target.structuredQuery;\n  var fromCount = query.from ? query.from.length : 0;\n  var collectionGroup = null;\n\n  if (fromCount > 0) {\n    hardAssert(fromCount === 1);\n    var from = query.from[0];\n\n    if (from.allDescendants) {\n      collectionGroup = from.collectionId;\n    } else {\n      path = path.child(from.collectionId);\n    }\n  }\n\n  var filterBy = [];\n\n  if (query.where) {\n    filterBy = fromFilter(query.where);\n  }\n\n  var orderBy = [];\n\n  if (query.orderBy) {\n    orderBy = fromOrder(query.orderBy);\n  }\n\n  var limit = null;\n\n  if (query.limit) {\n    limit = fromInt32Proto(query.limit);\n  }\n\n  var startAt = null;\n\n  if (query.startAt) {\n    startAt = fromCursor(query.startAt);\n  }\n\n  var endAt = null;\n\n  if (query.endAt) {\n    endAt = fromCursor(query.endAt);\n  }\n\n  return newQuery(path, collectionGroup, orderBy, filterBy, limit, \"F\"\n  /* First */\n  , startAt, endAt);\n}\n\nfunction fromQueryTarget(target) {\n  return queryToTarget(convertQueryTargetToQuery(target));\n}\n\nfunction toListenRequestLabels(serializer, targetData) {\n  var value = toLabel(serializer, targetData.purpose);\n\n  if (value == null) {\n    return null;\n  } else {\n    return {\n      'goog-listen-tags': value\n    };\n  }\n}\n\nfunction toLabel(serializer, purpose) {\n  switch (purpose) {\n    case 0\n    /* Listen */\n    :\n      return null;\n\n    case 1\n    /* ExistenceFilterMismatch */\n    :\n      return 'existence-filter-mismatch';\n\n    case 2\n    /* LimboResolution */\n    :\n      return 'limbo-document';\n\n    default:\n      return fail();\n  }\n}\n\nfunction toTarget(serializer, targetData) {\n  var result;\n  var target = targetData.target;\n\n  if (isDocumentTarget(target)) {\n    result = {\n      documents: toDocumentsTarget(serializer, target)\n    };\n  } else {\n    result = {\n      query: toQueryTarget(serializer, target)\n    };\n  }\n\n  result.targetId = targetData.targetId;\n\n  if (targetData.resumeToken.approximateByteSize() > 0) {\n    result.resumeToken = toBytes(serializer, targetData.resumeToken);\n  } else if (targetData.snapshotVersion.compareTo(SnapshotVersion.min()) > 0) {\n    // TODO(wuandy): Consider removing above check because it is most likely true.\n    // Right now, many tests depend on this behaviour though (leaving min() out\n    // of serialization).\n    result.readTime = toTimestamp(serializer, targetData.snapshotVersion.toTimestamp());\n  }\n\n  return result;\n}\n\nfunction toFilter(filters) {\n  if (filters.length === 0) {\n    return;\n  }\n\n  var protos = filters.map(function (filter) {\n    return toUnaryOrFieldFilter(filter);\n  });\n\n  if (protos.length === 1) {\n    return protos[0];\n  }\n\n  return {\n    compositeFilter: {\n      op: 'AND',\n      filters: protos\n    }\n  };\n}\n\nfunction fromFilter(filter) {\n  if (!filter) {\n    return [];\n  } else if (filter.unaryFilter !== undefined) {\n    return [fromUnaryFilter(filter)];\n  } else if (filter.fieldFilter !== undefined) {\n    return [fromFieldFilter(filter)];\n  } else if (filter.compositeFilter !== undefined) {\n    return filter.compositeFilter.filters.map(function (f) {\n      return fromFilter(f);\n    }).reduce(function (accum, current) {\n      return accum.concat(current);\n    });\n  } else {\n    return fail();\n  }\n}\n\nfunction toOrder(orderBys) {\n  if (orderBys.length === 0) {\n    return;\n  }\n\n  return orderBys.map(function (order) {\n    return toPropertyOrder(order);\n  });\n}\n\nfunction fromOrder(orderBys) {\n  return orderBys.map(function (order) {\n    return fromPropertyOrder(order);\n  });\n}\n\nfunction toCursor(cursor) {\n  return {\n    before: cursor.before,\n    values: cursor.position\n  };\n}\n\nfunction fromCursor(cursor) {\n  var before = !!cursor.before;\n  var position = cursor.values || [];\n  return new Bound(position, before);\n} // visible for testing\n\n\nfunction toDirection(dir) {\n  return DIRECTIONS[dir];\n} // visible for testing\n\n\nfunction fromDirection(dir) {\n  switch (dir) {\n    case 'ASCENDING':\n      return \"asc\"\n      /* ASCENDING */\n      ;\n\n    case 'DESCENDING':\n      return \"desc\"\n      /* DESCENDING */\n      ;\n\n    default:\n      return undefined;\n  }\n} // visible for testing\n\n\nfunction toOperatorName(op) {\n  return OPERATORS[op];\n}\n\nfunction fromOperatorName(op) {\n  switch (op) {\n    case 'EQUAL':\n      return \"==\"\n      /* EQUAL */\n      ;\n\n    case 'NOT_EQUAL':\n      return \"!=\"\n      /* NOT_EQUAL */\n      ;\n\n    case 'GREATER_THAN':\n      return \">\"\n      /* GREATER_THAN */\n      ;\n\n    case 'GREATER_THAN_OR_EQUAL':\n      return \">=\"\n      /* GREATER_THAN_OR_EQUAL */\n      ;\n\n    case 'LESS_THAN':\n      return \"<\"\n      /* LESS_THAN */\n      ;\n\n    case 'LESS_THAN_OR_EQUAL':\n      return \"<=\"\n      /* LESS_THAN_OR_EQUAL */\n      ;\n\n    case 'ARRAY_CONTAINS':\n      return \"array-contains\"\n      /* ARRAY_CONTAINS */\n      ;\n\n    case 'IN':\n      return \"in\"\n      /* IN */\n      ;\n\n    case 'NOT_IN':\n      return \"not-in\"\n      /* NOT_IN */\n      ;\n\n    case 'ARRAY_CONTAINS_ANY':\n      return \"array-contains-any\"\n      /* ARRAY_CONTAINS_ANY */\n      ;\n\n    case 'OPERATOR_UNSPECIFIED':\n      return fail();\n\n    default:\n      return fail();\n  }\n}\n\nfunction toFieldPathReference(path) {\n  return {\n    fieldPath: path.canonicalString()\n  };\n}\n\nfunction fromFieldPathReference(fieldReference) {\n  return FieldPath$1.fromServerFormat(fieldReference.fieldPath);\n} // visible for testing\n\n\nfunction toPropertyOrder(orderBy) {\n  return {\n    field: toFieldPathReference(orderBy.field),\n    direction: toDirection(orderBy.dir)\n  };\n}\n\nfunction fromPropertyOrder(orderBy) {\n  return new OrderBy(fromFieldPathReference(orderBy.field), fromDirection(orderBy.direction));\n}\n\nfunction fromFieldFilter(filter) {\n  return FieldFilter.create(fromFieldPathReference(filter.fieldFilter.field), fromOperatorName(filter.fieldFilter.op), filter.fieldFilter.value);\n} // visible for testing\n\n\nfunction toUnaryOrFieldFilter(filter) {\n  if (filter.op === \"==\"\n  /* EQUAL */\n  ) {\n      if (isNanValue(filter.value)) {\n        return {\n          unaryFilter: {\n            field: toFieldPathReference(filter.field),\n            op: 'IS_NAN'\n          }\n        };\n      } else if (isNullValue(filter.value)) {\n        return {\n          unaryFilter: {\n            field: toFieldPathReference(filter.field),\n            op: 'IS_NULL'\n          }\n        };\n      }\n    } else if (filter.op === \"!=\"\n  /* NOT_EQUAL */\n  ) {\n      if (isNanValue(filter.value)) {\n        return {\n          unaryFilter: {\n            field: toFieldPathReference(filter.field),\n            op: 'IS_NOT_NAN'\n          }\n        };\n      } else if (isNullValue(filter.value)) {\n        return {\n          unaryFilter: {\n            field: toFieldPathReference(filter.field),\n            op: 'IS_NOT_NULL'\n          }\n        };\n      }\n    }\n\n  return {\n    fieldFilter: {\n      field: toFieldPathReference(filter.field),\n      op: toOperatorName(filter.op),\n      value: filter.value\n    }\n  };\n}\n\nfunction fromUnaryFilter(filter) {\n  switch (filter.unaryFilter.op) {\n    case 'IS_NAN':\n      var nanField = fromFieldPathReference(filter.unaryFilter.field);\n      return FieldFilter.create(nanField, \"==\"\n      /* EQUAL */\n      , {\n        doubleValue: NaN\n      });\n\n    case 'IS_NULL':\n      var nullField = fromFieldPathReference(filter.unaryFilter.field);\n      return FieldFilter.create(nullField, \"==\"\n      /* EQUAL */\n      , {\n        nullValue: 'NULL_VALUE'\n      });\n\n    case 'IS_NOT_NAN':\n      var notNanField = fromFieldPathReference(filter.unaryFilter.field);\n      return FieldFilter.create(notNanField, \"!=\"\n      /* NOT_EQUAL */\n      , {\n        doubleValue: NaN\n      });\n\n    case 'IS_NOT_NULL':\n      var notNullField = fromFieldPathReference(filter.unaryFilter.field);\n      return FieldFilter.create(notNullField, \"!=\"\n      /* NOT_EQUAL */\n      , {\n        nullValue: 'NULL_VALUE'\n      });\n\n    case 'OPERATOR_UNSPECIFIED':\n      return fail();\n\n    default:\n      return fail();\n  }\n}\n\nfunction toDocumentMask(fieldMask) {\n  var canonicalFields = [];\n  fieldMask.fields.forEach(function (field) {\n    return canonicalFields.push(field.canonicalString());\n  });\n  return {\n    fieldPaths: canonicalFields\n  };\n}\n\nfunction fromDocumentMask(proto) {\n  var paths = proto.fieldPaths || [];\n  return new FieldMask(paths.map(function (path) {\n    return FieldPath$1.fromServerFormat(path);\n  }));\n}\n\nfunction isValidResourceName(path) {\n  // Resource names have at least 4 components (project ID, database ID)\n  return path.length >= 4 && path.get(0) === 'projects' && path.get(2) === 'databases';\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An immutable set of metadata that the local store tracks for each target.\r\n */\n\n\nvar TargetData =\n/** @class */\nfunction () {\n  function TargetData(\n  /** The target being listened to. */\n  target,\n  /**\r\n   * The target ID to which the target corresponds; Assigned by the\r\n   * LocalStore for user listens and by the SyncEngine for limbo watches.\r\n   */\n  targetId,\n  /** The purpose of the target. */\n  purpose,\n  /**\r\n   * The sequence number of the last transaction during which this target data\r\n   * was modified.\r\n   */\n  sequenceNumber,\n  /** The latest snapshot version seen for this target. */\n  snapshotVersion,\n  /**\r\n   * The maximum snapshot version at which the associated view\r\n   * contained no limbo documents.\r\n   */\n  lastLimboFreeSnapshotVersion,\n  /**\r\n   * An opaque, server-assigned token that allows watching a target to be\r\n   * resumed after disconnecting without retransmitting all the data that\r\n   * matches the target. The resume token essentially identifies a point in\r\n   * time from which the server should resume sending results.\r\n   */\n  resumeToken) {\n    if (snapshotVersion === void 0) {\n      snapshotVersion = SnapshotVersion.min();\n    }\n\n    if (lastLimboFreeSnapshotVersion === void 0) {\n      lastLimboFreeSnapshotVersion = SnapshotVersion.min();\n    }\n\n    if (resumeToken === void 0) {\n      resumeToken = ByteString.EMPTY_BYTE_STRING;\n    }\n\n    this.target = target;\n    this.targetId = targetId;\n    this.purpose = purpose;\n    this.sequenceNumber = sequenceNumber;\n    this.snapshotVersion = snapshotVersion;\n    this.lastLimboFreeSnapshotVersion = lastLimboFreeSnapshotVersion;\n    this.resumeToken = resumeToken;\n  }\n  /** Creates a new target data instance with an updated sequence number. */\n\n\n  TargetData.prototype.withSequenceNumber = function (sequenceNumber) {\n    return new TargetData(this.target, this.targetId, this.purpose, sequenceNumber, this.snapshotVersion, this.lastLimboFreeSnapshotVersion, this.resumeToken);\n  };\n  /**\r\n   * Creates a new target data instance with an updated resume token and\r\n   * snapshot version.\r\n   */\n\n\n  TargetData.prototype.withResumeToken = function (resumeToken, snapshotVersion) {\n    return new TargetData(this.target, this.targetId, this.purpose, this.sequenceNumber, snapshotVersion, this.lastLimboFreeSnapshotVersion, resumeToken);\n  };\n  /**\r\n   * Creates a new target data instance with an updated last limbo free\r\n   * snapshot version number.\r\n   */\n\n\n  TargetData.prototype.withLastLimboFreeSnapshotVersion = function (lastLimboFreeSnapshotVersion) {\n    return new TargetData(this.target, this.targetId, this.purpose, this.sequenceNumber, this.snapshotVersion, lastLimboFreeSnapshotVersion, this.resumeToken);\n  };\n\n  return TargetData;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Serializer for values stored in the LocalStore. */\n\n\nvar LocalSerializer =\n/** @class */\nfunction () {\n  function LocalSerializer(remoteSerializer) {\n    this.remoteSerializer = remoteSerializer;\n  }\n\n  return LocalSerializer;\n}();\n/** Decodes a remote document from storage locally to a Document. */\n\n\nfunction fromDbRemoteDocument(localSerializer, remoteDoc) {\n  if (remoteDoc.document) {\n    return fromDocument(localSerializer.remoteSerializer, remoteDoc.document, !!remoteDoc.hasCommittedMutations);\n  } else if (remoteDoc.noDocument) {\n    var key = DocumentKey.fromSegments(remoteDoc.noDocument.path);\n    var version_3 = fromDbTimestamp(remoteDoc.noDocument.readTime);\n    var document_1 = MutableDocument.newNoDocument(key, version_3);\n    return remoteDoc.hasCommittedMutations ? document_1.setHasCommittedMutations() : document_1;\n  } else if (remoteDoc.unknownDocument) {\n    var key = DocumentKey.fromSegments(remoteDoc.unknownDocument.path);\n    var version_4 = fromDbTimestamp(remoteDoc.unknownDocument.version);\n    return MutableDocument.newUnknownDocument(key, version_4);\n  } else {\n    return fail();\n  }\n}\n/** Encodes a document for storage locally. */\n\n\nfunction toDbRemoteDocument(localSerializer, document, readTime) {\n  var dbReadTime = toDbTimestampKey(readTime);\n  var parentPath = document.key.path.popLast().toArray();\n\n  if (document.isFoundDocument()) {\n    var doc_3 = toDocument(localSerializer.remoteSerializer, document);\n    var hasCommittedMutations = document.hasCommittedMutations;\n    return new DbRemoteDocument(\n    /* unknownDocument= */\n    null,\n    /* noDocument= */\n    null, doc_3, hasCommittedMutations, dbReadTime, parentPath);\n  } else if (document.isNoDocument()) {\n    var path = document.key.path.toArray();\n    var readTime_1 = toDbTimestamp(document.version);\n    var hasCommittedMutations = document.hasCommittedMutations;\n    return new DbRemoteDocument(\n    /* unknownDocument= */\n    null, new DbNoDocument(path, readTime_1),\n    /* document= */\n    null, hasCommittedMutations, dbReadTime, parentPath);\n  } else if (document.isUnknownDocument()) {\n    var path = document.key.path.toArray();\n    var readTime_2 = toDbTimestamp(document.version);\n    return new DbRemoteDocument(new DbUnknownDocument(path, readTime_2),\n    /* noDocument= */\n    null,\n    /* document= */\n    null,\n    /* hasCommittedMutations= */\n    true, dbReadTime, parentPath);\n  } else {\n    return fail();\n  }\n}\n\nfunction toDbTimestampKey(snapshotVersion) {\n  var timestamp = snapshotVersion.toTimestamp();\n  return [timestamp.seconds, timestamp.nanoseconds];\n}\n\nfunction fromDbTimestampKey(dbTimestampKey) {\n  var timestamp = new Timestamp(dbTimestampKey[0], dbTimestampKey[1]);\n  return SnapshotVersion.fromTimestamp(timestamp);\n}\n\nfunction toDbTimestamp(snapshotVersion) {\n  var timestamp = snapshotVersion.toTimestamp();\n  return new DbTimestamp(timestamp.seconds, timestamp.nanoseconds);\n}\n\nfunction fromDbTimestamp(dbTimestamp) {\n  var timestamp = new Timestamp(dbTimestamp.seconds, dbTimestamp.nanoseconds);\n  return SnapshotVersion.fromTimestamp(timestamp);\n}\n/** Encodes a batch of mutations into a DbMutationBatch for local storage. */\n\n\nfunction toDbMutationBatch(localSerializer, userId, batch) {\n  var serializedBaseMutations = batch.baseMutations.map(function (m) {\n    return toMutation(localSerializer.remoteSerializer, m);\n  });\n  var serializedMutations = batch.mutations.map(function (m) {\n    return toMutation(localSerializer.remoteSerializer, m);\n  });\n  return new DbMutationBatch(userId, batch.batchId, batch.localWriteTime.toMillis(), serializedBaseMutations, serializedMutations);\n}\n/** Decodes a DbMutationBatch into a MutationBatch */\n\n\nfunction fromDbMutationBatch(localSerializer, dbBatch) {\n  var baseMutations = (dbBatch.baseMutations || []).map(function (m) {\n    return fromMutation(localSerializer.remoteSerializer, m);\n  }); // Squash old transform mutations into existing patch or set mutations.\n  // The replacement of representing `transforms` with `update_transforms`\n  // on the SDK means that old `transform` mutations stored in IndexedDB need\n  // to be updated to `update_transforms`.\n  // TODO(b/174608374): Remove this code once we perform a schema migration.\n\n  for (var i = 0; i < dbBatch.mutations.length - 1; ++i) {\n    var currentMutation = dbBatch.mutations[i];\n    var hasTransform = i + 1 < dbBatch.mutations.length && dbBatch.mutations[i + 1].transform !== undefined;\n\n    if (hasTransform) {\n      var transformMutation = dbBatch.mutations[i + 1];\n      currentMutation.updateTransforms = transformMutation.transform.fieldTransforms;\n      dbBatch.mutations.splice(i + 1, 1);\n      ++i;\n    }\n  }\n\n  var mutations = dbBatch.mutations.map(function (m) {\n    return fromMutation(localSerializer.remoteSerializer, m);\n  });\n  var timestamp = Timestamp.fromMillis(dbBatch.localWriteTimeMs);\n  return new MutationBatch(dbBatch.batchId, timestamp, baseMutations, mutations);\n}\n/** Decodes a DbTarget into TargetData */\n\n\nfunction fromDbTarget(dbTarget) {\n  var version = fromDbTimestamp(dbTarget.readTime);\n  var lastLimboFreeSnapshotVersion = dbTarget.lastLimboFreeSnapshotVersion !== undefined ? fromDbTimestamp(dbTarget.lastLimboFreeSnapshotVersion) : SnapshotVersion.min();\n  var target;\n\n  if (isDocumentQuery(dbTarget.query)) {\n    target = fromDocumentsTarget(dbTarget.query);\n  } else {\n    target = fromQueryTarget(dbTarget.query);\n  }\n\n  return new TargetData(target, dbTarget.targetId, 0\n  /* Listen */\n  , dbTarget.lastListenSequenceNumber, version, lastLimboFreeSnapshotVersion, ByteString.fromBase64String(dbTarget.resumeToken));\n}\n/** Encodes TargetData into a DbTarget for storage locally. */\n\n\nfunction toDbTarget(localSerializer, targetData) {\n  var dbTimestamp = toDbTimestamp(targetData.snapshotVersion);\n  var dbLastLimboFreeTimestamp = toDbTimestamp(targetData.lastLimboFreeSnapshotVersion);\n  var queryProto;\n\n  if (isDocumentTarget(targetData.target)) {\n    queryProto = toDocumentsTarget(localSerializer.remoteSerializer, targetData.target);\n  } else {\n    queryProto = toQueryTarget(localSerializer.remoteSerializer, targetData.target);\n  } // We can't store the resumeToken as a ByteString in IndexedDb, so we\n  // convert it to a base64 string for storage.\n\n\n  var resumeToken = targetData.resumeToken.toBase64(); // lastListenSequenceNumber is always 0 until we do real GC.\n\n  return new DbTarget(targetData.targetId, canonifyTarget(targetData.target), dbTimestamp, resumeToken, targetData.sequenceNumber, dbLastLimboFreeTimestamp, queryProto);\n}\n/**\r\n * A helper function for figuring out what kind of query has been stored.\r\n */\n\n\nfunction isDocumentQuery(dbQuery) {\n  return dbQuery.documents !== undefined;\n}\n/** Encodes a DbBundle to a BundleMetadata object. */\n\n\nfunction fromDbBundle(dbBundle) {\n  return {\n    id: dbBundle.bundleId,\n    createTime: fromDbTimestamp(dbBundle.createTime),\n    version: dbBundle.version\n  };\n}\n/** Encodes a BundleMetadata to a DbBundle. */\n\n\nfunction toDbBundle(metadata) {\n  return {\n    bundleId: metadata.id,\n    createTime: toDbTimestamp(fromVersion(metadata.createTime)),\n    version: metadata.version\n  };\n}\n/** Encodes a DbNamedQuery to a NamedQuery. */\n\n\nfunction fromDbNamedQuery(dbNamedQuery) {\n  return {\n    name: dbNamedQuery.name,\n    query: fromBundledQuery(dbNamedQuery.bundledQuery),\n    readTime: fromDbTimestamp(dbNamedQuery.readTime)\n  };\n}\n/** Encodes a NamedQuery from a bundle proto to a DbNamedQuery. */\n\n\nfunction toDbNamedQuery(query) {\n  return {\n    name: query.name,\n    readTime: toDbTimestamp(fromVersion(query.readTime)),\n    bundledQuery: query.bundledQuery\n  };\n}\n/**\r\n * Encodes a `BundledQuery` from bundle proto to a Query object.\r\n *\r\n * This reconstructs the original query used to build the bundle being loaded,\r\n * including features exists only in SDKs (for example: limit-to-last).\r\n */\n\n\nfunction fromBundledQuery(bundledQuery) {\n  var query = convertQueryTargetToQuery({\n    parent: bundledQuery.parent,\n    structuredQuery: bundledQuery.structuredQuery\n  });\n\n  if (bundledQuery.limitType === 'LAST') {\n    return queryWithLimit(query, query.limit, \"L\"\n    /* Last */\n    );\n  }\n\n  return query;\n}\n/** Encodes a NamedQuery proto object to a NamedQuery model object. */\n\n\nfunction fromProtoNamedQuery(namedQuery) {\n  return {\n    name: namedQuery.name,\n    query: fromBundledQuery(namedQuery.bundledQuery),\n    readTime: fromVersion(namedQuery.readTime)\n  };\n}\n/** Decodes a BundleMetadata proto into a BundleMetadata object. */\n\n\nfunction fromBundleMetadata(metadata) {\n  return {\n    id: metadata.id,\n    version: metadata.version,\n    createTime: fromVersion(metadata.createTime)\n  };\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar IndexedDbBundleCache =\n/** @class */\nfunction () {\n  function IndexedDbBundleCache() {}\n\n  IndexedDbBundleCache.prototype.getBundleMetadata = function (transaction, bundleId) {\n    return bundlesStore(transaction).get(bundleId).next(function (bundle) {\n      if (bundle) {\n        return fromDbBundle(bundle);\n      }\n\n      return undefined;\n    });\n  };\n\n  IndexedDbBundleCache.prototype.saveBundleMetadata = function (transaction, bundleMetadata) {\n    return bundlesStore(transaction).put(toDbBundle(bundleMetadata));\n  };\n\n  IndexedDbBundleCache.prototype.getNamedQuery = function (transaction, queryName) {\n    return namedQueriesStore(transaction).get(queryName).next(function (query) {\n      if (query) {\n        return fromDbNamedQuery(query);\n      }\n\n      return undefined;\n    });\n  };\n\n  IndexedDbBundleCache.prototype.saveNamedQuery = function (transaction, query) {\n    return namedQueriesStore(transaction).put(toDbNamedQuery(query));\n  };\n\n  return IndexedDbBundleCache;\n}();\n/**\r\n * Helper to get a typed SimpleDbStore for the bundles object store.\r\n */\n\n\nfunction bundlesStore(txn) {\n  return getStore(txn, DbBundle.store);\n}\n/**\r\n * Helper to get a typed SimpleDbStore for the namedQueries object store.\r\n */\n\n\nfunction namedQueriesStore(txn) {\n  return getStore(txn, DbNamedQuery.store);\n}\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An in-memory implementation of IndexManager.\r\n */\n\n\nvar MemoryIndexManager =\n/** @class */\nfunction () {\n  function MemoryIndexManager() {\n    this.collectionParentIndex = new MemoryCollectionParentIndex();\n  }\n\n  MemoryIndexManager.prototype.addToCollectionParentIndex = function (transaction, collectionPath) {\n    this.collectionParentIndex.add(collectionPath);\n    return PersistencePromise.resolve();\n  };\n\n  MemoryIndexManager.prototype.getCollectionParents = function (transaction, collectionId) {\n    return PersistencePromise.resolve(this.collectionParentIndex.getEntries(collectionId));\n  };\n\n  return MemoryIndexManager;\n}();\n/**\r\n * Internal implementation of the collection-parent index exposed by MemoryIndexManager.\r\n * Also used for in-memory caching by IndexedDbIndexManager and initial index population\r\n * in indexeddb_schema.ts\r\n */\n\n\nvar MemoryCollectionParentIndex =\n/** @class */\nfunction () {\n  function MemoryCollectionParentIndex() {\n    this.index = {};\n  } // Returns false if the entry already existed.\n\n\n  MemoryCollectionParentIndex.prototype.add = function (collectionPath) {\n    var collectionId = collectionPath.lastSegment();\n    var parentPath = collectionPath.popLast();\n    var existingParents = this.index[collectionId] || new SortedSet(ResourcePath.comparator);\n    var added = !existingParents.has(parentPath);\n    this.index[collectionId] = existingParents.add(parentPath);\n    return added;\n  };\n\n  MemoryCollectionParentIndex.prototype.has = function (collectionPath) {\n    var collectionId = collectionPath.lastSegment();\n    var parentPath = collectionPath.popLast();\n    var existingParents = this.index[collectionId];\n    return existingParents && existingParents.has(parentPath);\n  };\n\n  MemoryCollectionParentIndex.prototype.getEntries = function (collectionId) {\n    var parentPaths = this.index[collectionId] || new SortedSet(ResourcePath.comparator);\n    return parentPaths.toArray();\n  };\n\n  return MemoryCollectionParentIndex;\n}();\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A persisted implementation of IndexManager.\r\n */\n\n\nvar IndexedDbIndexManager =\n/** @class */\nfunction () {\n  function IndexedDbIndexManager() {\n    /**\r\n     * An in-memory copy of the index entries we've already written since the SDK\r\n     * launched. Used to avoid re-writing the same entry repeatedly.\r\n     *\r\n     * This is *NOT* a complete cache of what's in persistence and so can never be used to\r\n     * satisfy reads.\r\n     */\n    this.collectionParentsCache = new MemoryCollectionParentIndex();\n  }\n  /**\r\n   * Adds a new entry to the collection parent index.\r\n   *\r\n   * Repeated calls for the same collectionPath should be avoided within a\r\n   * transaction as IndexedDbIndexManager only caches writes once a transaction\r\n   * has been committed.\r\n   */\n\n\n  IndexedDbIndexManager.prototype.addToCollectionParentIndex = function (transaction, collectionPath) {\n    var _this = this;\n\n    if (!this.collectionParentsCache.has(collectionPath)) {\n      var collectionId = collectionPath.lastSegment();\n      var parentPath = collectionPath.popLast();\n      transaction.addOnCommittedListener(function () {\n        // Add the collection to the in memory cache only if the transaction was\n        // successfully committed.\n        _this.collectionParentsCache.add(collectionPath);\n      });\n      var collectionParent = {\n        collectionId: collectionId,\n        parent: encodeResourcePath(parentPath)\n      };\n      return collectionParentsStore(transaction).put(collectionParent);\n    }\n\n    return PersistencePromise.resolve();\n  };\n\n  IndexedDbIndexManager.prototype.getCollectionParents = function (transaction, collectionId) {\n    var parentPaths = [];\n    var range = IDBKeyRange.bound([collectionId, ''], [immediateSuccessor(collectionId), ''],\n    /*lowerOpen=*/\n    false,\n    /*upperOpen=*/\n    true);\n    return collectionParentsStore(transaction).loadAll(range).next(function (entries) {\n      for (var _i = 0, entries_1 = entries; _i < entries_1.length; _i++) {\n        var entry = entries_1[_i]; // This collectionId guard shouldn't be necessary (and isn't as long\n        // as we're running in a real browser), but there's a bug in\n        // indexeddbshim that breaks our range in our tests running in node:\n        // https://github.com/axemclion/IndexedDBShim/issues/334\n\n        if (entry.collectionId !== collectionId) {\n          break;\n        }\n\n        parentPaths.push(decodeResourcePath(entry.parent));\n      }\n\n      return parentPaths;\n    });\n  };\n\n  return IndexedDbIndexManager;\n}();\n/**\r\n * Helper to get a typed SimpleDbStore for the collectionParents\r\n * document store.\r\n */\n\n\nfunction collectionParentsStore(txn) {\n  return getStore(txn, DbCollectionParent.store);\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Delete a mutation batch and the associated document mutations.\r\n * @returns A PersistencePromise of the document mutations that were removed.\r\n */\n\n\nfunction removeMutationBatch(txn, userId, batch) {\n  var mutationStore = txn.store(DbMutationBatch.store);\n  var indexTxn = txn.store(DbDocumentMutation.store);\n  var promises = [];\n  var range = IDBKeyRange.only(batch.batchId);\n  var numDeleted = 0;\n  var removePromise = mutationStore.iterate({\n    range: range\n  }, function (key, value, control) {\n    numDeleted++;\n    return control.delete();\n  });\n  promises.push(removePromise.next(function () {\n    hardAssert(numDeleted === 1);\n  }));\n  var removedDocuments = [];\n\n  for (var _i = 0, _d = batch.mutations; _i < _d.length; _i++) {\n    var mutation = _d[_i];\n    var indexKey = DbDocumentMutation.key(userId, mutation.key.path, batch.batchId);\n    promises.push(indexTxn.delete(indexKey));\n    removedDocuments.push(mutation.key);\n  }\n\n  return PersistencePromise.waitFor(promises).next(function () {\n    return removedDocuments;\n  });\n}\n/**\r\n * Returns an approximate size for the given document.\r\n */\n\n\nfunction dbDocumentSize(doc) {\n  if (!doc) {\n    return 0;\n  }\n\n  var value;\n\n  if (doc.document) {\n    value = doc.document;\n  } else if (doc.unknownDocument) {\n    value = doc.unknownDocument;\n  } else if (doc.noDocument) {\n    value = doc.noDocument;\n  } else {\n    throw fail();\n  }\n\n  return JSON.stringify(value).length;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** A mutation queue for a specific user, backed by IndexedDB. */\n\n\nvar IndexedDbMutationQueue =\n/** @class */\nfunction () {\n  function IndexedDbMutationQueue(\n  /**\r\n   * The normalized userId (e.g. null UID => \"\" userId) used to store /\r\n   * retrieve mutations.\r\n   */\n  userId, serializer, indexManager, referenceDelegate) {\n    this.userId = userId;\n    this.serializer = serializer;\n    this.indexManager = indexManager;\n    this.referenceDelegate = referenceDelegate;\n    /**\r\n     * Caches the document keys for pending mutation batches. If the mutation\r\n     * has been removed from IndexedDb, the cached value may continue to\r\n     * be used to retrieve the batch's document keys. To remove a cached value\r\n     * locally, `removeCachedMutationKeys()` should be invoked either directly\r\n     * or through `removeMutationBatches()`.\r\n     *\r\n     * With multi-tab, when the primary client acknowledges or rejects a mutation,\r\n     * this cache is used by secondary clients to invalidate the local\r\n     * view of the documents that were previously affected by the mutation.\r\n     */\n    // PORTING NOTE: Multi-tab only.\n\n    this.documentKeysByBatchId = {};\n  }\n  /**\r\n   * Creates a new mutation queue for the given user.\r\n   * @param user - The user for which to create a mutation queue.\r\n   * @param serializer - The serializer to use when persisting to IndexedDb.\r\n   */\n\n\n  IndexedDbMutationQueue.forUser = function (user, serializer, indexManager, referenceDelegate) {\n    // TODO(mcg): Figure out what constraints there are on userIDs\n    // In particular, are there any reserved characters? are empty ids allowed?\n    // For the moment store these together in the same mutations table assuming\n    // that empty userIDs aren't allowed.\n    hardAssert(user.uid !== '');\n    var userId = user.isAuthenticated() ? user.uid : '';\n    return new IndexedDbMutationQueue(userId, serializer, indexManager, referenceDelegate);\n  };\n\n  IndexedDbMutationQueue.prototype.checkEmpty = function (transaction) {\n    var empty = true;\n    var range = IDBKeyRange.bound([this.userId, Number.NEGATIVE_INFINITY], [this.userId, Number.POSITIVE_INFINITY]);\n    return mutationsStore(transaction).iterate({\n      index: DbMutationBatch.userMutationsIndex,\n      range: range\n    }, function (key, value, control) {\n      empty = false;\n      control.done();\n    }).next(function () {\n      return empty;\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.addMutationBatch = function (transaction, localWriteTime, baseMutations, mutations) {\n    var _this = this;\n\n    var documentStore = documentMutationsStore(transaction);\n    var mutationStore = mutationsStore(transaction); // The IndexedDb implementation in Chrome (and Firefox) does not handle\n    // compound indices that include auto-generated keys correctly. To ensure\n    // that the index entry is added correctly in all browsers, we perform two\n    // writes: The first write is used to retrieve the next auto-generated Batch\n    // ID, and the second write populates the index and stores the actual\n    // mutation batch.\n    // See: https://bugs.chromium.org/p/chromium/issues/detail?id=701972\n    // We write an empty object to obtain key\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n    return mutationStore.add({}).next(function (batchId) {\n      hardAssert(typeof batchId === 'number');\n      var batch = new MutationBatch(batchId, localWriteTime, baseMutations, mutations);\n      var dbBatch = toDbMutationBatch(_this.serializer, _this.userId, batch);\n      var promises = [];\n      var collectionParents = new SortedSet(function (l, r) {\n        return primitiveComparator(l.canonicalString(), r.canonicalString());\n      });\n\n      for (var _i = 0, mutations_1 = mutations; _i < mutations_1.length; _i++) {\n        var mutation = mutations_1[_i];\n        var indexKey = DbDocumentMutation.key(_this.userId, mutation.key.path, batchId);\n        collectionParents = collectionParents.add(mutation.key.path.popLast());\n        promises.push(mutationStore.put(dbBatch));\n        promises.push(documentStore.put(indexKey, DbDocumentMutation.PLACEHOLDER));\n      }\n\n      collectionParents.forEach(function (parent) {\n        promises.push(_this.indexManager.addToCollectionParentIndex(transaction, parent));\n      });\n      transaction.addOnCommittedListener(function () {\n        _this.documentKeysByBatchId[batchId] = batch.keys();\n      });\n      return PersistencePromise.waitFor(promises).next(function () {\n        return batch;\n      });\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.lookupMutationBatch = function (transaction, batchId) {\n    var _this = this;\n\n    return mutationsStore(transaction).get(batchId).next(function (dbBatch) {\n      if (dbBatch) {\n        hardAssert(dbBatch.userId === _this.userId);\n        return fromDbMutationBatch(_this.serializer, dbBatch);\n      }\n\n      return null;\n    });\n  };\n  /**\r\n   * Returns the document keys for the mutation batch with the given batchId.\r\n   * For primary clients, this method returns `null` after\r\n   * `removeMutationBatches()` has been called. Secondary clients return a\r\n   * cached result until `removeCachedMutationKeys()` is invoked.\r\n   */\n  // PORTING NOTE: Multi-tab only.\n\n\n  IndexedDbMutationQueue.prototype.lookupMutationKeys = function (transaction, batchId) {\n    var _this = this;\n\n    if (this.documentKeysByBatchId[batchId]) {\n      return PersistencePromise.resolve(this.documentKeysByBatchId[batchId]);\n    } else {\n      return this.lookupMutationBatch(transaction, batchId).next(function (batch) {\n        if (batch) {\n          var keys = batch.keys();\n          _this.documentKeysByBatchId[batchId] = keys;\n          return keys;\n        } else {\n          return null;\n        }\n      });\n    }\n  };\n\n  IndexedDbMutationQueue.prototype.getNextMutationBatchAfterBatchId = function (transaction, batchId) {\n    var _this = this;\n\n    var nextBatchId = batchId + 1;\n    var range = IDBKeyRange.lowerBound([this.userId, nextBatchId]);\n    var foundBatch = null;\n    return mutationsStore(transaction).iterate({\n      index: DbMutationBatch.userMutationsIndex,\n      range: range\n    }, function (key, dbBatch, control) {\n      if (dbBatch.userId === _this.userId) {\n        hardAssert(dbBatch.batchId >= nextBatchId);\n        foundBatch = fromDbMutationBatch(_this.serializer, dbBatch);\n      }\n\n      control.done();\n    }).next(function () {\n      return foundBatch;\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.getHighestUnacknowledgedBatchId = function (transaction) {\n    var range = IDBKeyRange.upperBound([this.userId, Number.POSITIVE_INFINITY]);\n    var batchId = BATCHID_UNKNOWN;\n    return mutationsStore(transaction).iterate({\n      index: DbMutationBatch.userMutationsIndex,\n      range: range,\n      reverse: true\n    }, function (key, dbBatch, control) {\n      batchId = dbBatch.batchId;\n      control.done();\n    }).next(function () {\n      return batchId;\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.getAllMutationBatches = function (transaction) {\n    var _this = this;\n\n    var range = IDBKeyRange.bound([this.userId, BATCHID_UNKNOWN], [this.userId, Number.POSITIVE_INFINITY]);\n    return mutationsStore(transaction).loadAll(DbMutationBatch.userMutationsIndex, range).next(function (dbBatches) {\n      return dbBatches.map(function (dbBatch) {\n        return fromDbMutationBatch(_this.serializer, dbBatch);\n      });\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.getAllMutationBatchesAffectingDocumentKey = function (transaction, documentKey) {\n    var _this = this; // Scan the document-mutation index starting with a prefix starting with\n    // the given documentKey.\n\n\n    var indexPrefix = DbDocumentMutation.prefixForPath(this.userId, documentKey.path);\n    var indexStart = IDBKeyRange.lowerBound(indexPrefix);\n    var results = [];\n    return documentMutationsStore(transaction).iterate({\n      range: indexStart\n    }, function (indexKey, _, control) {\n      var userID = indexKey[0],\n          encodedPath = indexKey[1],\n          batchId = indexKey[2]; // Only consider rows matching exactly the specific key of\n      // interest. Note that because we order by path first, and we\n      // order terminators before path separators, we'll encounter all\n      // the index rows for documentKey contiguously. In particular, all\n      // the rows for documentKey will occur before any rows for\n      // documents nested in a subcollection beneath documentKey so we\n      // can stop as soon as we hit any such row.\n\n      var path = decodeResourcePath(encodedPath);\n\n      if (userID !== _this.userId || !documentKey.path.isEqual(path)) {\n        control.done();\n        return;\n      } // Look up the mutation batch in the store.\n\n\n      return mutationsStore(transaction).get(batchId).next(function (mutation) {\n        if (!mutation) {\n          throw fail();\n        }\n\n        hardAssert(mutation.userId === _this.userId);\n        results.push(fromDbMutationBatch(_this.serializer, mutation));\n      });\n    }).next(function () {\n      return results;\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.getAllMutationBatchesAffectingDocumentKeys = function (transaction, documentKeys) {\n    var _this = this;\n\n    var uniqueBatchIDs = new SortedSet(primitiveComparator);\n    var promises = [];\n    documentKeys.forEach(function (documentKey) {\n      var indexStart = DbDocumentMutation.prefixForPath(_this.userId, documentKey.path);\n      var range = IDBKeyRange.lowerBound(indexStart);\n      var promise = documentMutationsStore(transaction).iterate({\n        range: range\n      }, function (indexKey, _, control) {\n        var userID = indexKey[0],\n            encodedPath = indexKey[1],\n            batchID = indexKey[2]; // Only consider rows matching exactly the specific key of\n        // interest. Note that because we order by path first, and we\n        // order terminators before path separators, we'll encounter all\n        // the index rows for documentKey contiguously. In particular, all\n        // the rows for documentKey will occur before any rows for\n        // documents nested in a subcollection beneath documentKey so we\n        // can stop as soon as we hit any such row.\n\n        var path = decodeResourcePath(encodedPath);\n\n        if (userID !== _this.userId || !documentKey.path.isEqual(path)) {\n          control.done();\n          return;\n        }\n\n        uniqueBatchIDs = uniqueBatchIDs.add(batchID);\n      });\n      promises.push(promise);\n    });\n    return PersistencePromise.waitFor(promises).next(function () {\n      return _this.lookupMutationBatches(transaction, uniqueBatchIDs);\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.getAllMutationBatchesAffectingQuery = function (transaction, query) {\n    var _this = this;\n\n    var queryPath = query.path;\n    var immediateChildrenLength = queryPath.length + 1; // TODO(mcg): Actually implement a single-collection query\n    //\n    // This is actually executing an ancestor query, traversing the whole\n    // subtree below the collection which can be horrifically inefficient for\n    // some structures. The right way to solve this is to implement the full\n    // value index, but that's not in the cards in the near future so this is\n    // the best we can do for the moment.\n    //\n    // Since we don't yet index the actual properties in the mutations, our\n    // current approach is to just return all mutation batches that affect\n    // documents in the collection being queried.\n\n    var indexPrefix = DbDocumentMutation.prefixForPath(this.userId, queryPath);\n    var indexStart = IDBKeyRange.lowerBound(indexPrefix); // Collect up unique batchIDs encountered during a scan of the index. Use a\n    // SortedSet to accumulate batch IDs so they can be traversed in order in a\n    // scan of the main table.\n\n    var uniqueBatchIDs = new SortedSet(primitiveComparator);\n    return documentMutationsStore(transaction).iterate({\n      range: indexStart\n    }, function (indexKey, _, control) {\n      var userID = indexKey[0],\n          encodedPath = indexKey[1],\n          batchID = indexKey[2];\n      var path = decodeResourcePath(encodedPath);\n\n      if (userID !== _this.userId || !queryPath.isPrefixOf(path)) {\n        control.done();\n        return;\n      } // Rows with document keys more than one segment longer than the\n      // query path can't be matches. For example, a query on 'rooms'\n      // can't match the document /rooms/abc/messages/xyx.\n      // TODO(mcg): we'll need a different scanner when we implement\n      // ancestor queries.\n\n\n      if (path.length !== immediateChildrenLength) {\n        return;\n      }\n\n      uniqueBatchIDs = uniqueBatchIDs.add(batchID);\n    }).next(function () {\n      return _this.lookupMutationBatches(transaction, uniqueBatchIDs);\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.lookupMutationBatches = function (transaction, batchIDs) {\n    var _this = this;\n\n    var results = [];\n    var promises = []; // TODO(rockwood): Implement this using iterate.\n\n    batchIDs.forEach(function (batchId) {\n      promises.push(mutationsStore(transaction).get(batchId).next(function (mutation) {\n        if (mutation === null) {\n          throw fail();\n        }\n\n        hardAssert(mutation.userId === _this.userId);\n        results.push(fromDbMutationBatch(_this.serializer, mutation));\n      }));\n    });\n    return PersistencePromise.waitFor(promises).next(function () {\n      return results;\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.removeMutationBatch = function (transaction, batch) {\n    var _this = this;\n\n    return removeMutationBatch(transaction.simpleDbTransaction, this.userId, batch).next(function (removedDocuments) {\n      transaction.addOnCommittedListener(function () {\n        _this.removeCachedMutationKeys(batch.batchId);\n      });\n      return PersistencePromise.forEach(removedDocuments, function (key) {\n        return _this.referenceDelegate.markPotentiallyOrphaned(transaction, key);\n      });\n    });\n  };\n  /**\r\n   * Clears the cached keys for a mutation batch. This method should be\r\n   * called by secondary clients after they process mutation updates.\r\n   *\r\n   * Note that this method does not have to be called from primary clients as\r\n   * the corresponding cache entries are cleared when an acknowledged or\r\n   * rejected batch is removed from the mutation queue.\r\n   */\n  // PORTING NOTE: Multi-tab only\n\n\n  IndexedDbMutationQueue.prototype.removeCachedMutationKeys = function (batchId) {\n    delete this.documentKeysByBatchId[batchId];\n  };\n\n  IndexedDbMutationQueue.prototype.performConsistencyCheck = function (txn) {\n    var _this = this;\n\n    return this.checkEmpty(txn).next(function (empty) {\n      if (!empty) {\n        return PersistencePromise.resolve();\n      } // Verify that there are no entries in the documentMutations index if\n      // the queue is empty.\n\n\n      var startRange = IDBKeyRange.lowerBound(DbDocumentMutation.prefixForUser(_this.userId));\n      var danglingMutationReferences = [];\n      return documentMutationsStore(txn).iterate({\n        range: startRange\n      }, function (key, _, control) {\n        var userID = key[0];\n\n        if (userID !== _this.userId) {\n          control.done();\n          return;\n        } else {\n          var path = decodeResourcePath(key[1]);\n          danglingMutationReferences.push(path);\n        }\n      }).next(function () {\n        hardAssert(danglingMutationReferences.length === 0);\n      });\n    });\n  };\n\n  IndexedDbMutationQueue.prototype.containsKey = function (txn, key) {\n    return mutationQueueContainsKey(txn, this.userId, key);\n  }; // PORTING NOTE: Multi-tab only (state is held in memory in other clients).\n\n  /** Returns the mutation queue's metadata from IndexedDb. */\n\n\n  IndexedDbMutationQueue.prototype.getMutationQueueMetadata = function (transaction) {\n    var _this = this;\n\n    return mutationQueuesStore(transaction).get(this.userId).next(function (metadata) {\n      return metadata || new DbMutationQueue(_this.userId, BATCHID_UNKNOWN,\n      /*lastStreamToken=*/\n      '');\n    });\n  };\n\n  return IndexedDbMutationQueue;\n}();\n/**\r\n * @returns true if the mutation queue for the given user contains a pending\r\n *         mutation for the given key.\r\n */\n\n\nfunction mutationQueueContainsKey(txn, userId, key) {\n  var indexKey = DbDocumentMutation.prefixForPath(userId, key.path);\n  var encodedPath = indexKey[1];\n  var startRange = IDBKeyRange.lowerBound(indexKey);\n  var containsKey = false;\n  return documentMutationsStore(txn).iterate({\n    range: startRange,\n    keysOnly: true\n  }, function (key, value, control) {\n    var userID = key[0],\n        keyPath = key[1];\n    /*batchID*/\n\n    key[2];\n\n    if (userID === userId && keyPath === encodedPath) {\n      containsKey = true;\n    }\n\n    control.done();\n  }).next(function () {\n    return containsKey;\n  });\n}\n/** Returns true if any mutation queue contains the given document. */\n\n\nfunction mutationQueuesContainKey(txn, docKey) {\n  var found = false;\n  return mutationQueuesStore(txn).iterateSerial(function (userId) {\n    return mutationQueueContainsKey(txn, userId, docKey).next(function (containsKey) {\n      if (containsKey) {\n        found = true;\n      }\n\n      return PersistencePromise.resolve(!containsKey);\n    });\n  }).next(function () {\n    return found;\n  });\n}\n/**\r\n * Helper to get a typed SimpleDbStore for the mutations object store.\r\n */\n\n\nfunction mutationsStore(txn) {\n  return getStore(txn, DbMutationBatch.store);\n}\n/**\r\n * Helper to get a typed SimpleDbStore for the mutationQueues object store.\r\n */\n\n\nfunction documentMutationsStore(txn) {\n  return getStore(txn, DbDocumentMutation.store);\n}\n/**\r\n * Helper to get a typed SimpleDbStore for the mutationQueues object store.\r\n */\n\n\nfunction mutationQueuesStore(txn) {\n  return getStore(txn, DbMutationQueue.store);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Offset to ensure non-overlapping target ids. */\n\n\nvar OFFSET = 2;\n/**\r\n * Generates monotonically increasing target IDs for sending targets to the\r\n * watch stream.\r\n *\r\n * The client constructs two generators, one for the target cache, and one for\r\n * for the sync engine (to generate limbo documents targets). These\r\n * generators produce non-overlapping IDs (by using even and odd IDs\r\n * respectively).\r\n *\r\n * By separating the target ID space, the query cache can generate target IDs\r\n * that persist across client restarts, while sync engine can independently\r\n * generate in-memory target IDs that are transient and can be reused after a\r\n * restart.\r\n */\n\nvar TargetIdGenerator =\n/** @class */\nfunction () {\n  function TargetIdGenerator(lastId) {\n    this.lastId = lastId;\n  }\n\n  TargetIdGenerator.prototype.next = function () {\n    this.lastId += OFFSET;\n    return this.lastId;\n  };\n\n  TargetIdGenerator.forTargetCache = function () {\n    // The target cache generator must return '2' in its first call to `next()`\n    // as there is no differentiation in the protocol layer between an unset\n    // number and the number '0'. If we were to sent a target with target ID\n    // '0', the backend would consider it unset and replace it with its own ID.\n    return new TargetIdGenerator(2 - OFFSET);\n  };\n\n  TargetIdGenerator.forSyncEngine = function () {\n    // Sync engine assigns target IDs for limbo document detection.\n    return new TargetIdGenerator(1 - OFFSET);\n  };\n\n  return TargetIdGenerator;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar IndexedDbTargetCache =\n/** @class */\nfunction () {\n  function IndexedDbTargetCache(referenceDelegate, serializer) {\n    this.referenceDelegate = referenceDelegate;\n    this.serializer = serializer;\n  } // PORTING NOTE: We don't cache global metadata for the target cache, since\n  // some of it (in particular `highestTargetId`) can be modified by secondary\n  // tabs. We could perhaps be more granular (and e.g. still cache\n  // `lastRemoteSnapshotVersion` in memory) but for simplicity we currently go\n  // to IndexedDb whenever we need to read metadata. We can revisit if it turns\n  // out to have a meaningful performance impact.\n\n\n  IndexedDbTargetCache.prototype.allocateTargetId = function (transaction) {\n    var _this = this;\n\n    return this.retrieveMetadata(transaction).next(function (metadata) {\n      var targetIdGenerator = new TargetIdGenerator(metadata.highestTargetId);\n      metadata.highestTargetId = targetIdGenerator.next();\n      return _this.saveMetadata(transaction, metadata).next(function () {\n        return metadata.highestTargetId;\n      });\n    });\n  };\n\n  IndexedDbTargetCache.prototype.getLastRemoteSnapshotVersion = function (transaction) {\n    return this.retrieveMetadata(transaction).next(function (metadata) {\n      return SnapshotVersion.fromTimestamp(new Timestamp(metadata.lastRemoteSnapshotVersion.seconds, metadata.lastRemoteSnapshotVersion.nanoseconds));\n    });\n  };\n\n  IndexedDbTargetCache.prototype.getHighestSequenceNumber = function (transaction) {\n    return this.retrieveMetadata(transaction).next(function (targetGlobal) {\n      return targetGlobal.highestListenSequenceNumber;\n    });\n  };\n\n  IndexedDbTargetCache.prototype.setTargetsMetadata = function (transaction, highestListenSequenceNumber, lastRemoteSnapshotVersion) {\n    var _this = this;\n\n    return this.retrieveMetadata(transaction).next(function (metadata) {\n      metadata.highestListenSequenceNumber = highestListenSequenceNumber;\n\n      if (lastRemoteSnapshotVersion) {\n        metadata.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion.toTimestamp();\n      }\n\n      if (highestListenSequenceNumber > metadata.highestListenSequenceNumber) {\n        metadata.highestListenSequenceNumber = highestListenSequenceNumber;\n      }\n\n      return _this.saveMetadata(transaction, metadata);\n    });\n  };\n\n  IndexedDbTargetCache.prototype.addTargetData = function (transaction, targetData) {\n    var _this = this;\n\n    return this.saveTargetData(transaction, targetData).next(function () {\n      return _this.retrieveMetadata(transaction).next(function (metadata) {\n        metadata.targetCount += 1;\n\n        _this.updateMetadataFromTargetData(targetData, metadata);\n\n        return _this.saveMetadata(transaction, metadata);\n      });\n    });\n  };\n\n  IndexedDbTargetCache.prototype.updateTargetData = function (transaction, targetData) {\n    return this.saveTargetData(transaction, targetData);\n  };\n\n  IndexedDbTargetCache.prototype.removeTargetData = function (transaction, targetData) {\n    var _this = this;\n\n    return this.removeMatchingKeysForTargetId(transaction, targetData.targetId).next(function () {\n      return targetsStore(transaction).delete(targetData.targetId);\n    }).next(function () {\n      return _this.retrieveMetadata(transaction);\n    }).next(function (metadata) {\n      hardAssert(metadata.targetCount > 0);\n      metadata.targetCount -= 1;\n      return _this.saveMetadata(transaction, metadata);\n    });\n  };\n  /**\r\n   * Drops any targets with sequence number less than or equal to the upper bound, excepting those\r\n   * present in `activeTargetIds`. Document associations for the removed targets are also removed.\r\n   * Returns the number of targets removed.\r\n   */\n\n\n  IndexedDbTargetCache.prototype.removeTargets = function (txn, upperBound, activeTargetIds) {\n    var _this = this;\n\n    var count = 0;\n    var promises = [];\n    return targetsStore(txn).iterate(function (key, value) {\n      var targetData = fromDbTarget(value);\n\n      if (targetData.sequenceNumber <= upperBound && activeTargetIds.get(targetData.targetId) === null) {\n        count++;\n        promises.push(_this.removeTargetData(txn, targetData));\n      }\n    }).next(function () {\n      return PersistencePromise.waitFor(promises);\n    }).next(function () {\n      return count;\n    });\n  };\n  /**\r\n   * Call provided function with each `TargetData` that we have cached.\r\n   */\n\n\n  IndexedDbTargetCache.prototype.forEachTarget = function (txn, f) {\n    return targetsStore(txn).iterate(function (key, value) {\n      var targetData = fromDbTarget(value);\n      f(targetData);\n    });\n  };\n\n  IndexedDbTargetCache.prototype.retrieveMetadata = function (transaction) {\n    return globalTargetStore(transaction).get(DbTargetGlobal.key).next(function (metadata) {\n      hardAssert(metadata !== null);\n      return metadata;\n    });\n  };\n\n  IndexedDbTargetCache.prototype.saveMetadata = function (transaction, metadata) {\n    return globalTargetStore(transaction).put(DbTargetGlobal.key, metadata);\n  };\n\n  IndexedDbTargetCache.prototype.saveTargetData = function (transaction, targetData) {\n    return targetsStore(transaction).put(toDbTarget(this.serializer, targetData));\n  };\n  /**\r\n   * In-place updates the provided metadata to account for values in the given\r\n   * TargetData. Saving is done separately. Returns true if there were any\r\n   * changes to the metadata.\r\n   */\n\n\n  IndexedDbTargetCache.prototype.updateMetadataFromTargetData = function (targetData, metadata) {\n    var updated = false;\n\n    if (targetData.targetId > metadata.highestTargetId) {\n      metadata.highestTargetId = targetData.targetId;\n      updated = true;\n    }\n\n    if (targetData.sequenceNumber > metadata.highestListenSequenceNumber) {\n      metadata.highestListenSequenceNumber = targetData.sequenceNumber;\n      updated = true;\n    }\n\n    return updated;\n  };\n\n  IndexedDbTargetCache.prototype.getTargetCount = function (transaction) {\n    return this.retrieveMetadata(transaction).next(function (metadata) {\n      return metadata.targetCount;\n    });\n  };\n\n  IndexedDbTargetCache.prototype.getTargetData = function (transaction, target) {\n    // Iterating by the canonicalId may yield more than one result because\n    // canonicalId values are not required to be unique per target. This query\n    // depends on the queryTargets index to be efficient.\n    var canonicalId = canonifyTarget(target);\n    var range = IDBKeyRange.bound([canonicalId, Number.NEGATIVE_INFINITY], [canonicalId, Number.POSITIVE_INFINITY]);\n    var result = null;\n    return targetsStore(transaction).iterate({\n      range: range,\n      index: DbTarget.queryTargetsIndexName\n    }, function (key, value, control) {\n      var found = fromDbTarget(value); // After finding a potential match, check that the target is\n      // actually equal to the requested target.\n\n      if (targetEquals(target, found.target)) {\n        result = found;\n        control.done();\n      }\n    }).next(function () {\n      return result;\n    });\n  };\n\n  IndexedDbTargetCache.prototype.addMatchingKeys = function (txn, keys, targetId) {\n    var _this = this; // PORTING NOTE: The reverse index (documentsTargets) is maintained by\n    // IndexedDb.\n\n\n    var promises = [];\n    var store = documentTargetStore(txn);\n    keys.forEach(function (key) {\n      var path = encodeResourcePath(key.path);\n      promises.push(store.put(new DbTargetDocument(targetId, path)));\n      promises.push(_this.referenceDelegate.addReference(txn, targetId, key));\n    });\n    return PersistencePromise.waitFor(promises);\n  };\n\n  IndexedDbTargetCache.prototype.removeMatchingKeys = function (txn, keys, targetId) {\n    var _this = this; // PORTING NOTE: The reverse index (documentsTargets) is maintained by\n    // IndexedDb.\n\n\n    var store = documentTargetStore(txn);\n    return PersistencePromise.forEach(keys, function (key) {\n      var path = encodeResourcePath(key.path);\n      return PersistencePromise.waitFor([store.delete([targetId, path]), _this.referenceDelegate.removeReference(txn, targetId, key)]);\n    });\n  };\n\n  IndexedDbTargetCache.prototype.removeMatchingKeysForTargetId = function (txn, targetId) {\n    var store = documentTargetStore(txn);\n    var range = IDBKeyRange.bound([targetId], [targetId + 1],\n    /*lowerOpen=*/\n    false,\n    /*upperOpen=*/\n    true);\n    return store.delete(range);\n  };\n\n  IndexedDbTargetCache.prototype.getMatchingKeysForTargetId = function (txn, targetId) {\n    var range = IDBKeyRange.bound([targetId], [targetId + 1],\n    /*lowerOpen=*/\n    false,\n    /*upperOpen=*/\n    true);\n    var store = documentTargetStore(txn);\n    var result = documentKeySet();\n    return store.iterate({\n      range: range,\n      keysOnly: true\n    }, function (key, _, control) {\n      var path = decodeResourcePath(key[1]);\n      var docKey = new DocumentKey(path);\n      result = result.add(docKey);\n    }).next(function () {\n      return result;\n    });\n  };\n\n  IndexedDbTargetCache.prototype.containsKey = function (txn, key) {\n    var path = encodeResourcePath(key.path);\n    var range = IDBKeyRange.bound([path], [immediateSuccessor(path)],\n    /*lowerOpen=*/\n    false,\n    /*upperOpen=*/\n    true);\n    var count = 0;\n    return documentTargetStore(txn).iterate({\n      index: DbTargetDocument.documentTargetsIndex,\n      keysOnly: true,\n      range: range\n    }, function (_d, _, control) {\n      var targetId = _d[0];\n      _d[1]; // Having a sentinel row for a document does not count as containing that document;\n      // For the target cache, containing the document means the document is part of some\n      // target.\n\n      if (targetId !== 0) {\n        count++;\n        control.done();\n      }\n    }).next(function () {\n      return count > 0;\n    });\n  };\n  /**\r\n   * Looks up a TargetData entry by target ID.\r\n   *\r\n   * @param targetId - The target ID of the TargetData entry to look up.\r\n   * @returns The cached TargetData entry, or null if the cache has no entry for\r\n   * the target.\r\n   */\n  // PORTING NOTE: Multi-tab only.\n\n\n  IndexedDbTargetCache.prototype.getTargetDataForTarget = function (transaction, targetId) {\n    return targetsStore(transaction).get(targetId).next(function (found) {\n      if (found) {\n        return fromDbTarget(found);\n      } else {\n        return null;\n      }\n    });\n  };\n\n  return IndexedDbTargetCache;\n}();\n/**\r\n * Helper to get a typed SimpleDbStore for the queries object store.\r\n */\n\n\nfunction targetsStore(txn) {\n  return getStore(txn, DbTarget.store);\n}\n/**\r\n * Helper to get a typed SimpleDbStore for the target globals object store.\r\n */\n\n\nfunction globalTargetStore(txn) {\n  return getStore(txn, DbTargetGlobal.store);\n}\n/**\r\n * Helper to get a typed SimpleDbStore for the document target object store.\r\n */\n\n\nfunction documentTargetStore(txn) {\n  return getStore(txn, DbTargetDocument.store);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Verifies the error thrown by a LocalStore operation. If a LocalStore\r\n * operation fails because the primary lease has been taken by another client,\r\n * we ignore the error (the persistence layer will immediately call\r\n * `applyPrimaryLease` to propagate the primary state change). All other errors\r\n * are re-thrown.\r\n *\r\n * @param err - An error returned by a LocalStore operation.\r\n * @returns A Promise that resolves after we recovered, or the original error.\r\n */\n\n\nfunction ignoreIfPrimaryLeaseLoss(err) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    return tslib.__generator(this, function (_d) {\n      if (err.code === Code.FAILED_PRECONDITION && err.message === PRIMARY_LEASE_LOST_ERROR_MSG) {\n        logDebug('LocalStore', 'Unexpectedly lost primary lease');\n      } else {\n        throw err;\n      }\n\n      return [2\n      /*return*/\n      ];\n    });\n  });\n}\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar GC_DID_NOT_RUN = {\n  didRun: false,\n  sequenceNumbersCollected: 0,\n  targetsRemoved: 0,\n  documentsRemoved: 0\n};\nvar LRU_COLLECTION_DISABLED = -1;\nvar LRU_DEFAULT_CACHE_SIZE_BYTES = 40 * 1024 * 1024;\n\nvar LruParams =\n/** @class */\nfunction () {\n  function LruParams( // When we attempt to collect, we will only do so if the cache size is greater than this\n  // threshold. Passing `COLLECTION_DISABLED` here will cause collection to always be skipped.\n  cacheSizeCollectionThreshold, // The percentage of sequence numbers that we will attempt to collect\n  percentileToCollect, // A cap on the total number of sequence numbers that will be collected. This prevents\n  // us from collecting a huge number of sequence numbers if the cache has grown very large.\n  maximumSequenceNumbersToCollect) {\n    this.cacheSizeCollectionThreshold = cacheSizeCollectionThreshold;\n    this.percentileToCollect = percentileToCollect;\n    this.maximumSequenceNumbersToCollect = maximumSequenceNumbersToCollect;\n  }\n\n  LruParams.withCacheSize = function (cacheSize) {\n    return new LruParams(cacheSize, LruParams.DEFAULT_COLLECTION_PERCENTILE, LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT);\n  };\n\n  return LruParams;\n}();\n\nLruParams.DEFAULT_COLLECTION_PERCENTILE = 10;\nLruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT = 1000;\nLruParams.DEFAULT = new LruParams(LRU_DEFAULT_CACHE_SIZE_BYTES, LruParams.DEFAULT_COLLECTION_PERCENTILE, LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT);\nLruParams.DISABLED = new LruParams(LRU_COLLECTION_DISABLED, 0, 0);\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\nvar LOG_TAG$e = 'LruGarbageCollector';\nvar LRU_MINIMUM_CACHE_SIZE_BYTES = 1 * 1024 * 1024;\n/** How long we wait to try running LRU GC after SDK initialization. */\n\nvar INITIAL_GC_DELAY_MS = 1 * 60 * 1000;\n/** Minimum amount of time between GC checks, after the first one. */\n\nvar REGULAR_GC_DELAY_MS = 5 * 60 * 1000;\n\nfunction bufferEntryComparator(_d, _e) {\n  var aSequence = _d[0],\n      aIndex = _d[1];\n  var bSequence = _e[0],\n      bIndex = _e[1];\n  var seqCmp = primitiveComparator(aSequence, bSequence);\n\n  if (seqCmp === 0) {\n    // This order doesn't matter, but we can bias against churn by sorting\n    // entries created earlier as less than newer entries.\n    return primitiveComparator(aIndex, bIndex);\n  } else {\n    return seqCmp;\n  }\n}\n/**\r\n * Used to calculate the nth sequence number. Keeps a rolling buffer of the\r\n * lowest n values passed to `addElement`, and finally reports the largest of\r\n * them in `maxValue`.\r\n */\n\n\nvar RollingSequenceNumberBuffer =\n/** @class */\nfunction () {\n  function RollingSequenceNumberBuffer(maxElements) {\n    this.maxElements = maxElements;\n    this.buffer = new SortedSet(bufferEntryComparator);\n    this.previousIndex = 0;\n  }\n\n  RollingSequenceNumberBuffer.prototype.nextIndex = function () {\n    return ++this.previousIndex;\n  };\n\n  RollingSequenceNumberBuffer.prototype.addElement = function (sequenceNumber) {\n    var entry = [sequenceNumber, this.nextIndex()];\n\n    if (this.buffer.size < this.maxElements) {\n      this.buffer = this.buffer.add(entry);\n    } else {\n      var highestValue = this.buffer.last();\n\n      if (bufferEntryComparator(entry, highestValue) < 0) {\n        this.buffer = this.buffer.delete(highestValue).add(entry);\n      }\n    }\n  };\n\n  Object.defineProperty(RollingSequenceNumberBuffer.prototype, \"maxValue\", {\n    get: function () {\n      // Guaranteed to be non-empty. If we decide we are not collecting any\n      // sequence numbers, nthSequenceNumber below short-circuits. If we have\n      // decided that we are collecting n sequence numbers, it's because n is some\n      // percentage of the existing sequence numbers. That means we should never\n      // be in a situation where we are collecting sequence numbers but don't\n      // actually have any.\n      return this.buffer.last()[0];\n    },\n    enumerable: false,\n    configurable: true\n  });\n  return RollingSequenceNumberBuffer;\n}();\n/**\r\n * This class is responsible for the scheduling of LRU garbage collection. It handles checking\r\n * whether or not GC is enabled, as well as which delay to use before the next run.\r\n */\n\n\nvar LruScheduler =\n/** @class */\nfunction () {\n  function LruScheduler(garbageCollector, asyncQueue) {\n    this.garbageCollector = garbageCollector;\n    this.asyncQueue = asyncQueue;\n    this.hasRun = false;\n    this.gcTask = null;\n  }\n\n  LruScheduler.prototype.start = function (localStore) {\n    if (this.garbageCollector.params.cacheSizeCollectionThreshold !== LRU_COLLECTION_DISABLED) {\n      this.scheduleGC(localStore);\n    }\n  };\n\n  LruScheduler.prototype.stop = function () {\n    if (this.gcTask) {\n      this.gcTask.cancel();\n      this.gcTask = null;\n    }\n  };\n\n  Object.defineProperty(LruScheduler.prototype, \"started\", {\n    get: function () {\n      return this.gcTask !== null;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  LruScheduler.prototype.scheduleGC = function (localStore) {\n    var _this = this;\n\n    var delay = this.hasRun ? REGULAR_GC_DELAY_MS : INITIAL_GC_DELAY_MS;\n    logDebug('LruGarbageCollector', \"Garbage collection scheduled in \" + delay + \"ms\");\n    this.gcTask = this.asyncQueue.enqueueAfterDelay(\"lru_garbage_collection\"\n    /* LruGarbageCollection */\n    , delay, function () {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        var e_1;\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              this.gcTask = null;\n              this.hasRun = true;\n              _d.label = 1;\n\n            case 1:\n              _d.trys.push([1, 3,, 7]);\n\n              return [4\n              /*yield*/\n              , localStore.collectGarbage(this.garbageCollector)];\n\n            case 2:\n              _d.sent();\n\n              return [3\n              /*break*/\n              , 7];\n\n            case 3:\n              e_1 = _d.sent();\n              if (!isIndexedDbTransactionError(e_1)) return [3\n              /*break*/\n              , 4];\n              logDebug(LOG_TAG$e, 'Ignoring IndexedDB error during garbage collection: ', e_1);\n              return [3\n              /*break*/\n              , 6];\n\n            case 4:\n              return [4\n              /*yield*/\n              , ignoreIfPrimaryLeaseLoss(e_1)];\n\n            case 5:\n              _d.sent();\n\n              _d.label = 6;\n\n            case 6:\n              return [3\n              /*break*/\n              , 7];\n\n            case 7:\n              return [4\n              /*yield*/\n              , this.scheduleGC(localStore)];\n\n            case 8:\n              _d.sent();\n\n              return [2\n              /*return*/\n              ];\n          }\n        });\n      });\n    });\n  };\n\n  return LruScheduler;\n}();\n/** Implements the steps for LRU garbage collection. */\n\n\nvar LruGarbageCollectorImpl =\n/** @class */\nfunction () {\n  function LruGarbageCollectorImpl(delegate, params) {\n    this.delegate = delegate;\n    this.params = params;\n  }\n\n  LruGarbageCollectorImpl.prototype.calculateTargetCount = function (txn, percentile) {\n    return this.delegate.getSequenceNumberCount(txn).next(function (targetCount) {\n      return Math.floor(percentile / 100.0 * targetCount);\n    });\n  };\n\n  LruGarbageCollectorImpl.prototype.nthSequenceNumber = function (txn, n) {\n    var _this = this;\n\n    if (n === 0) {\n      return PersistencePromise.resolve(ListenSequence.INVALID);\n    }\n\n    var buffer = new RollingSequenceNumberBuffer(n);\n    return this.delegate.forEachTarget(txn, function (target) {\n      return buffer.addElement(target.sequenceNumber);\n    }).next(function () {\n      return _this.delegate.forEachOrphanedDocumentSequenceNumber(txn, function (sequenceNumber) {\n        return buffer.addElement(sequenceNumber);\n      });\n    }).next(function () {\n      return buffer.maxValue;\n    });\n  };\n\n  LruGarbageCollectorImpl.prototype.removeTargets = function (txn, upperBound, activeTargetIds) {\n    return this.delegate.removeTargets(txn, upperBound, activeTargetIds);\n  };\n\n  LruGarbageCollectorImpl.prototype.removeOrphanedDocuments = function (txn, upperBound) {\n    return this.delegate.removeOrphanedDocuments(txn, upperBound);\n  };\n\n  LruGarbageCollectorImpl.prototype.collect = function (txn, activeTargetIds) {\n    var _this = this;\n\n    if (this.params.cacheSizeCollectionThreshold === LRU_COLLECTION_DISABLED) {\n      logDebug('LruGarbageCollector', 'Garbage collection skipped; disabled');\n      return PersistencePromise.resolve(GC_DID_NOT_RUN);\n    }\n\n    return this.getCacheSize(txn).next(function (cacheSize) {\n      if (cacheSize < _this.params.cacheSizeCollectionThreshold) {\n        logDebug('LruGarbageCollector', \"Garbage collection skipped; Cache size \" + cacheSize + \" \" + (\"is lower than threshold \" + _this.params.cacheSizeCollectionThreshold));\n        return GC_DID_NOT_RUN;\n      } else {\n        return _this.runGarbageCollection(txn, activeTargetIds);\n      }\n    });\n  };\n\n  LruGarbageCollectorImpl.prototype.getCacheSize = function (txn) {\n    return this.delegate.getCacheSize(txn);\n  };\n\n  LruGarbageCollectorImpl.prototype.runGarbageCollection = function (txn, activeTargetIds) {\n    var _this = this;\n\n    var upperBoundSequenceNumber;\n    var sequenceNumbersToCollect, targetsRemoved; // Timestamps for various pieces of the process\n\n    var countedTargetsTs, foundUpperBoundTs, removedTargetsTs, removedDocumentsTs;\n    var startTs = Date.now();\n    return this.calculateTargetCount(txn, this.params.percentileToCollect).next(function (sequenceNumbers) {\n      // Cap at the configured max\n      if (sequenceNumbers > _this.params.maximumSequenceNumbersToCollect) {\n        logDebug('LruGarbageCollector', 'Capping sequence numbers to collect down ' + (\"to the maximum of \" + _this.params.maximumSequenceNumbersToCollect + \" \") + (\"from \" + sequenceNumbers));\n        sequenceNumbersToCollect = _this.params.maximumSequenceNumbersToCollect;\n      } else {\n        sequenceNumbersToCollect = sequenceNumbers;\n      }\n\n      countedTargetsTs = Date.now();\n      return _this.nthSequenceNumber(txn, sequenceNumbersToCollect);\n    }).next(function (upperBound) {\n      upperBoundSequenceNumber = upperBound;\n      foundUpperBoundTs = Date.now();\n      return _this.removeTargets(txn, upperBoundSequenceNumber, activeTargetIds);\n    }).next(function (numTargetsRemoved) {\n      targetsRemoved = numTargetsRemoved;\n      removedTargetsTs = Date.now();\n      return _this.removeOrphanedDocuments(txn, upperBoundSequenceNumber);\n    }).next(function (documentsRemoved) {\n      removedDocumentsTs = Date.now();\n\n      if (getLogLevel() <= logger.LogLevel.DEBUG) {\n        var desc = 'LRU Garbage Collection\\n' + (\"\\tCounted targets in \" + (countedTargetsTs - startTs) + \"ms\\n\") + (\"\\tDetermined least recently used \" + sequenceNumbersToCollect + \" in \") + (foundUpperBoundTs - countedTargetsTs + \"ms\\n\") + (\"\\tRemoved \" + targetsRemoved + \" targets in \") + (removedTargetsTs - foundUpperBoundTs + \"ms\\n\") + (\"\\tRemoved \" + documentsRemoved + \" documents in \") + (removedDocumentsTs - removedTargetsTs + \"ms\\n\") + (\"Total Duration: \" + (removedDocumentsTs - startTs) + \"ms\");\n        logDebug('LruGarbageCollector', desc);\n      }\n\n      return PersistencePromise.resolve({\n        didRun: true,\n        sequenceNumbersCollected: sequenceNumbersToCollect,\n        targetsRemoved: targetsRemoved,\n        documentsRemoved: documentsRemoved\n      });\n    });\n  };\n\n  return LruGarbageCollectorImpl;\n}();\n\nfunction newLruGarbageCollector(delegate, params) {\n  return new LruGarbageCollectorImpl(delegate, params);\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Provides LRU functionality for IndexedDB persistence. */\n\n\nvar IndexedDbLruDelegateImpl =\n/** @class */\nfunction () {\n  function IndexedDbLruDelegateImpl(db, params) {\n    this.db = db;\n    this.garbageCollector = newLruGarbageCollector(this, params);\n  }\n\n  IndexedDbLruDelegateImpl.prototype.getSequenceNumberCount = function (txn) {\n    var docCountPromise = this.orphanedDocumentCount(txn);\n    var targetCountPromise = this.db.getTargetCache().getTargetCount(txn);\n    return targetCountPromise.next(function (targetCount) {\n      return docCountPromise.next(function (docCount) {\n        return targetCount + docCount;\n      });\n    });\n  };\n\n  IndexedDbLruDelegateImpl.prototype.orphanedDocumentCount = function (txn) {\n    var orphanedCount = 0;\n    return this.forEachOrphanedDocumentSequenceNumber(txn, function (_) {\n      orphanedCount++;\n    }).next(function () {\n      return orphanedCount;\n    });\n  };\n\n  IndexedDbLruDelegateImpl.prototype.forEachTarget = function (txn, f) {\n    return this.db.getTargetCache().forEachTarget(txn, f);\n  };\n\n  IndexedDbLruDelegateImpl.prototype.forEachOrphanedDocumentSequenceNumber = function (txn, f) {\n    return this.forEachOrphanedDocument(txn, function (docKey, sequenceNumber) {\n      return f(sequenceNumber);\n    });\n  };\n\n  IndexedDbLruDelegateImpl.prototype.addReference = function (txn, targetId, key) {\n    return writeSentinelKey(txn, key);\n  };\n\n  IndexedDbLruDelegateImpl.prototype.removeReference = function (txn, targetId, key) {\n    return writeSentinelKey(txn, key);\n  };\n\n  IndexedDbLruDelegateImpl.prototype.removeTargets = function (txn, upperBound, activeTargetIds) {\n    return this.db.getTargetCache().removeTargets(txn, upperBound, activeTargetIds);\n  };\n\n  IndexedDbLruDelegateImpl.prototype.markPotentiallyOrphaned = function (txn, key) {\n    return writeSentinelKey(txn, key);\n  };\n  /**\r\n   * Returns true if anything would prevent this document from being garbage\r\n   * collected, given that the document in question is not present in any\r\n   * targets and has a sequence number less than or equal to the upper bound for\r\n   * the collection run.\r\n   */\n\n\n  IndexedDbLruDelegateImpl.prototype.isPinned = function (txn, docKey) {\n    return mutationQueuesContainKey(txn, docKey);\n  };\n\n  IndexedDbLruDelegateImpl.prototype.removeOrphanedDocuments = function (txn, upperBound) {\n    var _this = this;\n\n    var documentCache = this.db.getRemoteDocumentCache();\n    var changeBuffer = documentCache.newChangeBuffer();\n    var promises = [];\n    var documentCount = 0;\n    var iteration = this.forEachOrphanedDocument(txn, function (docKey, sequenceNumber) {\n      if (sequenceNumber <= upperBound) {\n        var p = _this.isPinned(txn, docKey).next(function (isPinned) {\n          if (!isPinned) {\n            documentCount++; // Our size accounting requires us to read all documents before\n            // removing them.\n\n            return changeBuffer.getEntry(txn, docKey).next(function () {\n              changeBuffer.removeEntry(docKey);\n              return documentTargetStore(txn).delete(sentinelKey$1(docKey));\n            });\n          }\n        });\n\n        promises.push(p);\n      }\n    });\n    return iteration.next(function () {\n      return PersistencePromise.waitFor(promises);\n    }).next(function () {\n      return changeBuffer.apply(txn);\n    }).next(function () {\n      return documentCount;\n    });\n  };\n\n  IndexedDbLruDelegateImpl.prototype.removeTarget = function (txn, targetData) {\n    var updated = targetData.withSequenceNumber(txn.currentSequenceNumber);\n    return this.db.getTargetCache().updateTargetData(txn, updated);\n  };\n\n  IndexedDbLruDelegateImpl.prototype.updateLimboDocument = function (txn, key) {\n    return writeSentinelKey(txn, key);\n  };\n  /**\r\n   * Call provided function for each document in the cache that is 'orphaned'. Orphaned\r\n   * means not a part of any target, so the only entry in the target-document index for\r\n   * that document will be the sentinel row (targetId 0), which will also have the sequence\r\n   * number for the last time the document was accessed.\r\n   */\n\n\n  IndexedDbLruDelegateImpl.prototype.forEachOrphanedDocument = function (txn, f) {\n    var store = documentTargetStore(txn);\n    var nextToReport = ListenSequence.INVALID;\n    var nextPath;\n    return store.iterate({\n      index: DbTargetDocument.documentTargetsIndex\n    }, function (_d, _e) {\n      var targetId = _d[0];\n      _d[1];\n      var path = _e.path,\n          sequenceNumber = _e.sequenceNumber;\n\n      if (targetId === 0) {\n        // if nextToReport is valid, report it, this is a new key so the\n        // last one must not be a member of any targets.\n        if (nextToReport !== ListenSequence.INVALID) {\n          f(new DocumentKey(decodeResourcePath(nextPath)), nextToReport);\n        } // set nextToReport to be this sequence number. It's the next one we\n        // might report, if we don't find any targets for this document.\n        // Note that the sequence number must be defined when the targetId\n        // is 0.\n\n\n        nextToReport = sequenceNumber;\n        nextPath = path;\n      } else {\n        // set nextToReport to be invalid, we know we don't need to report\n        // this one since we found a target for it.\n        nextToReport = ListenSequence.INVALID;\n      }\n    }).next(function () {\n      // Since we report sequence numbers after getting to the next key, we\n      // need to check if the last key we iterated over was an orphaned\n      // document and report it.\n      if (nextToReport !== ListenSequence.INVALID) {\n        f(new DocumentKey(decodeResourcePath(nextPath)), nextToReport);\n      }\n    });\n  };\n\n  IndexedDbLruDelegateImpl.prototype.getCacheSize = function (txn) {\n    return this.db.getRemoteDocumentCache().getSize(txn);\n  };\n\n  return IndexedDbLruDelegateImpl;\n}();\n\nfunction sentinelKey$1(key) {\n  return [0, encodeResourcePath(key.path)];\n}\n/**\r\n * @returns A value suitable for writing a sentinel row in the target-document\r\n * store.\r\n */\n\n\nfunction sentinelRow(key, sequenceNumber) {\n  return new DbTargetDocument(0, encodeResourcePath(key.path), sequenceNumber);\n}\n\nfunction writeSentinelKey(txn, key) {\n  return documentTargetStore(txn).put(sentinelRow(key, txn.currentSequenceNumber));\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A map implementation that uses objects as keys. Objects must have an\r\n * associated equals function and must be immutable. Entries in the map are\r\n * stored together with the key being produced from the mapKeyFn. This map\r\n * automatically handles collisions of keys.\r\n */\n\n\nvar ObjectMap =\n/** @class */\nfunction () {\n  function ObjectMap(mapKeyFn, equalsFn) {\n    this.mapKeyFn = mapKeyFn;\n    this.equalsFn = equalsFn;\n    /**\r\n     * The inner map for a key/value pair. Due to the possibility of collisions we\r\n     * keep a list of entries that we do a linear search through to find an actual\r\n     * match. Note that collisions should be rare, so we still expect near\r\n     * constant time lookups in practice.\r\n     */\n\n    this.inner = {};\n  }\n  /** Get a value for this key, or undefined if it does not exist. */\n\n\n  ObjectMap.prototype.get = function (key) {\n    var id = this.mapKeyFn(key);\n    var matches = this.inner[id];\n\n    if (matches === undefined) {\n      return undefined;\n    }\n\n    for (var _i = 0, matches_1 = matches; _i < matches_1.length; _i++) {\n      var _d = matches_1[_i],\n          otherKey = _d[0],\n          value = _d[1];\n\n      if (this.equalsFn(otherKey, key)) {\n        return value;\n      }\n    }\n\n    return undefined;\n  };\n\n  ObjectMap.prototype.has = function (key) {\n    return this.get(key) !== undefined;\n  };\n  /** Put this key and value in the map. */\n\n\n  ObjectMap.prototype.set = function (key, value) {\n    var id = this.mapKeyFn(key);\n    var matches = this.inner[id];\n\n    if (matches === undefined) {\n      this.inner[id] = [[key, value]];\n      return;\n    }\n\n    for (var i = 0; i < matches.length; i++) {\n      if (this.equalsFn(matches[i][0], key)) {\n        matches[i] = [key, value];\n        return;\n      }\n    }\n\n    matches.push([key, value]);\n  };\n  /**\r\n   * Remove this key from the map. Returns a boolean if anything was deleted.\r\n   */\n\n\n  ObjectMap.prototype.delete = function (key) {\n    var id = this.mapKeyFn(key);\n    var matches = this.inner[id];\n\n    if (matches === undefined) {\n      return false;\n    }\n\n    for (var i = 0; i < matches.length; i++) {\n      if (this.equalsFn(matches[i][0], key)) {\n        if (matches.length === 1) {\n          delete this.inner[id];\n        } else {\n          matches.splice(i, 1);\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  };\n\n  ObjectMap.prototype.forEach = function (fn) {\n    forEach(this.inner, function (_, entries) {\n      for (var _i = 0, entries_2 = entries; _i < entries_2.length; _i++) {\n        var _d = entries_2[_i],\n            k = _d[0],\n            v = _d[1];\n        fn(k, v);\n      }\n    });\n  };\n\n  ObjectMap.prototype.isEmpty = function () {\n    return isEmpty(this.inner);\n  };\n\n  return ObjectMap;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An in-memory buffer of entries to be written to a RemoteDocumentCache.\r\n * It can be used to batch up a set of changes to be written to the cache, but\r\n * additionally supports reading entries back with the `getEntry()` method,\r\n * falling back to the underlying RemoteDocumentCache if no entry is\r\n * buffered.\r\n *\r\n * Entries added to the cache *must* be read first. This is to facilitate\r\n * calculating the size delta of the pending changes.\r\n *\r\n * PORTING NOTE: This class was implemented then removed from other platforms.\r\n * If byte-counting ends up being needed on the other platforms, consider\r\n * porting this class as part of that implementation work.\r\n */\n\n\nvar RemoteDocumentChangeBuffer =\n/** @class */\nfunction () {\n  function RemoteDocumentChangeBuffer() {\n    // A mapping of document key to the new cache entry that should be written (or null if any\n    // existing cache entry should be removed).\n    this.changes = new ObjectMap(function (key) {\n      return key.toString();\n    }, function (l, r) {\n      return l.isEqual(r);\n    });\n    this.changesApplied = false;\n  }\n\n  RemoteDocumentChangeBuffer.prototype.getReadTime = function (key) {\n    var change = this.changes.get(key);\n\n    if (change) {\n      return change.readTime;\n    }\n\n    return SnapshotVersion.min();\n  };\n  /**\r\n   * Buffers a `RemoteDocumentCache.addEntry()` call.\r\n   *\r\n   * You can only modify documents that have already been retrieved via\r\n   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).\r\n   */\n\n\n  RemoteDocumentChangeBuffer.prototype.addEntry = function (document, readTime) {\n    this.assertNotApplied();\n    this.changes.set(document.key, {\n      document: document,\n      readTime: readTime\n    });\n  };\n  /**\r\n   * Buffers a `RemoteDocumentCache.removeEntry()` call.\r\n   *\r\n   * You can only remove documents that have already been retrieved via\r\n   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).\r\n   */\n\n\n  RemoteDocumentChangeBuffer.prototype.removeEntry = function (key, readTime) {\n    if (readTime === void 0) {\n      readTime = null;\n    }\n\n    this.assertNotApplied();\n    this.changes.set(key, {\n      document: MutableDocument.newInvalidDocument(key),\n      readTime: readTime\n    });\n  };\n  /**\r\n   * Looks up an entry in the cache. The buffered changes will first be checked,\r\n   * and if no buffered change applies, this will forward to\r\n   * `RemoteDocumentCache.getEntry()`.\r\n   *\r\n   * @param transaction - The transaction in which to perform any persistence\r\n   *     operations.\r\n   * @param documentKey - The key of the entry to look up.\r\n   * @returns The cached document or an invalid document if we have nothing\r\n   * cached.\r\n   */\n\n\n  RemoteDocumentChangeBuffer.prototype.getEntry = function (transaction, documentKey) {\n    this.assertNotApplied();\n    var bufferedEntry = this.changes.get(documentKey);\n\n    if (bufferedEntry !== undefined) {\n      return PersistencePromise.resolve(bufferedEntry.document);\n    } else {\n      return this.getFromCache(transaction, documentKey);\n    }\n  };\n  /**\r\n   * Looks up several entries in the cache, forwarding to\r\n   * `RemoteDocumentCache.getEntry()`.\r\n   *\r\n   * @param transaction - The transaction in which to perform any persistence\r\n   *     operations.\r\n   * @param documentKeys - The keys of the entries to look up.\r\n   * @returns A map of cached documents, indexed by key. If an entry cannot be\r\n   *     found, the corresponding key will be mapped to an invalid document.\r\n   */\n\n\n  RemoteDocumentChangeBuffer.prototype.getEntries = function (transaction, documentKeys) {\n    return this.getAllFromCache(transaction, documentKeys);\n  };\n  /**\r\n   * Applies buffered changes to the underlying RemoteDocumentCache, using\r\n   * the provided transaction.\r\n   */\n\n\n  RemoteDocumentChangeBuffer.prototype.apply = function (transaction) {\n    this.assertNotApplied();\n    this.changesApplied = true;\n    return this.applyChanges(transaction);\n  };\n  /** Helper to assert this.changes is not null  */\n\n\n  RemoteDocumentChangeBuffer.prototype.assertNotApplied = function () {};\n\n  return RemoteDocumentChangeBuffer;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * The RemoteDocumentCache for IndexedDb. To construct, invoke\r\n * `newIndexedDbRemoteDocumentCache()`.\r\n */\n\n\nvar IndexedDbRemoteDocumentCacheImpl =\n/** @class */\nfunction () {\n  /**\r\n   * @param serializer - The document serializer.\r\n   * @param indexManager - The query indexes that need to be maintained.\r\n   */\n  function IndexedDbRemoteDocumentCacheImpl(serializer, indexManager) {\n    this.serializer = serializer;\n    this.indexManager = indexManager;\n  }\n  /**\r\n   * Adds the supplied entries to the cache.\r\n   *\r\n   * All calls of `addEntry` are required to go through the RemoteDocumentChangeBuffer\r\n   * returned by `newChangeBuffer()` to ensure proper accounting of metadata.\r\n   */\n\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.addEntry = function (transaction, key, doc) {\n    var documentStore = remoteDocumentsStore(transaction);\n    return documentStore.put(dbKey(key), doc);\n  };\n  /**\r\n   * Removes a document from the cache.\r\n   *\r\n   * All calls of `removeEntry`  are required to go through the RemoteDocumentChangeBuffer\r\n   * returned by `newChangeBuffer()` to ensure proper accounting of metadata.\r\n   */\n\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.removeEntry = function (transaction, documentKey) {\n    var store = remoteDocumentsStore(transaction);\n    var key = dbKey(documentKey);\n    return store.delete(key);\n  };\n  /**\r\n   * Updates the current cache size.\r\n   *\r\n   * Callers to `addEntry()` and `removeEntry()` *must* call this afterwards to update the\r\n   * cache's metadata.\r\n   */\n\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.updateMetadata = function (transaction, sizeDelta) {\n    var _this = this;\n\n    return this.getMetadata(transaction).next(function (metadata) {\n      metadata.byteSize += sizeDelta;\n      return _this.setMetadata(transaction, metadata);\n    });\n  };\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.getEntry = function (transaction, documentKey) {\n    var _this = this;\n\n    return remoteDocumentsStore(transaction).get(dbKey(documentKey)).next(function (dbRemoteDoc) {\n      return _this.maybeDecodeDocument(documentKey, dbRemoteDoc);\n    });\n  };\n  /**\r\n   * Looks up an entry in the cache.\r\n   *\r\n   * @param documentKey - The key of the entry to look up.\r\n   * @returns The cached document entry and its size.\r\n   */\n\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.getSizedEntry = function (transaction, documentKey) {\n    var _this = this;\n\n    return remoteDocumentsStore(transaction).get(dbKey(documentKey)).next(function (dbRemoteDoc) {\n      var doc = _this.maybeDecodeDocument(documentKey, dbRemoteDoc);\n\n      return {\n        document: doc,\n        size: dbDocumentSize(dbRemoteDoc)\n      };\n    });\n  };\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.getEntries = function (transaction, documentKeys) {\n    var _this = this;\n\n    var results = mutableDocumentMap();\n    return this.forEachDbEntry(transaction, documentKeys, function (key, dbRemoteDoc) {\n      var doc = _this.maybeDecodeDocument(key, dbRemoteDoc);\n\n      results = results.insert(key, doc);\n    }).next(function () {\n      return results;\n    });\n  };\n  /**\r\n   * Looks up several entries in the cache.\r\n   *\r\n   * @param documentKeys - The set of keys entries to look up.\r\n   * @returns A map of documents indexed by key and a map of sizes indexed by\r\n   *     key (zero if the document does not exist).\r\n   */\n\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.getSizedEntries = function (transaction, documentKeys) {\n    var _this = this;\n\n    var results = mutableDocumentMap();\n    var sizeMap = new SortedMap(DocumentKey.comparator);\n    return this.forEachDbEntry(transaction, documentKeys, function (key, dbRemoteDoc) {\n      var doc = _this.maybeDecodeDocument(key, dbRemoteDoc);\n\n      results = results.insert(key, doc);\n      sizeMap = sizeMap.insert(key, dbDocumentSize(dbRemoteDoc));\n    }).next(function () {\n      return {\n        documents: results,\n        sizeMap: sizeMap\n      };\n    });\n  };\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.forEachDbEntry = function (transaction, documentKeys, callback) {\n    if (documentKeys.isEmpty()) {\n      return PersistencePromise.resolve();\n    }\n\n    var range = IDBKeyRange.bound(documentKeys.first().path.toArray(), documentKeys.last().path.toArray());\n    var keyIter = documentKeys.getIterator();\n    var nextKey = keyIter.getNext();\n    return remoteDocumentsStore(transaction).iterate({\n      range: range\n    }, function (potentialKeyRaw, dbRemoteDoc, control) {\n      var potentialKey = DocumentKey.fromSegments(potentialKeyRaw); // Go through keys not found in cache.\n\n      while (nextKey && DocumentKey.comparator(nextKey, potentialKey) < 0) {\n        callback(nextKey, null);\n        nextKey = keyIter.getNext();\n      }\n\n      if (nextKey && nextKey.isEqual(potentialKey)) {\n        // Key found in cache.\n        callback(nextKey, dbRemoteDoc);\n        nextKey = keyIter.hasNext() ? keyIter.getNext() : null;\n      } // Skip to the next key (if there is one).\n\n\n      if (nextKey) {\n        control.skip(nextKey.path.toArray());\n      } else {\n        control.done();\n      }\n    }).next(function () {\n      // The rest of the keys are not in the cache. One case where `iterate`\n      // above won't go through them is when the cache is empty.\n      while (nextKey) {\n        callback(nextKey, null);\n        nextKey = keyIter.hasNext() ? keyIter.getNext() : null;\n      }\n    });\n  };\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.getDocumentsMatchingQuery = function (transaction, query, sinceReadTime) {\n    var _this = this;\n\n    var results = mutableDocumentMap();\n    var immediateChildrenPathLength = query.path.length + 1;\n    var iterationOptions = {};\n\n    if (sinceReadTime.isEqual(SnapshotVersion.min())) {\n      // Documents are ordered by key, so we can use a prefix scan to narrow\n      // down the documents we need to match the query against.\n      var startKey = query.path.toArray();\n      iterationOptions.range = IDBKeyRange.lowerBound(startKey);\n    } else {\n      // Execute an index-free query and filter by read time. This is safe\n      // since all document changes to queries that have a\n      // lastLimboFreeSnapshotVersion (`sinceReadTime`) have a read time set.\n      var collectionKey = query.path.toArray();\n      var readTimeKey = toDbTimestampKey(sinceReadTime);\n      iterationOptions.range = IDBKeyRange.lowerBound([collectionKey, readTimeKey],\n      /* open= */\n      true);\n      iterationOptions.index = DbRemoteDocument.collectionReadTimeIndex;\n    }\n\n    return remoteDocumentsStore(transaction).iterate(iterationOptions, function (key, dbRemoteDoc, control) {\n      // The query is actually returning any path that starts with the query\n      // path prefix which may include documents in subcollections. For\n      // example, a query on 'rooms' will return rooms/abc/messages/xyx but we\n      // shouldn't match it. Fix this by discarding rows with document keys\n      // more than one segment longer than the query path.\n      if (key.length !== immediateChildrenPathLength) {\n        return;\n      }\n\n      var document = fromDbRemoteDocument(_this.serializer, dbRemoteDoc);\n\n      if (!query.path.isPrefixOf(document.key.path)) {\n        control.done();\n      } else if (queryMatches(query, document)) {\n        results = results.insert(document.key, document);\n      }\n    }).next(function () {\n      return results;\n    });\n  };\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.newChangeBuffer = function (options) {\n    return new IndexedDbRemoteDocumentChangeBuffer(this, !!options && options.trackRemovals);\n  };\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.getSize = function (txn) {\n    return this.getMetadata(txn).next(function (metadata) {\n      return metadata.byteSize;\n    });\n  };\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.getMetadata = function (txn) {\n    return documentGlobalStore(txn).get(DbRemoteDocumentGlobal.key).next(function (metadata) {\n      hardAssert(!!metadata);\n      return metadata;\n    });\n  };\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.setMetadata = function (txn, metadata) {\n    return documentGlobalStore(txn).put(DbRemoteDocumentGlobal.key, metadata);\n  };\n  /**\r\n   * Decodes `remoteDoc` and returns the document (or null, if the document\r\n   * corresponds to the format used for sentinel deletes).\r\n   */\n\n\n  IndexedDbRemoteDocumentCacheImpl.prototype.maybeDecodeDocument = function (documentKey, dbRemoteDoc) {\n    if (dbRemoteDoc) {\n      var doc_4 = fromDbRemoteDocument(this.serializer, dbRemoteDoc); // Whether the document is a sentinel removal and should only be used in the\n      // `getNewDocumentChanges()`\n\n      var isSentinelRemoval = doc_4.isNoDocument() && doc_4.version.isEqual(SnapshotVersion.min());\n\n      if (!isSentinelRemoval) {\n        return doc_4;\n      }\n    }\n\n    return MutableDocument.newInvalidDocument(documentKey);\n  };\n\n  return IndexedDbRemoteDocumentCacheImpl;\n}();\n/**\r\n * Creates a new IndexedDbRemoteDocumentCache.\r\n *\r\n * @param serializer - The document serializer.\r\n * @param indexManager - The query indexes that need to be maintained.\r\n */\n\n\nfunction newIndexedDbRemoteDocumentCache(serializer, indexManager) {\n  return new IndexedDbRemoteDocumentCacheImpl(serializer, indexManager);\n}\n/**\r\n * Returns the set of documents that have changed since the specified read\r\n * time.\r\n */\n// PORTING NOTE: This is only used for multi-tab synchronization.\n\n\nfunction remoteDocumentCacheGetNewDocumentChanges(remoteDocumentCache, transaction, sinceReadTime) {\n  var remoteDocumentCacheImpl = debugCast(remoteDocumentCache);\n  var changedDocs = mutableDocumentMap();\n  var lastReadTime = toDbTimestampKey(sinceReadTime);\n  var documentsStore = remoteDocumentsStore(transaction);\n  var range = IDBKeyRange.lowerBound(lastReadTime, true);\n  return documentsStore.iterate({\n    index: DbRemoteDocument.readTimeIndex,\n    range: range\n  }, function (_, dbRemoteDoc) {\n    // Unlike `getEntry()` and others, `getNewDocumentChanges()` parses\n    // the documents directly since we want to keep sentinel deletes.\n    var doc = fromDbRemoteDocument(remoteDocumentCacheImpl.serializer, dbRemoteDoc);\n    changedDocs = changedDocs.insert(doc.key, doc);\n    lastReadTime = dbRemoteDoc.readTime;\n  }).next(function () {\n    return {\n      changedDocs: changedDocs,\n      readTime: fromDbTimestampKey(lastReadTime)\n    };\n  });\n}\n/**\r\n * Returns the read time of the most recently read document in the cache, or\r\n * SnapshotVersion.min() if not available.\r\n */\n// PORTING NOTE: This is only used for multi-tab synchronization.\n\n\nfunction remoteDocumentCacheGetLastReadTime(transaction) {\n  var documentsStore = remoteDocumentsStore(transaction); // If there are no existing entries, we return SnapshotVersion.min().\n\n  var readTime = SnapshotVersion.min();\n  return documentsStore.iterate({\n    index: DbRemoteDocument.readTimeIndex,\n    reverse: true\n  }, function (key, dbRemoteDoc, control) {\n    if (dbRemoteDoc.readTime) {\n      readTime = fromDbTimestampKey(dbRemoteDoc.readTime);\n    }\n\n    control.done();\n  }).next(function () {\n    return readTime;\n  });\n}\n/**\r\n * Handles the details of adding and updating documents in the IndexedDbRemoteDocumentCache.\r\n *\r\n * Unlike the MemoryRemoteDocumentChangeBuffer, the IndexedDb implementation computes the size\r\n * delta for all submitted changes. This avoids having to re-read all documents from IndexedDb\r\n * when we apply the changes.\r\n */\n\n\nvar IndexedDbRemoteDocumentChangeBuffer =\n/** @class */\nfunction (_super) {\n  tslib.__extends(IndexedDbRemoteDocumentChangeBuffer, _super);\n  /**\r\n   * @param documentCache - The IndexedDbRemoteDocumentCache to apply the changes to.\r\n   * @param trackRemovals - Whether to create sentinel deletes that can be tracked by\r\n   * `getNewDocumentChanges()`.\r\n   */\n\n\n  function IndexedDbRemoteDocumentChangeBuffer(documentCache, trackRemovals) {\n    var _this = _super.call(this) || this;\n\n    _this.documentCache = documentCache;\n    _this.trackRemovals = trackRemovals; // A map of document sizes prior to applying the changes in this buffer.\n\n    _this.documentSizes = new ObjectMap(function (key) {\n      return key.toString();\n    }, function (l, r) {\n      return l.isEqual(r);\n    });\n    return _this;\n  }\n\n  IndexedDbRemoteDocumentChangeBuffer.prototype.applyChanges = function (transaction) {\n    var _this = this;\n\n    var promises = [];\n    var sizeDelta = 0;\n    var collectionParents = new SortedSet(function (l, r) {\n      return primitiveComparator(l.canonicalString(), r.canonicalString());\n    });\n    this.changes.forEach(function (key, documentChange) {\n      var previousSize = _this.documentSizes.get(key);\n\n      if (documentChange.document.isValidDocument()) {\n        var doc_5 = toDbRemoteDocument(_this.documentCache.serializer, documentChange.document, _this.getReadTime(key));\n        collectionParents = collectionParents.add(key.path.popLast());\n        var size = dbDocumentSize(doc_5);\n        sizeDelta += size - previousSize;\n        promises.push(_this.documentCache.addEntry(transaction, key, doc_5));\n      } else {\n        sizeDelta -= previousSize;\n\n        if (_this.trackRemovals) {\n          // In order to track removals, we store a \"sentinel delete\" in the\n          // RemoteDocumentCache. This entry is represented by a NoDocument\n          // with a version of 0 and ignored by `maybeDecodeDocument()` but\n          // preserved in `getNewDocumentChanges()`.\n          var deletedDoc = toDbRemoteDocument(_this.documentCache.serializer, MutableDocument.newNoDocument(key, SnapshotVersion.min()), _this.getReadTime(key));\n          promises.push(_this.documentCache.addEntry(transaction, key, deletedDoc));\n        } else {\n          promises.push(_this.documentCache.removeEntry(transaction, key));\n        }\n      }\n    });\n    collectionParents.forEach(function (parent) {\n      promises.push(_this.documentCache.indexManager.addToCollectionParentIndex(transaction, parent));\n    });\n    promises.push(this.documentCache.updateMetadata(transaction, sizeDelta));\n    return PersistencePromise.waitFor(promises);\n  };\n\n  IndexedDbRemoteDocumentChangeBuffer.prototype.getFromCache = function (transaction, documentKey) {\n    var _this = this; // Record the size of everything we load from the cache so we can compute a delta later.\n\n\n    return this.documentCache.getSizedEntry(transaction, documentKey).next(function (getResult) {\n      _this.documentSizes.set(documentKey, getResult.size);\n\n      return getResult.document;\n    });\n  };\n\n  IndexedDbRemoteDocumentChangeBuffer.prototype.getAllFromCache = function (transaction, documentKeys) {\n    var _this = this; // Record the size of everything we load from the cache so we can compute\n    // a delta later.\n\n\n    return this.documentCache.getSizedEntries(transaction, documentKeys).next(function (_d) {\n      var documents = _d.documents,\n          sizeMap = _d.sizeMap; // Note: `getAllFromCache` returns two maps instead of a single map from\n      // keys to `DocumentSizeEntry`s. This is to allow returning the\n      // `MutableDocumentMap` directly, without a conversion.\n\n      sizeMap.forEach(function (documentKey, size) {\n        _this.documentSizes.set(documentKey, size);\n      });\n      return documents;\n    });\n  };\n\n  return IndexedDbRemoteDocumentChangeBuffer;\n}(RemoteDocumentChangeBuffer);\n\nfunction documentGlobalStore(txn) {\n  return getStore(txn, DbRemoteDocumentGlobal.store);\n}\n/**\r\n * Helper to get a typed SimpleDbStore for the remoteDocuments object store.\r\n */\n\n\nfunction remoteDocumentsStore(txn) {\n  return getStore(txn, DbRemoteDocument.store);\n}\n\nfunction dbKey(docKey) {\n  return docKey.path.toArray();\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Performs database creation and schema upgrades. */\n\n\nvar SchemaConverter =\n/** @class */\nfunction () {\n  function SchemaConverter(serializer) {\n    this.serializer = serializer;\n  }\n  /**\r\n   * Performs database creation and schema upgrades.\r\n   *\r\n   * Note that in production, this method is only ever used to upgrade the schema\r\n   * to SCHEMA_VERSION. Different values of toVersion are only used for testing\r\n   * and local feature development.\r\n   */\n\n\n  SchemaConverter.prototype.createOrUpgrade = function (db, txn, fromVersion, toVersion) {\n    var _this = this;\n\n    hardAssert(fromVersion < toVersion && fromVersion >= 0 && toVersion <= SCHEMA_VERSION);\n    var simpleDbTransaction = new SimpleDbTransaction('createOrUpgrade', txn);\n\n    if (fromVersion < 1 && toVersion >= 1) {\n      createPrimaryClientStore(db);\n      createMutationQueue(db);\n      createQueryCache(db);\n      createRemoteDocumentCache(db);\n    } // Migration 2 to populate the targetGlobal object no longer needed since\n    // migration 3 unconditionally clears it.\n\n\n    var p = PersistencePromise.resolve();\n\n    if (fromVersion < 3 && toVersion >= 3) {\n      // Brand new clients don't need to drop and recreate--only clients that\n      // potentially have corrupt data.\n      if (fromVersion !== 0) {\n        dropQueryCache(db);\n        createQueryCache(db);\n      }\n\n      p = p.next(function () {\n        return writeEmptyTargetGlobalEntry(simpleDbTransaction);\n      });\n    }\n\n    if (fromVersion < 4 && toVersion >= 4) {\n      if (fromVersion !== 0) {\n        // Schema version 3 uses auto-generated keys to generate globally unique\n        // mutation batch IDs (this was previously ensured internally by the\n        // client). To migrate to the new schema, we have to read all mutations\n        // and write them back out. We preserve the existing batch IDs to guarantee\n        // consistency with other object stores. Any further mutation batch IDs will\n        // be auto-generated.\n        p = p.next(function () {\n          return upgradeMutationBatchSchemaAndMigrateData(db, simpleDbTransaction);\n        });\n      }\n\n      p = p.next(function () {\n        createClientMetadataStore(db);\n      });\n    }\n\n    if (fromVersion < 5 && toVersion >= 5) {\n      p = p.next(function () {\n        return _this.removeAcknowledgedMutations(simpleDbTransaction);\n      });\n    }\n\n    if (fromVersion < 6 && toVersion >= 6) {\n      p = p.next(function () {\n        createDocumentGlobalStore(db);\n        return _this.addDocumentGlobal(simpleDbTransaction);\n      });\n    }\n\n    if (fromVersion < 7 && toVersion >= 7) {\n      p = p.next(function () {\n        return _this.ensureSequenceNumbers(simpleDbTransaction);\n      });\n    }\n\n    if (fromVersion < 8 && toVersion >= 8) {\n      p = p.next(function () {\n        return _this.createCollectionParentIndex(db, simpleDbTransaction);\n      });\n    }\n\n    if (fromVersion < 9 && toVersion >= 9) {\n      p = p.next(function () {\n        // Multi-Tab used to manage its own changelog, but this has been moved\n        // to the DbRemoteDocument object store itself. Since the previous change\n        // log only contained transient data, we can drop its object store.\n        dropRemoteDocumentChangesStore(db);\n        createRemoteDocumentReadTimeIndex(txn);\n      });\n    }\n\n    if (fromVersion < 10 && toVersion >= 10) {\n      p = p.next(function () {\n        return _this.rewriteCanonicalIds(simpleDbTransaction);\n      });\n    }\n\n    if (fromVersion < 11 && toVersion >= 11) {\n      p = p.next(function () {\n        createBundlesStore(db);\n        createNamedQueriesStore(db);\n      });\n    }\n\n    return p;\n  };\n\n  SchemaConverter.prototype.addDocumentGlobal = function (txn) {\n    var byteCount = 0;\n    return txn.store(DbRemoteDocument.store).iterate(function (_, doc) {\n      byteCount += dbDocumentSize(doc);\n    }).next(function () {\n      var metadata = new DbRemoteDocumentGlobal(byteCount);\n      return txn.store(DbRemoteDocumentGlobal.store).put(DbRemoteDocumentGlobal.key, metadata);\n    });\n  };\n\n  SchemaConverter.prototype.removeAcknowledgedMutations = function (txn) {\n    var _this = this;\n\n    var queuesStore = txn.store(DbMutationQueue.store);\n    var mutationsStore = txn.store(DbMutationBatch.store);\n    return queuesStore.loadAll().next(function (queues) {\n      return PersistencePromise.forEach(queues, function (queue) {\n        var range = IDBKeyRange.bound([queue.userId, BATCHID_UNKNOWN], [queue.userId, queue.lastAcknowledgedBatchId]);\n        return mutationsStore.loadAll(DbMutationBatch.userMutationsIndex, range).next(function (dbBatches) {\n          return PersistencePromise.forEach(dbBatches, function (dbBatch) {\n            hardAssert(dbBatch.userId === queue.userId);\n            var batch = fromDbMutationBatch(_this.serializer, dbBatch);\n            return removeMutationBatch(txn, queue.userId, batch).next(function () {});\n          });\n        });\n      });\n    });\n  };\n  /**\r\n   * Ensures that every document in the remote document cache has a corresponding sentinel row\r\n   * with a sequence number. Missing rows are given the most recently used sequence number.\r\n   */\n\n\n  SchemaConverter.prototype.ensureSequenceNumbers = function (txn) {\n    var documentTargetStore = txn.store(DbTargetDocument.store);\n    var documentsStore = txn.store(DbRemoteDocument.store);\n    var globalTargetStore = txn.store(DbTargetGlobal.store);\n    return globalTargetStore.get(DbTargetGlobal.key).next(function (metadata) {\n      var writeSentinelKey = function (path) {\n        return documentTargetStore.put(new DbTargetDocument(0, encodeResourcePath(path), metadata.highestListenSequenceNumber));\n      };\n\n      var promises = [];\n      return documentsStore.iterate(function (key, doc) {\n        var path = new ResourcePath(key);\n        var docSentinelKey = sentinelKey(path);\n        promises.push(documentTargetStore.get(docSentinelKey).next(function (maybeSentinel) {\n          if (!maybeSentinel) {\n            return writeSentinelKey(path);\n          } else {\n            return PersistencePromise.resolve();\n          }\n        }));\n      }).next(function () {\n        return PersistencePromise.waitFor(promises);\n      });\n    });\n  };\n\n  SchemaConverter.prototype.createCollectionParentIndex = function (db, txn) {\n    // Create the index.\n    db.createObjectStore(DbCollectionParent.store, {\n      keyPath: DbCollectionParent.keyPath\n    });\n    var collectionParentsStore = txn.store(DbCollectionParent.store); // Helper to add an index entry iff we haven't already written it.\n\n    var cache = new MemoryCollectionParentIndex();\n\n    var addEntry = function (collectionPath) {\n      if (cache.add(collectionPath)) {\n        var collectionId = collectionPath.lastSegment();\n        var parentPath = collectionPath.popLast();\n        return collectionParentsStore.put({\n          collectionId: collectionId,\n          parent: encodeResourcePath(parentPath)\n        });\n      }\n    }; // Index existing remote documents.\n\n\n    return txn.store(DbRemoteDocument.store).iterate({\n      keysOnly: true\n    }, function (pathSegments, _) {\n      var path = new ResourcePath(pathSegments);\n      return addEntry(path.popLast());\n    }).next(function () {\n      // Index existing mutations.\n      return txn.store(DbDocumentMutation.store).iterate({\n        keysOnly: true\n      }, function (_d, _) {\n        _d[0];\n        var encodedPath = _d[1];\n        _d[2];\n        var path = decodeResourcePath(encodedPath);\n        return addEntry(path.popLast());\n      });\n    });\n  };\n\n  SchemaConverter.prototype.rewriteCanonicalIds = function (txn) {\n    var _this = this;\n\n    var targetStore = txn.store(DbTarget.store);\n    return targetStore.iterate(function (key, originalDbTarget) {\n      var originalTargetData = fromDbTarget(originalDbTarget);\n      var updatedDbTarget = toDbTarget(_this.serializer, originalTargetData);\n      return targetStore.put(updatedDbTarget);\n    });\n  };\n\n  return SchemaConverter;\n}();\n\nfunction sentinelKey(path) {\n  return [0, encodeResourcePath(path)];\n}\n\nfunction createPrimaryClientStore(db) {\n  db.createObjectStore(DbPrimaryClient.store);\n}\n\nfunction createMutationQueue(db) {\n  db.createObjectStore(DbMutationQueue.store, {\n    keyPath: DbMutationQueue.keyPath\n  });\n  var mutationBatchesStore = db.createObjectStore(DbMutationBatch.store, {\n    keyPath: DbMutationBatch.keyPath,\n    autoIncrement: true\n  });\n  mutationBatchesStore.createIndex(DbMutationBatch.userMutationsIndex, DbMutationBatch.userMutationsKeyPath, {\n    unique: true\n  });\n  db.createObjectStore(DbDocumentMutation.store);\n}\n/**\r\n * Upgrade function to migrate the 'mutations' store from V1 to V3. Loads\r\n * and rewrites all data.\r\n */\n\n\nfunction upgradeMutationBatchSchemaAndMigrateData(db, txn) {\n  var v1MutationsStore = txn.store(DbMutationBatch.store);\n  return v1MutationsStore.loadAll().next(function (existingMutations) {\n    db.deleteObjectStore(DbMutationBatch.store);\n    var mutationsStore = db.createObjectStore(DbMutationBatch.store, {\n      keyPath: DbMutationBatch.keyPath,\n      autoIncrement: true\n    });\n    mutationsStore.createIndex(DbMutationBatch.userMutationsIndex, DbMutationBatch.userMutationsKeyPath, {\n      unique: true\n    });\n    var v3MutationsStore = txn.store(DbMutationBatch.store);\n    var writeAll = existingMutations.map(function (mutation) {\n      return v3MutationsStore.put(mutation);\n    });\n    return PersistencePromise.waitFor(writeAll);\n  });\n}\n\nfunction createRemoteDocumentCache(db) {\n  db.createObjectStore(DbRemoteDocument.store);\n}\n\nfunction createDocumentGlobalStore(db) {\n  db.createObjectStore(DbRemoteDocumentGlobal.store);\n}\n\nfunction createQueryCache(db) {\n  var targetDocumentsStore = db.createObjectStore(DbTargetDocument.store, {\n    keyPath: DbTargetDocument.keyPath\n  });\n  targetDocumentsStore.createIndex(DbTargetDocument.documentTargetsIndex, DbTargetDocument.documentTargetsKeyPath, {\n    unique: true\n  });\n  var targetStore = db.createObjectStore(DbTarget.store, {\n    keyPath: DbTarget.keyPath\n  }); // NOTE: This is unique only because the TargetId is the suffix.\n\n  targetStore.createIndex(DbTarget.queryTargetsIndexName, DbTarget.queryTargetsKeyPath, {\n    unique: true\n  });\n  db.createObjectStore(DbTargetGlobal.store);\n}\n\nfunction dropQueryCache(db) {\n  db.deleteObjectStore(DbTargetDocument.store);\n  db.deleteObjectStore(DbTarget.store);\n  db.deleteObjectStore(DbTargetGlobal.store);\n}\n\nfunction dropRemoteDocumentChangesStore(db) {\n  if (db.objectStoreNames.contains('remoteDocumentChanges')) {\n    db.deleteObjectStore('remoteDocumentChanges');\n  }\n}\n/**\r\n * Creates the target global singleton row.\r\n *\r\n * @param txn - The version upgrade transaction for indexeddb\r\n */\n\n\nfunction writeEmptyTargetGlobalEntry(txn) {\n  var globalStore = txn.store(DbTargetGlobal.store);\n  var metadata = new DbTargetGlobal(\n  /*highestTargetId=*/\n  0,\n  /*lastListenSequenceNumber=*/\n  0, SnapshotVersion.min().toTimestamp(),\n  /*targetCount=*/\n  0);\n  return globalStore.put(DbTargetGlobal.key, metadata);\n}\n/**\r\n * Creates indices on the RemoteDocuments store used for both multi-tab\r\n * and Index-Free queries.\r\n */\n\n\nfunction createRemoteDocumentReadTimeIndex(txn) {\n  var remoteDocumentStore = txn.objectStore(DbRemoteDocument.store);\n  remoteDocumentStore.createIndex(DbRemoteDocument.readTimeIndex, DbRemoteDocument.readTimeIndexPath, {\n    unique: false\n  });\n  remoteDocumentStore.createIndex(DbRemoteDocument.collectionReadTimeIndex, DbRemoteDocument.collectionReadTimeIndexPath, {\n    unique: false\n  });\n}\n\nfunction createClientMetadataStore(db) {\n  db.createObjectStore(DbClientMetadata.store, {\n    keyPath: DbClientMetadata.keyPath\n  });\n}\n\nfunction createBundlesStore(db) {\n  db.createObjectStore(DbBundle.store, {\n    keyPath: DbBundle.keyPath\n  });\n}\n\nfunction createNamedQueriesStore(db) {\n  db.createObjectStore(DbNamedQuery.store, {\n    keyPath: DbNamedQuery.keyPath\n  });\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$d = 'IndexedDbPersistence';\n/**\r\n * Oldest acceptable age in milliseconds for client metadata before the client\r\n * is considered inactive and its associated data is garbage collected.\r\n */\n\nvar MAX_CLIENT_AGE_MS = 30 * 60 * 1000; // 30 minutes\n\n/**\r\n * Oldest acceptable metadata age for clients that may participate in the\r\n * primary lease election. Clients that have not updated their client metadata\r\n * within 5 seconds are not eligible to receive a primary lease.\r\n */\n\nvar MAX_PRIMARY_ELIGIBLE_AGE_MS = 5000;\n/**\r\n * The interval at which clients will update their metadata, including\r\n * refreshing their primary lease if held or potentially trying to acquire it if\r\n * not held.\r\n *\r\n * Primary clients may opportunistically refresh their metadata earlier\r\n * if they're already performing an IndexedDB operation.\r\n */\n\nvar CLIENT_METADATA_REFRESH_INTERVAL_MS = 4000;\n/** User-facing error when the primary lease is required but not available. */\n\nvar PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG = 'Failed to obtain exclusive access to the persistence layer. To allow ' + 'shared access, multi-tab synchronization has to be enabled in all tabs. ' + 'If you are using `experimentalForceOwningTab:true`, make sure that only ' + 'one tab has persistence enabled at any given time.';\nvar UNSUPPORTED_PLATFORM_ERROR_MSG = 'This platform is either missing IndexedDB or is known to have ' + 'an incomplete implementation. Offline persistence has been disabled.'; // The format of the LocalStorage key that stores zombied client is:\n//     firestore_zombie_<persistence_prefix>_<instance_key>\n\nvar ZOMBIED_CLIENTS_KEY_PREFIX = 'firestore_zombie';\n/**\r\n * The name of the main (and currently only) IndexedDB database. This name is\r\n * appended to the prefix provided to the IndexedDbPersistence constructor.\r\n */\n\nvar MAIN_DATABASE = 'main';\n/**\r\n * An IndexedDB-backed instance of Persistence. Data is stored persistently\r\n * across sessions.\r\n *\r\n * On Web only, the Firestore SDKs support shared access to its persistence\r\n * layer. This allows multiple browser tabs to read and write to IndexedDb and\r\n * to synchronize state even without network connectivity. Shared access is\r\n * currently optional and not enabled unless all clients invoke\r\n * `enablePersistence()` with `{synchronizeTabs:true}`.\r\n *\r\n * In multi-tab mode, if multiple clients are active at the same time, the SDK\r\n * will designate one client as the primary client. An effort is made to pick\r\n * a visible, network-connected and active client, and this client is\r\n * responsible for letting other clients know about its presence. The primary\r\n * client writes a unique client-generated identifier (the client ID) to\r\n * IndexedDbs owner store every 4 seconds. If the primary client fails to\r\n * update this entry, another client can acquire the lease and take over as\r\n * primary.\r\n *\r\n * Some persistence operations in the SDK are designated as primary-client only\r\n * operations. This includes the acknowledgment of mutations and all updates of\r\n * remote documents. The effects of these operations are written to persistence\r\n * and then broadcast to other tabs via LocalStorage (see\r\n * `WebStorageSharedClientState`), which then refresh their state from\r\n * persistence.\r\n *\r\n * Similarly, the primary client listens to notifications sent by secondary\r\n * clients to discover persistence changes written by secondary clients, such as\r\n * the addition of new mutations and query targets.\r\n *\r\n * If multi-tab is not enabled and another tab already obtained the primary\r\n * lease, IndexedDbPersistence enters a failed state and all subsequent\r\n * operations will automatically fail.\r\n *\r\n * Additionally, there is an optimization so that when a tab is closed, the\r\n * primary lease is released immediately (this is especially important to make\r\n * sure that a refreshed tab is able to immediately re-acquire the primary\r\n * lease). Unfortunately, IndexedDB cannot be reliably used in window.unload\r\n * since it is an asynchronous API. So in addition to attempting to give up the\r\n * lease, the leaseholder writes its client ID to a \"zombiedClient\" entry in\r\n * LocalStorage which acts as an indicator that another tab should go ahead and\r\n * take the primary lease immediately regardless of the current lease timestamp.\r\n *\r\n * TODO(b/114226234): Remove `synchronizeTabs` section when multi-tab is no\r\n * longer optional.\r\n */\n\nvar IndexedDbPersistence =\n/** @class */\nfunction () {\n  function IndexedDbPersistence(\n  /**\r\n   * Whether to synchronize the in-memory state of multiple tabs and share\r\n   * access to local persistence.\r\n   */\n  allowTabSynchronization, persistenceKey, clientId, lruParams, queue, window, document, serializer, sequenceNumberSyncer,\n  /**\r\n   * If set to true, forcefully obtains database access. Existing tabs will\r\n   * no longer be able to access IndexedDB.\r\n   */\n  forceOwningTab) {\n    this.allowTabSynchronization = allowTabSynchronization;\n    this.persistenceKey = persistenceKey;\n    this.clientId = clientId;\n    this.queue = queue;\n    this.window = window;\n    this.document = document;\n    this.sequenceNumberSyncer = sequenceNumberSyncer;\n    this.forceOwningTab = forceOwningTab;\n    this.listenSequence = null;\n    this._started = false;\n    this.isPrimary = false;\n    this.networkEnabled = true;\n    /** Our window.unload handler, if registered. */\n\n    this.windowUnloadHandler = null;\n    this.inForeground = false;\n    /** Our 'visibilitychange' listener if registered. */\n\n    this.documentVisibilityHandler = null;\n    /** The client metadata refresh task. */\n\n    this.clientMetadataRefresher = null;\n    /** The last time we garbage collected the client metadata object store. */\n\n    this.lastGarbageCollectionTime = Number.NEGATIVE_INFINITY;\n    /** A listener to notify on primary state changes. */\n\n    this.primaryStateListener = function (_) {\n      return Promise.resolve();\n    };\n\n    if (!IndexedDbPersistence.isAvailable()) {\n      throw new FirestoreError(Code.UNIMPLEMENTED, UNSUPPORTED_PLATFORM_ERROR_MSG);\n    }\n\n    this.referenceDelegate = new IndexedDbLruDelegateImpl(this, lruParams);\n    this.dbName = persistenceKey + MAIN_DATABASE;\n    this.serializer = new LocalSerializer(serializer);\n    this.simpleDb = new SimpleDb(this.dbName, SCHEMA_VERSION, new SchemaConverter(this.serializer));\n    this.targetCache = new IndexedDbTargetCache(this.referenceDelegate, this.serializer);\n    this.indexManager = new IndexedDbIndexManager();\n    this.remoteDocumentCache = newIndexedDbRemoteDocumentCache(this.serializer, this.indexManager);\n    this.bundleCache = new IndexedDbBundleCache();\n\n    if (this.window && this.window.localStorage) {\n      this.webStorage = this.window.localStorage;\n    } else {\n      this.webStorage = null;\n\n      if (forceOwningTab === false) {\n        logError(LOG_TAG$d, 'LocalStorage is unavailable. As a result, persistence may not work ' + 'reliably. In particular enablePersistence() could fail immediately ' + 'after refreshing the page.');\n      }\n    }\n  }\n  /**\r\n   * Attempt to start IndexedDb persistence.\r\n   *\r\n   * @returns Whether persistence was enabled.\r\n   */\n\n\n  IndexedDbPersistence.prototype.start = function () {\n    var _this = this; // NOTE: This is expected to fail sometimes (in the case of another tab\n    // already having the persistence lock), so it's the first thing we should\n    // do.\n\n\n    return this.updateClientMetadataAndTryBecomePrimary().then(function () {\n      if (!_this.isPrimary && !_this.allowTabSynchronization) {\n        // Fail `start()` if `synchronizeTabs` is disabled and we cannot\n        // obtain the primary lease.\n        throw new FirestoreError(Code.FAILED_PRECONDITION, PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);\n      }\n\n      _this.attachVisibilityHandler();\n\n      _this.attachWindowUnloadHook();\n\n      _this.scheduleClientMetadataAndPrimaryLeaseRefreshes();\n\n      return _this.runTransaction('getHighestListenSequenceNumber', 'readonly', function (txn) {\n        return _this.targetCache.getHighestSequenceNumber(txn);\n      });\n    }).then(function (highestListenSequenceNumber) {\n      _this.listenSequence = new ListenSequence(highestListenSequenceNumber, _this.sequenceNumberSyncer);\n    }).then(function () {\n      _this._started = true;\n    }).catch(function (reason) {\n      _this.simpleDb && _this.simpleDb.close();\n      return Promise.reject(reason);\n    });\n  };\n  /**\r\n   * Registers a listener that gets called when the primary state of the\r\n   * instance changes. Upon registering, this listener is invoked immediately\r\n   * with the current primary state.\r\n   *\r\n   * PORTING NOTE: This is only used for Web multi-tab.\r\n   */\n\n\n  IndexedDbPersistence.prototype.setPrimaryStateListener = function (primaryStateListener) {\n    var _this = this;\n\n    this.primaryStateListener = function (primaryState) {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        return tslib.__generator(this, function (_d) {\n          if (this.started) {\n            return [2\n            /*return*/\n            , primaryStateListener(primaryState)];\n          }\n\n          return [2\n          /*return*/\n          ];\n        });\n      });\n    };\n\n    return primaryStateListener(this.isPrimary);\n  };\n  /**\r\n   * Registers a listener that gets called when the database receives a\r\n   * version change event indicating that it has deleted.\r\n   *\r\n   * PORTING NOTE: This is only used for Web multi-tab.\r\n   */\n\n\n  IndexedDbPersistence.prototype.setDatabaseDeletedListener = function (databaseDeletedListener) {\n    var _this = this;\n\n    this.simpleDb.setVersionChangeListener(function (event) {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              if (!(event.newVersion === null)) return [3\n              /*break*/\n              , 2];\n              return [4\n              /*yield*/\n              , databaseDeletedListener()];\n\n            case 1:\n              _d.sent();\n\n              _d.label = 2;\n\n            case 2:\n              return [2\n              /*return*/\n              ];\n          }\n        });\n      });\n    });\n  };\n  /**\r\n   * Adjusts the current network state in the client's metadata, potentially\r\n   * affecting the primary lease.\r\n   *\r\n   * PORTING NOTE: This is only used for Web multi-tab.\r\n   */\n\n\n  IndexedDbPersistence.prototype.setNetworkEnabled = function (networkEnabled) {\n    var _this = this;\n\n    if (this.networkEnabled !== networkEnabled) {\n      this.networkEnabled = networkEnabled; // Schedule a primary lease refresh for immediate execution. The eventual\n      // lease update will be propagated via `primaryStateListener`.\n\n      this.queue.enqueueAndForget(function () {\n        return tslib.__awaiter(_this, void 0, void 0, function () {\n          return tslib.__generator(this, function (_d) {\n            switch (_d.label) {\n              case 0:\n                if (!this.started) return [3\n                /*break*/\n                , 2];\n                return [4\n                /*yield*/\n                , this.updateClientMetadataAndTryBecomePrimary()];\n\n              case 1:\n                _d.sent();\n\n                _d.label = 2;\n\n              case 2:\n                return [2\n                /*return*/\n                ];\n            }\n          });\n        });\n      });\n    }\n  };\n  /**\r\n   * Updates the client metadata in IndexedDb and attempts to either obtain or\r\n   * extend the primary lease for the local client. Asynchronously notifies the\r\n   * primary state listener if the client either newly obtained or released its\r\n   * primary lease.\r\n   */\n\n\n  IndexedDbPersistence.prototype.updateClientMetadataAndTryBecomePrimary = function () {\n    var _this = this;\n\n    return this.runTransaction('updateClientMetadataAndTryBecomePrimary', 'readwrite', function (txn) {\n      var metadataStore = clientMetadataStore(txn);\n      return metadataStore.put(new DbClientMetadata(_this.clientId, Date.now(), _this.networkEnabled, _this.inForeground)).next(function () {\n        if (_this.isPrimary) {\n          return _this.verifyPrimaryLease(txn).next(function (success) {\n            if (!success) {\n              _this.isPrimary = false;\n\n              _this.queue.enqueueRetryable(function () {\n                return _this.primaryStateListener(false);\n              });\n            }\n          });\n        }\n      }).next(function () {\n        return _this.canActAsPrimary(txn);\n      }).next(function (canActAsPrimary) {\n        if (_this.isPrimary && !canActAsPrimary) {\n          return _this.releasePrimaryLeaseIfHeld(txn).next(function () {\n            return false;\n          });\n        } else if (canActAsPrimary) {\n          return _this.acquireOrExtendPrimaryLease(txn).next(function () {\n            return true;\n          });\n        } else {\n          return (\n            /* canActAsPrimary= */\n            false\n          );\n        }\n      });\n    }).catch(function (e) {\n      if (isIndexedDbTransactionError(e)) {\n        logDebug(LOG_TAG$d, 'Failed to extend owner lease: ', e); // Proceed with the existing state. Any subsequent access to\n        // IndexedDB will verify the lease.\n\n        return _this.isPrimary;\n      }\n\n      if (!_this.allowTabSynchronization) {\n        throw e;\n      }\n\n      logDebug(LOG_TAG$d, 'Releasing owner lease after error during lease refresh', e);\n      return (\n        /* isPrimary= */\n        false\n      );\n    }).then(function (isPrimary) {\n      if (_this.isPrimary !== isPrimary) {\n        _this.queue.enqueueRetryable(function () {\n          return _this.primaryStateListener(isPrimary);\n        });\n      }\n\n      _this.isPrimary = isPrimary;\n    });\n  };\n\n  IndexedDbPersistence.prototype.verifyPrimaryLease = function (txn) {\n    var _this = this;\n\n    var store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(function (primaryClient) {\n      return PersistencePromise.resolve(_this.isLocalClient(primaryClient));\n    });\n  };\n\n  IndexedDbPersistence.prototype.removeClientMetadata = function (txn) {\n    var metadataStore = clientMetadataStore(txn);\n    return metadataStore.delete(this.clientId);\n  };\n  /**\r\n   * If the garbage collection threshold has passed, prunes the\r\n   * RemoteDocumentChanges and the ClientMetadata store based on the last update\r\n   * time of all clients.\r\n   */\n\n\n  IndexedDbPersistence.prototype.maybeGarbageCollectMultiClientState = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var inactiveClients, _i, inactiveClients_1, inactiveClient;\n\n      var _this = this;\n\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            if (!(this.isPrimary && !this.isWithinAge(this.lastGarbageCollectionTime, MAX_CLIENT_AGE_MS))) return [3\n            /*break*/\n            , 2];\n            this.lastGarbageCollectionTime = Date.now();\n            return [4\n            /*yield*/\n            , this.runTransaction('maybeGarbageCollectMultiClientState', 'readwrite-primary', function (txn) {\n              var metadataStore = getStore(txn, DbClientMetadata.store);\n              return metadataStore.loadAll().next(function (existingClients) {\n                var active = _this.filterActiveClients(existingClients, MAX_CLIENT_AGE_MS);\n\n                var inactive = existingClients.filter(function (client) {\n                  return active.indexOf(client) === -1;\n                }); // Delete metadata for clients that are no longer considered active.\n\n                return PersistencePromise.forEach(inactive, function (inactiveClient) {\n                  return metadataStore.delete(inactiveClient.clientId);\n                }).next(function () {\n                  return inactive;\n                });\n              });\n            }).catch(function () {\n              // Ignore primary lease violations or any other type of error. The next\n              // primary will run `maybeGarbageCollectMultiClientState()` again.\n              // We don't use `ignoreIfPrimaryLeaseLoss()` since we don't want to depend\n              // on LocalStore.\n              return [];\n            })];\n\n          case 1:\n            inactiveClients = _d.sent(); // Delete potential leftover entries that may continue to mark the\n            // inactive clients as zombied in LocalStorage.\n            // Ideally we'd delete the IndexedDb and LocalStorage zombie entries for\n            // the client atomically, but we can't. So we opt to delete the IndexedDb\n            // entries first to avoid potentially reviving a zombied client.\n\n            if (this.webStorage) {\n              for (_i = 0, inactiveClients_1 = inactiveClients; _i < inactiveClients_1.length; _i++) {\n                inactiveClient = inactiveClients_1[_i];\n                this.webStorage.removeItem(this.zombiedClientLocalStorageKey(inactiveClient.clientId));\n              }\n            }\n\n            _d.label = 2;\n\n          case 2:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\r\n   * Schedules a recurring timer to update the client metadata and to either\r\n   * extend or acquire the primary lease if the client is eligible.\r\n   */\n\n\n  IndexedDbPersistence.prototype.scheduleClientMetadataAndPrimaryLeaseRefreshes = function () {\n    var _this = this;\n\n    this.clientMetadataRefresher = this.queue.enqueueAfterDelay(\"client_metadata_refresh\"\n    /* ClientMetadataRefresh */\n    , CLIENT_METADATA_REFRESH_INTERVAL_MS, function () {\n      return _this.updateClientMetadataAndTryBecomePrimary().then(function () {\n        return _this.maybeGarbageCollectMultiClientState();\n      }).then(function () {\n        return _this.scheduleClientMetadataAndPrimaryLeaseRefreshes();\n      });\n    });\n  };\n  /** Checks whether `client` is the local client. */\n\n\n  IndexedDbPersistence.prototype.isLocalClient = function (client) {\n    return client ? client.ownerId === this.clientId : false;\n  };\n  /**\r\n   * Evaluate the state of all active clients and determine whether the local\r\n   * client is or can act as the holder of the primary lease. Returns whether\r\n   * the client is eligible for the lease, but does not actually acquire it.\r\n   * May return 'false' even if there is no active leaseholder and another\r\n   * (foreground) client should become leaseholder instead.\r\n   */\n\n\n  IndexedDbPersistence.prototype.canActAsPrimary = function (txn) {\n    var _this = this;\n\n    if (this.forceOwningTab) {\n      return PersistencePromise.resolve(true);\n    }\n\n    var store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(function (currentPrimary) {\n      var currentLeaseIsValid = currentPrimary !== null && _this.isWithinAge(currentPrimary.leaseTimestampMs, MAX_PRIMARY_ELIGIBLE_AGE_MS) && !_this.isClientZombied(currentPrimary.ownerId); // A client is eligible for the primary lease if:\n      // - its network is enabled and the client's tab is in the foreground.\n      // - its network is enabled and no other client's tab is in the\n      //   foreground.\n      // - every clients network is disabled and the client's tab is in the\n      //   foreground.\n      // - every clients network is disabled and no other client's tab is in\n      //   the foreground.\n      // - the `forceOwningTab` setting was passed in.\n\n      if (currentLeaseIsValid) {\n        if (_this.isLocalClient(currentPrimary) && _this.networkEnabled) {\n          return true;\n        }\n\n        if (!_this.isLocalClient(currentPrimary)) {\n          if (!currentPrimary.allowTabSynchronization) {\n            // Fail the `canActAsPrimary` check if the current leaseholder has\n            // not opted into multi-tab synchronization. If this happens at\n            // client startup, we reject the Promise returned by\n            // `enablePersistence()` and the user can continue to use Firestore\n            // with in-memory persistence.\n            // If this fails during a lease refresh, we will instead block the\n            // AsyncQueue from executing further operations. Note that this is\n            // acceptable since mixing & matching different `synchronizeTabs`\n            // settings is not supported.\n            //\n            // TODO(b/114226234): Remove this check when `synchronizeTabs` can\n            // no longer be turned off.\n            throw new FirestoreError(Code.FAILED_PRECONDITION, PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);\n          }\n\n          return false;\n        }\n      }\n\n      if (_this.networkEnabled && _this.inForeground) {\n        return true;\n      }\n\n      return clientMetadataStore(txn).loadAll().next(function (existingClients) {\n        // Process all existing clients and determine whether at least one of\n        // them is better suited to obtain the primary lease.\n        var preferredCandidate = _this.filterActiveClients(existingClients, MAX_PRIMARY_ELIGIBLE_AGE_MS).find(function (otherClient) {\n          if (_this.clientId !== otherClient.clientId) {\n            var otherClientHasBetterNetworkState = !_this.networkEnabled && otherClient.networkEnabled;\n            var otherClientHasBetterVisibility = !_this.inForeground && otherClient.inForeground;\n            var otherClientHasSameNetworkState = _this.networkEnabled === otherClient.networkEnabled;\n\n            if (otherClientHasBetterNetworkState || otherClientHasBetterVisibility && otherClientHasSameNetworkState) {\n              return true;\n            }\n          }\n\n          return false;\n        });\n\n        return preferredCandidate === undefined;\n      });\n    }).next(function (canActAsPrimary) {\n      if (_this.isPrimary !== canActAsPrimary) {\n        logDebug(LOG_TAG$d, \"Client \" + (canActAsPrimary ? 'is' : 'is not') + \" eligible for a primary lease.\");\n      }\n\n      return canActAsPrimary;\n    });\n  };\n\n  IndexedDbPersistence.prototype.shutdown = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var _this = this;\n\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            // The shutdown() operations are idempotent and can be called even when\n            // start() aborted (e.g. because it couldn't acquire the persistence lease).\n            this._started = false;\n            this.markClientZombied();\n\n            if (this.clientMetadataRefresher) {\n              this.clientMetadataRefresher.cancel();\n              this.clientMetadataRefresher = null;\n            }\n\n            this.detachVisibilityHandler();\n            this.detachWindowUnloadHook(); // Use `SimpleDb.runTransaction` directly to avoid failing if another tab\n            // has obtained the primary lease.\n\n            return [4\n            /*yield*/\n            , this.simpleDb.runTransaction('shutdown', 'readwrite', [DbPrimaryClient.store, DbClientMetadata.store], function (simpleDbTxn) {\n              var persistenceTransaction = new IndexedDbTransaction(simpleDbTxn, ListenSequence.INVALID);\n              return _this.releasePrimaryLeaseIfHeld(persistenceTransaction).next(function () {\n                return _this.removeClientMetadata(persistenceTransaction);\n              });\n            })];\n\n          case 1:\n            // Use `SimpleDb.runTransaction` directly to avoid failing if another tab\n            // has obtained the primary lease.\n            _d.sent();\n\n            this.simpleDb.close(); // Remove the entry marking the client as zombied from LocalStorage since\n            // we successfully deleted its metadata from IndexedDb.\n\n            this.removeClientZombiedEntry();\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\r\n   * Returns clients that are not zombied and have an updateTime within the\r\n   * provided threshold.\r\n   */\n\n\n  IndexedDbPersistence.prototype.filterActiveClients = function (clients, activityThresholdMs) {\n    var _this = this;\n\n    return clients.filter(function (client) {\n      return _this.isWithinAge(client.updateTimeMs, activityThresholdMs) && !_this.isClientZombied(client.clientId);\n    });\n  };\n  /**\r\n   * Returns the IDs of the clients that are currently active. If multi-tab\r\n   * is not supported, returns an array that only contains the local client's\r\n   * ID.\r\n   *\r\n   * PORTING NOTE: This is only used for Web multi-tab.\r\n   */\n\n\n  IndexedDbPersistence.prototype.getActiveClients = function () {\n    var _this = this;\n\n    return this.runTransaction('getActiveClients', 'readonly', function (txn) {\n      return clientMetadataStore(txn).loadAll().next(function (clients) {\n        return _this.filterActiveClients(clients, MAX_CLIENT_AGE_MS).map(function (clientMetadata) {\n          return clientMetadata.clientId;\n        });\n      });\n    });\n  };\n\n  Object.defineProperty(IndexedDbPersistence.prototype, \"started\", {\n    get: function () {\n      return this._started;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  IndexedDbPersistence.prototype.getMutationQueue = function (user) {\n    return IndexedDbMutationQueue.forUser(user, this.serializer, this.indexManager, this.referenceDelegate);\n  };\n\n  IndexedDbPersistence.prototype.getTargetCache = function () {\n    return this.targetCache;\n  };\n\n  IndexedDbPersistence.prototype.getRemoteDocumentCache = function () {\n    return this.remoteDocumentCache;\n  };\n\n  IndexedDbPersistence.prototype.getIndexManager = function () {\n    return this.indexManager;\n  };\n\n  IndexedDbPersistence.prototype.getBundleCache = function () {\n    return this.bundleCache;\n  };\n\n  IndexedDbPersistence.prototype.runTransaction = function (action, mode, transactionOperation) {\n    var _this = this;\n\n    logDebug(LOG_TAG$d, 'Starting transaction:', action);\n    var simpleDbMode = mode === 'readonly' ? 'readonly' : 'readwrite';\n    var persistenceTransaction; // Do all transactions as readwrite against all object stores, since we\n    // are the only reader/writer.\n\n    return this.simpleDb.runTransaction(action, simpleDbMode, ALL_STORES, function (simpleDbTxn) {\n      persistenceTransaction = new IndexedDbTransaction(simpleDbTxn, _this.listenSequence ? _this.listenSequence.next() : ListenSequence.INVALID);\n\n      if (mode === 'readwrite-primary') {\n        // While we merely verify that we have (or can acquire) the lease\n        // immediately, we wait to extend the primary lease until after\n        // executing transactionOperation(). This ensures that even if the\n        // transactionOperation takes a long time, we'll use a recent\n        // leaseTimestampMs in the extended (or newly acquired) lease.\n        return _this.verifyPrimaryLease(persistenceTransaction).next(function (holdsPrimaryLease) {\n          if (holdsPrimaryLease) {\n            return (\n              /* holdsPrimaryLease= */\n              true\n            );\n          }\n\n          return _this.canActAsPrimary(persistenceTransaction);\n        }).next(function (holdsPrimaryLease) {\n          if (!holdsPrimaryLease) {\n            logError(\"Failed to obtain primary lease for action '\" + action + \"'.\");\n            _this.isPrimary = false;\n\n            _this.queue.enqueueRetryable(function () {\n              return _this.primaryStateListener(false);\n            });\n\n            throw new FirestoreError(Code.FAILED_PRECONDITION, PRIMARY_LEASE_LOST_ERROR_MSG);\n          }\n\n          return transactionOperation(persistenceTransaction);\n        }).next(function (result) {\n          return _this.acquireOrExtendPrimaryLease(persistenceTransaction).next(function () {\n            return result;\n          });\n        });\n      } else {\n        return _this.verifyAllowTabSynchronization(persistenceTransaction).next(function () {\n          return transactionOperation(persistenceTransaction);\n        });\n      }\n    }).then(function (result) {\n      persistenceTransaction.raiseOnCommittedEvent();\n      return result;\n    });\n  };\n  /**\r\n   * Verifies that the current tab is the primary leaseholder or alternatively\r\n   * that the leaseholder has opted into multi-tab synchronization.\r\n   */\n  // TODO(b/114226234): Remove this check when `synchronizeTabs` can no longer\n  // be turned off.\n\n\n  IndexedDbPersistence.prototype.verifyAllowTabSynchronization = function (txn) {\n    var _this = this;\n\n    var store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(function (currentPrimary) {\n      var currentLeaseIsValid = currentPrimary !== null && _this.isWithinAge(currentPrimary.leaseTimestampMs, MAX_PRIMARY_ELIGIBLE_AGE_MS) && !_this.isClientZombied(currentPrimary.ownerId);\n\n      if (currentLeaseIsValid && !_this.isLocalClient(currentPrimary)) {\n        if (!_this.forceOwningTab && (!_this.allowTabSynchronization || !currentPrimary.allowTabSynchronization)) {\n          throw new FirestoreError(Code.FAILED_PRECONDITION, PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG);\n        }\n      }\n    });\n  };\n  /**\r\n   * Obtains or extends the new primary lease for the local client. This\r\n   * method does not verify that the client is eligible for this lease.\r\n   */\n\n\n  IndexedDbPersistence.prototype.acquireOrExtendPrimaryLease = function (txn) {\n    var newPrimary = new DbPrimaryClient(this.clientId, this.allowTabSynchronization, Date.now());\n    return primaryClientStore(txn).put(DbPrimaryClient.key, newPrimary);\n  };\n\n  IndexedDbPersistence.isAvailable = function () {\n    return SimpleDb.isAvailable();\n  };\n  /** Checks the primary lease and removes it if we are the current primary. */\n\n\n  IndexedDbPersistence.prototype.releasePrimaryLeaseIfHeld = function (txn) {\n    var _this = this;\n\n    var store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(function (primaryClient) {\n      if (_this.isLocalClient(primaryClient)) {\n        logDebug(LOG_TAG$d, 'Releasing primary lease.');\n        return store.delete(DbPrimaryClient.key);\n      } else {\n        return PersistencePromise.resolve();\n      }\n    });\n  };\n  /** Verifies that `updateTimeMs` is within `maxAgeMs`. */\n\n\n  IndexedDbPersistence.prototype.isWithinAge = function (updateTimeMs, maxAgeMs) {\n    var now = Date.now();\n    var minAcceptable = now - maxAgeMs;\n    var maxAcceptable = now;\n\n    if (updateTimeMs < minAcceptable) {\n      return false;\n    } else if (updateTimeMs > maxAcceptable) {\n      logError(\"Detected an update time that is in the future: \" + updateTimeMs + \" > \" + maxAcceptable);\n      return false;\n    }\n\n    return true;\n  };\n\n  IndexedDbPersistence.prototype.attachVisibilityHandler = function () {\n    var _this = this;\n\n    if (this.document !== null && typeof this.document.addEventListener === 'function') {\n      this.documentVisibilityHandler = function () {\n        _this.queue.enqueueAndForget(function () {\n          _this.inForeground = _this.document.visibilityState === 'visible';\n          return _this.updateClientMetadataAndTryBecomePrimary();\n        });\n      };\n\n      this.document.addEventListener('visibilitychange', this.documentVisibilityHandler);\n      this.inForeground = this.document.visibilityState === 'visible';\n    }\n  };\n\n  IndexedDbPersistence.prototype.detachVisibilityHandler = function () {\n    if (this.documentVisibilityHandler) {\n      this.document.removeEventListener('visibilitychange', this.documentVisibilityHandler);\n      this.documentVisibilityHandler = null;\n    }\n  };\n  /**\r\n   * Attaches a window.unload handler that will synchronously write our\r\n   * clientId to a \"zombie client id\" location in LocalStorage. This can be used\r\n   * by tabs trying to acquire the primary lease to determine that the lease\r\n   * is no longer valid even if the timestamp is recent. This is particularly\r\n   * important for the refresh case (so the tab correctly re-acquires the\r\n   * primary lease). LocalStorage is used for this rather than IndexedDb because\r\n   * it is a synchronous API and so can be used reliably from  an unload\r\n   * handler.\r\n   */\n\n\n  IndexedDbPersistence.prototype.attachWindowUnloadHook = function () {\n    var _this = this;\n\n    var _a;\n\n    if (typeof ((_a = this.window) === null || _a === void 0 ? void 0 : _a.addEventListener) === 'function') {\n      this.windowUnloadHandler = function () {\n        // Note: In theory, this should be scheduled on the AsyncQueue since it\n        // accesses internal state. We execute this code directly during shutdown\n        // to make sure it gets a chance to run.\n        _this.markClientZombied();\n\n        if (util.isSafari() && navigator.appVersion.match(\"Version/14\")) {\n          // On Safari 14, we do not run any cleanup actions as it might trigger\n          // a bug that prevents Safari from re-opening IndexedDB during the\n          // next page load.\n          // See https://bugs.webkit.org/show_bug.cgi?id=226547\n          _this.queue.enterRestrictedMode(\n          /* purgeExistingTasks= */\n          true);\n        }\n\n        _this.queue.enqueueAndForget(function () {\n          // Attempt graceful shutdown (including releasing our primary lease),\n          // but there's no guarantee it will complete.\n          return _this.shutdown();\n        });\n      };\n\n      this.window.addEventListener('pagehide', this.windowUnloadHandler);\n    }\n  };\n\n  IndexedDbPersistence.prototype.detachWindowUnloadHook = function () {\n    if (this.windowUnloadHandler) {\n      this.window.removeEventListener('pagehide', this.windowUnloadHandler);\n      this.windowUnloadHandler = null;\n    }\n  };\n  /**\r\n   * Returns whether a client is \"zombied\" based on its LocalStorage entry.\r\n   * Clients become zombied when their tab closes without running all of the\r\n   * cleanup logic in `shutdown()`.\r\n   */\n\n\n  IndexedDbPersistence.prototype.isClientZombied = function (clientId) {\n    var _a;\n\n    try {\n      var isZombied = ((_a = this.webStorage) === null || _a === void 0 ? void 0 : _a.getItem(this.zombiedClientLocalStorageKey(clientId))) !== null;\n      logDebug(LOG_TAG$d, \"Client '\" + clientId + \"' \" + (isZombied ? 'is' : 'is not') + \" zombied in LocalStorage\");\n      return isZombied;\n    } catch (e) {\n      // Gracefully handle if LocalStorage isn't working.\n      logError(LOG_TAG$d, 'Failed to get zombied client id.', e);\n      return false;\n    }\n  };\n  /**\r\n   * Record client as zombied (a client that had its tab closed). Zombied\r\n   * clients are ignored during primary tab selection.\r\n   */\n\n\n  IndexedDbPersistence.prototype.markClientZombied = function () {\n    if (!this.webStorage) {\n      return;\n    }\n\n    try {\n      this.webStorage.setItem(this.zombiedClientLocalStorageKey(this.clientId), String(Date.now()));\n    } catch (e) {\n      // Gracefully handle if LocalStorage isn't available / working.\n      logError('Failed to set zombie client id.', e);\n    }\n  };\n  /** Removes the zombied client entry if it exists. */\n\n\n  IndexedDbPersistence.prototype.removeClientZombiedEntry = function () {\n    if (!this.webStorage) {\n      return;\n    }\n\n    try {\n      this.webStorage.removeItem(this.zombiedClientLocalStorageKey(this.clientId));\n    } catch (e) {// Ignore\n    }\n  };\n\n  IndexedDbPersistence.prototype.zombiedClientLocalStorageKey = function (clientId) {\n    return ZOMBIED_CLIENTS_KEY_PREFIX + \"_\" + this.persistenceKey + \"_\" + clientId;\n  };\n\n  return IndexedDbPersistence;\n}();\n/**\r\n * Helper to get a typed SimpleDbStore for the primary client object store.\r\n */\n\n\nfunction primaryClientStore(txn) {\n  return getStore(txn, DbPrimaryClient.store);\n}\n/**\r\n * Helper to get a typed SimpleDbStore for the client metadata object store.\r\n */\n\n\nfunction clientMetadataStore(txn) {\n  return getStore(txn, DbClientMetadata.store);\n}\n/**\r\n * Generates a string used as a prefix when storing data in IndexedDB and\r\n * LocalStorage.\r\n */\n\n\nfunction indexedDbStoragePrefix(databaseId, persistenceKey) {\n  // Use two different prefix formats:\n  //\n  //   * firestore / persistenceKey / projectID . databaseID / ...\n  //   * firestore / persistenceKey / projectID / ...\n  //\n  // projectIDs are DNS-compatible names and cannot contain dots\n  // so there's no danger of collisions.\n  var database = databaseId.projectId;\n\n  if (!databaseId.isDefaultDatabase) {\n    database += '.' + databaseId.database;\n  }\n\n  return 'firestore/' + persistenceKey + '/' + database + '/';\n}\n\nfunction indexedDbClearPersistence(persistenceKey) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var dbName;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          if (!SimpleDb.isAvailable()) {\n            return [2\n            /*return*/\n            , Promise.resolve()];\n          }\n\n          dbName = persistenceKey + MAIN_DATABASE;\n          return [4\n          /*yield*/\n          , SimpleDb.delete(dbName)];\n\n        case 1:\n          _d.sent();\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A readonly view of the local state of all documents we're tracking (i.e. we\r\n * have a cached version in remoteDocumentCache or local mutations for the\r\n * document). The view is computed by applying the mutations in the\r\n * MutationQueue to the RemoteDocumentCache.\r\n */\n\n\nvar LocalDocumentsView =\n/** @class */\nfunction () {\n  function LocalDocumentsView(remoteDocumentCache, mutationQueue, indexManager) {\n    this.remoteDocumentCache = remoteDocumentCache;\n    this.mutationQueue = mutationQueue;\n    this.indexManager = indexManager;\n  }\n  /**\r\n   * Get the local view of the document identified by `key`.\r\n   *\r\n   * @returns Local view of the document or null if we don't have any cached\r\n   * state for it.\r\n   */\n\n\n  LocalDocumentsView.prototype.getDocument = function (transaction, key) {\n    var _this = this;\n\n    return this.mutationQueue.getAllMutationBatchesAffectingDocumentKey(transaction, key).next(function (batches) {\n      return _this.getDocumentInternal(transaction, key, batches);\n    });\n  };\n  /** Internal version of `getDocument` that allows reusing batches. */\n\n\n  LocalDocumentsView.prototype.getDocumentInternal = function (transaction, key, inBatches) {\n    return this.remoteDocumentCache.getEntry(transaction, key).next(function (doc) {\n      for (var _i = 0, inBatches_1 = inBatches; _i < inBatches_1.length; _i++) {\n        var batch = inBatches_1[_i];\n        batch.applyToLocalView(doc);\n      }\n\n      return doc;\n    });\n  }; // Returns the view of the given `docs` as they would appear after applying\n  // all mutations in the given `batches`.\n\n\n  LocalDocumentsView.prototype.applyLocalMutationsToDocuments = function (docs, batches) {\n    docs.forEach(function (key, localView) {\n      for (var _i = 0, batches_1 = batches; _i < batches_1.length; _i++) {\n        var batch = batches_1[_i];\n        batch.applyToLocalView(localView);\n      }\n    });\n  };\n  /**\r\n   * Gets the local view of the documents identified by `keys`.\r\n   *\r\n   * If we don't have cached state for a document in `keys`, a NoDocument will\r\n   * be stored for that key in the resulting set.\r\n   */\n\n\n  LocalDocumentsView.prototype.getDocuments = function (transaction, keys) {\n    var _this = this;\n\n    return this.remoteDocumentCache.getEntries(transaction, keys).next(function (docs) {\n      return _this.applyLocalViewToDocuments(transaction, docs).next(function () {\n        return docs;\n      });\n    });\n  };\n  /**\r\n   * Applies the local view the given `baseDocs` without retrieving documents\r\n   * from the local store.\r\n   */\n\n\n  LocalDocumentsView.prototype.applyLocalViewToDocuments = function (transaction, baseDocs) {\n    var _this = this;\n\n    return this.mutationQueue.getAllMutationBatchesAffectingDocumentKeys(transaction, baseDocs).next(function (batches) {\n      return _this.applyLocalMutationsToDocuments(baseDocs, batches);\n    });\n  };\n  /**\r\n   * Performs a query against the local view of all documents.\r\n   *\r\n   * @param transaction - The persistence transaction.\r\n   * @param query - The query to match documents against.\r\n   * @param sinceReadTime - If not set to SnapshotVersion.min(), return only\r\n   *     documents that have been read since this snapshot version (exclusive).\r\n   */\n\n\n  LocalDocumentsView.prototype.getDocumentsMatchingQuery = function (transaction, query, sinceReadTime) {\n    if (isDocumentQuery$1(query)) {\n      return this.getDocumentsMatchingDocumentQuery(transaction, query.path);\n    } else if (isCollectionGroupQuery(query)) {\n      return this.getDocumentsMatchingCollectionGroupQuery(transaction, query, sinceReadTime);\n    } else {\n      return this.getDocumentsMatchingCollectionQuery(transaction, query, sinceReadTime);\n    }\n  };\n\n  LocalDocumentsView.prototype.getDocumentsMatchingDocumentQuery = function (transaction, docPath) {\n    // Just do a simple document lookup.\n    return this.getDocument(transaction, new DocumentKey(docPath)).next(function (document) {\n      var result = documentMap();\n\n      if (document.isFoundDocument()) {\n        result = result.insert(document.key, document);\n      }\n\n      return result;\n    });\n  };\n\n  LocalDocumentsView.prototype.getDocumentsMatchingCollectionGroupQuery = function (transaction, query, sinceReadTime) {\n    var _this = this;\n\n    var collectionId = query.collectionGroup;\n    var results = documentMap();\n    return this.indexManager.getCollectionParents(transaction, collectionId).next(function (parents) {\n      // Perform a collection query against each parent that contains the\n      // collectionId and aggregate the results.\n      return PersistencePromise.forEach(parents, function (parent) {\n        var collectionQuery = asCollectionQueryAtPath(query, parent.child(collectionId));\n        return _this.getDocumentsMatchingCollectionQuery(transaction, collectionQuery, sinceReadTime).next(function (r) {\n          r.forEach(function (key, doc) {\n            results = results.insert(key, doc);\n          });\n        });\n      }).next(function () {\n        return results;\n      });\n    });\n  };\n\n  LocalDocumentsView.prototype.getDocumentsMatchingCollectionQuery = function (transaction, query, sinceReadTime) {\n    var _this = this; // Query the remote documents and overlay mutations.\n\n\n    var results;\n    var mutationBatches;\n    return this.remoteDocumentCache.getDocumentsMatchingQuery(transaction, query, sinceReadTime).next(function (queryResults) {\n      results = queryResults;\n      return _this.mutationQueue.getAllMutationBatchesAffectingQuery(transaction, query);\n    }).next(function (matchingMutationBatches) {\n      mutationBatches = matchingMutationBatches; // It is possible that a PatchMutation can make a document match a query, even if\n      // the version in the RemoteDocumentCache is not a match yet (waiting for server\n      // to ack). To handle this, we find all document keys affected by the PatchMutations\n      // that are not in `result` yet, and back fill them via `remoteDocumentCache.getEntries`,\n      // otherwise those `PatchMutations` will be ignored because no base document can be found,\n      // and lead to missing result for the query.\n\n      return _this.addMissingBaseDocuments(transaction, mutationBatches, results).next(function (mergedDocuments) {\n        results = mergedDocuments;\n\n        for (var _i = 0, mutationBatches_1 = mutationBatches; _i < mutationBatches_1.length; _i++) {\n          var batch = mutationBatches_1[_i];\n\n          for (var _d = 0, _e = batch.mutations; _d < _e.length; _d++) {\n            var mutation = _e[_d];\n            var key = mutation.key;\n            var document_2 = results.get(key);\n\n            if (document_2 == null) {\n              // Create invalid document to apply mutations on top of\n              document_2 = MutableDocument.newInvalidDocument(key);\n              results = results.insert(key, document_2);\n            }\n\n            applyMutationToLocalView(mutation, document_2, batch.localWriteTime);\n\n            if (!document_2.isFoundDocument()) {\n              results = results.remove(key);\n            }\n          }\n        }\n      });\n    }).next(function () {\n      // Finally, filter out any documents that don't actually match\n      // the query.\n      results.forEach(function (key, doc) {\n        if (!queryMatches(query, doc)) {\n          results = results.remove(key);\n        }\n      });\n      return results;\n    });\n  };\n\n  LocalDocumentsView.prototype.addMissingBaseDocuments = function (transaction, matchingMutationBatches, existingDocuments) {\n    var missingBaseDocEntriesForPatching = documentKeySet();\n\n    for (var _i = 0, matchingMutationBatches_1 = matchingMutationBatches; _i < matchingMutationBatches_1.length; _i++) {\n      var batch = matchingMutationBatches_1[_i];\n\n      for (var _d = 0, _e = batch.mutations; _d < _e.length; _d++) {\n        var mutation = _e[_d];\n\n        if (mutation instanceof PatchMutation && existingDocuments.get(mutation.key) === null) {\n          missingBaseDocEntriesForPatching = missingBaseDocEntriesForPatching.add(mutation.key);\n        }\n      }\n    }\n\n    var mergedDocuments = existingDocuments;\n    return this.remoteDocumentCache.getEntries(transaction, missingBaseDocEntriesForPatching).next(function (missingBaseDocs) {\n      missingBaseDocs.forEach(function (key, doc) {\n        if (doc.isFoundDocument()) {\n          mergedDocuments = mergedDocuments.insert(key, doc);\n        }\n      });\n      return mergedDocuments;\n    });\n  };\n\n  return LocalDocumentsView;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$c = 'LocalStore';\n/**\r\n * The maximum time to leave a resume token buffered without writing it out.\r\n * This value is arbitrary: it's long enough to avoid several writes\r\n * (possibly indefinitely if updates come more frequently than this) but\r\n * short enough that restarting after crashing will still have a pretty\r\n * recent resume token.\r\n */\n\nvar RESUME_TOKEN_MAX_AGE_MICROS = 5 * 60 * 1e6;\n/**\r\n * Implements `LocalStore` interface.\r\n *\r\n * Note: some field defined in this class might have public access level, but\r\n * the class is not exported so they are only accessible from this module.\r\n * This is useful to implement optional features (like bundles) in free\r\n * functions, such that they are tree-shakeable.\r\n */\n\nvar LocalStoreImpl =\n/** @class */\nfunction () {\n  function LocalStoreImpl(\n  /** Manages our in-memory or durable persistence. */\n  persistence, queryEngine, initialUser, serializer) {\n    this.persistence = persistence;\n    this.queryEngine = queryEngine;\n    this.serializer = serializer;\n    /**\r\n     * Maps a targetID to data about its target.\r\n     *\r\n     * PORTING NOTE: We are using an immutable data structure on Web to make re-runs\r\n     * of `applyRemoteEvent()` idempotent.\r\n     */\n\n    this.targetDataByTarget = new SortedMap(primitiveComparator);\n    /** Maps a target to its targetID. */\n    // TODO(wuandy): Evaluate if TargetId can be part of Target.\n\n    this.targetIdByTarget = new ObjectMap(function (t) {\n      return canonifyTarget(t);\n    }, targetEquals);\n    /**\r\n     * The read time of the last entry processed by `getNewDocumentChanges()`.\r\n     *\r\n     * PORTING NOTE: This is only used for multi-tab synchronization.\r\n     */\n\n    this.lastDocumentChangeReadTime = SnapshotVersion.min();\n    this.mutationQueue = persistence.getMutationQueue(initialUser);\n    this.remoteDocuments = persistence.getRemoteDocumentCache();\n    this.targetCache = persistence.getTargetCache();\n    this.localDocuments = new LocalDocumentsView(this.remoteDocuments, this.mutationQueue, this.persistence.getIndexManager());\n    this.bundleCache = persistence.getBundleCache();\n    this.queryEngine.setLocalDocumentsView(this.localDocuments);\n  }\n\n  LocalStoreImpl.prototype.collectGarbage = function (garbageCollector) {\n    var _this = this;\n\n    return this.persistence.runTransaction('Collect garbage', 'readwrite-primary', function (txn) {\n      return garbageCollector.collect(txn, _this.targetDataByTarget);\n    });\n  };\n\n  return LocalStoreImpl;\n}();\n\nfunction newLocalStore(\n/** Manages our in-memory or durable persistence. */\npersistence, queryEngine, initialUser, serializer) {\n  return new LocalStoreImpl(persistence, queryEngine, initialUser, serializer);\n}\n/**\r\n * Tells the LocalStore that the currently authenticated user has changed.\r\n *\r\n * In response the local store switches the mutation queue to the new user and\r\n * returns any resulting document changes.\r\n */\n// PORTING NOTE: Android and iOS only return the documents affected by the\n// change.\n\n\nfunction localStoreHandleUserChange(localStore, user) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var localStoreImpl, newMutationQueue, newLocalDocuments, result;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          localStoreImpl = debugCast(localStore);\n          newMutationQueue = localStoreImpl.mutationQueue;\n          newLocalDocuments = localStoreImpl.localDocuments;\n          return [4\n          /*yield*/\n          , localStoreImpl.persistence.runTransaction('Handle user change', 'readonly', function (txn) {\n            // Swap out the mutation queue, grabbing the pending mutation batches\n            // before and after.\n            var oldBatches;\n            return localStoreImpl.mutationQueue.getAllMutationBatches(txn).next(function (promisedOldBatches) {\n              oldBatches = promisedOldBatches;\n              newMutationQueue = localStoreImpl.persistence.getMutationQueue(user); // Recreate our LocalDocumentsView using the new\n              // MutationQueue.\n\n              newLocalDocuments = new LocalDocumentsView(localStoreImpl.remoteDocuments, newMutationQueue, localStoreImpl.persistence.getIndexManager());\n              return newMutationQueue.getAllMutationBatches(txn);\n            }).next(function (newBatches) {\n              var removedBatchIds = [];\n              var addedBatchIds = []; // Union the old/new changed keys.\n\n              var changedKeys = documentKeySet();\n\n              for (var _i = 0, oldBatches_1 = oldBatches; _i < oldBatches_1.length; _i++) {\n                var batch = oldBatches_1[_i];\n                removedBatchIds.push(batch.batchId);\n\n                for (var _d = 0, _e = batch.mutations; _d < _e.length; _d++) {\n                  var mutation = _e[_d];\n                  changedKeys = changedKeys.add(mutation.key);\n                }\n              }\n\n              for (var _f = 0, newBatches_1 = newBatches; _f < newBatches_1.length; _f++) {\n                var batch = newBatches_1[_f];\n                addedBatchIds.push(batch.batchId);\n\n                for (var _g = 0, _h = batch.mutations; _g < _h.length; _g++) {\n                  var mutation = _h[_g];\n                  changedKeys = changedKeys.add(mutation.key);\n                }\n              } // Return the set of all (potentially) changed documents and the list\n              // of mutation batch IDs that were affected by change.\n\n\n              return newLocalDocuments.getDocuments(txn, changedKeys).next(function (affectedDocuments) {\n                return {\n                  affectedDocuments: affectedDocuments,\n                  removedBatchIds: removedBatchIds,\n                  addedBatchIds: addedBatchIds\n                };\n              });\n            });\n          })];\n\n        case 1:\n          result = _d.sent();\n          localStoreImpl.mutationQueue = newMutationQueue;\n          localStoreImpl.localDocuments = newLocalDocuments;\n          localStoreImpl.queryEngine.setLocalDocumentsView(localStoreImpl.localDocuments);\n          return [2\n          /*return*/\n          , result];\n      }\n    });\n  });\n}\n/* Accepts locally generated Mutations and commit them to storage. */\n\n\nfunction localStoreWriteLocally(localStore, mutations) {\n  var localStoreImpl = debugCast(localStore);\n  var localWriteTime = Timestamp.now();\n  var keys = mutations.reduce(function (keys, m) {\n    return keys.add(m.key);\n  }, documentKeySet());\n  var existingDocs;\n  return localStoreImpl.persistence.runTransaction('Locally write mutations', 'readwrite', function (txn) {\n    // Load and apply all existing mutations. This lets us compute the\n    // current base state for all non-idempotent transforms before applying\n    // any additional user-provided writes.\n    return localStoreImpl.localDocuments.getDocuments(txn, keys).next(function (docs) {\n      existingDocs = docs; // For non-idempotent mutations (such as `FieldValue.increment()`),\n      // we record the base state in a separate patch mutation. This is\n      // later used to guarantee consistent values and prevents flicker\n      // even if the backend sends us an update that already includes our\n      // transform.\n\n      var baseMutations = [];\n\n      for (var _i = 0, mutations_2 = mutations; _i < mutations_2.length; _i++) {\n        var mutation = mutations_2[_i];\n        var baseValue = extractMutationBaseValue(mutation, existingDocs.get(mutation.key));\n\n        if (baseValue != null) {\n          // NOTE: The base state should only be applied if there's some\n          // existing document to override, so use a Precondition of\n          // exists=true\n          baseMutations.push(new PatchMutation(mutation.key, baseValue, extractFieldMask(baseValue.value.mapValue), Precondition.exists(true)));\n        }\n      }\n\n      return localStoreImpl.mutationQueue.addMutationBatch(txn, localWriteTime, baseMutations, mutations);\n    });\n  }).then(function (batch) {\n    batch.applyToLocalDocumentSet(existingDocs);\n    return {\n      batchId: batch.batchId,\n      changes: existingDocs\n    };\n  });\n}\n/**\r\n * Acknowledges the given batch.\r\n *\r\n * On the happy path when a batch is acknowledged, the local store will\r\n *\r\n *  + remove the batch from the mutation queue;\r\n *  + apply the changes to the remote document cache;\r\n *  + recalculate the latency compensated view implied by those changes (there\r\n *    may be mutations in the queue that affect the documents but haven't been\r\n *    acknowledged yet); and\r\n *  + give the changed documents back the sync engine\r\n *\r\n * @returns The resulting (modified) documents.\r\n */\n\n\nfunction localStoreAcknowledgeBatch(localStore, batchResult) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Acknowledge batch', 'readwrite-primary', function (txn) {\n    var affected = batchResult.batch.keys();\n    var documentBuffer = localStoreImpl.remoteDocuments.newChangeBuffer({\n      trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\n\n    });\n    return applyWriteToRemoteDocuments(localStoreImpl, txn, batchResult, documentBuffer).next(function () {\n      return documentBuffer.apply(txn);\n    }).next(function () {\n      return localStoreImpl.mutationQueue.performConsistencyCheck(txn);\n    }).next(function () {\n      return localStoreImpl.localDocuments.getDocuments(txn, affected);\n    });\n  });\n}\n/**\r\n * Removes mutations from the MutationQueue for the specified batch;\r\n * LocalDocuments will be recalculated.\r\n *\r\n * @returns The resulting modified documents.\r\n */\n\n\nfunction localStoreRejectBatch(localStore, batchId) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Reject batch', 'readwrite-primary', function (txn) {\n    var affectedKeys;\n    return localStoreImpl.mutationQueue.lookupMutationBatch(txn, batchId).next(function (batch) {\n      hardAssert(batch !== null);\n      affectedKeys = batch.keys();\n      return localStoreImpl.mutationQueue.removeMutationBatch(txn, batch);\n    }).next(function () {\n      return localStoreImpl.mutationQueue.performConsistencyCheck(txn);\n    }).next(function () {\n      return localStoreImpl.localDocuments.getDocuments(txn, affectedKeys);\n    });\n  });\n}\n/**\r\n * Returns the largest (latest) batch id in mutation queue that is pending\r\n * server response.\r\n *\r\n * Returns `BATCHID_UNKNOWN` if the queue is empty.\r\n */\n\n\nfunction localStoreGetHighestUnacknowledgedBatchId(localStore) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Get highest unacknowledged batch id', 'readonly', function (txn) {\n    return localStoreImpl.mutationQueue.getHighestUnacknowledgedBatchId(txn);\n  });\n}\n/**\r\n * Returns the last consistent snapshot processed (used by the RemoteStore to\r\n * determine whether to buffer incoming snapshots from the backend).\r\n */\n\n\nfunction localStoreGetLastRemoteSnapshotVersion(localStore) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Get last remote snapshot version', 'readonly', function (txn) {\n    return localStoreImpl.targetCache.getLastRemoteSnapshotVersion(txn);\n  });\n}\n/**\r\n * Updates the \"ground-state\" (remote) documents. We assume that the remote\r\n * event reflects any write batches that have been acknowledged or rejected\r\n * (i.e. we do not re-apply local mutations to updates from this event).\r\n *\r\n * LocalDocuments are re-calculated if there are remaining mutations in the\r\n * queue.\r\n */\n\n\nfunction localStoreApplyRemoteEventToLocalCache(localStore, remoteEvent) {\n  var localStoreImpl = debugCast(localStore);\n  var remoteVersion = remoteEvent.snapshotVersion;\n  var newTargetDataByTargetMap = localStoreImpl.targetDataByTarget;\n  return localStoreImpl.persistence.runTransaction('Apply remote event', 'readwrite-primary', function (txn) {\n    var documentBuffer = localStoreImpl.remoteDocuments.newChangeBuffer({\n      trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\n\n    }); // Reset newTargetDataByTargetMap in case this transaction gets re-run.\n\n    newTargetDataByTargetMap = localStoreImpl.targetDataByTarget;\n    var promises = [];\n    remoteEvent.targetChanges.forEach(function (change, targetId) {\n      var oldTargetData = newTargetDataByTargetMap.get(targetId);\n\n      if (!oldTargetData) {\n        return;\n      } // Only update the remote keys if the target is still active. This\n      // ensures that we can persist the updated target data along with\n      // the updated assignment.\n\n\n      promises.push(localStoreImpl.targetCache.removeMatchingKeys(txn, change.removedDocuments, targetId).next(function () {\n        return localStoreImpl.targetCache.addMatchingKeys(txn, change.addedDocuments, targetId);\n      }));\n      var resumeToken = change.resumeToken; // Update the resume token if the change includes one.\n\n      if (resumeToken.approximateByteSize() > 0) {\n        var newTargetData = oldTargetData.withResumeToken(resumeToken, remoteVersion).withSequenceNumber(txn.currentSequenceNumber);\n        newTargetDataByTargetMap = newTargetDataByTargetMap.insert(targetId, newTargetData); // Update the target data if there are target changes (or if\n        // sufficient time has passed since the last update).\n\n        if (shouldPersistTargetData(oldTargetData, newTargetData, change)) {\n          promises.push(localStoreImpl.targetCache.updateTargetData(txn, newTargetData));\n        }\n      }\n    });\n    var changedDocs = mutableDocumentMap();\n    remoteEvent.documentUpdates.forEach(function (key, doc) {\n      if (remoteEvent.resolvedLimboDocuments.has(key)) {\n        promises.push(localStoreImpl.persistence.referenceDelegate.updateLimboDocument(txn, key));\n      }\n    }); // Each loop iteration only affects its \"own\" doc, so it's safe to get all the remote\n    // documents in advance in a single call.\n\n    promises.push(populateDocumentChangeBuffer(txn, documentBuffer, remoteEvent.documentUpdates, remoteVersion, undefined).next(function (result) {\n      changedDocs = result;\n    })); // HACK: The only reason we allow a null snapshot version is so that we\n    // can synthesize remote events when we get permission denied errors while\n    // trying to resolve the state of a locally cached document that is in\n    // limbo.\n\n    if (!remoteVersion.isEqual(SnapshotVersion.min())) {\n      var updateRemoteVersion = localStoreImpl.targetCache.getLastRemoteSnapshotVersion(txn).next(function (lastRemoteSnapshotVersion) {\n        return localStoreImpl.targetCache.setTargetsMetadata(txn, txn.currentSequenceNumber, remoteVersion);\n      });\n      promises.push(updateRemoteVersion);\n    }\n\n    return PersistencePromise.waitFor(promises).next(function () {\n      return documentBuffer.apply(txn);\n    }).next(function () {\n      return localStoreImpl.localDocuments.applyLocalViewToDocuments(txn, changedDocs);\n    }).next(function () {\n      return changedDocs;\n    });\n  }).then(function (changedDocs) {\n    localStoreImpl.targetDataByTarget = newTargetDataByTargetMap;\n    return changedDocs;\n  });\n}\n/**\r\n * Populates document change buffer with documents from backend or a bundle.\r\n * Returns the document changes resulting from applying those documents.\r\n *\r\n * @param txn - Transaction to use to read existing documents from storage.\r\n * @param documentBuffer - Document buffer to collect the resulted changes to be\r\n *        applied to storage.\r\n * @param documents - Documents to be applied.\r\n * @param globalVersion - A `SnapshotVersion` representing the read time if all\r\n *        documents have the same read time.\r\n * @param documentVersions - A DocumentKey-to-SnapshotVersion map if documents\r\n *        have their own read time.\r\n *\r\n * Note: this function will use `documentVersions` if it is defined;\r\n * when it is not defined, resorts to `globalVersion`.\r\n */\n\n\nfunction populateDocumentChangeBuffer(txn, documentBuffer, documents, globalVersion, // TODO(wuandy): We could add `readTime` to MaybeDocument instead to remove\n// this parameter.\ndocumentVersions) {\n  var updatedKeys = documentKeySet();\n  documents.forEach(function (k) {\n    return updatedKeys = updatedKeys.add(k);\n  });\n  return documentBuffer.getEntries(txn, updatedKeys).next(function (existingDocs) {\n    var changedDocs = mutableDocumentMap();\n    documents.forEach(function (key, doc) {\n      var existingDoc = existingDocs.get(key);\n      var docReadTime = (documentVersions === null || documentVersions === void 0 ? void 0 : documentVersions.get(key)) || globalVersion; // Note: The order of the steps below is important, since we want\n      // to ensure that rejected limbo resolutions (which fabricate\n      // NoDocuments with SnapshotVersion.min()) never add documents to\n      // cache.\n\n      if (doc.isNoDocument() && doc.version.isEqual(SnapshotVersion.min())) {\n        // NoDocuments with SnapshotVersion.min() are used in manufactured\n        // events. We remove these documents from cache since we lost\n        // access.\n        documentBuffer.removeEntry(key, docReadTime);\n        changedDocs = changedDocs.insert(key, doc);\n      } else if (!existingDoc.isValidDocument() || doc.version.compareTo(existingDoc.version) > 0 || doc.version.compareTo(existingDoc.version) === 0 && existingDoc.hasPendingWrites) {\n        documentBuffer.addEntry(doc, docReadTime);\n        changedDocs = changedDocs.insert(key, doc);\n      } else {\n        logDebug(LOG_TAG$c, 'Ignoring outdated watch update for ', key, '. Current version:', existingDoc.version, ' Watch version:', doc.version);\n      }\n    });\n    return changedDocs;\n  });\n}\n/**\r\n * Returns true if the newTargetData should be persisted during an update of\r\n * an active target. TargetData should always be persisted when a target is\r\n * being released and should not call this function.\r\n *\r\n * While the target is active, TargetData updates can be omitted when nothing\r\n * about the target has changed except metadata like the resume token or\r\n * snapshot version. Occasionally it's worth the extra write to prevent these\r\n * values from getting too stale after a crash, but this doesn't have to be\r\n * too frequent.\r\n */\n\n\nfunction shouldPersistTargetData(oldTargetData, newTargetData, change) {\n  hardAssert(newTargetData.resumeToken.approximateByteSize() > 0); // Always persist target data if we don't already have a resume token.\n\n  if (oldTargetData.resumeToken.approximateByteSize() === 0) {\n    return true;\n  } // Don't allow resume token changes to be buffered indefinitely. This\n  // allows us to be reasonably up-to-date after a crash and avoids needing\n  // to loop over all active queries on shutdown. Especially in the browser\n  // we may not get time to do anything interesting while the current tab is\n  // closing.\n\n\n  var timeDelta = newTargetData.snapshotVersion.toMicroseconds() - oldTargetData.snapshotVersion.toMicroseconds();\n\n  if (timeDelta >= RESUME_TOKEN_MAX_AGE_MICROS) {\n    return true;\n  } // Otherwise if the only thing that has changed about a target is its resume\n  // token it's not worth persisting. Note that the RemoteStore keeps an\n  // in-memory view of the currently active targets which includes the current\n  // resume token, so stream failure or user changes will still use an\n  // up-to-date resume token regardless of what we do here.\n\n\n  var changes = change.addedDocuments.size + change.modifiedDocuments.size + change.removedDocuments.size;\n  return changes > 0;\n}\n/**\r\n * Notifies local store of the changed views to locally pin documents.\r\n */\n\n\nfunction localStoreNotifyLocalViewChanges(localStore, viewChanges) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var localStoreImpl, e_2, _i, viewChanges_1, viewChange, targetId, targetData, lastLimboFreeSnapshotVersion, updatedTargetData;\n\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          localStoreImpl = debugCast(localStore);\n          _d.label = 1;\n\n        case 1:\n          _d.trys.push([1, 3,, 4]);\n\n          return [4\n          /*yield*/\n          , localStoreImpl.persistence.runTransaction('notifyLocalViewChanges', 'readwrite', function (txn) {\n            return PersistencePromise.forEach(viewChanges, function (viewChange) {\n              return PersistencePromise.forEach(viewChange.addedKeys, function (key) {\n                return localStoreImpl.persistence.referenceDelegate.addReference(txn, viewChange.targetId, key);\n              }).next(function () {\n                return PersistencePromise.forEach(viewChange.removedKeys, function (key) {\n                  return localStoreImpl.persistence.referenceDelegate.removeReference(txn, viewChange.targetId, key);\n                });\n              });\n            });\n          })];\n\n        case 2:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 4];\n\n        case 3:\n          e_2 = _d.sent();\n\n          if (isIndexedDbTransactionError(e_2)) {\n            // If `notifyLocalViewChanges` fails, we did not advance the sequence\n            // number for the documents that were included in this transaction.\n            // This might trigger them to be deleted earlier than they otherwise\n            // would have, but it should not invalidate the integrity of the data.\n            logDebug(LOG_TAG$c, 'Failed to update sequence numbers: ' + e_2);\n          } else {\n            throw e_2;\n          }\n\n          return [3\n          /*break*/\n          , 4];\n\n        case 4:\n          for (_i = 0, viewChanges_1 = viewChanges; _i < viewChanges_1.length; _i++) {\n            viewChange = viewChanges_1[_i];\n            targetId = viewChange.targetId;\n\n            if (!viewChange.fromCache) {\n              targetData = localStoreImpl.targetDataByTarget.get(targetId);\n              lastLimboFreeSnapshotVersion = targetData.snapshotVersion;\n              updatedTargetData = targetData.withLastLimboFreeSnapshotVersion(lastLimboFreeSnapshotVersion);\n              localStoreImpl.targetDataByTarget = localStoreImpl.targetDataByTarget.insert(targetId, updatedTargetData);\n            }\n          }\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Gets the mutation batch after the passed in batchId in the mutation queue\r\n * or null if empty.\r\n * @param afterBatchId - If provided, the batch to search after.\r\n * @returns The next mutation or null if there wasn't one.\r\n */\n\n\nfunction localStoreGetNextMutationBatch(localStore, afterBatchId) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Get next mutation batch', 'readonly', function (txn) {\n    if (afterBatchId === undefined) {\n      afterBatchId = BATCHID_UNKNOWN;\n    }\n\n    return localStoreImpl.mutationQueue.getNextMutationBatchAfterBatchId(txn, afterBatchId);\n  });\n}\n/**\r\n * Reads the current value of a Document with a given key or null if not\r\n * found - used for testing.\r\n */\n\n\nfunction localStoreReadDocument(localStore, key) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('read document', 'readonly', function (txn) {\n    return localStoreImpl.localDocuments.getDocument(txn, key);\n  });\n}\n/**\r\n * Assigns the given target an internal ID so that its results can be pinned so\r\n * they don't get GC'd. A target must be allocated in the local store before\r\n * the store can be used to manage its view.\r\n *\r\n * Allocating an already allocated `Target` will return the existing `TargetData`\r\n * for that `Target`.\r\n */\n\n\nfunction localStoreAllocateTarget(localStore, target) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Allocate target', 'readwrite', function (txn) {\n    var targetData;\n    return localStoreImpl.targetCache.getTargetData(txn, target).next(function (cached) {\n      if (cached) {\n        // This target has been listened to previously, so reuse the\n        // previous targetID.\n        // TODO(mcg): freshen last accessed date?\n        targetData = cached;\n        return PersistencePromise.resolve(targetData);\n      } else {\n        return localStoreImpl.targetCache.allocateTargetId(txn).next(function (targetId) {\n          targetData = new TargetData(target, targetId, 0\n          /* Listen */\n          , txn.currentSequenceNumber);\n          return localStoreImpl.targetCache.addTargetData(txn, targetData).next(function () {\n            return targetData;\n          });\n        });\n      }\n    });\n  }).then(function (targetData) {\n    // If Multi-Tab is enabled, the existing target data may be newer than\n    // the in-memory data\n    var cachedTargetData = localStoreImpl.targetDataByTarget.get(targetData.targetId);\n\n    if (cachedTargetData === null || targetData.snapshotVersion.compareTo(cachedTargetData.snapshotVersion) > 0) {\n      localStoreImpl.targetDataByTarget = localStoreImpl.targetDataByTarget.insert(targetData.targetId, targetData);\n      localStoreImpl.targetIdByTarget.set(target, targetData.targetId);\n    }\n\n    return targetData;\n  });\n}\n/**\r\n * Returns the TargetData as seen by the LocalStore, including updates that may\r\n * have not yet been persisted to the TargetCache.\r\n */\n// Visible for testing.\n\n\nfunction localStoreGetTargetData(localStore, transaction, target) {\n  var localStoreImpl = debugCast(localStore);\n  var targetId = localStoreImpl.targetIdByTarget.get(target);\n\n  if (targetId !== undefined) {\n    return PersistencePromise.resolve(localStoreImpl.targetDataByTarget.get(targetId));\n  } else {\n    return localStoreImpl.targetCache.getTargetData(transaction, target);\n  }\n}\n/**\r\n * Unpins all the documents associated with the given target. If\r\n * `keepPersistedTargetData` is set to false and Eager GC enabled, the method\r\n * directly removes the associated target data from the target cache.\r\n *\r\n * Releasing a non-existing `Target` is a no-op.\r\n */\n// PORTING NOTE: `keepPersistedTargetData` is multi-tab only.\n\n\nfunction localStoreReleaseTarget(localStore, targetId, keepPersistedTargetData) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var localStoreImpl, targetData, mode, e_3;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          localStoreImpl = debugCast(localStore);\n          targetData = localStoreImpl.targetDataByTarget.get(targetId);\n          mode = keepPersistedTargetData ? 'readwrite' : 'readwrite-primary';\n          _d.label = 1;\n\n        case 1:\n          _d.trys.push([1, 4,, 5]);\n\n          if (!!keepPersistedTargetData) return [3\n          /*break*/\n          , 3];\n          return [4\n          /*yield*/\n          , localStoreImpl.persistence.runTransaction('Release target', mode, function (txn) {\n            return localStoreImpl.persistence.referenceDelegate.removeTarget(txn, targetData);\n          })];\n\n        case 2:\n          _d.sent();\n\n          _d.label = 3;\n\n        case 3:\n          return [3\n          /*break*/\n          , 5];\n\n        case 4:\n          e_3 = _d.sent();\n\n          if (isIndexedDbTransactionError(e_3)) {\n            // All `releaseTarget` does is record the final metadata state for the\n            // target, but we've been recording this periodically during target\n            // activity. If we lose this write this could cause a very slight\n            // difference in the order of target deletion during GC, but we\n            // don't define exact LRU semantics so this is acceptable.\n            logDebug(LOG_TAG$c, \"Failed to update sequence numbers for target \" + targetId + \": \" + e_3);\n          } else {\n            throw e_3;\n          }\n\n          return [3\n          /*break*/\n          , 5];\n\n        case 5:\n          localStoreImpl.targetDataByTarget = localStoreImpl.targetDataByTarget.remove(targetId);\n          localStoreImpl.targetIdByTarget.delete(targetData.target);\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Runs the specified query against the local store and returns the results,\r\n * potentially taking advantage of query data from previous executions (such\r\n * as the set of remote keys).\r\n *\r\n * @param usePreviousResults - Whether results from previous executions can\r\n * be used to optimize this query execution.\r\n */\n\n\nfunction localStoreExecuteQuery(localStore, query, usePreviousResults) {\n  var localStoreImpl = debugCast(localStore);\n  var lastLimboFreeSnapshotVersion = SnapshotVersion.min();\n  var remoteKeys = documentKeySet();\n  return localStoreImpl.persistence.runTransaction('Execute query', 'readonly', function (txn) {\n    return localStoreGetTargetData(localStoreImpl, txn, queryToTarget(query)).next(function (targetData) {\n      if (targetData) {\n        lastLimboFreeSnapshotVersion = targetData.lastLimboFreeSnapshotVersion;\n        return localStoreImpl.targetCache.getMatchingKeysForTargetId(txn, targetData.targetId).next(function (result) {\n          remoteKeys = result;\n        });\n      }\n    }).next(function () {\n      return localStoreImpl.queryEngine.getDocumentsMatchingQuery(txn, query, usePreviousResults ? lastLimboFreeSnapshotVersion : SnapshotVersion.min(), usePreviousResults ? remoteKeys : documentKeySet());\n    }).next(function (documents) {\n      return {\n        documents: documents,\n        remoteKeys: remoteKeys\n      };\n    });\n  });\n}\n\nfunction applyWriteToRemoteDocuments(localStoreImpl, txn, batchResult, documentBuffer) {\n  var batch = batchResult.batch;\n  var docKeys = batch.keys();\n  var promiseChain = PersistencePromise.resolve();\n  docKeys.forEach(function (docKey) {\n    promiseChain = promiseChain.next(function () {\n      return documentBuffer.getEntry(txn, docKey);\n    }).next(function (doc) {\n      var ackVersion = batchResult.docVersions.get(docKey);\n      hardAssert(ackVersion !== null);\n\n      if (doc.version.compareTo(ackVersion) < 0) {\n        batch.applyToRemoteDocument(doc, batchResult);\n\n        if (doc.isValidDocument()) {\n          // We use the commitVersion as the readTime rather than the\n          // document's updateTime since the updateTime is not advanced\n          // for updates that do not modify the underlying document.\n          documentBuffer.addEntry(doc, batchResult.commitVersion);\n        }\n      }\n    });\n  });\n  return promiseChain.next(function () {\n    return localStoreImpl.mutationQueue.removeMutationBatch(txn, batch);\n  });\n}\n/** Returns the local view of the documents affected by a mutation batch. */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction localStoreLookupMutationDocuments(localStore, batchId) {\n  var localStoreImpl = debugCast(localStore);\n  var mutationQueueImpl = debugCast(localStoreImpl.mutationQueue);\n  return localStoreImpl.persistence.runTransaction('Lookup mutation documents', 'readonly', function (txn) {\n    return mutationQueueImpl.lookupMutationKeys(txn, batchId).next(function (keys) {\n      if (keys) {\n        return localStoreImpl.localDocuments.getDocuments(txn, keys);\n      } else {\n        return PersistencePromise.resolve(null);\n      }\n    });\n  });\n} // PORTING NOTE: Multi-Tab only.\n\n\nfunction localStoreRemoveCachedMutationBatchMetadata(localStore, batchId) {\n  var mutationQueueImpl = debugCast(debugCast(localStore, LocalStoreImpl).mutationQueue);\n  mutationQueueImpl.removeCachedMutationKeys(batchId);\n} // PORTING NOTE: Multi-Tab only.\n\n\nfunction localStoreGetActiveClients(localStore) {\n  var persistenceImpl = debugCast(debugCast(localStore, LocalStoreImpl).persistence);\n  return persistenceImpl.getActiveClients();\n} // PORTING NOTE: Multi-Tab only.\n\n\nfunction localStoreGetCachedTarget(localStore, targetId) {\n  var localStoreImpl = debugCast(localStore);\n  var targetCacheImpl = debugCast(localStoreImpl.targetCache);\n  var cachedTargetData = localStoreImpl.targetDataByTarget.get(targetId);\n\n  if (cachedTargetData) {\n    return Promise.resolve(cachedTargetData.target);\n  } else {\n    return localStoreImpl.persistence.runTransaction('Get target data', 'readonly', function (txn) {\n      return targetCacheImpl.getTargetDataForTarget(txn, targetId).next(function (targetData) {\n        return targetData ? targetData.target : null;\n      });\n    });\n  }\n}\n/**\r\n * Returns the set of documents that have been updated since the last call.\r\n * If this is the first call, returns the set of changes since client\r\n * initialization. Further invocations will return document that have changed\r\n * since the prior call.\r\n */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction localStoreGetNewDocumentChanges(localStore) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Get new document changes', 'readonly', function (txn) {\n    return remoteDocumentCacheGetNewDocumentChanges(localStoreImpl.remoteDocuments, txn, localStoreImpl.lastDocumentChangeReadTime);\n  }).then(function (_d) {\n    var changedDocs = _d.changedDocs,\n        readTime = _d.readTime;\n    localStoreImpl.lastDocumentChangeReadTime = readTime;\n    return changedDocs;\n  });\n}\n/**\r\n * Reads the newest document change from persistence and moves the internal\r\n * synchronization marker forward so that calls to `getNewDocumentChanges()`\r\n * only return changes that happened after client initialization.\r\n */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction localStoreSynchronizeLastDocumentChangeReadTime(localStore) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var localStoreImpl;\n    return tslib.__generator(this, function (_d) {\n      localStoreImpl = debugCast(localStore);\n      return [2\n      /*return*/\n      , localStoreImpl.persistence.runTransaction('Synchronize last document change read time', 'readonly', function (txn) {\n        return remoteDocumentCacheGetLastReadTime(txn);\n      }).then(function (readTime) {\n        localStoreImpl.lastDocumentChangeReadTime = readTime;\n      })];\n    });\n  });\n}\n/**\r\n * Creates a new target using the given bundle name, which will be used to\r\n * hold the keys of all documents from the bundle in query-document mappings.\r\n * This ensures that the loaded documents do not get garbage collected\r\n * right away.\r\n */\n\n\nfunction umbrellaTarget(bundleName) {\n  // It is OK that the path used for the query is not valid, because this will\n  // not be read and queried.\n  return queryToTarget(newQueryForPath(ResourcePath.fromString(\"__bundle__/docs/\" + bundleName)));\n}\n/**\r\n * Applies the documents from a bundle to the \"ground-state\" (remote)\r\n * documents.\r\n *\r\n * LocalDocuments are re-calculated if there are remaining mutations in the\r\n * queue.\r\n */\n\n\nfunction localStoreApplyBundledDocuments(localStore, bundleConverter, documents, bundleName) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var localStoreImpl, documentKeys, documentMap, versionMap, _i, documents_1, bundleDoc, documentKey, documentBuffer, umbrellaTargetData;\n\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          localStoreImpl = debugCast(localStore);\n          documentKeys = documentKeySet();\n          documentMap = mutableDocumentMap();\n          versionMap = documentVersionMap();\n\n          for (_i = 0, documents_1 = documents; _i < documents_1.length; _i++) {\n            bundleDoc = documents_1[_i];\n            documentKey = bundleConverter.toDocumentKey(bundleDoc.metadata.name);\n\n            if (bundleDoc.document) {\n              documentKeys = documentKeys.add(documentKey);\n            }\n\n            documentMap = documentMap.insert(documentKey, bundleConverter.toMutableDocument(bundleDoc));\n            versionMap = versionMap.insert(documentKey, bundleConverter.toSnapshotVersion(bundleDoc.metadata.readTime));\n          }\n\n          documentBuffer = localStoreImpl.remoteDocuments.newChangeBuffer({\n            trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\n\n          });\n          return [4\n          /*yield*/\n          , localStoreAllocateTarget(localStoreImpl, umbrellaTarget(bundleName))];\n\n        case 1:\n          umbrellaTargetData = _d.sent();\n          return [2\n          /*return*/\n          , localStoreImpl.persistence.runTransaction('Apply bundle documents', 'readwrite', function (txn) {\n            return populateDocumentChangeBuffer(txn, documentBuffer, documentMap, SnapshotVersion.min(), versionMap).next(function (changedDocs) {\n              documentBuffer.apply(txn);\n              return changedDocs;\n            }).next(function (changedDocs) {\n              return localStoreImpl.targetCache.removeMatchingKeysForTargetId(txn, umbrellaTargetData.targetId).next(function () {\n                return localStoreImpl.targetCache.addMatchingKeys(txn, documentKeys, umbrellaTargetData.targetId);\n              }).next(function () {\n                return localStoreImpl.localDocuments.applyLocalViewToDocuments(txn, changedDocs);\n              }).next(function () {\n                return changedDocs;\n              });\n            });\n          })];\n      }\n    });\n  });\n}\n/**\r\n * Returns a promise of a boolean to indicate if the given bundle has already\r\n * been loaded and the create time is newer than the current loading bundle.\r\n */\n\n\nfunction localStoreHasNewerBundle(localStore, bundleMetadata) {\n  var localStoreImpl = debugCast(localStore);\n  var currentReadTime = fromVersion(bundleMetadata.createTime);\n  return localStoreImpl.persistence.runTransaction('hasNewerBundle', 'readonly', function (transaction) {\n    return localStoreImpl.bundleCache.getBundleMetadata(transaction, bundleMetadata.id);\n  }).then(function (cached) {\n    return !!cached && cached.createTime.compareTo(currentReadTime) >= 0;\n  });\n}\n/**\r\n * Saves the given `BundleMetadata` to local persistence.\r\n */\n\n\nfunction localStoreSaveBundle(localStore, bundleMetadata) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Save bundle', 'readwrite', function (transaction) {\n    return localStoreImpl.bundleCache.saveBundleMetadata(transaction, bundleMetadata);\n  });\n}\n/**\r\n * Returns a promise of a `NamedQuery` associated with given query name. Promise\r\n * resolves to undefined if no persisted data can be found.\r\n */\n\n\nfunction localStoreGetNamedQuery(localStore, queryName) {\n  var localStoreImpl = debugCast(localStore);\n  return localStoreImpl.persistence.runTransaction('Get named query', 'readonly', function (transaction) {\n    return localStoreImpl.bundleCache.getNamedQuery(transaction, queryName);\n  });\n}\n/**\r\n * Saves the given `NamedQuery` to local persistence.\r\n */\n\n\nfunction localStoreSaveNamedQuery(localStore, query, documents) {\n  if (documents === void 0) {\n    documents = documentKeySet();\n  }\n\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var allocated, localStoreImpl;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          return [4\n          /*yield*/\n          , localStoreAllocateTarget(localStore, queryToTarget(fromBundledQuery(query.bundledQuery)))];\n\n        case 1:\n          allocated = _d.sent();\n          localStoreImpl = debugCast(localStore);\n          return [2\n          /*return*/\n          , localStoreImpl.persistence.runTransaction('Save named query', 'readwrite', function (transaction) {\n            var readTime = fromVersion(query.readTime); // Simply save the query itself if it is older than what the SDK already\n            // has.\n\n            if (allocated.snapshotVersion.compareTo(readTime) >= 0) {\n              return localStoreImpl.bundleCache.saveNamedQuery(transaction, query);\n            } // Update existing target data because the query from the bundle is newer.\n\n\n            var newTargetData = allocated.withResumeToken(ByteString.EMPTY_BYTE_STRING, readTime);\n            localStoreImpl.targetDataByTarget = localStoreImpl.targetDataByTarget.insert(newTargetData.targetId, newTargetData);\n            return localStoreImpl.targetCache.updateTargetData(transaction, newTargetData).next(function () {\n              return localStoreImpl.targetCache.removeMatchingKeysForTargetId(transaction, allocated.targetId);\n            }).next(function () {\n              return localStoreImpl.targetCache.addMatchingKeys(transaction, documents, allocated.targetId);\n            }).next(function () {\n              return localStoreImpl.bundleCache.saveNamedQuery(transaction, query);\n            });\n          })];\n      }\n    });\n  });\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar MemoryBundleCache =\n/** @class */\nfunction () {\n  function MemoryBundleCache(serializer) {\n    this.serializer = serializer;\n    this.bundles = new Map();\n    this.namedQueries = new Map();\n  }\n\n  MemoryBundleCache.prototype.getBundleMetadata = function (transaction, bundleId) {\n    return PersistencePromise.resolve(this.bundles.get(bundleId));\n  };\n\n  MemoryBundleCache.prototype.saveBundleMetadata = function (transaction, bundleMetadata) {\n    this.bundles.set(bundleMetadata.id, fromBundleMetadata(bundleMetadata));\n    return PersistencePromise.resolve();\n  };\n\n  MemoryBundleCache.prototype.getNamedQuery = function (transaction, queryName) {\n    return PersistencePromise.resolve(this.namedQueries.get(queryName));\n  };\n\n  MemoryBundleCache.prototype.saveNamedQuery = function (transaction, query) {\n    this.namedQueries.set(query.name, fromProtoNamedQuery(query));\n    return PersistencePromise.resolve();\n  };\n\n  return MemoryBundleCache;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A collection of references to a document from some kind of numbered entity\r\n * (either a target ID or batch ID). As references are added to or removed from\r\n * the set corresponding events are emitted to a registered garbage collector.\r\n *\r\n * Each reference is represented by a DocumentReference object. Each of them\r\n * contains enough information to uniquely identify the reference. They are all\r\n * stored primarily in a set sorted by key. A document is considered garbage if\r\n * there's no references in that set (this can be efficiently checked thanks to\r\n * sorting by key).\r\n *\r\n * ReferenceSet also keeps a secondary set that contains references sorted by\r\n * IDs. This one is used to efficiently implement removal of all references by\r\n * some target ID.\r\n */\n\n\nvar ReferenceSet =\n/** @class */\nfunction () {\n  function ReferenceSet() {\n    // A set of outstanding references to a document sorted by key.\n    this.refsByKey = new SortedSet(DocReference.compareByKey); // A set of outstanding references to a document sorted by target id.\n\n    this.refsByTarget = new SortedSet(DocReference.compareByTargetId);\n  }\n  /** Returns true if the reference set contains no references. */\n\n\n  ReferenceSet.prototype.isEmpty = function () {\n    return this.refsByKey.isEmpty();\n  };\n  /** Adds a reference to the given document key for the given ID. */\n\n\n  ReferenceSet.prototype.addReference = function (key, id) {\n    var ref = new DocReference(key, id);\n    this.refsByKey = this.refsByKey.add(ref);\n    this.refsByTarget = this.refsByTarget.add(ref);\n  };\n  /** Add references to the given document keys for the given ID. */\n\n\n  ReferenceSet.prototype.addReferences = function (keys, id) {\n    var _this = this;\n\n    keys.forEach(function (key) {\n      return _this.addReference(key, id);\n    });\n  };\n  /**\r\n   * Removes a reference to the given document key for the given\r\n   * ID.\r\n   */\n\n\n  ReferenceSet.prototype.removeReference = function (key, id) {\n    this.removeRef(new DocReference(key, id));\n  };\n\n  ReferenceSet.prototype.removeReferences = function (keys, id) {\n    var _this = this;\n\n    keys.forEach(function (key) {\n      return _this.removeReference(key, id);\n    });\n  };\n  /**\r\n   * Clears all references with a given ID. Calls removeRef() for each key\r\n   * removed.\r\n   */\n\n\n  ReferenceSet.prototype.removeReferencesForId = function (id) {\n    var _this = this;\n\n    var emptyKey = new DocumentKey(new ResourcePath([]));\n    var startRef = new DocReference(emptyKey, id);\n    var endRef = new DocReference(emptyKey, id + 1);\n    var keys = [];\n    this.refsByTarget.forEachInRange([startRef, endRef], function (ref) {\n      _this.removeRef(ref);\n\n      keys.push(ref.key);\n    });\n    return keys;\n  };\n\n  ReferenceSet.prototype.removeAllReferences = function () {\n    var _this = this;\n\n    this.refsByKey.forEach(function (ref) {\n      return _this.removeRef(ref);\n    });\n  };\n\n  ReferenceSet.prototype.removeRef = function (ref) {\n    this.refsByKey = this.refsByKey.delete(ref);\n    this.refsByTarget = this.refsByTarget.delete(ref);\n  };\n\n  ReferenceSet.prototype.referencesForId = function (id) {\n    var emptyKey = new DocumentKey(new ResourcePath([]));\n    var startRef = new DocReference(emptyKey, id);\n    var endRef = new DocReference(emptyKey, id + 1);\n    var keys = documentKeySet();\n    this.refsByTarget.forEachInRange([startRef, endRef], function (ref) {\n      keys = keys.add(ref.key);\n    });\n    return keys;\n  };\n\n  ReferenceSet.prototype.containsKey = function (key) {\n    var ref = new DocReference(key, 0);\n    var firstRef = this.refsByKey.firstAfterOrEqual(ref);\n    return firstRef !== null && key.isEqual(firstRef.key);\n  };\n\n  return ReferenceSet;\n}();\n\nvar DocReference =\n/** @class */\nfunction () {\n  function DocReference(key, targetOrBatchId) {\n    this.key = key;\n    this.targetOrBatchId = targetOrBatchId;\n  }\n  /** Compare by key then by ID */\n\n\n  DocReference.compareByKey = function (left, right) {\n    return DocumentKey.comparator(left.key, right.key) || primitiveComparator(left.targetOrBatchId, right.targetOrBatchId);\n  };\n  /** Compare by ID then by key */\n\n\n  DocReference.compareByTargetId = function (left, right) {\n    return primitiveComparator(left.targetOrBatchId, right.targetOrBatchId) || DocumentKey.comparator(left.key, right.key);\n  };\n\n  return DocReference;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar MemoryMutationQueue =\n/** @class */\nfunction () {\n  function MemoryMutationQueue(indexManager, referenceDelegate) {\n    this.indexManager = indexManager;\n    this.referenceDelegate = referenceDelegate;\n    /**\r\n     * The set of all mutations that have been sent but not yet been applied to\r\n     * the backend.\r\n     */\n\n    this.mutationQueue = [];\n    /** Next value to use when assigning sequential IDs to each mutation batch. */\n\n    this.nextBatchId = 1;\n    /** An ordered mapping between documents and the mutations batch IDs. */\n\n    this.batchesByDocumentKey = new SortedSet(DocReference.compareByKey);\n  }\n\n  MemoryMutationQueue.prototype.checkEmpty = function (transaction) {\n    return PersistencePromise.resolve(this.mutationQueue.length === 0);\n  };\n\n  MemoryMutationQueue.prototype.addMutationBatch = function (transaction, localWriteTime, baseMutations, mutations) {\n    var batchId = this.nextBatchId;\n    this.nextBatchId++;\n\n    if (this.mutationQueue.length > 0) {\n      this.mutationQueue[this.mutationQueue.length - 1];\n    }\n\n    var batch = new MutationBatch(batchId, localWriteTime, baseMutations, mutations);\n    this.mutationQueue.push(batch); // Track references by document key and index collection parents.\n\n    for (var _i = 0, mutations_3 = mutations; _i < mutations_3.length; _i++) {\n      var mutation = mutations_3[_i];\n      this.batchesByDocumentKey = this.batchesByDocumentKey.add(new DocReference(mutation.key, batchId));\n      this.indexManager.addToCollectionParentIndex(transaction, mutation.key.path.popLast());\n    }\n\n    return PersistencePromise.resolve(batch);\n  };\n\n  MemoryMutationQueue.prototype.lookupMutationBatch = function (transaction, batchId) {\n    return PersistencePromise.resolve(this.findMutationBatch(batchId));\n  };\n\n  MemoryMutationQueue.prototype.getNextMutationBatchAfterBatchId = function (transaction, batchId) {\n    var nextBatchId = batchId + 1; // The requested batchId may still be out of range so normalize it to the\n    // start of the queue.\n\n    var rawIndex = this.indexOfBatchId(nextBatchId);\n    var index = rawIndex < 0 ? 0 : rawIndex;\n    return PersistencePromise.resolve(this.mutationQueue.length > index ? this.mutationQueue[index] : null);\n  };\n\n  MemoryMutationQueue.prototype.getHighestUnacknowledgedBatchId = function () {\n    return PersistencePromise.resolve(this.mutationQueue.length === 0 ? BATCHID_UNKNOWN : this.nextBatchId - 1);\n  };\n\n  MemoryMutationQueue.prototype.getAllMutationBatches = function (transaction) {\n    return PersistencePromise.resolve(this.mutationQueue.slice());\n  };\n\n  MemoryMutationQueue.prototype.getAllMutationBatchesAffectingDocumentKey = function (transaction, documentKey) {\n    var _this = this;\n\n    var start = new DocReference(documentKey, 0);\n    var end = new DocReference(documentKey, Number.POSITIVE_INFINITY);\n    var result = [];\n    this.batchesByDocumentKey.forEachInRange([start, end], function (ref) {\n      var batch = _this.findMutationBatch(ref.targetOrBatchId);\n\n      result.push(batch);\n    });\n    return PersistencePromise.resolve(result);\n  };\n\n  MemoryMutationQueue.prototype.getAllMutationBatchesAffectingDocumentKeys = function (transaction, documentKeys) {\n    var _this = this;\n\n    var uniqueBatchIDs = new SortedSet(primitiveComparator);\n    documentKeys.forEach(function (documentKey) {\n      var start = new DocReference(documentKey, 0);\n      var end = new DocReference(documentKey, Number.POSITIVE_INFINITY);\n\n      _this.batchesByDocumentKey.forEachInRange([start, end], function (ref) {\n        uniqueBatchIDs = uniqueBatchIDs.add(ref.targetOrBatchId);\n      });\n    });\n    return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));\n  };\n\n  MemoryMutationQueue.prototype.getAllMutationBatchesAffectingQuery = function (transaction, query) {\n    // Use the query path as a prefix for testing if a document matches the\n    // query.\n    var prefix = query.path;\n    var immediateChildrenPathLength = prefix.length + 1; // Construct a document reference for actually scanning the index. Unlike\n    // the prefix the document key in this reference must have an even number of\n    // segments. The empty segment can be used a suffix of the query path\n    // because it precedes all other segments in an ordered traversal.\n\n    var startPath = prefix;\n\n    if (!DocumentKey.isDocumentKey(startPath)) {\n      startPath = startPath.child('');\n    }\n\n    var start = new DocReference(new DocumentKey(startPath), 0); // Find unique batchIDs referenced by all documents potentially matching the\n    // query.\n\n    var uniqueBatchIDs = new SortedSet(primitiveComparator);\n    this.batchesByDocumentKey.forEachWhile(function (ref) {\n      var rowKeyPath = ref.key.path;\n\n      if (!prefix.isPrefixOf(rowKeyPath)) {\n        return false;\n      } else {\n        // Rows with document keys more than one segment longer than the query\n        // path can't be matches. For example, a query on 'rooms' can't match\n        // the document /rooms/abc/messages/xyx.\n        // TODO(mcg): we'll need a different scanner when we implement\n        // ancestor queries.\n        if (rowKeyPath.length === immediateChildrenPathLength) {\n          uniqueBatchIDs = uniqueBatchIDs.add(ref.targetOrBatchId);\n        }\n\n        return true;\n      }\n    }, start);\n    return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));\n  };\n\n  MemoryMutationQueue.prototype.findMutationBatches = function (batchIDs) {\n    var _this = this; // Construct an array of matching batches, sorted by batchID to ensure that\n    // multiple mutations affecting the same document key are applied in order.\n\n\n    var result = [];\n    batchIDs.forEach(function (batchId) {\n      var batch = _this.findMutationBatch(batchId);\n\n      if (batch !== null) {\n        result.push(batch);\n      }\n    });\n    return result;\n  };\n\n  MemoryMutationQueue.prototype.removeMutationBatch = function (transaction, batch) {\n    var _this = this; // Find the position of the first batch for removal.\n\n\n    var batchIndex = this.indexOfExistingBatchId(batch.batchId, 'removed');\n    hardAssert(batchIndex === 0);\n    this.mutationQueue.shift();\n    var references = this.batchesByDocumentKey;\n    return PersistencePromise.forEach(batch.mutations, function (mutation) {\n      var ref = new DocReference(mutation.key, batch.batchId);\n      references = references.delete(ref);\n      return _this.referenceDelegate.markPotentiallyOrphaned(transaction, mutation.key);\n    }).next(function () {\n      _this.batchesByDocumentKey = references;\n    });\n  };\n\n  MemoryMutationQueue.prototype.removeCachedMutationKeys = function (batchId) {// No-op since the memory mutation queue does not maintain a separate cache.\n  };\n\n  MemoryMutationQueue.prototype.containsKey = function (txn, key) {\n    var ref = new DocReference(key, 0);\n    var firstRef = this.batchesByDocumentKey.firstAfterOrEqual(ref);\n    return PersistencePromise.resolve(key.isEqual(firstRef && firstRef.key));\n  };\n\n  MemoryMutationQueue.prototype.performConsistencyCheck = function (txn) {\n    if (this.mutationQueue.length === 0) ;\n    return PersistencePromise.resolve();\n  };\n  /**\r\n   * Finds the index of the given batchId in the mutation queue and asserts that\r\n   * the resulting index is within the bounds of the queue.\r\n   *\r\n   * @param batchId - The batchId to search for\r\n   * @param action - A description of what the caller is doing, phrased in passive\r\n   * form (e.g. \"acknowledged\" in a routine that acknowledges batches).\r\n   */\n\n\n  MemoryMutationQueue.prototype.indexOfExistingBatchId = function (batchId, action) {\n    var index = this.indexOfBatchId(batchId);\n    return index;\n  };\n  /**\r\n   * Finds the index of the given batchId in the mutation queue. This operation\r\n   * is O(1).\r\n   *\r\n   * @returns The computed index of the batch with the given batchId, based on\r\n   * the state of the queue. Note this index can be negative if the requested\r\n   * batchId has already been remvoed from the queue or past the end of the\r\n   * queue if the batchId is larger than the last added batch.\r\n   */\n\n\n  MemoryMutationQueue.prototype.indexOfBatchId = function (batchId) {\n    if (this.mutationQueue.length === 0) {\n      // As an index this is past the end of the queue\n      return 0;\n    } // Examine the front of the queue to figure out the difference between the\n    // batchId and indexes in the array. Note that since the queue is ordered\n    // by batchId, if the first batch has a larger batchId then the requested\n    // batchId doesn't exist in the queue.\n\n\n    var firstBatchId = this.mutationQueue[0].batchId;\n    return batchId - firstBatchId;\n  };\n  /**\r\n   * A version of lookupMutationBatch that doesn't return a promise, this makes\r\n   * other functions that uses this code easier to read and more efficent.\r\n   */\n\n\n  MemoryMutationQueue.prototype.findMutationBatch = function (batchId) {\n    var index = this.indexOfBatchId(batchId);\n\n    if (index < 0 || index >= this.mutationQueue.length) {\n      return null;\n    }\n\n    var batch = this.mutationQueue[index];\n    return batch;\n  };\n\n  return MemoryMutationQueue;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction documentEntryMap() {\n  return new SortedMap(DocumentKey.comparator);\n}\n/**\r\n * The memory-only RemoteDocumentCache for IndexedDb. To construct, invoke\r\n * `newMemoryRemoteDocumentCache()`.\r\n */\n\n\nvar MemoryRemoteDocumentCacheImpl =\n/** @class */\nfunction () {\n  /**\r\n   * @param sizer - Used to assess the size of a document. For eager GC, this is\r\n   * expected to just return 0 to avoid unnecessarily doing the work of\r\n   * calculating the size.\r\n   */\n  function MemoryRemoteDocumentCacheImpl(indexManager, sizer) {\n    this.indexManager = indexManager;\n    this.sizer = sizer;\n    /** Underlying cache of documents and their read times. */\n\n    this.docs = documentEntryMap();\n    /** Size of all cached documents. */\n\n    this.size = 0;\n  }\n  /**\r\n   * Adds the supplied entry to the cache and updates the cache size as appropriate.\r\n   *\r\n   * All calls of `addEntry`  are required to go through the RemoteDocumentChangeBuffer\r\n   * returned by `newChangeBuffer()`.\r\n   */\n\n\n  MemoryRemoteDocumentCacheImpl.prototype.addEntry = function (transaction, doc, readTime) {\n    var key = doc.key;\n    var entry = this.docs.get(key);\n    var previousSize = entry ? entry.size : 0;\n    var currentSize = this.sizer(doc);\n    this.docs = this.docs.insert(key, {\n      document: doc.clone(),\n      size: currentSize,\n      readTime: readTime\n    });\n    this.size += currentSize - previousSize;\n    return this.indexManager.addToCollectionParentIndex(transaction, key.path.popLast());\n  };\n  /**\r\n   * Removes the specified entry from the cache and updates the cache size as appropriate.\r\n   *\r\n   * All calls of `removeEntry` are required to go through the RemoteDocumentChangeBuffer\r\n   * returned by `newChangeBuffer()`.\r\n   */\n\n\n  MemoryRemoteDocumentCacheImpl.prototype.removeEntry = function (documentKey) {\n    var entry = this.docs.get(documentKey);\n\n    if (entry) {\n      this.docs = this.docs.remove(documentKey);\n      this.size -= entry.size;\n    }\n  };\n\n  MemoryRemoteDocumentCacheImpl.prototype.getEntry = function (transaction, documentKey) {\n    var entry = this.docs.get(documentKey);\n    return PersistencePromise.resolve(entry ? entry.document.clone() : MutableDocument.newInvalidDocument(documentKey));\n  };\n\n  MemoryRemoteDocumentCacheImpl.prototype.getEntries = function (transaction, documentKeys) {\n    var _this = this;\n\n    var results = mutableDocumentMap();\n    documentKeys.forEach(function (documentKey) {\n      var entry = _this.docs.get(documentKey);\n\n      results = results.insert(documentKey, entry ? entry.document.clone() : MutableDocument.newInvalidDocument(documentKey));\n    });\n    return PersistencePromise.resolve(results);\n  };\n\n  MemoryRemoteDocumentCacheImpl.prototype.getDocumentsMatchingQuery = function (transaction, query, sinceReadTime) {\n    var results = mutableDocumentMap(); // Documents are ordered by key, so we can use a prefix scan to narrow down\n    // the documents we need to match the query against.\n\n    var prefix = new DocumentKey(query.path.child(''));\n    var iterator = this.docs.getIteratorFrom(prefix);\n\n    while (iterator.hasNext()) {\n      var _d = iterator.getNext(),\n          key = _d.key,\n          _e = _d.value,\n          document_3 = _e.document,\n          readTime = _e.readTime;\n\n      if (!query.path.isPrefixOf(key.path)) {\n        break;\n      }\n\n      if (readTime.compareTo(sinceReadTime) <= 0) {\n        continue;\n      }\n\n      if (!queryMatches(query, document_3)) {\n        continue;\n      }\n\n      results = results.insert(document_3.key, document_3.clone());\n    }\n\n    return PersistencePromise.resolve(results);\n  };\n\n  MemoryRemoteDocumentCacheImpl.prototype.forEachDocumentKey = function (transaction, f) {\n    return PersistencePromise.forEach(this.docs, function (key) {\n      return f(key);\n    });\n  };\n\n  MemoryRemoteDocumentCacheImpl.prototype.newChangeBuffer = function (options) {\n    // `trackRemovals` is ignores since the MemoryRemoteDocumentCache keeps\n    // a separate changelog and does not need special handling for removals.\n    return new MemoryRemoteDocumentChangeBuffer(this);\n  };\n\n  MemoryRemoteDocumentCacheImpl.prototype.getSize = function (txn) {\n    return PersistencePromise.resolve(this.size);\n  };\n\n  return MemoryRemoteDocumentCacheImpl;\n}();\n/**\r\n * Creates a new memory-only RemoteDocumentCache.\r\n *\r\n * @param indexManager - A class that manages collection group indices.\r\n * @param sizer - Used to assess the size of a document. For eager GC, this is\r\n * expected to just return 0 to avoid unnecessarily doing the work of\r\n * calculating the size.\r\n */\n\n\nfunction newMemoryRemoteDocumentCache(indexManager, sizer) {\n  return new MemoryRemoteDocumentCacheImpl(indexManager, sizer);\n}\n/**\r\n * Handles the details of adding and updating documents in the MemoryRemoteDocumentCache.\r\n */\n\n\nvar MemoryRemoteDocumentChangeBuffer =\n/** @class */\nfunction (_super) {\n  tslib.__extends(MemoryRemoteDocumentChangeBuffer, _super);\n\n  function MemoryRemoteDocumentChangeBuffer(documentCache) {\n    var _this = _super.call(this) || this;\n\n    _this.documentCache = documentCache;\n    return _this;\n  }\n\n  MemoryRemoteDocumentChangeBuffer.prototype.applyChanges = function (transaction) {\n    var _this = this;\n\n    var promises = [];\n    this.changes.forEach(function (key, doc) {\n      if (doc.document.isValidDocument()) {\n        promises.push(_this.documentCache.addEntry(transaction, doc.document, _this.getReadTime(key)));\n      } else {\n        _this.documentCache.removeEntry(key);\n      }\n    });\n    return PersistencePromise.waitFor(promises);\n  };\n\n  MemoryRemoteDocumentChangeBuffer.prototype.getFromCache = function (transaction, documentKey) {\n    return this.documentCache.getEntry(transaction, documentKey);\n  };\n\n  MemoryRemoteDocumentChangeBuffer.prototype.getAllFromCache = function (transaction, documentKeys) {\n    return this.documentCache.getEntries(transaction, documentKeys);\n  };\n\n  return MemoryRemoteDocumentChangeBuffer;\n}(RemoteDocumentChangeBuffer);\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar MemoryTargetCache =\n/** @class */\nfunction () {\n  function MemoryTargetCache(persistence) {\n    this.persistence = persistence;\n    /**\r\n     * Maps a target to the data about that target\r\n     */\n\n    this.targets = new ObjectMap(function (t) {\n      return canonifyTarget(t);\n    }, targetEquals);\n    /** The last received snapshot version. */\n\n    this.lastRemoteSnapshotVersion = SnapshotVersion.min();\n    /** The highest numbered target ID encountered. */\n\n    this.highestTargetId = 0;\n    /** The highest sequence number encountered. */\n\n    this.highestSequenceNumber = 0;\n    /**\r\n     * A ordered bidirectional mapping between documents and the remote target\r\n     * IDs.\r\n     */\n\n    this.references = new ReferenceSet();\n    this.targetCount = 0;\n    this.targetIdGenerator = TargetIdGenerator.forTargetCache();\n  }\n\n  MemoryTargetCache.prototype.forEachTarget = function (txn, f) {\n    this.targets.forEach(function (_, targetData) {\n      return f(targetData);\n    });\n    return PersistencePromise.resolve();\n  };\n\n  MemoryTargetCache.prototype.getLastRemoteSnapshotVersion = function (transaction) {\n    return PersistencePromise.resolve(this.lastRemoteSnapshotVersion);\n  };\n\n  MemoryTargetCache.prototype.getHighestSequenceNumber = function (transaction) {\n    return PersistencePromise.resolve(this.highestSequenceNumber);\n  };\n\n  MemoryTargetCache.prototype.allocateTargetId = function (transaction) {\n    this.highestTargetId = this.targetIdGenerator.next();\n    return PersistencePromise.resolve(this.highestTargetId);\n  };\n\n  MemoryTargetCache.prototype.setTargetsMetadata = function (transaction, highestListenSequenceNumber, lastRemoteSnapshotVersion) {\n    if (lastRemoteSnapshotVersion) {\n      this.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion;\n    }\n\n    if (highestListenSequenceNumber > this.highestSequenceNumber) {\n      this.highestSequenceNumber = highestListenSequenceNumber;\n    }\n\n    return PersistencePromise.resolve();\n  };\n\n  MemoryTargetCache.prototype.saveTargetData = function (targetData) {\n    this.targets.set(targetData.target, targetData);\n    var targetId = targetData.targetId;\n\n    if (targetId > this.highestTargetId) {\n      this.targetIdGenerator = new TargetIdGenerator(targetId);\n      this.highestTargetId = targetId;\n    }\n\n    if (targetData.sequenceNumber > this.highestSequenceNumber) {\n      this.highestSequenceNumber = targetData.sequenceNumber;\n    }\n  };\n\n  MemoryTargetCache.prototype.addTargetData = function (transaction, targetData) {\n    this.saveTargetData(targetData);\n    this.targetCount += 1;\n    return PersistencePromise.resolve();\n  };\n\n  MemoryTargetCache.prototype.updateTargetData = function (transaction, targetData) {\n    this.saveTargetData(targetData);\n    return PersistencePromise.resolve();\n  };\n\n  MemoryTargetCache.prototype.removeTargetData = function (transaction, targetData) {\n    this.targets.delete(targetData.target);\n    this.references.removeReferencesForId(targetData.targetId);\n    this.targetCount -= 1;\n    return PersistencePromise.resolve();\n  };\n\n  MemoryTargetCache.prototype.removeTargets = function (transaction, upperBound, activeTargetIds) {\n    var _this = this;\n\n    var count = 0;\n    var removals = [];\n    this.targets.forEach(function (key, targetData) {\n      if (targetData.sequenceNumber <= upperBound && activeTargetIds.get(targetData.targetId) === null) {\n        _this.targets.delete(key);\n\n        removals.push(_this.removeMatchingKeysForTargetId(transaction, targetData.targetId));\n        count++;\n      }\n    });\n    return PersistencePromise.waitFor(removals).next(function () {\n      return count;\n    });\n  };\n\n  MemoryTargetCache.prototype.getTargetCount = function (transaction) {\n    return PersistencePromise.resolve(this.targetCount);\n  };\n\n  MemoryTargetCache.prototype.getTargetData = function (transaction, target) {\n    var targetData = this.targets.get(target) || null;\n    return PersistencePromise.resolve(targetData);\n  };\n\n  MemoryTargetCache.prototype.addMatchingKeys = function (txn, keys, targetId) {\n    this.references.addReferences(keys, targetId);\n    return PersistencePromise.resolve();\n  };\n\n  MemoryTargetCache.prototype.removeMatchingKeys = function (txn, keys, targetId) {\n    this.references.removeReferences(keys, targetId);\n    var referenceDelegate = this.persistence.referenceDelegate;\n    var promises = [];\n\n    if (referenceDelegate) {\n      keys.forEach(function (key) {\n        promises.push(referenceDelegate.markPotentiallyOrphaned(txn, key));\n      });\n    }\n\n    return PersistencePromise.waitFor(promises);\n  };\n\n  MemoryTargetCache.prototype.removeMatchingKeysForTargetId = function (txn, targetId) {\n    this.references.removeReferencesForId(targetId);\n    return PersistencePromise.resolve();\n  };\n\n  MemoryTargetCache.prototype.getMatchingKeysForTargetId = function (txn, targetId) {\n    var matchingKeys = this.references.referencesForId(targetId);\n    return PersistencePromise.resolve(matchingKeys);\n  };\n\n  MemoryTargetCache.prototype.containsKey = function (txn, key) {\n    return PersistencePromise.resolve(this.references.containsKey(key));\n  };\n\n  return MemoryTargetCache;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$b = 'MemoryPersistence';\n/**\r\n * A memory-backed instance of Persistence. Data is stored only in RAM and\r\n * not persisted across sessions.\r\n */\n\nvar MemoryPersistence =\n/** @class */\nfunction () {\n  /**\r\n   * The constructor accepts a factory for creating a reference delegate. This\r\n   * allows both the delegate and this instance to have strong references to\r\n   * each other without having nullable fields that would then need to be\r\n   * checked or asserted on every access.\r\n   */\n  function MemoryPersistence(referenceDelegateFactory, serializer) {\n    var _this = this;\n\n    this.mutationQueues = {};\n    this.listenSequence = new ListenSequence(0);\n    this._started = false;\n    this._started = true;\n    this.referenceDelegate = referenceDelegateFactory(this);\n    this.targetCache = new MemoryTargetCache(this);\n\n    var sizer = function (doc) {\n      return _this.referenceDelegate.documentSize(doc);\n    };\n\n    this.indexManager = new MemoryIndexManager();\n    this.remoteDocumentCache = newMemoryRemoteDocumentCache(this.indexManager, sizer);\n    this.serializer = new LocalSerializer(serializer);\n    this.bundleCache = new MemoryBundleCache(this.serializer);\n  }\n\n  MemoryPersistence.prototype.start = function () {\n    return Promise.resolve();\n  };\n\n  MemoryPersistence.prototype.shutdown = function () {\n    // No durable state to ensure is closed on shutdown.\n    this._started = false;\n    return Promise.resolve();\n  };\n\n  Object.defineProperty(MemoryPersistence.prototype, \"started\", {\n    get: function () {\n      return this._started;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  MemoryPersistence.prototype.setDatabaseDeletedListener = function () {// No op.\n  };\n\n  MemoryPersistence.prototype.setNetworkEnabled = function () {// No op.\n  };\n\n  MemoryPersistence.prototype.getIndexManager = function () {\n    return this.indexManager;\n  };\n\n  MemoryPersistence.prototype.getMutationQueue = function (user) {\n    var queue = this.mutationQueues[user.toKey()];\n\n    if (!queue) {\n      queue = new MemoryMutationQueue(this.indexManager, this.referenceDelegate);\n      this.mutationQueues[user.toKey()] = queue;\n    }\n\n    return queue;\n  };\n\n  MemoryPersistence.prototype.getTargetCache = function () {\n    return this.targetCache;\n  };\n\n  MemoryPersistence.prototype.getRemoteDocumentCache = function () {\n    return this.remoteDocumentCache;\n  };\n\n  MemoryPersistence.prototype.getBundleCache = function () {\n    return this.bundleCache;\n  };\n\n  MemoryPersistence.prototype.runTransaction = function (action, mode, transactionOperation) {\n    var _this = this;\n\n    logDebug(LOG_TAG$b, 'Starting transaction:', action);\n    var txn = new MemoryTransaction(this.listenSequence.next());\n    this.referenceDelegate.onTransactionStarted();\n    return transactionOperation(txn).next(function (result) {\n      return _this.referenceDelegate.onTransactionCommitted(txn).next(function () {\n        return result;\n      });\n    }).toPromise().then(function (result) {\n      txn.raiseOnCommittedEvent();\n      return result;\n    });\n  };\n\n  MemoryPersistence.prototype.mutationQueuesContainKey = function (transaction, key) {\n    return PersistencePromise.or(Object.values(this.mutationQueues).map(function (queue) {\n      return function () {\n        return queue.containsKey(transaction, key);\n      };\n    }));\n  };\n\n  return MemoryPersistence;\n}();\n/**\r\n * Memory persistence is not actually transactional, but future implementations\r\n * may have transaction-scoped state.\r\n */\n\n\nvar MemoryTransaction =\n/** @class */\nfunction (_super) {\n  tslib.__extends(MemoryTransaction, _super);\n\n  function MemoryTransaction(currentSequenceNumber) {\n    var _this = _super.call(this) || this;\n\n    _this.currentSequenceNumber = currentSequenceNumber;\n    return _this;\n  }\n\n  return MemoryTransaction;\n}(PersistenceTransaction);\n\nvar MemoryEagerDelegate =\n/** @class */\nfunction () {\n  function MemoryEagerDelegate(persistence) {\n    this.persistence = persistence;\n    /** Tracks all documents that are active in Query views. */\n\n    this.localViewReferences = new ReferenceSet();\n    /** The list of documents that are potentially GCed after each transaction. */\n\n    this._orphanedDocuments = null;\n  }\n\n  MemoryEagerDelegate.factory = function (persistence) {\n    return new MemoryEagerDelegate(persistence);\n  };\n\n  Object.defineProperty(MemoryEagerDelegate.prototype, \"orphanedDocuments\", {\n    get: function () {\n      if (!this._orphanedDocuments) {\n        throw fail();\n      } else {\n        return this._orphanedDocuments;\n      }\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  MemoryEagerDelegate.prototype.addReference = function (txn, targetId, key) {\n    this.localViewReferences.addReference(key, targetId);\n    this.orphanedDocuments.delete(key.toString());\n    return PersistencePromise.resolve();\n  };\n\n  MemoryEagerDelegate.prototype.removeReference = function (txn, targetId, key) {\n    this.localViewReferences.removeReference(key, targetId);\n    this.orphanedDocuments.add(key.toString());\n    return PersistencePromise.resolve();\n  };\n\n  MemoryEagerDelegate.prototype.markPotentiallyOrphaned = function (txn, key) {\n    this.orphanedDocuments.add(key.toString());\n    return PersistencePromise.resolve();\n  };\n\n  MemoryEagerDelegate.prototype.removeTarget = function (txn, targetData) {\n    var _this = this;\n\n    var orphaned = this.localViewReferences.removeReferencesForId(targetData.targetId);\n    orphaned.forEach(function (key) {\n      return _this.orphanedDocuments.add(key.toString());\n    });\n    var cache = this.persistence.getTargetCache();\n    return cache.getMatchingKeysForTargetId(txn, targetData.targetId).next(function (keys) {\n      keys.forEach(function (key) {\n        return _this.orphanedDocuments.add(key.toString());\n      });\n    }).next(function () {\n      return cache.removeTargetData(txn, targetData);\n    });\n  };\n\n  MemoryEagerDelegate.prototype.onTransactionStarted = function () {\n    this._orphanedDocuments = new Set();\n  };\n\n  MemoryEagerDelegate.prototype.onTransactionCommitted = function (txn) {\n    var _this = this; // Remove newly orphaned documents.\n\n\n    var cache = this.persistence.getRemoteDocumentCache();\n    var changeBuffer = cache.newChangeBuffer();\n    return PersistencePromise.forEach(this.orphanedDocuments, function (path) {\n      var key = DocumentKey.fromPath(path);\n      return _this.isReferenced(txn, key).next(function (isReferenced) {\n        if (!isReferenced) {\n          changeBuffer.removeEntry(key);\n        }\n      });\n    }).next(function () {\n      _this._orphanedDocuments = null;\n      return changeBuffer.apply(txn);\n    });\n  };\n\n  MemoryEagerDelegate.prototype.updateLimboDocument = function (txn, key) {\n    var _this = this;\n\n    return this.isReferenced(txn, key).next(function (isReferenced) {\n      if (isReferenced) {\n        _this.orphanedDocuments.delete(key.toString());\n      } else {\n        _this.orphanedDocuments.add(key.toString());\n      }\n    });\n  };\n\n  MemoryEagerDelegate.prototype.documentSize = function (doc) {\n    // For eager GC, we don't care about the document size, there are no size thresholds.\n    return 0;\n  };\n\n  MemoryEagerDelegate.prototype.isReferenced = function (txn, key) {\n    var _this = this;\n\n    return PersistencePromise.or([function () {\n      return PersistencePromise.resolve(_this.localViewReferences.containsKey(key));\n    }, function () {\n      return _this.persistence.getTargetCache().containsKey(txn, key);\n    }, function () {\n      return _this.persistence.mutationQueuesContainKey(txn, key);\n    }]);\n  };\n\n  return MemoryEagerDelegate;\n}();\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A query engine that takes advantage of the target document mapping in the\r\n * QueryCache. Query execution is optimized by only reading the documents that\r\n * previously matched a query plus any documents that were edited after the\r\n * query was last listened to.\r\n *\r\n * There are some cases when this optimization is not guaranteed to produce\r\n * the same results as full collection scans. In these cases, query\r\n * processing falls back to full scans. These cases are:\r\n *\r\n * - Limit queries where a document that matched the query previously no longer\r\n *   matches the query.\r\n *\r\n * - Limit queries where a document edit may cause the document to sort below\r\n *   another document that is in the local cache.\r\n *\r\n * - Queries that have never been CURRENT or free of limbo documents.\r\n */\n\n\nvar QueryEngine =\n/** @class */\nfunction () {\n  function QueryEngine() {}\n  /** Sets the document view to query against. */\n\n\n  QueryEngine.prototype.setLocalDocumentsView = function (localDocuments) {\n    this.localDocumentsView = localDocuments;\n  };\n  /** Returns all local documents matching the specified query. */\n\n\n  QueryEngine.prototype.getDocumentsMatchingQuery = function (transaction, query, lastLimboFreeSnapshotVersion, remoteKeys) {\n    var _this = this; // Queries that match all documents don't benefit from using\n    // key-based lookups. It is more efficient to scan all documents in a\n    // collection, rather than to perform individual lookups.\n\n\n    if (matchesAllDocuments(query)) {\n      return this.executeFullCollectionScan(transaction, query);\n    } // Queries that have never seen a snapshot without limbo free documents\n    // should also be run as a full collection scan.\n\n\n    if (lastLimboFreeSnapshotVersion.isEqual(SnapshotVersion.min())) {\n      return this.executeFullCollectionScan(transaction, query);\n    }\n\n    return this.localDocumentsView.getDocuments(transaction, remoteKeys).next(function (documents) {\n      var previousResults = _this.applyQuery(query, documents);\n\n      if ((hasLimitToFirst(query) || hasLimitToLast(query)) && _this.needsRefill(query.limitType, previousResults, remoteKeys, lastLimboFreeSnapshotVersion)) {\n        return _this.executeFullCollectionScan(transaction, query);\n      }\n\n      if (getLogLevel() <= logger.LogLevel.DEBUG) {\n        logDebug('QueryEngine', 'Re-using previous result from %s to execute query: %s', lastLimboFreeSnapshotVersion.toString(), stringifyQuery(query));\n      } // Retrieve all results for documents that were updated since the last\n      // limbo-document free remote snapshot.\n\n\n      return _this.localDocumentsView.getDocumentsMatchingQuery(transaction, query, lastLimboFreeSnapshotVersion).next(function (updatedResults) {\n        // We merge `previousResults` into `updateResults`, since\n        // `updateResults` is already a DocumentMap. If a document is\n        // contained in both lists, then its contents are the same.\n        previousResults.forEach(function (doc) {\n          updatedResults = updatedResults.insert(doc.key, doc);\n        });\n        return updatedResults;\n      });\n    });\n  };\n  /** Applies the query filter and sorting to the provided documents.  */\n\n\n  QueryEngine.prototype.applyQuery = function (query, documents) {\n    // Sort the documents and re-apply the query filter since previously\n    // matching documents do not necessarily still match the query.\n    var queryResults = new SortedSet(newQueryComparator(query));\n    documents.forEach(function (_, maybeDoc) {\n      if (queryMatches(query, maybeDoc)) {\n        queryResults = queryResults.add(maybeDoc);\n      }\n    });\n    return queryResults;\n  };\n  /**\r\n   * Determines if a limit query needs to be refilled from cache, making it\r\n   * ineligible for index-free execution.\r\n   *\r\n   * @param sortedPreviousResults - The documents that matched the query when it\r\n   * was last synchronized, sorted by the query's comparator.\r\n   * @param remoteKeys - The document keys that matched the query at the last\r\n   * snapshot.\r\n   * @param limboFreeSnapshotVersion - The version of the snapshot when the\r\n   * query was last synchronized.\r\n   */\n\n\n  QueryEngine.prototype.needsRefill = function (limitType, sortedPreviousResults, remoteKeys, limboFreeSnapshotVersion) {\n    // The query needs to be refilled if a previously matching document no\n    // longer matches.\n    if (remoteKeys.size !== sortedPreviousResults.size) {\n      return true;\n    } // Limit queries are not eligible for index-free query execution if there is\n    // a potential that an older document from cache now sorts before a document\n    // that was previously part of the limit. This, however, can only happen if\n    // the document at the edge of the limit goes out of limit.\n    // If a document that is not the limit boundary sorts differently,\n    // the boundary of the limit itself did not change and documents from cache\n    // will continue to be \"rejected\" by this boundary. Therefore, we can ignore\n    // any modifications that don't affect the last document.\n\n\n    var docAtLimitEdge = limitType === \"F\"\n    /* First */\n    ? sortedPreviousResults.last() : sortedPreviousResults.first();\n\n    if (!docAtLimitEdge) {\n      // We don't need to refill the query if there were already no documents.\n      return false;\n    }\n\n    return docAtLimitEdge.hasPendingWrites || docAtLimitEdge.version.compareTo(limboFreeSnapshotVersion) > 0;\n  };\n\n  QueryEngine.prototype.executeFullCollectionScan = function (transaction, query) {\n    if (getLogLevel() <= logger.LogLevel.DEBUG) {\n      logDebug('QueryEngine', 'Using full collection scan to execute query:', stringifyQuery(query));\n    }\n\n    return this.localDocumentsView.getDocumentsMatchingQuery(transaction, query, SnapshotVersion.min());\n  };\n\n  return QueryEngine;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Simple wrapper around a nullable UID. Mostly exists to make code more\r\n * readable.\r\n */\n\n\nvar User =\n/** @class */\nfunction () {\n  function User(uid) {\n    this.uid = uid;\n  }\n\n  User.prototype.isAuthenticated = function () {\n    return this.uid != null;\n  };\n  /**\r\n   * Returns a key representing this user, suitable for inclusion in a\r\n   * dictionary.\r\n   */\n\n\n  User.prototype.toKey = function () {\n    if (this.isAuthenticated()) {\n      return 'uid:' + this.uid;\n    } else {\n      return 'anonymous-user';\n    }\n  };\n\n  User.prototype.isEqual = function (otherUser) {\n    return otherUser.uid === this.uid;\n  };\n\n  return User;\n}();\n/** A user with a null UID. */\n\n\nUser.UNAUTHENTICATED = new User(null); // TODO(mikelehen): Look into getting a proper uid-equivalent for\n// non-FirebaseAuth providers.\n\nUser.GOOGLE_CREDENTIALS = new User('google-credentials-uid');\nUser.FIRST_PARTY = new User('first-party-uid');\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// The format of the LocalStorage key that stores the client state is:\n//     firestore_clients_<persistence_prefix>_<instance_key>\n\nvar CLIENT_STATE_KEY_PREFIX = 'firestore_clients';\n/** Assembles the key for a client state in WebStorage */\n\nfunction createWebStorageClientStateKey(persistenceKey, clientId) {\n  return CLIENT_STATE_KEY_PREFIX + \"_\" + persistenceKey + \"_\" + clientId;\n} // The format of the WebStorage key that stores the mutation state is:\n//     firestore_mutations_<persistence_prefix>_<batch_id>\n//     (for unauthenticated users)\n// or: firestore_mutations_<persistence_prefix>_<batch_id>_<user_uid>\n//\n// 'user_uid' is last to avoid needing to escape '_' characters that it might\n// contain.\n\n\nvar MUTATION_BATCH_KEY_PREFIX = 'firestore_mutations';\n/** Assembles the key for a mutation batch in WebStorage */\n\nfunction createWebStorageMutationBatchKey(persistenceKey, user, batchId) {\n  var mutationKey = MUTATION_BATCH_KEY_PREFIX + \"_\" + persistenceKey + \"_\" + batchId;\n\n  if (user.isAuthenticated()) {\n    mutationKey += \"_\" + user.uid;\n  }\n\n  return mutationKey;\n} // The format of the WebStorage key that stores a query target's metadata is:\n//     firestore_targets_<persistence_prefix>_<target_id>\n\n\nvar QUERY_TARGET_KEY_PREFIX = 'firestore_targets';\n/** Assembles the key for a query state in WebStorage */\n\nfunction createWebStorageQueryTargetMetadataKey(persistenceKey, targetId) {\n  return QUERY_TARGET_KEY_PREFIX + \"_\" + persistenceKey + \"_\" + targetId;\n} // The WebStorage prefix that stores the primary tab's online state. The\n// format of the key is:\n//     firestore_online_state_<persistence_prefix>\n\n\nvar ONLINE_STATE_KEY_PREFIX = 'firestore_online_state';\n/** Assembles the key for the online state of the primary tab. */\n\nfunction createWebStorageOnlineStateKey(persistenceKey) {\n  return ONLINE_STATE_KEY_PREFIX + \"_\" + persistenceKey;\n} // The WebStorage prefix that plays as a event to indicate the remote documents\n// might have changed due to some secondary tabs loading a bundle.\n// format of the key is:\n//     firestore_bundle_loaded_<persistenceKey>\n\n\nvar BUNDLE_LOADED_KEY_PREFIX = 'firestore_bundle_loaded';\n\nfunction createBundleLoadedKey(persistenceKey) {\n  return BUNDLE_LOADED_KEY_PREFIX + \"_\" + persistenceKey;\n} // The WebStorage key prefix for the key that stores the last sequence number allocated. The key\n// looks like 'firestore_sequence_number_<persistence_prefix>'.\n\n\nvar SEQUENCE_NUMBER_KEY_PREFIX = 'firestore_sequence_number';\n/** Assembles the key for the current sequence number. */\n\nfunction createWebStorageSequenceNumberKey(persistenceKey) {\n  return SEQUENCE_NUMBER_KEY_PREFIX + \"_\" + persistenceKey;\n}\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$a = 'SharedClientState';\n/**\r\n * Holds the state of a mutation batch, including its user ID, batch ID and\r\n * whether the batch is 'pending', 'acknowledged' or 'rejected'.\r\n */\n// Visible for testing\n\nvar MutationMetadata =\n/** @class */\nfunction () {\n  function MutationMetadata(user, batchId, state, error) {\n    this.user = user;\n    this.batchId = batchId;\n    this.state = state;\n    this.error = error;\n  }\n  /**\r\n   * Parses a MutationMetadata from its JSON representation in WebStorage.\r\n   * Logs a warning and returns null if the format of the data is not valid.\r\n   */\n\n\n  MutationMetadata.fromWebStorageEntry = function (user, batchId, value) {\n    var mutationBatch = JSON.parse(value);\n    var validData = typeof mutationBatch === 'object' && ['pending', 'acknowledged', 'rejected'].indexOf(mutationBatch.state) !== -1 && (mutationBatch.error === undefined || typeof mutationBatch.error === 'object');\n    var firestoreError = undefined;\n\n    if (validData && mutationBatch.error) {\n      validData = typeof mutationBatch.error.message === 'string' && typeof mutationBatch.error.code === 'string';\n\n      if (validData) {\n        firestoreError = new FirestoreError(mutationBatch.error.code, mutationBatch.error.message);\n      }\n    }\n\n    if (validData) {\n      return new MutationMetadata(user, batchId, mutationBatch.state, firestoreError);\n    } else {\n      logError(LOG_TAG$a, \"Failed to parse mutation state for ID '\" + batchId + \"': \" + value);\n      return null;\n    }\n  };\n\n  MutationMetadata.prototype.toWebStorageJSON = function () {\n    var batchMetadata = {\n      state: this.state,\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n\n    };\n\n    if (this.error) {\n      batchMetadata.error = {\n        code: this.error.code,\n        message: this.error.message\n      };\n    }\n\n    return JSON.stringify(batchMetadata);\n  };\n\n  return MutationMetadata;\n}();\n/**\r\n * Holds the state of a query target, including its target ID and whether the\r\n * target is 'not-current', 'current' or 'rejected'.\r\n */\n// Visible for testing\n\n\nvar QueryTargetMetadata =\n/** @class */\nfunction () {\n  function QueryTargetMetadata(targetId, state, error) {\n    this.targetId = targetId;\n    this.state = state;\n    this.error = error;\n  }\n  /**\r\n   * Parses a QueryTargetMetadata from its JSON representation in WebStorage.\r\n   * Logs a warning and returns null if the format of the data is not valid.\r\n   */\n\n\n  QueryTargetMetadata.fromWebStorageEntry = function (targetId, value) {\n    var targetState = JSON.parse(value);\n    var validData = typeof targetState === 'object' && ['not-current', 'current', 'rejected'].indexOf(targetState.state) !== -1 && (targetState.error === undefined || typeof targetState.error === 'object');\n    var firestoreError = undefined;\n\n    if (validData && targetState.error) {\n      validData = typeof targetState.error.message === 'string' && typeof targetState.error.code === 'string';\n\n      if (validData) {\n        firestoreError = new FirestoreError(targetState.error.code, targetState.error.message);\n      }\n    }\n\n    if (validData) {\n      return new QueryTargetMetadata(targetId, targetState.state, firestoreError);\n    } else {\n      logError(LOG_TAG$a, \"Failed to parse target state for ID '\" + targetId + \"': \" + value);\n      return null;\n    }\n  };\n\n  QueryTargetMetadata.prototype.toWebStorageJSON = function () {\n    var targetState = {\n      state: this.state,\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n\n    };\n\n    if (this.error) {\n      targetState.error = {\n        code: this.error.code,\n        message: this.error.message\n      };\n    }\n\n    return JSON.stringify(targetState);\n  };\n\n  return QueryTargetMetadata;\n}();\n/**\r\n * This class represents the immutable ClientState for a client read from\r\n * WebStorage, containing the list of active query targets.\r\n */\n\n\nvar RemoteClientState =\n/** @class */\nfunction () {\n  function RemoteClientState(clientId, activeTargetIds) {\n    this.clientId = clientId;\n    this.activeTargetIds = activeTargetIds;\n  }\n  /**\r\n   * Parses a RemoteClientState from the JSON representation in WebStorage.\r\n   * Logs a warning and returns null if the format of the data is not valid.\r\n   */\n\n\n  RemoteClientState.fromWebStorageEntry = function (clientId, value) {\n    var clientState = JSON.parse(value);\n    var validData = typeof clientState === 'object' && clientState.activeTargetIds instanceof Array;\n    var activeTargetIdsSet = targetIdSet();\n\n    for (var i = 0; validData && i < clientState.activeTargetIds.length; ++i) {\n      validData = isSafeInteger(clientState.activeTargetIds[i]);\n      activeTargetIdsSet = activeTargetIdsSet.add(clientState.activeTargetIds[i]);\n    }\n\n    if (validData) {\n      return new RemoteClientState(clientId, activeTargetIdsSet);\n    } else {\n      logError(LOG_TAG$a, \"Failed to parse client data for instance '\" + clientId + \"': \" + value);\n      return null;\n    }\n  };\n\n  return RemoteClientState;\n}();\n/**\r\n * This class represents the online state for all clients participating in\r\n * multi-tab. The online state is only written to by the primary client, and\r\n * used in secondary clients to update their query views.\r\n */\n\n\nvar SharedOnlineState =\n/** @class */\nfunction () {\n  function SharedOnlineState(clientId, onlineState) {\n    this.clientId = clientId;\n    this.onlineState = onlineState;\n  }\n  /**\r\n   * Parses a SharedOnlineState from its JSON representation in WebStorage.\r\n   * Logs a warning and returns null if the format of the data is not valid.\r\n   */\n\n\n  SharedOnlineState.fromWebStorageEntry = function (value) {\n    var onlineState = JSON.parse(value);\n    var validData = typeof onlineState === 'object' && ['Unknown', 'Online', 'Offline'].indexOf(onlineState.onlineState) !== -1 && typeof onlineState.clientId === 'string';\n\n    if (validData) {\n      return new SharedOnlineState(onlineState.clientId, onlineState.onlineState);\n    } else {\n      logError(LOG_TAG$a, \"Failed to parse online state: \" + value);\n      return null;\n    }\n  };\n\n  return SharedOnlineState;\n}();\n/**\r\n * Metadata state of the local client. Unlike `RemoteClientState`, this class is\r\n * mutable and keeps track of all pending mutations, which allows us to\r\n * update the range of pending mutation batch IDs as new mutations are added or\r\n * removed.\r\n *\r\n * The data in `LocalClientState` is not read from WebStorage and instead\r\n * updated via its instance methods. The updated state can be serialized via\r\n * `toWebStorageJSON()`.\r\n */\n// Visible for testing.\n\n\nvar LocalClientState =\n/** @class */\nfunction () {\n  function LocalClientState() {\n    this.activeTargetIds = targetIdSet();\n  }\n\n  LocalClientState.prototype.addQueryTarget = function (targetId) {\n    this.activeTargetIds = this.activeTargetIds.add(targetId);\n  };\n\n  LocalClientState.prototype.removeQueryTarget = function (targetId) {\n    this.activeTargetIds = this.activeTargetIds.delete(targetId);\n  };\n  /**\r\n   * Converts this entry into a JSON-encoded format we can use for WebStorage.\r\n   * Does not encode `clientId` as it is part of the key in WebStorage.\r\n   */\n\n\n  LocalClientState.prototype.toWebStorageJSON = function () {\n    var data = {\n      activeTargetIds: this.activeTargetIds.toArray(),\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n\n    };\n    return JSON.stringify(data);\n  };\n\n  return LocalClientState;\n}();\n/**\r\n * `WebStorageSharedClientState` uses WebStorage (window.localStorage) as the\r\n * backing store for the SharedClientState. It keeps track of all active\r\n * clients and supports modifications of the local client's data.\r\n */\n\n\nvar WebStorageSharedClientState =\n/** @class */\nfunction () {\n  function WebStorageSharedClientState(window, queue, persistenceKey, localClientId, initialUser) {\n    this.window = window;\n    this.queue = queue;\n    this.persistenceKey = persistenceKey;\n    this.localClientId = localClientId;\n    this.syncEngine = null;\n    this.onlineStateHandler = null;\n    this.sequenceNumberHandler = null;\n    this.storageListener = this.handleWebStorageEvent.bind(this);\n    this.activeClients = new SortedMap(primitiveComparator);\n    this.started = false;\n    /**\r\n     * Captures WebStorage events that occur before `start()` is called. These\r\n     * events are replayed once `WebStorageSharedClientState` is started.\r\n     */\n\n    this.earlyEvents = []; // Escape the special characters mentioned here:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions\n\n    var escapedPersistenceKey = persistenceKey.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n    this.storage = this.window.localStorage;\n    this.currentUser = initialUser;\n    this.localClientStorageKey = createWebStorageClientStateKey(this.persistenceKey, this.localClientId);\n    this.sequenceNumberKey = createWebStorageSequenceNumberKey(this.persistenceKey);\n    this.activeClients = this.activeClients.insert(this.localClientId, new LocalClientState());\n    this.clientStateKeyRe = new RegExp(\"^\" + CLIENT_STATE_KEY_PREFIX + \"_\" + escapedPersistenceKey + \"_([^_]*)$\");\n    this.mutationBatchKeyRe = new RegExp(\"^\" + MUTATION_BATCH_KEY_PREFIX + \"_\" + escapedPersistenceKey + \"_(\\\\d+)(?:_(.*))?$\");\n    this.queryTargetKeyRe = new RegExp(\"^\" + QUERY_TARGET_KEY_PREFIX + \"_\" + escapedPersistenceKey + \"_(\\\\d+)$\");\n    this.onlineStateKey = createWebStorageOnlineStateKey(this.persistenceKey);\n    this.bundleLoadedKey = createBundleLoadedKey(this.persistenceKey); // Rather than adding the storage observer during start(), we add the\n    // storage observer during initialization. This ensures that we collect\n    // events before other components populate their initial state (during their\n    // respective start() calls). Otherwise, we might for example miss a\n    // mutation that is added after LocalStore's start() processed the existing\n    // mutations but before we observe WebStorage events.\n\n    this.window.addEventListener('storage', this.storageListener);\n  }\n  /** Returns 'true' if WebStorage is available in the current environment. */\n\n\n  WebStorageSharedClientState.isAvailable = function (window) {\n    return !!(window && window.localStorage);\n  };\n\n  WebStorageSharedClientState.prototype.start = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var existingClients, _i, existingClients_1, clientId, storageItem, clientState, onlineStateJSON, onlineState, _d, _e, event_1;\n\n      var _this = this;\n\n      return tslib.__generator(this, function (_f) {\n        switch (_f.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , this.syncEngine.getActiveClients()];\n\n          case 1:\n            existingClients = _f.sent();\n\n            for (_i = 0, existingClients_1 = existingClients; _i < existingClients_1.length; _i++) {\n              clientId = existingClients_1[_i];\n\n              if (clientId === this.localClientId) {\n                continue;\n              }\n\n              storageItem = this.getItem(createWebStorageClientStateKey(this.persistenceKey, clientId));\n\n              if (storageItem) {\n                clientState = RemoteClientState.fromWebStorageEntry(clientId, storageItem);\n\n                if (clientState) {\n                  this.activeClients = this.activeClients.insert(clientState.clientId, clientState);\n                }\n              }\n            }\n\n            this.persistClientState();\n            onlineStateJSON = this.storage.getItem(this.onlineStateKey);\n\n            if (onlineStateJSON) {\n              onlineState = this.fromWebStorageOnlineState(onlineStateJSON);\n\n              if (onlineState) {\n                this.handleOnlineStateEvent(onlineState);\n              }\n            }\n\n            for (_d = 0, _e = this.earlyEvents; _d < _e.length; _d++) {\n              event_1 = _e[_d];\n              this.handleWebStorageEvent(event_1);\n            }\n\n            this.earlyEvents = []; // Register a window unload hook to remove the client metadata entry from\n            // WebStorage even if `shutdown()` was not called.\n\n            this.window.addEventListener('pagehide', function () {\n              return _this.shutdown();\n            });\n            this.started = true;\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  WebStorageSharedClientState.prototype.writeSequenceNumber = function (sequenceNumber) {\n    this.setItem(this.sequenceNumberKey, JSON.stringify(sequenceNumber));\n  };\n\n  WebStorageSharedClientState.prototype.getAllActiveQueryTargets = function () {\n    return this.extractActiveQueryTargets(this.activeClients);\n  };\n\n  WebStorageSharedClientState.prototype.isActiveQueryTarget = function (targetId) {\n    var found = false;\n    this.activeClients.forEach(function (key, value) {\n      if (value.activeTargetIds.has(targetId)) {\n        found = true;\n      }\n    });\n    return found;\n  };\n\n  WebStorageSharedClientState.prototype.addPendingMutation = function (batchId) {\n    this.persistMutationState(batchId, 'pending');\n  };\n\n  WebStorageSharedClientState.prototype.updateMutationState = function (batchId, state, error) {\n    this.persistMutationState(batchId, state, error); // Once a final mutation result is observed by other clients, they no longer\n    // access the mutation's metadata entry. Since WebStorage replays events\n    // in order, it is safe to delete the entry right after updating it.\n\n    this.removeMutationState(batchId);\n  };\n\n  WebStorageSharedClientState.prototype.addLocalQueryTarget = function (targetId) {\n    var queryState = 'not-current'; // Lookup an existing query state if the target ID was already registered\n    // by another tab\n\n    if (this.isActiveQueryTarget(targetId)) {\n      var storageItem = this.storage.getItem(createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId));\n\n      if (storageItem) {\n        var metadata = QueryTargetMetadata.fromWebStorageEntry(targetId, storageItem);\n\n        if (metadata) {\n          queryState = metadata.state;\n        }\n      }\n    }\n\n    this.localClientState.addQueryTarget(targetId);\n    this.persistClientState();\n    return queryState;\n  };\n\n  WebStorageSharedClientState.prototype.removeLocalQueryTarget = function (targetId) {\n    this.localClientState.removeQueryTarget(targetId);\n    this.persistClientState();\n  };\n\n  WebStorageSharedClientState.prototype.isLocalQueryTarget = function (targetId) {\n    return this.localClientState.activeTargetIds.has(targetId);\n  };\n\n  WebStorageSharedClientState.prototype.clearQueryState = function (targetId) {\n    this.removeItem(createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId));\n  };\n\n  WebStorageSharedClientState.prototype.updateQueryState = function (targetId, state, error) {\n    this.persistQueryTargetState(targetId, state, error);\n  };\n\n  WebStorageSharedClientState.prototype.handleUserChange = function (user, removedBatchIds, addedBatchIds) {\n    var _this = this;\n\n    removedBatchIds.forEach(function (batchId) {\n      _this.removeMutationState(batchId);\n    });\n    this.currentUser = user;\n    addedBatchIds.forEach(function (batchId) {\n      _this.addPendingMutation(batchId);\n    });\n  };\n\n  WebStorageSharedClientState.prototype.setOnlineState = function (onlineState) {\n    this.persistOnlineState(onlineState);\n  };\n\n  WebStorageSharedClientState.prototype.notifyBundleLoaded = function () {\n    this.persistBundleLoadedState();\n  };\n\n  WebStorageSharedClientState.prototype.shutdown = function () {\n    if (this.started) {\n      this.window.removeEventListener('storage', this.storageListener);\n      this.removeItem(this.localClientStorageKey);\n      this.started = false;\n    }\n  };\n\n  WebStorageSharedClientState.prototype.getItem = function (key) {\n    var value = this.storage.getItem(key);\n    logDebug(LOG_TAG$a, 'READ', key, value);\n    return value;\n  };\n\n  WebStorageSharedClientState.prototype.setItem = function (key, value) {\n    logDebug(LOG_TAG$a, 'SET', key, value);\n    this.storage.setItem(key, value);\n  };\n\n  WebStorageSharedClientState.prototype.removeItem = function (key) {\n    logDebug(LOG_TAG$a, 'REMOVE', key);\n    this.storage.removeItem(key);\n  };\n\n  WebStorageSharedClientState.prototype.handleWebStorageEvent = function (event) {\n    var _this = this; // Note: The function is typed to take Event to be interface-compatible with\n    // `Window.addEventListener`.\n\n\n    var storageEvent = event;\n\n    if (storageEvent.storageArea === this.storage) {\n      logDebug(LOG_TAG$a, 'EVENT', storageEvent.key, storageEvent.newValue);\n\n      if (storageEvent.key === this.localClientStorageKey) {\n        logError('Received WebStorage notification for local change. Another client might have ' + 'garbage-collected our state');\n        return;\n      }\n\n      this.queue.enqueueRetryable(function () {\n        return tslib.__awaiter(_this, void 0, void 0, function () {\n          var clientState, clientId, mutationMetadata, queryTargetMetadata, onlineState, sequenceNumber;\n          return tslib.__generator(this, function (_d) {\n            if (!this.started) {\n              this.earlyEvents.push(storageEvent);\n              return [2\n              /*return*/\n              ];\n            }\n\n            if (storageEvent.key === null) {\n              return [2\n              /*return*/\n              ];\n            }\n\n            if (this.clientStateKeyRe.test(storageEvent.key)) {\n              if (storageEvent.newValue != null) {\n                clientState = this.fromWebStorageClientState(storageEvent.key, storageEvent.newValue);\n\n                if (clientState) {\n                  return [2\n                  /*return*/\n                  , this.handleClientStateEvent(clientState.clientId, clientState)];\n                }\n              } else {\n                clientId = this.fromWebStorageClientStateKey(storageEvent.key);\n                return [2\n                /*return*/\n                , this.handleClientStateEvent(clientId, null)];\n              }\n            } else if (this.mutationBatchKeyRe.test(storageEvent.key)) {\n              if (storageEvent.newValue !== null) {\n                mutationMetadata = this.fromWebStorageMutationMetadata(storageEvent.key, storageEvent.newValue);\n\n                if (mutationMetadata) {\n                  return [2\n                  /*return*/\n                  , this.handleMutationBatchEvent(mutationMetadata)];\n                }\n              }\n            } else if (this.queryTargetKeyRe.test(storageEvent.key)) {\n              if (storageEvent.newValue !== null) {\n                queryTargetMetadata = this.fromWebStorageQueryTargetMetadata(storageEvent.key, storageEvent.newValue);\n\n                if (queryTargetMetadata) {\n                  return [2\n                  /*return*/\n                  , this.handleQueryTargetEvent(queryTargetMetadata)];\n                }\n              }\n            } else if (storageEvent.key === this.onlineStateKey) {\n              if (storageEvent.newValue !== null) {\n                onlineState = this.fromWebStorageOnlineState(storageEvent.newValue);\n\n                if (onlineState) {\n                  return [2\n                  /*return*/\n                  , this.handleOnlineStateEvent(onlineState)];\n                }\n              }\n            } else if (storageEvent.key === this.sequenceNumberKey) {\n              sequenceNumber = fromWebStorageSequenceNumber(storageEvent.newValue);\n\n              if (sequenceNumber !== ListenSequence.INVALID) {\n                this.sequenceNumberHandler(sequenceNumber);\n              }\n            } else if (storageEvent.key === this.bundleLoadedKey) {\n              return [2\n              /*return*/\n              , this.syncEngine.synchronizeWithChangedDocuments()];\n            }\n\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      });\n    }\n  };\n\n  Object.defineProperty(WebStorageSharedClientState.prototype, \"localClientState\", {\n    get: function () {\n      return this.activeClients.get(this.localClientId);\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  WebStorageSharedClientState.prototype.persistClientState = function () {\n    this.setItem(this.localClientStorageKey, this.localClientState.toWebStorageJSON());\n  };\n\n  WebStorageSharedClientState.prototype.persistMutationState = function (batchId, state, error) {\n    var mutationState = new MutationMetadata(this.currentUser, batchId, state, error);\n    var mutationKey = createWebStorageMutationBatchKey(this.persistenceKey, this.currentUser, batchId);\n    this.setItem(mutationKey, mutationState.toWebStorageJSON());\n  };\n\n  WebStorageSharedClientState.prototype.removeMutationState = function (batchId) {\n    var mutationKey = createWebStorageMutationBatchKey(this.persistenceKey, this.currentUser, batchId);\n    this.removeItem(mutationKey);\n  };\n\n  WebStorageSharedClientState.prototype.persistOnlineState = function (onlineState) {\n    var entry = {\n      clientId: this.localClientId,\n      onlineState: onlineState\n    };\n    this.storage.setItem(this.onlineStateKey, JSON.stringify(entry));\n  };\n\n  WebStorageSharedClientState.prototype.persistQueryTargetState = function (targetId, state, error) {\n    var targetKey = createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId);\n    var targetMetadata = new QueryTargetMetadata(targetId, state, error);\n    this.setItem(targetKey, targetMetadata.toWebStorageJSON());\n  };\n\n  WebStorageSharedClientState.prototype.persistBundleLoadedState = function () {\n    this.setItem(this.bundleLoadedKey, 'value-not-used');\n  };\n  /**\r\n   * Parses a client state key in WebStorage. Returns null if the key does not\r\n   * match the expected key format.\r\n   */\n\n\n  WebStorageSharedClientState.prototype.fromWebStorageClientStateKey = function (key) {\n    var match = this.clientStateKeyRe.exec(key);\n    return match ? match[1] : null;\n  };\n  /**\r\n   * Parses a client state in WebStorage. Returns 'null' if the value could not\r\n   * be parsed.\r\n   */\n\n\n  WebStorageSharedClientState.prototype.fromWebStorageClientState = function (key, value) {\n    var clientId = this.fromWebStorageClientStateKey(key);\n    return RemoteClientState.fromWebStorageEntry(clientId, value);\n  };\n  /**\r\n   * Parses a mutation batch state in WebStorage. Returns 'null' if the value\r\n   * could not be parsed.\r\n   */\n\n\n  WebStorageSharedClientState.prototype.fromWebStorageMutationMetadata = function (key, value) {\n    var match = this.mutationBatchKeyRe.exec(key);\n    var batchId = Number(match[1]);\n    var userId = match[2] !== undefined ? match[2] : null;\n    return MutationMetadata.fromWebStorageEntry(new User(userId), batchId, value);\n  };\n  /**\r\n   * Parses a query target state from WebStorage. Returns 'null' if the value\r\n   * could not be parsed.\r\n   */\n\n\n  WebStorageSharedClientState.prototype.fromWebStorageQueryTargetMetadata = function (key, value) {\n    var match = this.queryTargetKeyRe.exec(key);\n    var targetId = Number(match[1]);\n    return QueryTargetMetadata.fromWebStorageEntry(targetId, value);\n  };\n  /**\r\n   * Parses an online state from WebStorage. Returns 'null' if the value\r\n   * could not be parsed.\r\n   */\n\n\n  WebStorageSharedClientState.prototype.fromWebStorageOnlineState = function (value) {\n    return SharedOnlineState.fromWebStorageEntry(value);\n  };\n\n  WebStorageSharedClientState.prototype.handleMutationBatchEvent = function (mutationBatch) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        if (mutationBatch.user.uid !== this.currentUser.uid) {\n          logDebug(LOG_TAG$a, \"Ignoring mutation for non-active user \" + mutationBatch.user.uid);\n          return [2\n          /*return*/\n          ];\n        }\n\n        return [2\n        /*return*/\n        , this.syncEngine.applyBatchState(mutationBatch.batchId, mutationBatch.state, mutationBatch.error)];\n      });\n    });\n  };\n\n  WebStorageSharedClientState.prototype.handleQueryTargetEvent = function (targetMetadata) {\n    return this.syncEngine.applyTargetState(targetMetadata.targetId, targetMetadata.state, targetMetadata.error);\n  };\n\n  WebStorageSharedClientState.prototype.handleClientStateEvent = function (clientId, clientState) {\n    var _this = this;\n\n    var updatedClients = clientState ? this.activeClients.insert(clientId, clientState) : this.activeClients.remove(clientId);\n    var existingTargets = this.extractActiveQueryTargets(this.activeClients);\n    var newTargets = this.extractActiveQueryTargets(updatedClients);\n    var addedTargets = [];\n    var removedTargets = [];\n    newTargets.forEach(function (targetId) {\n      if (!existingTargets.has(targetId)) {\n        addedTargets.push(targetId);\n      }\n    });\n    existingTargets.forEach(function (targetId) {\n      if (!newTargets.has(targetId)) {\n        removedTargets.push(targetId);\n      }\n    });\n    return this.syncEngine.applyActiveTargetsChange(addedTargets, removedTargets).then(function () {\n      _this.activeClients = updatedClients;\n    });\n  };\n\n  WebStorageSharedClientState.prototype.handleOnlineStateEvent = function (onlineState) {\n    // We check whether the client that wrote this online state is still active\n    // by comparing its client ID to the list of clients kept active in\n    // IndexedDb. If a client does not update their IndexedDb client state\n    // within 5 seconds, it is considered inactive and we don't emit an online\n    // state event.\n    if (this.activeClients.get(onlineState.clientId)) {\n      this.onlineStateHandler(onlineState.onlineState);\n    }\n  };\n\n  WebStorageSharedClientState.prototype.extractActiveQueryTargets = function (clients) {\n    var activeTargets = targetIdSet();\n    clients.forEach(function (kev, value) {\n      activeTargets = activeTargets.unionWith(value.activeTargetIds);\n    });\n    return activeTargets;\n  };\n\n  return WebStorageSharedClientState;\n}();\n\nfunction fromWebStorageSequenceNumber(seqString) {\n  var sequenceNumber = ListenSequence.INVALID;\n\n  if (seqString != null) {\n    try {\n      var parsed = JSON.parse(seqString);\n      hardAssert(typeof parsed === 'number');\n      sequenceNumber = parsed;\n    } catch (e) {\n      logError(LOG_TAG$a, 'Failed to read sequence number from WebStorage', e);\n    }\n  }\n\n  return sequenceNumber;\n}\n/**\r\n * `MemorySharedClientState` is a simple implementation of SharedClientState for\r\n * clients using memory persistence. The state in this class remains fully\r\n * isolated and no synchronization is performed.\r\n */\n\n\nvar MemorySharedClientState =\n/** @class */\nfunction () {\n  function MemorySharedClientState() {\n    this.localState = new LocalClientState();\n    this.queryState = {};\n    this.onlineStateHandler = null;\n    this.sequenceNumberHandler = null;\n  }\n\n  MemorySharedClientState.prototype.addPendingMutation = function (batchId) {// No op.\n  };\n\n  MemorySharedClientState.prototype.updateMutationState = function (batchId, state, error) {// No op.\n  };\n\n  MemorySharedClientState.prototype.addLocalQueryTarget = function (targetId) {\n    this.localState.addQueryTarget(targetId);\n    return this.queryState[targetId] || 'not-current';\n  };\n\n  MemorySharedClientState.prototype.updateQueryState = function (targetId, state, error) {\n    this.queryState[targetId] = state;\n  };\n\n  MemorySharedClientState.prototype.removeLocalQueryTarget = function (targetId) {\n    this.localState.removeQueryTarget(targetId);\n  };\n\n  MemorySharedClientState.prototype.isLocalQueryTarget = function (targetId) {\n    return this.localState.activeTargetIds.has(targetId);\n  };\n\n  MemorySharedClientState.prototype.clearQueryState = function (targetId) {\n    delete this.queryState[targetId];\n  };\n\n  MemorySharedClientState.prototype.getAllActiveQueryTargets = function () {\n    return this.localState.activeTargetIds;\n  };\n\n  MemorySharedClientState.prototype.isActiveQueryTarget = function (targetId) {\n    return this.localState.activeTargetIds.has(targetId);\n  };\n\n  MemorySharedClientState.prototype.start = function () {\n    this.localState = new LocalClientState();\n    return Promise.resolve();\n  };\n\n  MemorySharedClientState.prototype.handleUserChange = function (user, removedBatchIds, addedBatchIds) {// No op.\n  };\n\n  MemorySharedClientState.prototype.setOnlineState = function (onlineState) {// No op.\n  };\n\n  MemorySharedClientState.prototype.shutdown = function () {};\n\n  MemorySharedClientState.prototype.writeSequenceNumber = function (sequenceNumber) {};\n\n  MemorySharedClientState.prototype.notifyBundleLoaded = function () {// No op.\n  };\n\n  return MemorySharedClientState;\n}();\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar NoopConnectivityMonitor =\n/** @class */\nfunction () {\n  function NoopConnectivityMonitor() {}\n\n  NoopConnectivityMonitor.prototype.addCallback = function (callback) {// No-op.\n  };\n\n  NoopConnectivityMonitor.prototype.shutdown = function () {// No-op.\n  };\n\n  return NoopConnectivityMonitor;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Provides a simple helper class that implements the Stream interface to\r\n * bridge to other implementations that are streams but do not implement the\r\n * interface. The stream callbacks are invoked with the callOn... methods.\r\n */\n\n\nvar StreamBridge =\n/** @class */\nfunction () {\n  function StreamBridge(args) {\n    this.sendFn = args.sendFn;\n    this.closeFn = args.closeFn;\n  }\n\n  StreamBridge.prototype.onOpen = function (callback) {\n    this.wrappedOnOpen = callback;\n  };\n\n  StreamBridge.prototype.onClose = function (callback) {\n    this.wrappedOnClose = callback;\n  };\n\n  StreamBridge.prototype.onMessage = function (callback) {\n    this.wrappedOnMessage = callback;\n  };\n\n  StreamBridge.prototype.close = function () {\n    this.closeFn();\n  };\n\n  StreamBridge.prototype.send = function (msg) {\n    this.sendFn(msg);\n  };\n\n  StreamBridge.prototype.callOnOpen = function () {\n    this.wrappedOnOpen();\n  };\n\n  StreamBridge.prototype.callOnClose = function (err) {\n    this.wrappedOnClose(err);\n  };\n\n  StreamBridge.prototype.callOnMessage = function (msg) {\n    this.wrappedOnMessage(msg);\n  };\n\n  return StreamBridge;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/*\r\n * Utilities for dealing with node.js-style APIs. See nodePromise for more\r\n * details.\r\n */\n\n/**\r\n * Creates a node-style callback that resolves or rejects a new Promise. The\r\n * callback is passed to the given action which can then use the callback as\r\n * a parameter to a node-style function.\r\n *\r\n * The intent is to directly bridge a node-style function (which takes a\r\n * callback) into a Promise without manually converting between the node-style\r\n * callback and the promise at each call.\r\n *\r\n * In effect it allows you to convert:\r\n *\r\n * @example\r\n * new Promise((resolve: (value?: fs.Stats) => void,\r\n *              reject: (error?: any) => void) => {\r\n *   fs.stat(path, (error?: any, stat?: fs.Stats) => {\r\n *     if (error) {\r\n *       reject(error);\r\n *     } else {\r\n *       resolve(stat);\r\n *     }\r\n *   });\r\n * });\r\n *\r\n * Into\r\n * @example\r\n * nodePromise((callback: NodeCallback<fs.Stats>) => {\r\n *   fs.stat(path, callback);\r\n * });\r\n *\r\n * @param action - a function that takes a node-style callback as an argument\r\n *     and then uses that callback to invoke some node-style API.\r\n * @returns a new Promise which will be rejected if the callback is given the\r\n *     first Error parameter or will resolve to the value given otherwise.\r\n */\n\n\nfunction nodePromise(action) {\n  return new Promise(function (resolve, reject) {\n    action(function (error, value) {\n      if (error) {\n        reject(error);\n      } else {\n        resolve(value);\n      }\n    });\n  });\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$9 = 'Connection';\nvar X_GOOG_API_CLIENT_VALUE = \"gl-node/\" + process.versions.node + \" fire/\" + SDK_VERSION + \" grpc/\" + package_json.version;\n\nfunction createMetadata(databasePath, token, appId) {\n  hardAssert(token === null || token.type === 'OAuth');\n  var metadata = new grpcJs.Metadata();\n\n  if (token) {\n    for (var header in token.authHeaders) {\n      if (token.authHeaders.hasOwnProperty(header)) {\n        metadata.set(header, token.authHeaders[header]);\n      }\n    }\n  }\n\n  if (appId) {\n    metadata.set('X-Firebase-GMPID', appId);\n  }\n\n  metadata.set('X-Goog-Api-Client', X_GOOG_API_CLIENT_VALUE); // This header is used to improve routing and project isolation by the\n  // backend.\n\n  metadata.set('Google-Cloud-Resource-Prefix', databasePath);\n  return metadata;\n}\n/**\r\n * A Connection implemented by GRPC-Node.\r\n */\n\n\nvar GrpcConnection =\n/** @class */\nfunction () {\n  function GrpcConnection(protos, databaseInfo) {\n    this.databaseInfo = databaseInfo; // We cache stubs for the most-recently-used token.\n\n    this.cachedStub = null; // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n    this.firestore = protos['google']['firestore']['v1'];\n    this.databasePath = \"projects/\" + databaseInfo.databaseId.projectId + \"/databases/\" + databaseInfo.databaseId.database;\n  }\n\n  GrpcConnection.prototype.ensureActiveStub = function () {\n    if (!this.cachedStub) {\n      logDebug(LOG_TAG$9, 'Creating Firestore stub.');\n      var credentials$1 = this.databaseInfo.ssl ? grpcJs.credentials.createSsl() : grpcJs.credentials.createInsecure();\n      this.cachedStub = new this.firestore.Firestore(this.databaseInfo.host, credentials$1);\n    }\n\n    return this.cachedStub;\n  };\n\n  GrpcConnection.prototype.invokeRPC = function (rpcName, path, request, token) {\n    var stub = this.ensureActiveStub();\n    var metadata = createMetadata(this.databasePath, token, this.databaseInfo.appId);\n    var jsonRequest = Object.assign({\n      database: this.databasePath\n    }, request);\n    return nodePromise(function (callback) {\n      logDebug(LOG_TAG$9, \"RPC '\" + rpcName + \"' invoked with request:\", request);\n      return stub[rpcName](jsonRequest, metadata, function (grpcError, value) {\n        if (grpcError) {\n          logDebug(LOG_TAG$9, \"RPC '\" + rpcName + \"' failed with error:\", grpcError);\n          callback(new FirestoreError(mapCodeFromRpcCode(grpcError.code), grpcError.message));\n        } else {\n          logDebug(LOG_TAG$9, \"RPC '\" + rpcName + \"' completed with response:\", value);\n          callback(undefined, value);\n        }\n      });\n    });\n  };\n\n  GrpcConnection.prototype.invokeStreamingRPC = function (rpcName, path, request, token) {\n    var results = [];\n    var responseDeferred = new Deferred();\n    logDebug(LOG_TAG$9, \"RPC '\" + rpcName + \"' invoked (streaming) with request:\", request);\n    var stub = this.ensureActiveStub();\n    var metadata = createMetadata(this.databasePath, token, this.databaseInfo.appId);\n    var jsonRequest = Object.assign(Object.assign({}, request), {\n      database: this.databasePath\n    });\n    var stream = stub[rpcName](jsonRequest, metadata);\n    stream.on('data', function (response) {\n      logDebug(LOG_TAG$9, \"RPC \" + rpcName + \" received result:\", response);\n      results.push(response);\n    });\n    stream.on('end', function () {\n      logDebug(LOG_TAG$9, \"RPC '\" + rpcName + \"' completed.\");\n      responseDeferred.resolve(results);\n    });\n    stream.on('error', function (grpcError) {\n      logDebug(LOG_TAG$9, \"RPC '\" + rpcName + \"' failed with error:\", grpcError);\n      var code = mapCodeFromRpcCode(grpcError.code);\n      responseDeferred.reject(new FirestoreError(code, grpcError.message));\n    });\n    return responseDeferred.promise;\n  }; // TODO(mikelehen): This \"method\" is a monster. Should be refactored.\n\n\n  GrpcConnection.prototype.openStream = function (rpcName, token) {\n    var stub = this.ensureActiveStub();\n    var metadata = createMetadata(this.databasePath, token, this.databaseInfo.appId);\n    var grpcStream = stub[rpcName](metadata);\n    var closed = false;\n\n    var close = function (err) {\n      if (!closed) {\n        closed = true;\n        stream.callOnClose(err);\n        grpcStream.end();\n      }\n    };\n\n    var stream = new StreamBridge({\n      sendFn: function (msg) {\n        if (!closed) {\n          logDebug(LOG_TAG$9, 'GRPC stream sending:', msg);\n\n          try {\n            grpcStream.write(msg);\n          } catch (e) {\n            // This probably means we didn't conform to the proto.  Make sure to\n            // log the message we sent.\n            logError('Failure sending:', msg);\n            logError('Error:', e);\n            throw e;\n          }\n        } else {\n          logDebug(LOG_TAG$9, 'Not sending because gRPC stream is closed:', msg);\n        }\n      },\n      closeFn: function () {\n        logDebug(LOG_TAG$9, 'GRPC stream closed locally via close().');\n        close();\n      }\n    });\n    grpcStream.on('data', function (msg) {\n      if (!closed) {\n        logDebug(LOG_TAG$9, 'GRPC stream received:', msg);\n        stream.callOnMessage(msg);\n      }\n    });\n    grpcStream.on('end', function () {\n      logDebug(LOG_TAG$9, 'GRPC stream ended.');\n      close();\n    });\n    grpcStream.on('error', function (grpcError) {\n      if (!closed) {\n        logWarn(LOG_TAG$9, 'GRPC stream error. Code:', grpcError.code, 'Message:', grpcError.message);\n        var code = mapCodeFromRpcCode(grpcError.code);\n        close(new FirestoreError(code, grpcError.message));\n      }\n    });\n    logDebug(LOG_TAG$9, 'Opening GRPC stream'); // TODO(dimond): Since grpc has no explicit open status (or does it?) we\n    // simulate an onOpen in the next loop after the stream had it's listeners\n    // registered\n\n    setTimeout(function () {\n      stream.callOnOpen();\n    }, 0);\n    return stream;\n  };\n\n  return GrpcConnection;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Used by tests so we can match @grpc/proto-loader behavior. */\n\n\nvar protoLoaderOptions = {\n  longs: String,\n  enums: String,\n  defaults: true,\n  oneofs: false\n};\n/**\r\n * Loads the protocol buffer definitions for Firestore.\r\n *\r\n * @returns The GrpcObject representing our protos.\r\n */\n\nfunction loadProtos() {\n  var root = path.resolve(__dirname, \"../protos\");\n  var firestoreProtoFile = path.join(root, 'google/firestore/v1/firestore.proto');\n  var packageDefinition = protoLoader.loadSync(firestoreProtoFile, Object.assign(Object.assign({}, protoLoaderOptions), {\n    includeDirs: [root]\n  }));\n  return grpcJs.loadPackageDefinition(packageDefinition);\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Loads the GRPC stack */\n\n\nfunction newConnection(databaseInfo) {\n  var protos = loadProtos();\n  return new GrpcConnection(protos, databaseInfo);\n}\n/** Return the Platform-specific connectivity monitor. */\n\n\nfunction newConnectivityMonitor() {\n  return new NoopConnectivityMonitor();\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** The Platform's 'window' implementation or null if not available. */\n\n\nfunction getWindow() {\n  if (process.env.USE_MOCK_PERSISTENCE === 'YES') {\n    // eslint-disable-next-line no-restricted-globals\n    return window;\n  }\n\n  return null;\n}\n/** The Platform's 'document' implementation or null if not available. */\n\n\nfunction getDocument() {\n  return null;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction newSerializer(databaseId) {\n  return new JsonProtoSerializer(databaseId,\n  /* useProto3Json= */\n  false);\n}\n/**\r\n * An instance of the Platform's 'TextEncoder' implementation.\r\n */\n\n\nfunction newTextEncoder() {\n  return new util$1.TextEncoder();\n}\n/**\r\n * An instance of the Platform's 'TextDecoder' implementation.\r\n */\n\n\nfunction newTextDecoder() {\n  return new util$1.TextDecoder('utf-8');\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$8 = 'ExponentialBackoff';\n/**\r\n * Initial backoff time in milliseconds after an error.\r\n * Set to 1s according to https://cloud.google.com/apis/design/errors.\r\n */\n\nvar DEFAULT_BACKOFF_INITIAL_DELAY_MS = 1000;\nvar DEFAULT_BACKOFF_FACTOR = 1.5;\n/** Maximum backoff time in milliseconds */\n\nvar DEFAULT_BACKOFF_MAX_DELAY_MS = 60 * 1000;\n/**\r\n * A helper for running delayed tasks following an exponential backoff curve\r\n * between attempts.\r\n *\r\n * Each delay is made up of a \"base\" delay which follows the exponential\r\n * backoff curve, and a +/- 50% \"jitter\" that is calculated and added to the\r\n * base delay. This prevents clients from accidentally synchronizing their\r\n * delays causing spikes of load to the backend.\r\n */\n\nvar ExponentialBackoff =\n/** @class */\nfunction () {\n  function ExponentialBackoff(\n  /**\r\n   * The AsyncQueue to run backoff operations on.\r\n   */\n  queue,\n  /**\r\n   * The ID to use when scheduling backoff operations on the AsyncQueue.\r\n   */\n  timerId,\n  /**\r\n   * The initial delay (used as the base delay on the first retry attempt).\r\n   * Note that jitter will still be applied, so the actual delay could be as\r\n   * little as 0.5*initialDelayMs.\r\n   */\n  initialDelayMs,\n  /**\r\n   * The multiplier to use to determine the extended base delay after each\r\n   * attempt.\r\n   */\n  backoffFactor,\n  /**\r\n   * The maximum base delay after which no further backoff is performed.\r\n   * Note that jitter will still be applied, so the actual delay could be as\r\n   * much as 1.5*maxDelayMs.\r\n   */\n  maxDelayMs) {\n    if (initialDelayMs === void 0) {\n      initialDelayMs = DEFAULT_BACKOFF_INITIAL_DELAY_MS;\n    }\n\n    if (backoffFactor === void 0) {\n      backoffFactor = DEFAULT_BACKOFF_FACTOR;\n    }\n\n    if (maxDelayMs === void 0) {\n      maxDelayMs = DEFAULT_BACKOFF_MAX_DELAY_MS;\n    }\n\n    this.queue = queue;\n    this.timerId = timerId;\n    this.initialDelayMs = initialDelayMs;\n    this.backoffFactor = backoffFactor;\n    this.maxDelayMs = maxDelayMs;\n    this.currentBaseMs = 0;\n    this.timerPromise = null;\n    /** The last backoff attempt, as epoch milliseconds. */\n\n    this.lastAttemptTime = Date.now();\n    this.reset();\n  }\n  /**\r\n   * Resets the backoff delay.\r\n   *\r\n   * The very next backoffAndWait() will have no delay. If it is called again\r\n   * (i.e. due to an error), initialDelayMs (plus jitter) will be used, and\r\n   * subsequent ones will increase according to the backoffFactor.\r\n   */\n\n\n  ExponentialBackoff.prototype.reset = function () {\n    this.currentBaseMs = 0;\n  };\n  /**\r\n   * Resets the backoff delay to the maximum delay (e.g. for use after a\r\n   * RESOURCE_EXHAUSTED error).\r\n   */\n\n\n  ExponentialBackoff.prototype.resetToMax = function () {\n    this.currentBaseMs = this.maxDelayMs;\n  };\n  /**\r\n   * Returns a promise that resolves after currentDelayMs, and increases the\r\n   * delay for any subsequent attempts. If there was a pending backoff operation\r\n   * already, it will be canceled.\r\n   */\n\n\n  ExponentialBackoff.prototype.backoffAndRun = function (op) {\n    var _this = this; // Cancel any pending backoff operation.\n\n\n    this.cancel(); // First schedule using the current base (which may be 0 and should be\n    // honored as such).\n\n    var desiredDelayWithJitterMs = Math.floor(this.currentBaseMs + this.jitterDelayMs()); // Guard against lastAttemptTime being in the future due to a clock change.\n\n    var delaySoFarMs = Math.max(0, Date.now() - this.lastAttemptTime); // Guard against the backoff delay already being past.\n\n    var remainingDelayMs = Math.max(0, desiredDelayWithJitterMs - delaySoFarMs);\n\n    if (remainingDelayMs > 0) {\n      logDebug(LOG_TAG$8, \"Backing off for \" + remainingDelayMs + \" ms \" + (\"(base delay: \" + this.currentBaseMs + \" ms, \") + (\"delay with jitter: \" + desiredDelayWithJitterMs + \" ms, \") + (\"last attempt: \" + delaySoFarMs + \" ms ago)\"));\n    }\n\n    this.timerPromise = this.queue.enqueueAfterDelay(this.timerId, remainingDelayMs, function () {\n      _this.lastAttemptTime = Date.now();\n      return op();\n    }); // Apply backoff factor to determine next delay and ensure it is within\n    // bounds.\n\n    this.currentBaseMs *= this.backoffFactor;\n\n    if (this.currentBaseMs < this.initialDelayMs) {\n      this.currentBaseMs = this.initialDelayMs;\n    }\n\n    if (this.currentBaseMs > this.maxDelayMs) {\n      this.currentBaseMs = this.maxDelayMs;\n    }\n  };\n\n  ExponentialBackoff.prototype.skipBackoff = function () {\n    if (this.timerPromise !== null) {\n      this.timerPromise.skipDelay();\n      this.timerPromise = null;\n    }\n  };\n\n  ExponentialBackoff.prototype.cancel = function () {\n    if (this.timerPromise !== null) {\n      this.timerPromise.cancel();\n      this.timerPromise = null;\n    }\n  };\n  /** Returns a random value in the range [-currentBaseMs/2, currentBaseMs/2] */\n\n\n  ExponentialBackoff.prototype.jitterDelayMs = function () {\n    return (Math.random() - 0.5) * this.currentBaseMs;\n  };\n\n  return ExponentialBackoff;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$7 = 'PersistentStream';\n/** The time a stream stays open after it is marked idle. */\n\nvar IDLE_TIMEOUT_MS = 60 * 1000;\n/**\r\n * A PersistentStream is an abstract base class that represents a streaming RPC\r\n * to the Firestore backend. It's built on top of the connections own support\r\n * for streaming RPCs, and adds several critical features for our clients:\r\n *\r\n *   - Exponential backoff on failure\r\n *   - Authentication via CredentialsProvider\r\n *   - Dispatching all callbacks into the shared worker queue\r\n *   - Closing idle streams after 60 seconds of inactivity\r\n *\r\n * Subclasses of PersistentStream implement serialization of models to and\r\n * from the JSON representation of the protocol buffers for a specific\r\n * streaming RPC.\r\n *\r\n * ## Starting and Stopping\r\n *\r\n * Streaming RPCs are stateful and need to be start()ed before messages can\r\n * be sent and received. The PersistentStream will call the onOpen() function\r\n * of the listener once the stream is ready to accept requests.\r\n *\r\n * Should a start() fail, PersistentStream will call the registered onClose()\r\n * listener with a FirestoreError indicating what went wrong.\r\n *\r\n * A PersistentStream can be started and stopped repeatedly.\r\n *\r\n * Generic types:\r\n *  SendType: The type of the outgoing message of the underlying\r\n *    connection stream\r\n *  ReceiveType: The type of the incoming message of the underlying\r\n *    connection stream\r\n *  ListenerType: The type of the listener that will be used for callbacks\r\n */\n\nvar PersistentStream =\n/** @class */\nfunction () {\n  function PersistentStream(queue, connectionTimerId, idleTimerId, connection, credentialsProvider, listener) {\n    this.queue = queue;\n    this.idleTimerId = idleTimerId;\n    this.connection = connection;\n    this.credentialsProvider = credentialsProvider;\n    this.listener = listener;\n    this.state = 0\n    /* Initial */\n    ;\n    /**\r\n     * A close count that's incremented every time the stream is closed; used by\r\n     * getCloseGuardedDispatcher() to invalidate callbacks that happen after\r\n     * close.\r\n     */\n\n    this.closeCount = 0;\n    this.idleTimer = null;\n    this.stream = null;\n    this.backoff = new ExponentialBackoff(queue, connectionTimerId);\n  }\n  /**\r\n   * Returns true if start() has been called and no error has occurred. True\r\n   * indicates the stream is open or in the process of opening (which\r\n   * encompasses respecting backoff, getting auth tokens, and starting the\r\n   * actual RPC). Use isOpen() to determine if the stream is open and ready for\r\n   * outbound requests.\r\n   */\n\n\n  PersistentStream.prototype.isStarted = function () {\n    return this.state === 1\n    /* Starting */\n    || this.state === 2\n    /* Open */\n    || this.state === 4\n    /* Backoff */\n    ;\n  };\n  /**\r\n   * Returns true if the underlying RPC is open (the onOpen() listener has been\r\n   * called) and the stream is ready for outbound requests.\r\n   */\n\n\n  PersistentStream.prototype.isOpen = function () {\n    return this.state === 2\n    /* Open */\n    ;\n  };\n  /**\r\n   * Starts the RPC. Only allowed if isStarted() returns false. The stream is\r\n   * not immediately ready for use: onOpen() will be invoked when the RPC is\r\n   * ready for outbound requests, at which point isOpen() will return true.\r\n   *\r\n   * When start returns, isStarted() will return true.\r\n   */\n\n\n  PersistentStream.prototype.start = function () {\n    if (this.state === 3\n    /* Error */\n    ) {\n        this.performBackoff();\n        return;\n      }\n\n    this.auth();\n  };\n  /**\r\n   * Stops the RPC. This call is idempotent and allowed regardless of the\r\n   * current isStarted() state.\r\n   *\r\n   * When stop returns, isStarted() and isOpen() will both return false.\r\n   */\n\n\n  PersistentStream.prototype.stop = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            if (!this.isStarted()) return [3\n            /*break*/\n            , 2];\n            return [4\n            /*yield*/\n            , this.close(0\n            /* Initial */\n            )];\n\n          case 1:\n            _d.sent();\n\n            _d.label = 2;\n\n          case 2:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\r\n   * After an error the stream will usually back off on the next attempt to\r\n   * start it. If the error warrants an immediate restart of the stream, the\r\n   * sender can use this to indicate that the receiver should not back off.\r\n   *\r\n   * Each error will call the onClose() listener. That function can decide to\r\n   * inhibit backoff if required.\r\n   */\n\n\n  PersistentStream.prototype.inhibitBackoff = function () {\n    this.state = 0\n    /* Initial */\n    ;\n    this.backoff.reset();\n  };\n  /**\r\n   * Marks this stream as idle. If no further actions are performed on the\r\n   * stream for one minute, the stream will automatically close itself and\r\n   * notify the stream's onClose() handler with Status.OK. The stream will then\r\n   * be in a !isStarted() state, requiring the caller to start the stream again\r\n   * before further use.\r\n   *\r\n   * Only streams that are in state 'Open' can be marked idle, as all other\r\n   * states imply pending network operations.\r\n   */\n\n\n  PersistentStream.prototype.markIdle = function () {\n    var _this = this; // Starts the idle time if we are in state 'Open' and are not yet already\n    // running a timer (in which case the previous idle timeout still applies).\n\n\n    if (this.isOpen() && this.idleTimer === null) {\n      this.idleTimer = this.queue.enqueueAfterDelay(this.idleTimerId, IDLE_TIMEOUT_MS, function () {\n        return _this.handleIdleCloseTimer();\n      });\n    }\n  };\n  /** Sends a message to the underlying stream. */\n\n\n  PersistentStream.prototype.sendRequest = function (msg) {\n    this.cancelIdleCheck();\n    this.stream.send(msg);\n  };\n  /** Called by the idle timer when the stream should close due to inactivity. */\n\n\n  PersistentStream.prototype.handleIdleCloseTimer = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        if (this.isOpen()) {\n          // When timing out an idle stream there's no reason to force the stream into backoff when\n          // it restarts so set the stream state to Initial instead of Error.\n          return [2\n          /*return*/\n          , this.close(0\n          /* Initial */\n          )];\n        }\n\n        return [2\n        /*return*/\n        ];\n      });\n    });\n  };\n  /** Marks the stream as active again. */\n\n\n  PersistentStream.prototype.cancelIdleCheck = function () {\n    if (this.idleTimer) {\n      this.idleTimer.cancel();\n      this.idleTimer = null;\n    }\n  };\n  /**\r\n   * Closes the stream and cleans up as necessary:\r\n   *\r\n   * * closes the underlying GRPC stream;\r\n   * * calls the onClose handler with the given 'error';\r\n   * * sets internal stream state to 'finalState';\r\n   * * adjusts the backoff timer based on the error\r\n   *\r\n   * A new stream can be opened by calling start().\r\n   *\r\n   * @param finalState - the intended state of the stream after closing.\r\n   * @param error - the error the connection was closed with.\r\n   */\n\n\n  PersistentStream.prototype.close = function (finalState, error) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            // Cancel any outstanding timers (they're guaranteed not to execute).\n            this.cancelIdleCheck();\n            this.backoff.cancel(); // Invalidates any stream-related callbacks (e.g. from auth or the\n            // underlying stream), guaranteeing they won't execute.\n\n            this.closeCount++;\n\n            if (finalState !== 3\n            /* Error */\n            ) {\n                // If this is an intentional close ensure we don't delay our next connection attempt.\n                this.backoff.reset();\n              } else if (error && error.code === Code.RESOURCE_EXHAUSTED) {\n              // Log the error. (Probably either 'quota exceeded' or 'max queue length reached'.)\n              logError(error.toString());\n              logError('Using maximum backoff delay to prevent overloading the backend.');\n              this.backoff.resetToMax();\n            } else if (error && error.code === Code.UNAUTHENTICATED) {\n              // \"unauthenticated\" error means the token was rejected. Try force refreshing it in case it\n              // just expired.\n              this.credentialsProvider.invalidateToken();\n            } // Clean up the underlying stream because we are no longer interested in events.\n\n\n            if (this.stream !== null) {\n              this.tearDown();\n              this.stream.close();\n              this.stream = null;\n            } // This state must be assigned before calling onClose() to allow the callback to\n            // inhibit backoff or otherwise manipulate the state in its non-started state.\n\n\n            this.state = finalState; // Notify the listener that the stream closed.\n\n            return [4\n            /*yield*/\n            , this.listener.onClose(error)];\n\n          case 1:\n            // Notify the listener that the stream closed.\n            _d.sent();\n\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\r\n   * Can be overridden to perform additional cleanup before the stream is closed.\r\n   * Calling super.tearDown() is not required.\r\n   */\n\n\n  PersistentStream.prototype.tearDown = function () {};\n\n  PersistentStream.prototype.auth = function () {\n    var _this = this;\n\n    this.state = 1\n    /* Starting */\n    ;\n    var dispatchIfNotClosed = this.getCloseGuardedDispatcher(this.closeCount); // TODO(mikelehen): Just use dispatchIfNotClosed, but see TODO below.\n\n    var closeCount = this.closeCount;\n    this.credentialsProvider.getToken().then(function (token) {\n      // Stream can be stopped while waiting for authentication.\n      // TODO(mikelehen): We really should just use dispatchIfNotClosed\n      // and let this dispatch onto the queue, but that opened a spec test can\n      // of worms that I don't want to deal with in this PR.\n      if (_this.closeCount === closeCount) {\n        // Normally we'd have to schedule the callback on the AsyncQueue.\n        // However, the following calls are safe to be called outside the\n        // AsyncQueue since they don't chain asynchronous calls\n        _this.startStream(token);\n      }\n    }, function (error) {\n      dispatchIfNotClosed(function () {\n        var rpcError = new FirestoreError(Code.UNKNOWN, 'Fetching auth token failed: ' + error.message);\n        return _this.handleStreamClose(rpcError);\n      });\n    });\n  };\n\n  PersistentStream.prototype.startStream = function (token) {\n    var _this = this;\n\n    var dispatchIfNotClosed = this.getCloseGuardedDispatcher(this.closeCount);\n    this.stream = this.startRpc(token);\n    this.stream.onOpen(function () {\n      dispatchIfNotClosed(function () {\n        _this.state = 2\n        /* Open */\n        ;\n        return _this.listener.onOpen();\n      });\n    });\n    this.stream.onClose(function (error) {\n      dispatchIfNotClosed(function () {\n        return _this.handleStreamClose(error);\n      });\n    });\n    this.stream.onMessage(function (msg) {\n      dispatchIfNotClosed(function () {\n        return _this.onMessage(msg);\n      });\n    });\n  };\n\n  PersistentStream.prototype.performBackoff = function () {\n    var _this = this;\n\n    this.state = 4\n    /* Backoff */\n    ;\n    this.backoff.backoffAndRun(function () {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        return tslib.__generator(this, function (_d) {\n          this.state = 0\n          /* Initial */\n          ;\n          this.start();\n          return [2\n          /*return*/\n          ];\n        });\n      });\n    });\n  }; // Visible for tests\n\n\n  PersistentStream.prototype.handleStreamClose = function (error) {\n    logDebug(LOG_TAG$7, \"close with error: \" + error);\n    this.stream = null; // In theory the stream could close cleanly, however, in our current model\n    // we never expect this to happen because if we stop a stream ourselves,\n    // this callback will never be called. To prevent cases where we retry\n    // without a backoff accidentally, we set the stream to error in all cases.\n\n    return this.close(3\n    /* Error */\n    , error);\n  };\n  /**\r\n   * Returns a \"dispatcher\" function that dispatches operations onto the\r\n   * AsyncQueue but only runs them if closeCount remains unchanged. This allows\r\n   * us to turn auth / stream callbacks into no-ops if the stream is closed /\r\n   * re-opened, etc.\r\n   */\n\n\n  PersistentStream.prototype.getCloseGuardedDispatcher = function (startCloseCount) {\n    var _this = this;\n\n    return function (fn) {\n      _this.queue.enqueueAndForget(function () {\n        if (_this.closeCount === startCloseCount) {\n          return fn();\n        } else {\n          logDebug(LOG_TAG$7, 'stream callback skipped by getCloseGuardedDispatcher.');\n          return Promise.resolve();\n        }\n      });\n    };\n  };\n\n  return PersistentStream;\n}();\n/**\r\n * A PersistentStream that implements the Listen RPC.\r\n *\r\n * Once the Listen stream has called the onOpen() listener, any number of\r\n * listen() and unlisten() calls can be made to control what changes will be\r\n * sent from the server for ListenResponses.\r\n */\n\n\nvar PersistentListenStream =\n/** @class */\nfunction (_super) {\n  tslib.__extends(PersistentListenStream, _super);\n\n  function PersistentListenStream(queue, connection, credentials, serializer, listener) {\n    var _this = _super.call(this, queue, \"listen_stream_connection_backoff\"\n    /* ListenStreamConnectionBackoff */\n    , \"listen_stream_idle\"\n    /* ListenStreamIdle */\n    , connection, credentials, listener) || this;\n\n    _this.serializer = serializer;\n    return _this;\n  }\n\n  PersistentListenStream.prototype.startRpc = function (token) {\n    return this.connection.openStream('Listen', token);\n  };\n\n  PersistentListenStream.prototype.onMessage = function (watchChangeProto) {\n    // A successful response means the stream is healthy\n    this.backoff.reset();\n    var watchChange = fromWatchChange(this.serializer, watchChangeProto);\n    var snapshot = versionFromListenResponse(watchChangeProto);\n    return this.listener.onWatchChange(watchChange, snapshot);\n  };\n  /**\r\n   * Registers interest in the results of the given target. If the target\r\n   * includes a resumeToken it will be included in the request. Results that\r\n   * affect the target will be streamed back as WatchChange messages that\r\n   * reference the targetId.\r\n   */\n\n\n  PersistentListenStream.prototype.watch = function (targetData) {\n    var request = {};\n    request.database = getEncodedDatabaseId(this.serializer);\n    request.addTarget = toTarget(this.serializer, targetData);\n    var labels = toListenRequestLabels(this.serializer, targetData);\n\n    if (labels) {\n      request.labels = labels;\n    }\n\n    this.sendRequest(request);\n  };\n  /**\r\n   * Unregisters interest in the results of the target associated with the\r\n   * given targetId.\r\n   */\n\n\n  PersistentListenStream.prototype.unwatch = function (targetId) {\n    var request = {};\n    request.database = getEncodedDatabaseId(this.serializer);\n    request.removeTarget = targetId;\n    this.sendRequest(request);\n  };\n\n  return PersistentListenStream;\n}(PersistentStream);\n/**\r\n * A Stream that implements the Write RPC.\r\n *\r\n * The Write RPC requires the caller to maintain special streamToken\r\n * state in between calls, to help the server understand which responses the\r\n * client has processed by the time the next request is made. Every response\r\n * will contain a streamToken; this value must be passed to the next\r\n * request.\r\n *\r\n * After calling start() on this stream, the next request must be a handshake,\r\n * containing whatever streamToken is on hand. Once a response to this\r\n * request is received, all pending mutations may be submitted. When\r\n * submitting multiple batches of mutations at the same time, it's\r\n * okay to use the same streamToken for the calls to writeMutations.\r\n *\r\n * TODO(b/33271235): Use proto types\r\n */\n\n\nvar PersistentWriteStream =\n/** @class */\nfunction (_super) {\n  tslib.__extends(PersistentWriteStream, _super);\n\n  function PersistentWriteStream(queue, connection, credentials, serializer, listener) {\n    var _this = _super.call(this, queue, \"write_stream_connection_backoff\"\n    /* WriteStreamConnectionBackoff */\n    , \"write_stream_idle\"\n    /* WriteStreamIdle */\n    , connection, credentials, listener) || this;\n\n    _this.serializer = serializer;\n    _this.handshakeComplete_ = false;\n    return _this;\n  }\n\n  Object.defineProperty(PersistentWriteStream.prototype, \"handshakeComplete\", {\n    /**\r\n     * Tracks whether or not a handshake has been successfully exchanged and\r\n     * the stream is ready to accept mutations.\r\n     */\n    get: function () {\n      return this.handshakeComplete_;\n    },\n    enumerable: false,\n    configurable: true\n  }); // Override of PersistentStream.start\n\n  PersistentWriteStream.prototype.start = function () {\n    this.handshakeComplete_ = false;\n    this.lastStreamToken = undefined;\n\n    _super.prototype.start.call(this);\n  };\n\n  PersistentWriteStream.prototype.tearDown = function () {\n    if (this.handshakeComplete_) {\n      this.writeMutations([]);\n    }\n  };\n\n  PersistentWriteStream.prototype.startRpc = function (token) {\n    return this.connection.openStream('Write', token);\n  };\n\n  PersistentWriteStream.prototype.onMessage = function (responseProto) {\n    // Always capture the last stream token.\n    hardAssert(!!responseProto.streamToken);\n    this.lastStreamToken = responseProto.streamToken;\n\n    if (!this.handshakeComplete_) {\n      // The first response is always the handshake response\n      hardAssert(!responseProto.writeResults || responseProto.writeResults.length === 0);\n      this.handshakeComplete_ = true;\n      return this.listener.onHandshakeComplete();\n    } else {\n      // A successful first write response means the stream is healthy,\n      // Note, that we could consider a successful handshake healthy, however,\n      // the write itself might be causing an error we want to back off from.\n      this.backoff.reset();\n      var results = fromWriteResults(responseProto.writeResults, responseProto.commitTime);\n      var commitVersion = fromVersion(responseProto.commitTime);\n      return this.listener.onMutationResult(commitVersion, results);\n    }\n  };\n  /**\r\n   * Sends an initial streamToken to the server, performing the handshake\r\n   * required to make the StreamingWrite RPC work. Subsequent\r\n   * calls should wait until onHandshakeComplete was called.\r\n   */\n\n\n  PersistentWriteStream.prototype.writeHandshake = function () {\n    // TODO(dimond): Support stream resumption. We intentionally do not set the\n    // stream token on the handshake, ignoring any stream token we might have.\n    var request = {};\n    request.database = getEncodedDatabaseId(this.serializer);\n    this.sendRequest(request);\n  };\n  /** Sends a group of mutations to the Firestore backend to apply. */\n\n\n  PersistentWriteStream.prototype.writeMutations = function (mutations) {\n    var _this = this;\n\n    var request = {\n      streamToken: this.lastStreamToken,\n      writes: mutations.map(function (mutation) {\n        return toMutation(_this.serializer, mutation);\n      })\n    };\n    this.sendRequest(request);\n  };\n\n  return PersistentWriteStream;\n}(PersistentStream);\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Datastore and its related methods are a wrapper around the external Google\r\n * Cloud Datastore grpc API, which provides an interface that is more convenient\r\n * for the rest of the client SDK architecture to consume.\r\n */\n\n\nvar Datastore =\n/** @class */\nfunction () {\n  function Datastore() {}\n\n  return Datastore;\n}();\n/**\r\n * An implementation of Datastore that exposes additional state for internal\r\n * consumption.\r\n */\n\n\nvar DatastoreImpl =\n/** @class */\nfunction (_super) {\n  tslib.__extends(DatastoreImpl, _super);\n\n  function DatastoreImpl(credentials, connection, serializer) {\n    var _this = _super.call(this) || this;\n\n    _this.credentials = credentials;\n    _this.connection = connection;\n    _this.serializer = serializer;\n    _this.terminated = false;\n    return _this;\n  }\n\n  DatastoreImpl.prototype.verifyInitialized = function () {\n    if (this.terminated) {\n      throw new FirestoreError(Code.FAILED_PRECONDITION, 'The client has already been terminated.');\n    }\n  };\n  /** Gets an auth token and invokes the provided RPC. */\n\n\n  DatastoreImpl.prototype.invokeRPC = function (rpcName, path, request) {\n    var _this = this;\n\n    this.verifyInitialized();\n    return this.credentials.getToken().then(function (token) {\n      return _this.connection.invokeRPC(rpcName, path, request, token);\n    }).catch(function (error) {\n      if (error.name === 'FirebaseError') {\n        if (error.code === Code.UNAUTHENTICATED) {\n          _this.credentials.invalidateToken();\n        }\n\n        throw error;\n      } else {\n        throw new FirestoreError(Code.UNKNOWN, error.toString());\n      }\n    });\n  };\n  /** Gets an auth token and invokes the provided RPC with streamed results. */\n\n\n  DatastoreImpl.prototype.invokeStreamingRPC = function (rpcName, path, request) {\n    var _this = this;\n\n    this.verifyInitialized();\n    return this.credentials.getToken().then(function (token) {\n      return _this.connection.invokeStreamingRPC(rpcName, path, request, token);\n    }).catch(function (error) {\n      if (error.name === 'FirebaseError') {\n        if (error.code === Code.UNAUTHENTICATED) {\n          _this.credentials.invalidateToken();\n        }\n\n        throw error;\n      } else {\n        throw new FirestoreError(Code.UNKNOWN, error.toString());\n      }\n    });\n  };\n\n  DatastoreImpl.prototype.terminate = function () {\n    this.terminated = true;\n  };\n\n  return DatastoreImpl;\n}(Datastore); // TODO(firestorexp): Make sure there is only one Datastore instance per\n// firestore-exp client.\n\n\nfunction newDatastore(credentials, connection, serializer) {\n  return new DatastoreImpl(credentials, connection, serializer);\n}\n\nfunction invokeCommitRpc(datastore, mutations) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var datastoreImpl, path, request;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          datastoreImpl = debugCast(datastore);\n          path = getEncodedDatabaseId(datastoreImpl.serializer) + '/documents';\n          request = {\n            writes: mutations.map(function (m) {\n              return toMutation(datastoreImpl.serializer, m);\n            })\n          };\n          return [4\n          /*yield*/\n          , datastoreImpl.invokeRPC('Commit', path, request)];\n\n        case 1:\n          _d.sent();\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction invokeBatchGetDocumentsRpc(datastore, keys) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var datastoreImpl, path, request, response, docs, result;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          datastoreImpl = debugCast(datastore);\n          path = getEncodedDatabaseId(datastoreImpl.serializer) + '/documents';\n          request = {\n            documents: keys.map(function (k) {\n              return toName(datastoreImpl.serializer, k);\n            })\n          };\n          return [4\n          /*yield*/\n          , datastoreImpl.invokeStreamingRPC('BatchGetDocuments', path, request)];\n\n        case 1:\n          response = _d.sent();\n          docs = new Map();\n          response.forEach(function (proto) {\n            var doc = fromBatchGetDocumentsResponse(datastoreImpl.serializer, proto);\n            docs.set(doc.key.toString(), doc);\n          });\n          result = [];\n          keys.forEach(function (key) {\n            var doc = docs.get(key.toString());\n            hardAssert(!!doc);\n            result.push(doc);\n          });\n          return [2\n          /*return*/\n          , result];\n      }\n    });\n  });\n}\n\nfunction newPersistentWriteStream(datastore, queue, listener) {\n  var datastoreImpl = debugCast(datastore);\n  datastoreImpl.verifyInitialized();\n  return new PersistentWriteStream(queue, datastoreImpl.connection, datastoreImpl.credentials, datastoreImpl.serializer, listener);\n}\n\nfunction newPersistentWatchStream(datastore, queue, listener) {\n  var datastoreImpl = debugCast(datastore);\n  datastoreImpl.verifyInitialized();\n  return new PersistentListenStream(queue, datastoreImpl.connection, datastoreImpl.credentials, datastoreImpl.serializer, listener);\n}\n/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$6 = 'OnlineStateTracker'; // To deal with transient failures, we allow multiple stream attempts before\n// giving up and transitioning from OnlineState.Unknown to Offline.\n// TODO(mikelehen): This used to be set to 2 as a mitigation for b/66228394.\n// @jdimond thinks that bug is sufficiently fixed so that we can set this back\n// to 1. If that works okay, we could potentially remove this logic entirely.\n\nvar MAX_WATCH_STREAM_FAILURES = 1; // To deal with stream attempts that don't succeed or fail in a timely manner,\n// we have a timeout for OnlineState to reach Online or Offline.\n// If the timeout is reached, we transition to Offline rather than waiting\n// indefinitely.\n\nvar ONLINE_STATE_TIMEOUT_MS = 10 * 1000;\n/**\r\n * A component used by the RemoteStore to track the OnlineState (that is,\r\n * whether or not the client as a whole should be considered to be online or\r\n * offline), implementing the appropriate heuristics.\r\n *\r\n * In particular, when the client is trying to connect to the backend, we\r\n * allow up to MAX_WATCH_STREAM_FAILURES within ONLINE_STATE_TIMEOUT_MS for\r\n * a connection to succeed. If we have too many failures or the timeout elapses,\r\n * then we set the OnlineState to Offline, and the client will behave as if\r\n * it is offline (get()s will return cached data, etc.).\r\n */\n\nvar OnlineStateTracker =\n/** @class */\nfunction () {\n  function OnlineStateTracker(asyncQueue, onlineStateHandler) {\n    this.asyncQueue = asyncQueue;\n    this.onlineStateHandler = onlineStateHandler;\n    /** The current OnlineState. */\n\n    this.state = \"Unknown\"\n    /* Unknown */\n    ;\n    /**\r\n     * A count of consecutive failures to open the stream. If it reaches the\r\n     * maximum defined by MAX_WATCH_STREAM_FAILURES, we'll set the OnlineState to\r\n     * Offline.\r\n     */\n\n    this.watchStreamFailures = 0;\n    /**\r\n     * A timer that elapses after ONLINE_STATE_TIMEOUT_MS, at which point we\r\n     * transition from OnlineState.Unknown to OnlineState.Offline without waiting\r\n     * for the stream to actually fail (MAX_WATCH_STREAM_FAILURES times).\r\n     */\n\n    this.onlineStateTimer = null;\n    /**\r\n     * Whether the client should log a warning message if it fails to connect to\r\n     * the backend (initially true, cleared after a successful stream, or if we've\r\n     * logged the message already).\r\n     */\n\n    this.shouldWarnClientIsOffline = true;\n  }\n  /**\r\n   * Called by RemoteStore when a watch stream is started (including on each\r\n   * backoff attempt).\r\n   *\r\n   * If this is the first attempt, it sets the OnlineState to Unknown and starts\r\n   * the onlineStateTimer.\r\n   */\n\n\n  OnlineStateTracker.prototype.handleWatchStreamStart = function () {\n    var _this = this;\n\n    if (this.watchStreamFailures === 0) {\n      this.setAndBroadcast(\"Unknown\"\n      /* Unknown */\n      );\n      this.onlineStateTimer = this.asyncQueue.enqueueAfterDelay(\"online_state_timeout\"\n      /* OnlineStateTimeout */\n      , ONLINE_STATE_TIMEOUT_MS, function () {\n        _this.onlineStateTimer = null;\n\n        _this.logClientOfflineWarningIfNecessary(\"Backend didn't respond within \" + ONLINE_STATE_TIMEOUT_MS / 1000 + \" \" + \"seconds.\");\n\n        _this.setAndBroadcast(\"Offline\"\n        /* Offline */\n        ); // NOTE: handleWatchStreamFailure() will continue to increment\n        // watchStreamFailures even though we are already marked Offline,\n        // but this is non-harmful.\n\n\n        return Promise.resolve();\n      });\n    }\n  };\n  /**\r\n   * Updates our OnlineState as appropriate after the watch stream reports a\r\n   * failure. The first failure moves us to the 'Unknown' state. We then may\r\n   * allow multiple failures (based on MAX_WATCH_STREAM_FAILURES) before we\r\n   * actually transition to the 'Offline' state.\r\n   */\n\n\n  OnlineStateTracker.prototype.handleWatchStreamFailure = function (error) {\n    if (this.state === \"Online\"\n    /* Online */\n    ) {\n        this.setAndBroadcast(\"Unknown\"\n        /* Unknown */\n        );\n      } else {\n      this.watchStreamFailures++;\n\n      if (this.watchStreamFailures >= MAX_WATCH_STREAM_FAILURES) {\n        this.clearOnlineStateTimer();\n        this.logClientOfflineWarningIfNecessary(\"Connection failed \" + MAX_WATCH_STREAM_FAILURES + \" \" + (\"times. Most recent error: \" + error.toString()));\n        this.setAndBroadcast(\"Offline\"\n        /* Offline */\n        );\n      }\n    }\n  };\n  /**\r\n   * Explicitly sets the OnlineState to the specified state.\r\n   *\r\n   * Note that this resets our timers / failure counters, etc. used by our\r\n   * Offline heuristics, so must not be used in place of\r\n   * handleWatchStreamStart() and handleWatchStreamFailure().\r\n   */\n\n\n  OnlineStateTracker.prototype.set = function (newState) {\n    this.clearOnlineStateTimer();\n    this.watchStreamFailures = 0;\n\n    if (newState === \"Online\"\n    /* Online */\n    ) {\n        // We've connected to watch at least once. Don't warn the developer\n        // about being offline going forward.\n        this.shouldWarnClientIsOffline = false;\n      }\n\n    this.setAndBroadcast(newState);\n  };\n\n  OnlineStateTracker.prototype.setAndBroadcast = function (newState) {\n    if (newState !== this.state) {\n      this.state = newState;\n      this.onlineStateHandler(newState);\n    }\n  };\n\n  OnlineStateTracker.prototype.logClientOfflineWarningIfNecessary = function (details) {\n    var message = \"Could not reach Cloud Firestore backend. \" + details + \"\\n\" + \"This typically indicates that your device does not have a healthy \" + \"Internet connection at the moment. The client will operate in offline \" + \"mode until it is able to successfully connect to the backend.\";\n\n    if (this.shouldWarnClientIsOffline) {\n      logError(message);\n      this.shouldWarnClientIsOffline = false;\n    } else {\n      logDebug(LOG_TAG$6, message);\n    }\n  };\n\n  OnlineStateTracker.prototype.clearOnlineStateTimer = function () {\n    if (this.onlineStateTimer !== null) {\n      this.onlineStateTimer.cancel();\n      this.onlineStateTimer = null;\n    }\n  };\n\n  return OnlineStateTracker;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$5 = 'RemoteStore'; // TODO(b/35853402): Negotiate this with the stream.\n\nvar MAX_PENDING_WRITES = 10;\n\nvar RemoteStoreImpl =\n/** @class */\nfunction () {\n  function RemoteStoreImpl(\n  /**\r\n   * The local store, used to fill the write pipeline with outbound mutations.\r\n   */\n  localStore,\n  /** The client-side proxy for interacting with the backend. */\n  datastore, asyncQueue, onlineStateHandler, connectivityMonitor) {\n    var _this = this;\n\n    this.localStore = localStore;\n    this.datastore = datastore;\n    this.asyncQueue = asyncQueue;\n    this.remoteSyncer = {};\n    /**\r\n     * A list of up to MAX_PENDING_WRITES writes that we have fetched from the\r\n     * LocalStore via fillWritePipeline() and have or will send to the write\r\n     * stream.\r\n     *\r\n     * Whenever writePipeline.length > 0 the RemoteStore will attempt to start or\r\n     * restart the write stream. When the stream is established the writes in the\r\n     * pipeline will be sent in order.\r\n     *\r\n     * Writes remain in writePipeline until they are acknowledged by the backend\r\n     * and thus will automatically be re-sent if the stream is interrupted /\r\n     * restarted before they're acknowledged.\r\n     *\r\n     * Write responses from the backend are linked to their originating request\r\n     * purely based on order, and so we can just shift() writes from the front of\r\n     * the writePipeline as we receive responses.\r\n     */\n\n    this.writePipeline = [];\n    /**\r\n     * A mapping of watched targets that the client cares about tracking and the\r\n     * user has explicitly called a 'listen' for this target.\r\n     *\r\n     * These targets may or may not have been sent to or acknowledged by the\r\n     * server. On re-establishing the listen stream, these targets should be sent\r\n     * to the server. The targets removed with unlistens are removed eagerly\r\n     * without waiting for confirmation from the listen stream.\r\n     */\n\n    this.listenTargets = new Map();\n    /**\r\n     * A set of reasons for why the RemoteStore may be offline. If empty, the\r\n     * RemoteStore may start its network connections.\r\n     */\n\n    this.offlineCauses = new Set();\n    /**\r\n     * Event handlers that get called when the network is disabled or enabled.\r\n     *\r\n     * PORTING NOTE: These functions are used on the Web client to create the\r\n     * underlying streams (to support tree-shakeable streams). On Android and iOS,\r\n     * the streams are created during construction of RemoteStore.\r\n     */\n\n    this.onNetworkStatusChange = [];\n    this.connectivityMonitor = connectivityMonitor;\n    this.connectivityMonitor.addCallback(function (_) {\n      asyncQueue.enqueueAndForget(function () {\n        return tslib.__awaiter(_this, void 0, void 0, function () {\n          return tslib.__generator(this, function (_d) {\n            switch (_d.label) {\n              case 0:\n                if (!canUseNetwork(this)) return [3\n                /*break*/\n                , 2];\n                logDebug(LOG_TAG$5, 'Restarting streams for network reachability change.');\n                return [4\n                /*yield*/\n                , restartNetwork(this)];\n\n              case 1:\n                _d.sent();\n\n                _d.label = 2;\n\n              case 2:\n                return [2\n                /*return*/\n                ];\n            }\n          });\n        });\n      });\n    });\n    this.onlineStateTracker = new OnlineStateTracker(asyncQueue, onlineStateHandler);\n  }\n\n  return RemoteStoreImpl;\n}();\n\nfunction newRemoteStore(localStore, datastore, asyncQueue, onlineStateHandler, connectivityMonitor) {\n  return new RemoteStoreImpl(localStore, datastore, asyncQueue, onlineStateHandler, connectivityMonitor);\n}\n/** Re-enables the network. Idempotent. */\n\n\nfunction remoteStoreEnableNetwork(remoteStore) {\n  var remoteStoreImpl = debugCast(remoteStore);\n  remoteStoreImpl.offlineCauses.delete(0\n  /* UserDisabled */\n  );\n  return enableNetworkInternal(remoteStoreImpl);\n}\n\nfunction enableNetworkInternal(remoteStoreImpl) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var _i, _d, networkStatusHandler;\n\n    return tslib.__generator(this, function (_e) {\n      switch (_e.label) {\n        case 0:\n          if (!canUseNetwork(remoteStoreImpl)) return [3\n          /*break*/\n          , 4];\n          _i = 0, _d = remoteStoreImpl.onNetworkStatusChange;\n          _e.label = 1;\n\n        case 1:\n          if (!(_i < _d.length)) return [3\n          /*break*/\n          , 4];\n          networkStatusHandler = _d[_i];\n          return [4\n          /*yield*/\n          , networkStatusHandler(\n          /* enabled= */\n          true)];\n\n        case 2:\n          _e.sent();\n\n          _e.label = 3;\n\n        case 3:\n          _i++;\n          return [3\n          /*break*/\n          , 1];\n\n        case 4:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Temporarily disables the network. The network can be re-enabled using\r\n * enableNetwork().\r\n */\n\n\nfunction remoteStoreDisableNetwork(remoteStore) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var remoteStoreImpl;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          remoteStoreImpl = debugCast(remoteStore);\n          remoteStoreImpl.offlineCauses.add(0\n          /* UserDisabled */\n          );\n          return [4\n          /*yield*/\n          , disableNetworkInternal(remoteStoreImpl)];\n\n        case 1:\n          _d.sent(); // Set the OnlineState to Offline so get()s return from cache, etc.\n\n\n          remoteStoreImpl.onlineStateTracker.set(\"Offline\"\n          /* Offline */\n          );\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction disableNetworkInternal(remoteStoreImpl) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var _i, _d, networkStatusHandler;\n\n    return tslib.__generator(this, function (_e) {\n      switch (_e.label) {\n        case 0:\n          _i = 0, _d = remoteStoreImpl.onNetworkStatusChange;\n          _e.label = 1;\n\n        case 1:\n          if (!(_i < _d.length)) return [3\n          /*break*/\n          , 4];\n          networkStatusHandler = _d[_i];\n          return [4\n          /*yield*/\n          , networkStatusHandler(\n          /* enabled= */\n          false)];\n\n        case 2:\n          _e.sent();\n\n          _e.label = 3;\n\n        case 3:\n          _i++;\n          return [3\n          /*break*/\n          , 1];\n\n        case 4:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction remoteStoreShutdown(remoteStore) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var remoteStoreImpl;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          remoteStoreImpl = debugCast(remoteStore);\n          logDebug(LOG_TAG$5, 'RemoteStore shutting down.');\n          remoteStoreImpl.offlineCauses.add(5\n          /* Shutdown */\n          );\n          return [4\n          /*yield*/\n          , disableNetworkInternal(remoteStoreImpl)];\n\n        case 1:\n          _d.sent();\n\n          remoteStoreImpl.connectivityMonitor.shutdown(); // Set the OnlineState to Unknown (rather than Offline) to avoid potentially\n          // triggering spurious listener events with cached data, etc.\n\n          remoteStoreImpl.onlineStateTracker.set(\"Unknown\"\n          /* Unknown */\n          );\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Starts new listen for the given target. Uses resume token if provided. It\r\n * is a no-op if the target of given `TargetData` is already being listened to.\r\n */\n\n\nfunction remoteStoreListen(remoteStore, targetData) {\n  var remoteStoreImpl = debugCast(remoteStore);\n\n  if (remoteStoreImpl.listenTargets.has(targetData.targetId)) {\n    return;\n  } // Mark this as something the client is currently listening for.\n\n\n  remoteStoreImpl.listenTargets.set(targetData.targetId, targetData);\n\n  if (shouldStartWatchStream(remoteStoreImpl)) {\n    // The listen will be sent in onWatchStreamOpen\n    startWatchStream(remoteStoreImpl);\n  } else if (ensureWatchStream(remoteStoreImpl).isOpen()) {\n    sendWatchRequest(remoteStoreImpl, targetData);\n  }\n}\n/**\r\n * Removes the listen from server. It is a no-op if the given target id is\r\n * not being listened to.\r\n */\n\n\nfunction remoteStoreUnlisten(remoteStore, targetId) {\n  var remoteStoreImpl = debugCast(remoteStore);\n  var watchStream = ensureWatchStream(remoteStoreImpl);\n  remoteStoreImpl.listenTargets.delete(targetId);\n\n  if (watchStream.isOpen()) {\n    sendUnwatchRequest(remoteStoreImpl, targetId);\n  }\n\n  if (remoteStoreImpl.listenTargets.size === 0) {\n    if (watchStream.isOpen()) {\n      watchStream.markIdle();\n    } else if (canUseNetwork(remoteStoreImpl)) {\n      // Revert to OnlineState.Unknown if the watch stream is not open and we\n      // have no listeners, since without any listens to send we cannot\n      // confirm if the stream is healthy and upgrade to OnlineState.Online.\n      remoteStoreImpl.onlineStateTracker.set(\"Unknown\"\n      /* Unknown */\n      );\n    }\n  }\n}\n/**\r\n * We need to increment the the expected number of pending responses we're due\r\n * from watch so we wait for the ack to process any messages from this target.\r\n */\n\n\nfunction sendWatchRequest(remoteStoreImpl, targetData) {\n  remoteStoreImpl.watchChangeAggregator.recordPendingTargetRequest(targetData.targetId);\n  ensureWatchStream(remoteStoreImpl).watch(targetData);\n}\n/**\r\n * We need to increment the expected number of pending responses we're due\r\n * from watch so we wait for the removal on the server before we process any\r\n * messages from this target.\r\n */\n\n\nfunction sendUnwatchRequest(remoteStoreImpl, targetId) {\n  remoteStoreImpl.watchChangeAggregator.recordPendingTargetRequest(targetId);\n  ensureWatchStream(remoteStoreImpl).unwatch(targetId);\n}\n\nfunction startWatchStream(remoteStoreImpl) {\n  remoteStoreImpl.watchChangeAggregator = new WatchChangeAggregator({\n    getRemoteKeysForTarget: function (targetId) {\n      return remoteStoreImpl.remoteSyncer.getRemoteKeysForTarget(targetId);\n    },\n    getTargetDataForTarget: function (targetId) {\n      return remoteStoreImpl.listenTargets.get(targetId) || null;\n    }\n  });\n  ensureWatchStream(remoteStoreImpl).start();\n  remoteStoreImpl.onlineStateTracker.handleWatchStreamStart();\n}\n/**\r\n * Returns whether the watch stream should be started because it's necessary\r\n * and has not yet been started.\r\n */\n\n\nfunction shouldStartWatchStream(remoteStoreImpl) {\n  return canUseNetwork(remoteStoreImpl) && !ensureWatchStream(remoteStoreImpl).isStarted() && remoteStoreImpl.listenTargets.size > 0;\n}\n\nfunction canUseNetwork(remoteStore) {\n  var remoteStoreImpl = debugCast(remoteStore);\n  return remoteStoreImpl.offlineCauses.size === 0;\n}\n\nfunction cleanUpWatchStreamState(remoteStoreImpl) {\n  remoteStoreImpl.watchChangeAggregator = undefined;\n}\n\nfunction onWatchStreamOpen(remoteStoreImpl) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    return tslib.__generator(this, function (_d) {\n      remoteStoreImpl.listenTargets.forEach(function (targetData, targetId) {\n        sendWatchRequest(remoteStoreImpl, targetData);\n      });\n      return [2\n      /*return*/\n      ];\n    });\n  });\n}\n\nfunction onWatchStreamClose(remoteStoreImpl, error) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    return tslib.__generator(this, function (_d) {\n      cleanUpWatchStreamState(remoteStoreImpl); // If we still need the watch stream, retry the connection.\n\n      if (shouldStartWatchStream(remoteStoreImpl)) {\n        remoteStoreImpl.onlineStateTracker.handleWatchStreamFailure(error);\n        startWatchStream(remoteStoreImpl);\n      } else {\n        // No need to restart watch stream because there are no active targets.\n        // The online state is set to unknown because there is no active attempt\n        // at establishing a connection\n        remoteStoreImpl.onlineStateTracker.set(\"Unknown\"\n        /* Unknown */\n        );\n      }\n\n      return [2\n      /*return*/\n      ];\n    });\n  });\n}\n\nfunction onWatchStreamChange(remoteStoreImpl, watchChange, snapshotVersion) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var e_4, lastRemoteSnapshotVersion, e_5;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          // Mark the client as online since we got a message from the server\n          remoteStoreImpl.onlineStateTracker.set(\"Online\"\n          /* Online */\n          );\n          if (!(watchChange instanceof WatchTargetChange && watchChange.state === 2\n          /* Removed */\n          && watchChange.cause)) return [3\n          /*break*/\n          , 6];\n          _d.label = 1;\n\n        case 1:\n          _d.trys.push([1, 3,, 5]);\n\n          return [4\n          /*yield*/\n          , handleTargetError(remoteStoreImpl, watchChange)];\n\n        case 2:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 5];\n\n        case 3:\n          e_4 = _d.sent();\n          logDebug(LOG_TAG$5, 'Failed to remove targets %s: %s ', watchChange.targetIds.join(','), e_4);\n          return [4\n          /*yield*/\n          , disableNetworkUntilRecovery(remoteStoreImpl, e_4)];\n\n        case 4:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 5];\n\n        case 5:\n          return [2\n          /*return*/\n          ];\n\n        case 6:\n          if (watchChange instanceof DocumentWatchChange) {\n            remoteStoreImpl.watchChangeAggregator.handleDocumentChange(watchChange);\n          } else if (watchChange instanceof ExistenceFilterChange) {\n            remoteStoreImpl.watchChangeAggregator.handleExistenceFilter(watchChange);\n          } else {\n            remoteStoreImpl.watchChangeAggregator.handleTargetChange(watchChange);\n          }\n\n          if (!!snapshotVersion.isEqual(SnapshotVersion.min())) return [3\n          /*break*/\n          , 13];\n          _d.label = 7;\n\n        case 7:\n          _d.trys.push([7, 11,, 13]);\n\n          return [4\n          /*yield*/\n          , localStoreGetLastRemoteSnapshotVersion(remoteStoreImpl.localStore)];\n\n        case 8:\n          lastRemoteSnapshotVersion = _d.sent();\n          if (!(snapshotVersion.compareTo(lastRemoteSnapshotVersion) >= 0)) return [3\n          /*break*/\n          , 10]; // We have received a target change with a global snapshot if the snapshot\n          // version is not equal to SnapshotVersion.min().\n\n          return [4\n          /*yield*/\n          , raiseWatchSnapshot(remoteStoreImpl, snapshotVersion)];\n\n        case 9:\n          // We have received a target change with a global snapshot if the snapshot\n          // version is not equal to SnapshotVersion.min().\n          _d.sent();\n\n          _d.label = 10;\n\n        case 10:\n          return [3\n          /*break*/\n          , 13];\n\n        case 11:\n          e_5 = _d.sent();\n          logDebug(LOG_TAG$5, 'Failed to raise snapshot:', e_5);\n          return [4\n          /*yield*/\n          , disableNetworkUntilRecovery(remoteStoreImpl, e_5)];\n\n        case 12:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 13];\n\n        case 13:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Recovery logic for IndexedDB errors that takes the network offline until\r\n * `op` succeeds. Retries are scheduled with backoff using\r\n * `enqueueRetryable()`. If `op()` is not provided, IndexedDB access is\r\n * validated via a generic operation.\r\n *\r\n * The returned Promise is resolved once the network is disabled and before\r\n * any retry attempt.\r\n */\n\n\nfunction disableNetworkUntilRecovery(remoteStoreImpl, e, op) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var _this = this;\n\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          if (!isIndexedDbTransactionError(e)) return [3\n          /*break*/\n          , 2];\n          remoteStoreImpl.offlineCauses.add(1\n          /* IndexedDbFailed */\n          ); // Disable network and raise offline snapshots\n\n          return [4\n          /*yield*/\n          , disableNetworkInternal(remoteStoreImpl)];\n\n        case 1:\n          // Disable network and raise offline snapshots\n          _d.sent();\n\n          remoteStoreImpl.onlineStateTracker.set(\"Offline\"\n          /* Offline */\n          );\n\n          if (!op) {\n            // Use a simple read operation to determine if IndexedDB recovered.\n            // Ideally, we would expose a health check directly on SimpleDb, but\n            // RemoteStore only has access to persistence through LocalStore.\n            op = function () {\n              return localStoreGetLastRemoteSnapshotVersion(remoteStoreImpl.localStore);\n            };\n          } // Probe IndexedDB periodically and re-enable network\n\n\n          remoteStoreImpl.asyncQueue.enqueueRetryable(function () {\n            return tslib.__awaiter(_this, void 0, void 0, function () {\n              return tslib.__generator(this, function (_d) {\n                switch (_d.label) {\n                  case 0:\n                    logDebug(LOG_TAG$5, 'Retrying IndexedDB access');\n                    return [4\n                    /*yield*/\n                    , op()];\n\n                  case 1:\n                    _d.sent();\n\n                    remoteStoreImpl.offlineCauses.delete(1\n                    /* IndexedDbFailed */\n                    );\n                    return [4\n                    /*yield*/\n                    , enableNetworkInternal(remoteStoreImpl)];\n\n                  case 2:\n                    _d.sent();\n\n                    return [2\n                    /*return*/\n                    ];\n                }\n              });\n            });\n          });\n          return [3\n          /*break*/\n          , 3];\n\n        case 2:\n          throw e;\n\n        case 3:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Executes `op`. If `op` fails, takes the network offline until `op`\r\n * succeeds. Returns after the first attempt.\r\n */\n\n\nfunction executeWithRecovery(remoteStoreImpl, op) {\n  return op().catch(function (e) {\n    return disableNetworkUntilRecovery(remoteStoreImpl, e, op);\n  });\n}\n/**\r\n * Takes a batch of changes from the Datastore, repackages them as a\r\n * RemoteEvent, and passes that on to the listener, which is typically the\r\n * SyncEngine.\r\n */\n\n\nfunction raiseWatchSnapshot(remoteStoreImpl, snapshotVersion) {\n  var remoteEvent = remoteStoreImpl.watchChangeAggregator.createRemoteEvent(snapshotVersion); // Update in-memory resume tokens. LocalStore will update the\n  // persistent view of these when applying the completed RemoteEvent.\n\n  remoteEvent.targetChanges.forEach(function (change, targetId) {\n    if (change.resumeToken.approximateByteSize() > 0) {\n      var targetData = remoteStoreImpl.listenTargets.get(targetId); // A watched target might have been removed already.\n\n      if (targetData) {\n        remoteStoreImpl.listenTargets.set(targetId, targetData.withResumeToken(change.resumeToken, snapshotVersion));\n      }\n    }\n  }); // Re-establish listens for the targets that have been invalidated by\n  // existence filter mismatches.\n\n  remoteEvent.targetMismatches.forEach(function (targetId) {\n    var targetData = remoteStoreImpl.listenTargets.get(targetId);\n\n    if (!targetData) {\n      // A watched target might have been removed already.\n      return;\n    } // Clear the resume token for the target, since we're in a known mismatch\n    // state.\n\n\n    remoteStoreImpl.listenTargets.set(targetId, targetData.withResumeToken(ByteString.EMPTY_BYTE_STRING, targetData.snapshotVersion)); // Cause a hard reset by unwatching and rewatching immediately, but\n    // deliberately don't send a resume token so that we get a full update.\n\n    sendUnwatchRequest(remoteStoreImpl, targetId); // Mark the target we send as being on behalf of an existence filter\n    // mismatch, but don't actually retain that in listenTargets. This ensures\n    // that we flag the first re-listen this way without impacting future\n    // listens of this target (that might happen e.g. on reconnect).\n\n    var requestTargetData = new TargetData(targetData.target, targetId, 1\n    /* ExistenceFilterMismatch */\n    , targetData.sequenceNumber);\n    sendWatchRequest(remoteStoreImpl, requestTargetData);\n  });\n  return remoteStoreImpl.remoteSyncer.applyRemoteEvent(remoteEvent);\n}\n/** Handles an error on a target */\n\n\nfunction handleTargetError(remoteStoreImpl, watchChange) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var error, _i, _d, targetId;\n\n    return tslib.__generator(this, function (_e) {\n      switch (_e.label) {\n        case 0:\n          error = watchChange.cause;\n          _i = 0, _d = watchChange.targetIds;\n          _e.label = 1;\n\n        case 1:\n          if (!(_i < _d.length)) return [3\n          /*break*/\n          , 4];\n          targetId = _d[_i];\n          if (!remoteStoreImpl.listenTargets.has(targetId)) return [3\n          /*break*/\n          , 3];\n          return [4\n          /*yield*/\n          , remoteStoreImpl.remoteSyncer.rejectListen(targetId, error)];\n\n        case 2:\n          _e.sent();\n\n          remoteStoreImpl.listenTargets.delete(targetId);\n          remoteStoreImpl.watchChangeAggregator.removeTarget(targetId);\n          _e.label = 3;\n\n        case 3:\n          _i++;\n          return [3\n          /*break*/\n          , 1];\n\n        case 4:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Attempts to fill our write pipeline with writes from the LocalStore.\r\n *\r\n * Called internally to bootstrap or refill the write pipeline and by\r\n * SyncEngine whenever there are new mutations to process.\r\n *\r\n * Starts the write stream if necessary.\r\n */\n\n\nfunction fillWritePipeline(remoteStore) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var remoteStoreImpl, writeStream, lastBatchIdRetrieved, batch, e_6;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          remoteStoreImpl = debugCast(remoteStore);\n          writeStream = ensureWriteStream(remoteStoreImpl);\n          lastBatchIdRetrieved = remoteStoreImpl.writePipeline.length > 0 ? remoteStoreImpl.writePipeline[remoteStoreImpl.writePipeline.length - 1].batchId : BATCHID_UNKNOWN;\n          _d.label = 1;\n\n        case 1:\n          if (!canAddToWritePipeline(remoteStoreImpl)) return [3\n          /*break*/\n          , 7];\n          _d.label = 2;\n\n        case 2:\n          _d.trys.push([2, 4,, 6]);\n\n          return [4\n          /*yield*/\n          , localStoreGetNextMutationBatch(remoteStoreImpl.localStore, lastBatchIdRetrieved)];\n\n        case 3:\n          batch = _d.sent();\n\n          if (batch === null) {\n            if (remoteStoreImpl.writePipeline.length === 0) {\n              writeStream.markIdle();\n            }\n\n            return [3\n            /*break*/\n            , 7];\n          } else {\n            lastBatchIdRetrieved = batch.batchId;\n            addToWritePipeline(remoteStoreImpl, batch);\n          }\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 4:\n          e_6 = _d.sent();\n          return [4\n          /*yield*/\n          , disableNetworkUntilRecovery(remoteStoreImpl, e_6)];\n\n        case 5:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 6:\n          return [3\n          /*break*/\n          , 1];\n\n        case 7:\n          if (shouldStartWriteStream(remoteStoreImpl)) {\n            startWriteStream(remoteStoreImpl);\n          }\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Returns true if we can add to the write pipeline (i.e. the network is\r\n * enabled and the write pipeline is not full).\r\n */\n\n\nfunction canAddToWritePipeline(remoteStoreImpl) {\n  return canUseNetwork(remoteStoreImpl) && remoteStoreImpl.writePipeline.length < MAX_PENDING_WRITES;\n}\n/**\r\n * Queues additional writes to be sent to the write stream, sending them\r\n * immediately if the write stream is established.\r\n */\n\n\nfunction addToWritePipeline(remoteStoreImpl, batch) {\n  remoteStoreImpl.writePipeline.push(batch);\n  var writeStream = ensureWriteStream(remoteStoreImpl);\n\n  if (writeStream.isOpen() && writeStream.handshakeComplete) {\n    writeStream.writeMutations(batch.mutations);\n  }\n}\n\nfunction shouldStartWriteStream(remoteStoreImpl) {\n  return canUseNetwork(remoteStoreImpl) && !ensureWriteStream(remoteStoreImpl).isStarted() && remoteStoreImpl.writePipeline.length > 0;\n}\n\nfunction startWriteStream(remoteStoreImpl) {\n  ensureWriteStream(remoteStoreImpl).start();\n}\n\nfunction onWriteStreamOpen(remoteStoreImpl) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    return tslib.__generator(this, function (_d) {\n      ensureWriteStream(remoteStoreImpl).writeHandshake();\n      return [2\n      /*return*/\n      ];\n    });\n  });\n}\n\nfunction onWriteHandshakeComplete(remoteStoreImpl) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var writeStream, _i, _d, batch;\n\n    return tslib.__generator(this, function (_e) {\n      writeStream = ensureWriteStream(remoteStoreImpl); // Send the write pipeline now that the stream is established.\n\n      for (_i = 0, _d = remoteStoreImpl.writePipeline; _i < _d.length; _i++) {\n        batch = _d[_i];\n        writeStream.writeMutations(batch.mutations);\n      }\n\n      return [2\n      /*return*/\n      ];\n    });\n  });\n}\n\nfunction onMutationResult(remoteStoreImpl, commitVersion, results) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var batch, success;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          batch = remoteStoreImpl.writePipeline.shift();\n          success = MutationBatchResult.from(batch, commitVersion, results);\n          return [4\n          /*yield*/\n          , executeWithRecovery(remoteStoreImpl, function () {\n            return remoteStoreImpl.remoteSyncer.applySuccessfulWrite(success);\n          })];\n\n        case 1:\n          _d.sent(); // It's possible that with the completion of this mutation another\n          // slot has freed up.\n\n\n          return [4\n          /*yield*/\n          , fillWritePipeline(remoteStoreImpl)];\n\n        case 2:\n          // It's possible that with the completion of this mutation another\n          // slot has freed up.\n          _d.sent();\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction onWriteStreamClose(remoteStoreImpl, error) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          if (!(error && ensureWriteStream(remoteStoreImpl).handshakeComplete)) return [3\n          /*break*/\n          , 2]; // This error affects the actual write.\n\n          return [4\n          /*yield*/\n          , handleWriteError(remoteStoreImpl, error)];\n\n        case 1:\n          // This error affects the actual write.\n          _d.sent();\n\n          _d.label = 2;\n\n        case 2:\n          // The write stream might have been started by refilling the write\n          // pipeline for failed writes\n          if (shouldStartWriteStream(remoteStoreImpl)) {\n            startWriteStream(remoteStoreImpl);\n          }\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction handleWriteError(remoteStoreImpl, error) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var batch_1;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          if (!isPermanentWriteError(error.code)) return [3\n          /*break*/\n          , 3];\n          batch_1 = remoteStoreImpl.writePipeline.shift(); // In this case it's also unlikely that the server itself is melting\n          // down -- this was just a bad request so inhibit backoff on the next\n          // restart.\n\n          ensureWriteStream(remoteStoreImpl).inhibitBackoff();\n          return [4\n          /*yield*/\n          , executeWithRecovery(remoteStoreImpl, function () {\n            return remoteStoreImpl.remoteSyncer.rejectFailedWrite(batch_1.batchId, error);\n          })];\n\n        case 1:\n          _d.sent(); // It's possible that with the completion of this mutation\n          // another slot has freed up.\n\n\n          return [4\n          /*yield*/\n          , fillWritePipeline(remoteStoreImpl)];\n\n        case 2:\n          // It's possible that with the completion of this mutation\n          // another slot has freed up.\n          _d.sent();\n\n          _d.label = 3;\n\n        case 3:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction restartNetwork(remoteStore) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var remoteStoreImpl;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          remoteStoreImpl = debugCast(remoteStore);\n          remoteStoreImpl.offlineCauses.add(4\n          /* ConnectivityChange */\n          );\n          return [4\n          /*yield*/\n          , disableNetworkInternal(remoteStoreImpl)];\n\n        case 1:\n          _d.sent();\n\n          remoteStoreImpl.onlineStateTracker.set(\"Unknown\"\n          /* Unknown */\n          );\n          remoteStoreImpl.offlineCauses.delete(4\n          /* ConnectivityChange */\n          );\n          return [4\n          /*yield*/\n          , enableNetworkInternal(remoteStoreImpl)];\n\n        case 2:\n          _d.sent();\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction remoteStoreHandleCredentialChange(remoteStore, user) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var remoteStoreImpl, usesNetwork;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          remoteStoreImpl = debugCast(remoteStore);\n          remoteStoreImpl.asyncQueue.verifyOperationInProgress();\n          logDebug(LOG_TAG$5, 'RemoteStore received new credentials');\n          usesNetwork = canUseNetwork(remoteStoreImpl); // Tear down and re-create our network streams. This will ensure we get a\n          // fresh auth token for the new user and re-fill the write pipeline with\n          // new mutations from the LocalStore (since mutations are per-user).\n\n          remoteStoreImpl.offlineCauses.add(3\n          /* CredentialChange */\n          );\n          return [4\n          /*yield*/\n          , disableNetworkInternal(remoteStoreImpl)];\n\n        case 1:\n          _d.sent();\n\n          if (usesNetwork) {\n            // Don't set the network status to Unknown if we are offline.\n            remoteStoreImpl.onlineStateTracker.set(\"Unknown\"\n            /* Unknown */\n            );\n          }\n\n          return [4\n          /*yield*/\n          , remoteStoreImpl.remoteSyncer.handleCredentialChange(user)];\n\n        case 2:\n          _d.sent();\n\n          remoteStoreImpl.offlineCauses.delete(3\n          /* CredentialChange */\n          );\n          return [4\n          /*yield*/\n          , enableNetworkInternal(remoteStoreImpl)];\n\n        case 3:\n          _d.sent();\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Toggles the network state when the client gains or loses its primary lease.\r\n */\n\n\nfunction remoteStoreApplyPrimaryState(remoteStore, isPrimary) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var remoteStoreImpl;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          remoteStoreImpl = debugCast(remoteStore);\n          if (!isPrimary) return [3\n          /*break*/\n          , 2];\n          remoteStoreImpl.offlineCauses.delete(2\n          /* IsSecondary */\n          );\n          return [4\n          /*yield*/\n          , enableNetworkInternal(remoteStoreImpl)];\n\n        case 1:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 4];\n\n        case 2:\n          if (!!isPrimary) return [3\n          /*break*/\n          , 4];\n          remoteStoreImpl.offlineCauses.add(2\n          /* IsSecondary */\n          );\n          return [4\n          /*yield*/\n          , disableNetworkInternal(remoteStoreImpl)];\n\n        case 3:\n          _d.sent();\n\n          remoteStoreImpl.onlineStateTracker.set(\"Unknown\"\n          /* Unknown */\n          );\n          _d.label = 4;\n\n        case 4:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * If not yet initialized, registers the WatchStream and its network state\r\n * callback with `remoteStoreImpl`. Returns the existing stream if one is\r\n * already available.\r\n *\r\n * PORTING NOTE: On iOS and Android, the WatchStream gets registered on startup.\r\n * This is not done on Web to allow it to be tree-shaken.\r\n */\n\n\nfunction ensureWatchStream(remoteStoreImpl) {\n  var _this = this;\n\n  if (!remoteStoreImpl.watchStream) {\n    // Create stream (but note that it is not started yet).\n    remoteStoreImpl.watchStream = newPersistentWatchStream(remoteStoreImpl.datastore, remoteStoreImpl.asyncQueue, {\n      onOpen: onWatchStreamOpen.bind(null, remoteStoreImpl),\n      onClose: onWatchStreamClose.bind(null, remoteStoreImpl),\n      onWatchChange: onWatchStreamChange.bind(null, remoteStoreImpl)\n    });\n    remoteStoreImpl.onNetworkStatusChange.push(function (enabled) {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              if (!enabled) return [3\n              /*break*/\n              , 1];\n              remoteStoreImpl.watchStream.inhibitBackoff();\n\n              if (shouldStartWatchStream(remoteStoreImpl)) {\n                startWatchStream(remoteStoreImpl);\n              } else {\n                remoteStoreImpl.onlineStateTracker.set(\"Unknown\"\n                /* Unknown */\n                );\n              }\n\n              return [3\n              /*break*/\n              , 3];\n\n            case 1:\n              return [4\n              /*yield*/\n              , remoteStoreImpl.watchStream.stop()];\n\n            case 2:\n              _d.sent();\n\n              cleanUpWatchStreamState(remoteStoreImpl);\n              _d.label = 3;\n\n            case 3:\n              return [2\n              /*return*/\n              ];\n          }\n        });\n      });\n    });\n  }\n\n  return remoteStoreImpl.watchStream;\n}\n/**\r\n * If not yet initialized, registers the WriteStream and its network state\r\n * callback with `remoteStoreImpl`. Returns the existing stream if one is\r\n * already available.\r\n *\r\n * PORTING NOTE: On iOS and Android, the WriteStream gets registered on startup.\r\n * This is not done on Web to allow it to be tree-shaken.\r\n */\n\n\nfunction ensureWriteStream(remoteStoreImpl) {\n  var _this = this;\n\n  if (!remoteStoreImpl.writeStream) {\n    // Create stream (but note that it is not started yet).\n    remoteStoreImpl.writeStream = newPersistentWriteStream(remoteStoreImpl.datastore, remoteStoreImpl.asyncQueue, {\n      onOpen: onWriteStreamOpen.bind(null, remoteStoreImpl),\n      onClose: onWriteStreamClose.bind(null, remoteStoreImpl),\n      onHandshakeComplete: onWriteHandshakeComplete.bind(null, remoteStoreImpl),\n      onMutationResult: onMutationResult.bind(null, remoteStoreImpl)\n    });\n    remoteStoreImpl.onNetworkStatusChange.push(function (enabled) {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              if (!enabled) return [3\n              /*break*/\n              , 2];\n              remoteStoreImpl.writeStream.inhibitBackoff(); // This will start the write stream if necessary.\n\n              return [4\n              /*yield*/\n              , fillWritePipeline(remoteStoreImpl)];\n\n            case 1:\n              // This will start the write stream if necessary.\n              _d.sent();\n\n              return [3\n              /*break*/\n              , 4];\n\n            case 2:\n              return [4\n              /*yield*/\n              , remoteStoreImpl.writeStream.stop()];\n\n            case 3:\n              _d.sent();\n\n              if (remoteStoreImpl.writePipeline.length > 0) {\n                logDebug(LOG_TAG$5, \"Stopping write stream with \" + remoteStoreImpl.writePipeline.length + \" pending writes\");\n                remoteStoreImpl.writePipeline = [];\n              }\n\n              _d.label = 4;\n\n            case 4:\n              return [2\n              /*return*/\n              ];\n          }\n        });\n      });\n    });\n  }\n\n  return remoteStoreImpl.writeStream;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$4 = 'AsyncQueue';\n/**\r\n * Represents an operation scheduled to be run in the future on an AsyncQueue.\r\n *\r\n * It is created via DelayedOperation.createAndSchedule().\r\n *\r\n * Supports cancellation (via cancel()) and early execution (via skipDelay()).\r\n *\r\n * Note: We implement `PromiseLike` instead of `Promise`, as the `Promise` type\r\n * in newer versions of TypeScript defines `finally`, which is not available in\r\n * IE.\r\n */\n\nvar DelayedOperation =\n/** @class */\nfunction () {\n  function DelayedOperation(asyncQueue, timerId, targetTimeMs, op, removalCallback) {\n    this.asyncQueue = asyncQueue;\n    this.timerId = timerId;\n    this.targetTimeMs = targetTimeMs;\n    this.op = op;\n    this.removalCallback = removalCallback;\n    this.deferred = new Deferred();\n    this.then = this.deferred.promise.then.bind(this.deferred.promise); // It's normal for the deferred promise to be canceled (due to cancellation)\n    // and so we attach a dummy catch callback to avoid\n    // 'UnhandledPromiseRejectionWarning' log spam.\n\n    this.deferred.promise.catch(function (err) {});\n  }\n  /**\r\n   * Creates and returns a DelayedOperation that has been scheduled to be\r\n   * executed on the provided asyncQueue after the provided delayMs.\r\n   *\r\n   * @param asyncQueue - The queue to schedule the operation on.\r\n   * @param id - A Timer ID identifying the type of operation this is.\r\n   * @param delayMs - The delay (ms) before the operation should be scheduled.\r\n   * @param op - The operation to run.\r\n   * @param removalCallback - A callback to be called synchronously once the\r\n   *   operation is executed or canceled, notifying the AsyncQueue to remove it\r\n   *   from its delayedOperations list.\r\n   *   PORTING NOTE: This exists to prevent making removeDelayedOperation() and\r\n   *   the DelayedOperation class public.\r\n   */\n\n\n  DelayedOperation.createAndSchedule = function (asyncQueue, timerId, delayMs, op, removalCallback) {\n    var targetTime = Date.now() + delayMs;\n    var delayedOp = new DelayedOperation(asyncQueue, timerId, targetTime, op, removalCallback);\n    delayedOp.start(delayMs);\n    return delayedOp;\n  };\n  /**\r\n   * Starts the timer. This is called immediately after construction by\r\n   * createAndSchedule().\r\n   */\n\n\n  DelayedOperation.prototype.start = function (delayMs) {\n    var _this = this;\n\n    this.timerHandle = setTimeout(function () {\n      return _this.handleDelayElapsed();\n    }, delayMs);\n  };\n  /**\r\n   * Queues the operation to run immediately (if it hasn't already been run or\r\n   * canceled).\r\n   */\n\n\n  DelayedOperation.prototype.skipDelay = function () {\n    return this.handleDelayElapsed();\n  };\n  /**\r\n   * Cancels the operation if it hasn't already been executed or canceled. The\r\n   * promise will be rejected.\r\n   *\r\n   * As long as the operation has not yet been run, calling cancel() provides a\r\n   * guarantee that the operation will not be run.\r\n   */\n\n\n  DelayedOperation.prototype.cancel = function (reason) {\n    if (this.timerHandle !== null) {\n      this.clearTimeout();\n      this.deferred.reject(new FirestoreError(Code.CANCELLED, 'Operation cancelled' + (reason ? ': ' + reason : '')));\n    }\n  };\n\n  DelayedOperation.prototype.handleDelayElapsed = function () {\n    var _this = this;\n\n    this.asyncQueue.enqueueAndForget(function () {\n      if (_this.timerHandle !== null) {\n        _this.clearTimeout();\n\n        return _this.op().then(function (result) {\n          return _this.deferred.resolve(result);\n        });\n      } else {\n        return Promise.resolve();\n      }\n    });\n  };\n\n  DelayedOperation.prototype.clearTimeout = function () {\n    if (this.timerHandle !== null) {\n      this.removalCallback(this);\n      clearTimeout(this.timerHandle);\n      this.timerHandle = null;\n    }\n  };\n\n  return DelayedOperation;\n}();\n/**\r\n * Returns a FirestoreError that can be surfaced to the user if the provided\r\n * error is an IndexedDbTransactionError. Re-throws the error otherwise.\r\n */\n\n\nfunction wrapInUserErrorIfRecoverable(e, msg) {\n  logError(LOG_TAG$4, msg + \": \" + e);\n\n  if (isIndexedDbTransactionError(e)) {\n    return new FirestoreError(Code.UNAVAILABLE, msg + \": \" + e);\n  } else {\n    throw e;\n  }\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * DocumentSet is an immutable (copy-on-write) collection that holds documents\r\n * in order specified by the provided comparator. We always add a document key\r\n * comparator on top of what is provided to guarantee document equality based on\r\n * the key.\r\n */\n\n\nvar DocumentSet =\n/** @class */\nfunction () {\n  /** The default ordering is by key if the comparator is omitted */\n  function DocumentSet(comp) {\n    // We are adding document key comparator to the end as it's the only\n    // guaranteed unique property of a document.\n    if (comp) {\n      this.comparator = function (d1, d2) {\n        return comp(d1, d2) || DocumentKey.comparator(d1.key, d2.key);\n      };\n    } else {\n      this.comparator = function (d1, d2) {\n        return DocumentKey.comparator(d1.key, d2.key);\n      };\n    }\n\n    this.keyedMap = documentMap();\n    this.sortedSet = new SortedMap(this.comparator);\n  }\n  /**\r\n   * Returns an empty copy of the existing DocumentSet, using the same\r\n   * comparator.\r\n   */\n\n\n  DocumentSet.emptySet = function (oldSet) {\n    return new DocumentSet(oldSet.comparator);\n  };\n\n  DocumentSet.prototype.has = function (key) {\n    return this.keyedMap.get(key) != null;\n  };\n\n  DocumentSet.prototype.get = function (key) {\n    return this.keyedMap.get(key);\n  };\n\n  DocumentSet.prototype.first = function () {\n    return this.sortedSet.minKey();\n  };\n\n  DocumentSet.prototype.last = function () {\n    return this.sortedSet.maxKey();\n  };\n\n  DocumentSet.prototype.isEmpty = function () {\n    return this.sortedSet.isEmpty();\n  };\n  /**\r\n   * Returns the index of the provided key in the document set, or -1 if the\r\n   * document key is not present in the set;\r\n   */\n\n\n  DocumentSet.prototype.indexOf = function (key) {\n    var doc = this.keyedMap.get(key);\n    return doc ? this.sortedSet.indexOf(doc) : -1;\n  };\n\n  Object.defineProperty(DocumentSet.prototype, \"size\", {\n    get: function () {\n      return this.sortedSet.size;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /** Iterates documents in order defined by \"comparator\" */\n\n  DocumentSet.prototype.forEach = function (cb) {\n    this.sortedSet.inorderTraversal(function (k, v) {\n      cb(k);\n      return false;\n    });\n  };\n  /** Inserts or updates a document with the same key */\n\n\n  DocumentSet.prototype.add = function (doc) {\n    // First remove the element if we have it.\n    var set = this.delete(doc.key);\n    return set.copy(set.keyedMap.insert(doc.key, doc), set.sortedSet.insert(doc, null));\n  };\n  /** Deletes a document with a given key */\n\n\n  DocumentSet.prototype.delete = function (key) {\n    var doc = this.get(key);\n\n    if (!doc) {\n      return this;\n    }\n\n    return this.copy(this.keyedMap.remove(key), this.sortedSet.remove(doc));\n  };\n\n  DocumentSet.prototype.isEqual = function (other) {\n    if (!(other instanceof DocumentSet)) {\n      return false;\n    }\n\n    if (this.size !== other.size) {\n      return false;\n    }\n\n    var thisIt = this.sortedSet.getIterator();\n    var otherIt = other.sortedSet.getIterator();\n\n    while (thisIt.hasNext()) {\n      var thisDoc = thisIt.getNext().key;\n      var otherDoc = otherIt.getNext().key;\n\n      if (!thisDoc.isEqual(otherDoc)) {\n        return false;\n      }\n    }\n\n    return true;\n  };\n\n  DocumentSet.prototype.toString = function () {\n    var docStrings = [];\n    this.forEach(function (doc) {\n      docStrings.push(doc.toString());\n    });\n\n    if (docStrings.length === 0) {\n      return 'DocumentSet ()';\n    } else {\n      return 'DocumentSet (\\n  ' + docStrings.join('  \\n') + '\\n)';\n    }\n  };\n\n  DocumentSet.prototype.copy = function (keyedMap, sortedSet) {\n    var newSet = new DocumentSet();\n    newSet.comparator = this.comparator;\n    newSet.keyedMap = keyedMap;\n    newSet.sortedSet = sortedSet;\n    return newSet;\n  };\n\n  return DocumentSet;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * DocumentChangeSet keeps track of a set of changes to docs in a query, merging\r\n * duplicate events for the same doc.\r\n */\n\n\nvar DocumentChangeSet =\n/** @class */\nfunction () {\n  function DocumentChangeSet() {\n    this.changeMap = new SortedMap(DocumentKey.comparator);\n  }\n\n  DocumentChangeSet.prototype.track = function (change) {\n    var key = change.doc.key;\n    var oldChange = this.changeMap.get(key);\n\n    if (!oldChange) {\n      this.changeMap = this.changeMap.insert(key, change);\n      return;\n    } // Merge the new change with the existing change.\n\n\n    if (change.type !== 0\n    /* Added */\n    && oldChange.type === 3\n    /* Metadata */\n    ) {\n        this.changeMap = this.changeMap.insert(key, change);\n      } else if (change.type === 3\n    /* Metadata */\n    && oldChange.type !== 1\n    /* Removed */\n    ) {\n        this.changeMap = this.changeMap.insert(key, {\n          type: oldChange.type,\n          doc: change.doc\n        });\n      } else if (change.type === 2\n    /* Modified */\n    && oldChange.type === 2\n    /* Modified */\n    ) {\n        this.changeMap = this.changeMap.insert(key, {\n          type: 2\n          /* Modified */\n          ,\n          doc: change.doc\n        });\n      } else if (change.type === 2\n    /* Modified */\n    && oldChange.type === 0\n    /* Added */\n    ) {\n        this.changeMap = this.changeMap.insert(key, {\n          type: 0\n          /* Added */\n          ,\n          doc: change.doc\n        });\n      } else if (change.type === 1\n    /* Removed */\n    && oldChange.type === 0\n    /* Added */\n    ) {\n        this.changeMap = this.changeMap.remove(key);\n      } else if (change.type === 1\n    /* Removed */\n    && oldChange.type === 2\n    /* Modified */\n    ) {\n        this.changeMap = this.changeMap.insert(key, {\n          type: 1\n          /* Removed */\n          ,\n          doc: oldChange.doc\n        });\n      } else if (change.type === 0\n    /* Added */\n    && oldChange.type === 1\n    /* Removed */\n    ) {\n        this.changeMap = this.changeMap.insert(key, {\n          type: 2\n          /* Modified */\n          ,\n          doc: change.doc\n        });\n      } else {\n      // This includes these cases, which don't make sense:\n      // Added->Added\n      // Removed->Removed\n      // Modified->Added\n      // Removed->Modified\n      // Metadata->Added\n      // Removed->Metadata\n      fail();\n    }\n  };\n\n  DocumentChangeSet.prototype.getChanges = function () {\n    var changes = [];\n    this.changeMap.inorderTraversal(function (key, change) {\n      changes.push(change);\n    });\n    return changes;\n  };\n\n  return DocumentChangeSet;\n}();\n\nvar ViewSnapshot =\n/** @class */\nfunction () {\n  function ViewSnapshot(query, docs, oldDocs, docChanges, mutatedKeys, fromCache, syncStateChanged, excludesMetadataChanges) {\n    this.query = query;\n    this.docs = docs;\n    this.oldDocs = oldDocs;\n    this.docChanges = docChanges;\n    this.mutatedKeys = mutatedKeys;\n    this.fromCache = fromCache;\n    this.syncStateChanged = syncStateChanged;\n    this.excludesMetadataChanges = excludesMetadataChanges;\n  }\n  /** Returns a view snapshot as if all documents in the snapshot were added. */\n\n\n  ViewSnapshot.fromInitialDocuments = function (query, documents, mutatedKeys, fromCache) {\n    var changes = [];\n    documents.forEach(function (doc) {\n      changes.push({\n        type: 0\n        /* Added */\n        ,\n        doc: doc\n      });\n    });\n    return new ViewSnapshot(query, documents, DocumentSet.emptySet(documents), changes, mutatedKeys, fromCache,\n    /* syncStateChanged= */\n    true,\n    /* excludesMetadataChanges= */\n    false);\n  };\n\n  Object.defineProperty(ViewSnapshot.prototype, \"hasPendingWrites\", {\n    get: function () {\n      return !this.mutatedKeys.isEmpty();\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  ViewSnapshot.prototype.isEqual = function (other) {\n    if (this.fromCache !== other.fromCache || this.syncStateChanged !== other.syncStateChanged || !this.mutatedKeys.isEqual(other.mutatedKeys) || !queryEquals(this.query, other.query) || !this.docs.isEqual(other.docs) || !this.oldDocs.isEqual(other.oldDocs)) {\n      return false;\n    }\n\n    var changes = this.docChanges;\n    var otherChanges = other.docChanges;\n\n    if (changes.length !== otherChanges.length) {\n      return false;\n    }\n\n    for (var i = 0; i < changes.length; i++) {\n      if (changes[i].type !== otherChanges[i].type || !changes[i].doc.isEqual(otherChanges[i].doc)) {\n        return false;\n      }\n    }\n\n    return true;\n  };\n\n  return ViewSnapshot;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Holds the listeners and the last received ViewSnapshot for a query being\r\n * tracked by EventManager.\r\n */\n\n\nvar QueryListenersInfo =\n/** @class */\nfunction () {\n  function QueryListenersInfo() {\n    this.viewSnap = undefined;\n    this.listeners = [];\n  }\n\n  return QueryListenersInfo;\n}();\n\nfunction newEventManager() {\n  return new EventManagerImpl();\n}\n\nvar EventManagerImpl =\n/** @class */\nfunction () {\n  function EventManagerImpl() {\n    this.queries = new ObjectMap(function (q) {\n      return canonifyQuery(q);\n    }, queryEquals);\n    this.onlineState = \"Unknown\"\n    /* Unknown */\n    ;\n    this.snapshotsInSyncListeners = new Set();\n  }\n\n  return EventManagerImpl;\n}();\n\nfunction eventManagerListen(eventManager, listener) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var eventManagerImpl, query, firstListen, queryInfo, _d, e_7, firestoreError, raisedEvent;\n\n    return tslib.__generator(this, function (_e) {\n      switch (_e.label) {\n        case 0:\n          eventManagerImpl = debugCast(eventManager);\n          query = listener.query;\n          firstListen = false;\n          queryInfo = eventManagerImpl.queries.get(query);\n\n          if (!queryInfo) {\n            firstListen = true;\n            queryInfo = new QueryListenersInfo();\n          }\n\n          if (!firstListen) return [3\n          /*break*/\n          , 4];\n          _e.label = 1;\n\n        case 1:\n          _e.trys.push([1, 3,, 4]);\n\n          _d = queryInfo;\n          return [4\n          /*yield*/\n          , eventManagerImpl.onListen(query)];\n\n        case 2:\n          _d.viewSnap = _e.sent();\n          return [3\n          /*break*/\n          , 4];\n\n        case 3:\n          e_7 = _e.sent();\n          firestoreError = wrapInUserErrorIfRecoverable(e_7, \"Initialization of query '\" + stringifyQuery(listener.query) + \"' failed\");\n          listener.onError(firestoreError);\n          return [2\n          /*return*/\n          ];\n\n        case 4:\n          eventManagerImpl.queries.set(query, queryInfo);\n          queryInfo.listeners.push(listener); // Run global snapshot listeners if a consistent snapshot has been emitted.\n\n          listener.applyOnlineStateChange(eventManagerImpl.onlineState);\n\n          if (queryInfo.viewSnap) {\n            raisedEvent = listener.onViewSnapshot(queryInfo.viewSnap);\n\n            if (raisedEvent) {\n              raiseSnapshotsInSyncEvent(eventManagerImpl);\n            }\n          }\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction eventManagerUnlisten(eventManager, listener) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var eventManagerImpl, query, lastListen, queryInfo, i;\n    return tslib.__generator(this, function (_d) {\n      eventManagerImpl = debugCast(eventManager);\n      query = listener.query;\n      lastListen = false;\n      queryInfo = eventManagerImpl.queries.get(query);\n\n      if (queryInfo) {\n        i = queryInfo.listeners.indexOf(listener);\n\n        if (i >= 0) {\n          queryInfo.listeners.splice(i, 1);\n          lastListen = queryInfo.listeners.length === 0;\n        }\n      }\n\n      if (lastListen) {\n        eventManagerImpl.queries.delete(query);\n        return [2\n        /*return*/\n        , eventManagerImpl.onUnlisten(query)];\n      }\n\n      return [2\n      /*return*/\n      ];\n    });\n  });\n}\n\nfunction eventManagerOnWatchChange(eventManager, viewSnaps) {\n  var eventManagerImpl = debugCast(eventManager);\n  var raisedEvent = false;\n\n  for (var _i = 0, viewSnaps_1 = viewSnaps; _i < viewSnaps_1.length; _i++) {\n    var viewSnap = viewSnaps_1[_i];\n    var query_1 = viewSnap.query;\n    var queryInfo = eventManagerImpl.queries.get(query_1);\n\n    if (queryInfo) {\n      for (var _d = 0, _e = queryInfo.listeners; _d < _e.length; _d++) {\n        var listener = _e[_d];\n\n        if (listener.onViewSnapshot(viewSnap)) {\n          raisedEvent = true;\n        }\n      }\n\n      queryInfo.viewSnap = viewSnap;\n    }\n  }\n\n  if (raisedEvent) {\n    raiseSnapshotsInSyncEvent(eventManagerImpl);\n  }\n}\n\nfunction eventManagerOnWatchError(eventManager, query, error) {\n  var eventManagerImpl = debugCast(eventManager);\n  var queryInfo = eventManagerImpl.queries.get(query);\n\n  if (queryInfo) {\n    for (var _i = 0, _d = queryInfo.listeners; _i < _d.length; _i++) {\n      var listener = _d[_i];\n      listener.onError(error);\n    }\n  } // Remove all listeners. NOTE: We don't need to call syncEngine.unlisten()\n  // after an error.\n\n\n  eventManagerImpl.queries.delete(query);\n}\n\nfunction eventManagerOnOnlineStateChange(eventManager, onlineState) {\n  var eventManagerImpl = debugCast(eventManager);\n  eventManagerImpl.onlineState = onlineState;\n  var raisedEvent = false;\n  eventManagerImpl.queries.forEach(function (_, queryInfo) {\n    for (var _i = 0, _d = queryInfo.listeners; _i < _d.length; _i++) {\n      var listener = _d[_i]; // Run global snapshot listeners if a consistent snapshot has been emitted.\n\n      if (listener.applyOnlineStateChange(onlineState)) {\n        raisedEvent = true;\n      }\n    }\n  });\n\n  if (raisedEvent) {\n    raiseSnapshotsInSyncEvent(eventManagerImpl);\n  }\n}\n\nfunction addSnapshotsInSyncListener(eventManager, observer) {\n  var eventManagerImpl = debugCast(eventManager);\n  eventManagerImpl.snapshotsInSyncListeners.add(observer); // Immediately fire an initial event, indicating all existing listeners\n  // are in-sync.\n\n  observer.next();\n}\n\nfunction removeSnapshotsInSyncListener(eventManager, observer) {\n  var eventManagerImpl = debugCast(eventManager);\n  eventManagerImpl.snapshotsInSyncListeners.delete(observer);\n} // Call all global snapshot listeners that have been set.\n\n\nfunction raiseSnapshotsInSyncEvent(eventManagerImpl) {\n  eventManagerImpl.snapshotsInSyncListeners.forEach(function (observer) {\n    observer.next();\n  });\n}\n/**\r\n * QueryListener takes a series of internal view snapshots and determines\r\n * when to raise the event.\r\n *\r\n * It uses an Observer to dispatch events.\r\n */\n\n\nvar QueryListener =\n/** @class */\nfunction () {\n  function QueryListener(query, queryObserver, options) {\n    this.query = query;\n    this.queryObserver = queryObserver;\n    /**\r\n     * Initial snapshots (e.g. from cache) may not be propagated to the wrapped\r\n     * observer. This flag is set to true once we've actually raised an event.\r\n     */\n\n    this.raisedInitialEvent = false;\n    this.snap = null;\n    this.onlineState = \"Unknown\"\n    /* Unknown */\n    ;\n    this.options = options || {};\n  }\n  /**\r\n   * Applies the new ViewSnapshot to this listener, raising a user-facing event\r\n   * if applicable (depending on what changed, whether the user has opted into\r\n   * metadata-only changes, etc.). Returns true if a user-facing event was\r\n   * indeed raised.\r\n   */\n\n\n  QueryListener.prototype.onViewSnapshot = function (snap) {\n    if (!this.options.includeMetadataChanges) {\n      // Remove the metadata only changes.\n      var docChanges = [];\n\n      for (var _i = 0, _d = snap.docChanges; _i < _d.length; _i++) {\n        var docChange = _d[_i];\n\n        if (docChange.type !== 3\n        /* Metadata */\n        ) {\n            docChanges.push(docChange);\n          }\n      }\n\n      snap = new ViewSnapshot(snap.query, snap.docs, snap.oldDocs, docChanges, snap.mutatedKeys, snap.fromCache, snap.syncStateChanged,\n      /* excludesMetadataChanges= */\n      true);\n    }\n\n    var raisedEvent = false;\n\n    if (!this.raisedInitialEvent) {\n      if (this.shouldRaiseInitialEvent(snap, this.onlineState)) {\n        this.raiseInitialEvent(snap);\n        raisedEvent = true;\n      }\n    } else if (this.shouldRaiseEvent(snap)) {\n      this.queryObserver.next(snap);\n      raisedEvent = true;\n    }\n\n    this.snap = snap;\n    return raisedEvent;\n  };\n\n  QueryListener.prototype.onError = function (error) {\n    this.queryObserver.error(error);\n  };\n  /** Returns whether a snapshot was raised. */\n\n\n  QueryListener.prototype.applyOnlineStateChange = function (onlineState) {\n    this.onlineState = onlineState;\n    var raisedEvent = false;\n\n    if (this.snap && !this.raisedInitialEvent && this.shouldRaiseInitialEvent(this.snap, onlineState)) {\n      this.raiseInitialEvent(this.snap);\n      raisedEvent = true;\n    }\n\n    return raisedEvent;\n  };\n\n  QueryListener.prototype.shouldRaiseInitialEvent = function (snap, onlineState) {\n    // Always raise the first event when we're synced\n    if (!snap.fromCache) {\n      return true;\n    } // NOTE: We consider OnlineState.Unknown as online (it should become Offline\n    // or Online if we wait long enough).\n\n\n    var maybeOnline = onlineState !== \"Offline\"\n    /* Offline */\n    ; // Don't raise the event if we're online, aren't synced yet (checked\n    // above) and are waiting for a sync.\n\n    if (this.options.waitForSyncWhenOnline && maybeOnline) {\n      return false;\n    } // Raise data from cache if we have any documents or we are offline\n\n\n    return !snap.docs.isEmpty() || onlineState === \"Offline\"\n    /* Offline */\n    ;\n  };\n\n  QueryListener.prototype.shouldRaiseEvent = function (snap) {\n    // We don't need to handle includeDocumentMetadataChanges here because\n    // the Metadata only changes have already been stripped out if needed.\n    // At this point the only changes we will see are the ones we should\n    // propagate.\n    if (snap.docChanges.length > 0) {\n      return true;\n    }\n\n    var hasPendingWritesChanged = this.snap && this.snap.hasPendingWrites !== snap.hasPendingWrites;\n\n    if (snap.syncStateChanged || hasPendingWritesChanged) {\n      return this.options.includeMetadataChanges === true;\n    } // Generally we should have hit one of the cases above, but it's possible\n    // to get here if there were only metadata docChanges and they got\n    // stripped out.\n\n\n    return false;\n  };\n\n  QueryListener.prototype.raiseInitialEvent = function (snap) {\n    snap = ViewSnapshot.fromInitialDocuments(snap.query, snap.docs, snap.mutatedKeys, snap.fromCache);\n    this.raisedInitialEvent = true;\n    this.queryObserver.next(snap);\n  };\n\n  return QueryListener;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A set of changes to what documents are currently in view and out of view for\r\n * a given query. These changes are sent to the LocalStore by the View (via\r\n * the SyncEngine) and are used to pin / unpin documents as appropriate.\r\n */\n\n\nvar LocalViewChanges =\n/** @class */\nfunction () {\n  function LocalViewChanges(targetId, fromCache, addedKeys, removedKeys) {\n    this.targetId = targetId;\n    this.fromCache = fromCache;\n    this.addedKeys = addedKeys;\n    this.removedKeys = removedKeys;\n  }\n\n  LocalViewChanges.fromSnapshot = function (targetId, viewSnapshot) {\n    var addedKeys = documentKeySet();\n    var removedKeys = documentKeySet();\n\n    for (var _i = 0, _d = viewSnapshot.docChanges; _i < _d.length; _i++) {\n      var docChange = _d[_i];\n\n      switch (docChange.type) {\n        case 0\n        /* Added */\n        :\n          addedKeys = addedKeys.add(docChange.doc.key);\n          break;\n\n        case 1\n        /* Removed */\n        :\n          removedKeys = removedKeys.add(docChange.doc.key);\n          break;\n        // do nothing\n      }\n    }\n\n    return new LocalViewChanges(targetId, viewSnapshot.fromCache, addedKeys, removedKeys);\n  };\n\n  return LocalViewChanges;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar BundleLoadResult =\n/** @class */\nfunction () {\n  function BundleLoadResult(progress, changedDocs) {\n    this.progress = progress;\n    this.changedDocs = changedDocs;\n  }\n\n  return BundleLoadResult;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Helper to convert objects from bundles to model objects in the SDK.\r\n */\n\n\nvar BundleConverterImpl =\n/** @class */\nfunction () {\n  function BundleConverterImpl(serializer) {\n    this.serializer = serializer;\n  }\n\n  BundleConverterImpl.prototype.toDocumentKey = function (name) {\n    return fromName(this.serializer, name);\n  };\n  /**\r\n   * Converts a BundleDocument to a MutableDocument.\r\n   */\n\n\n  BundleConverterImpl.prototype.toMutableDocument = function (bundledDoc) {\n    if (bundledDoc.metadata.exists) {\n      return fromDocument(this.serializer, bundledDoc.document, false);\n    } else {\n      return MutableDocument.newNoDocument(this.toDocumentKey(bundledDoc.metadata.name), this.toSnapshotVersion(bundledDoc.metadata.readTime));\n    }\n  };\n\n  BundleConverterImpl.prototype.toSnapshotVersion = function (time) {\n    return fromVersion(time);\n  };\n\n  return BundleConverterImpl;\n}();\n/**\r\n * A class to process the elements from a bundle, load them into local\r\n * storage and provide progress update while loading.\r\n */\n\n\nvar BundleLoader =\n/** @class */\nfunction () {\n  function BundleLoader(bundleMetadata, localStore, serializer) {\n    this.bundleMetadata = bundleMetadata;\n    this.localStore = localStore;\n    this.serializer = serializer;\n    /** Batched queries to be saved into storage */\n\n    this.queries = [];\n    /** Batched documents to be saved into storage */\n\n    this.documents = [];\n    this.progress = bundleInitialProgress(bundleMetadata);\n  }\n  /**\r\n   * Adds an element from the bundle to the loader.\r\n   *\r\n   * Returns a new progress if adding the element leads to a new progress,\r\n   * otherwise returns null.\r\n   */\n\n\n  BundleLoader.prototype.addSizedElement = function (element) {\n    this.progress.bytesLoaded += element.byteLength;\n    var documentsLoaded = this.progress.documentsLoaded;\n\n    if (element.payload.namedQuery) {\n      this.queries.push(element.payload.namedQuery);\n    } else if (element.payload.documentMetadata) {\n      this.documents.push({\n        metadata: element.payload.documentMetadata\n      });\n\n      if (!element.payload.documentMetadata.exists) {\n        ++documentsLoaded;\n      }\n    } else if (element.payload.document) {\n      this.documents[this.documents.length - 1].document = element.payload.document;\n      ++documentsLoaded;\n    }\n\n    if (documentsLoaded !== this.progress.documentsLoaded) {\n      this.progress.documentsLoaded = documentsLoaded;\n      return Object.assign({}, this.progress);\n    }\n\n    return null;\n  };\n\n  BundleLoader.prototype.getQueryDocumentMapping = function (documents) {\n    var queryDocumentMap = new Map();\n    var bundleConverter = new BundleConverterImpl(this.serializer);\n\n    for (var _i = 0, documents_2 = documents; _i < documents_2.length; _i++) {\n      var bundleDoc = documents_2[_i];\n\n      if (bundleDoc.metadata.queries) {\n        var documentKey = bundleConverter.toDocumentKey(bundleDoc.metadata.name);\n\n        for (var _d = 0, _e = bundleDoc.metadata.queries; _d < _e.length; _d++) {\n          var queryName = _e[_d];\n          var documentKeys = (queryDocumentMap.get(queryName) || documentKeySet()).add(documentKey);\n          queryDocumentMap.set(queryName, documentKeys);\n        }\n      }\n    }\n\n    return queryDocumentMap;\n  };\n  /**\r\n   * Update the progress to 'Success' and return the updated progress.\r\n   */\n\n\n  BundleLoader.prototype.complete = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var changedDocuments, queryDocumentMap, _i, _d, q;\n\n      return tslib.__generator(this, function (_e) {\n        switch (_e.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , localStoreApplyBundledDocuments(this.localStore, new BundleConverterImpl(this.serializer), this.documents, this.bundleMetadata.id)];\n\n          case 1:\n            changedDocuments = _e.sent();\n            queryDocumentMap = this.getQueryDocumentMapping(this.documents);\n            _i = 0, _d = this.queries;\n            _e.label = 2;\n\n          case 2:\n            if (!(_i < _d.length)) return [3\n            /*break*/\n            , 5];\n            q = _d[_i];\n            return [4\n            /*yield*/\n            , localStoreSaveNamedQuery(this.localStore, q, queryDocumentMap.get(q.name))];\n\n          case 3:\n            _e.sent();\n\n            _e.label = 4;\n\n          case 4:\n            _i++;\n            return [3\n            /*break*/\n            , 2];\n\n          case 5:\n            this.progress.taskState = 'Success';\n            return [2\n            /*return*/\n            , new BundleLoadResult(Object.assign({}, this.progress), changedDocuments)];\n        }\n      });\n    });\n  };\n\n  return BundleLoader;\n}();\n/**\r\n * Returns a `LoadBundleTaskProgress` representing the initial progress of\r\n * loading a bundle.\r\n */\n\n\nfunction bundleInitialProgress(metadata) {\n  return {\n    taskState: 'Running',\n    documentsLoaded: 0,\n    bytesLoaded: 0,\n    totalDocuments: metadata.totalDocuments,\n    totalBytes: metadata.totalBytes\n  };\n}\n/**\r\n * Returns a `LoadBundleTaskProgress` representing the progress that the loading\r\n * has succeeded.\r\n */\n\n\nfunction bundleSuccessProgress(metadata) {\n  return {\n    taskState: 'Success',\n    documentsLoaded: metadata.totalDocuments,\n    bytesLoaded: metadata.totalBytes,\n    totalDocuments: metadata.totalDocuments,\n    totalBytes: metadata.totalBytes\n  };\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar AddedLimboDocument =\n/** @class */\nfunction () {\n  function AddedLimboDocument(key) {\n    this.key = key;\n  }\n\n  return AddedLimboDocument;\n}();\n\nvar RemovedLimboDocument =\n/** @class */\nfunction () {\n  function RemovedLimboDocument(key) {\n    this.key = key;\n  }\n\n  return RemovedLimboDocument;\n}();\n/**\r\n * View is responsible for computing the final merged truth of what docs are in\r\n * a query. It gets notified of local and remote changes to docs, and applies\r\n * the query filters and limits to determine the most correct possible results.\r\n */\n\n\nvar View =\n/** @class */\nfunction () {\n  function View(query,\n  /** Documents included in the remote target */\n  _syncedDocuments) {\n    this.query = query;\n    this._syncedDocuments = _syncedDocuments;\n    this.syncState = null;\n    /**\r\n     * A flag whether the view is current with the backend. A view is considered\r\n     * current after it has seen the current flag from the backend and did not\r\n     * lose consistency within the watch stream (e.g. because of an existence\r\n     * filter mismatch).\r\n     */\n\n    this.current = false;\n    /** Documents in the view but not in the remote target */\n\n    this.limboDocuments = documentKeySet();\n    /** Document Keys that have local changes */\n\n    this.mutatedKeys = documentKeySet();\n    this.docComparator = newQueryComparator(query);\n    this.documentSet = new DocumentSet(this.docComparator);\n  }\n\n  Object.defineProperty(View.prototype, \"syncedDocuments\", {\n    /**\r\n     * The set of remote documents that the server has told us belongs to the target associated with\r\n     * this view.\r\n     */\n    get: function () {\n      return this._syncedDocuments;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Iterates over a set of doc changes, applies the query limit, and computes\r\n   * what the new results should be, what the changes were, and whether we may\r\n   * need to go back to the local cache for more results. Does not make any\r\n   * changes to the view.\r\n   * @param docChanges - The doc changes to apply to this view.\r\n   * @param previousChanges - If this is being called with a refill, then start\r\n   *        with this set of docs and changes instead of the current view.\r\n   * @returns a new set of docs, changes, and refill flag.\r\n   */\n\n  View.prototype.computeDocChanges = function (docChanges, previousChanges) {\n    var _this = this;\n\n    var changeSet = previousChanges ? previousChanges.changeSet : new DocumentChangeSet();\n    var oldDocumentSet = previousChanges ? previousChanges.documentSet : this.documentSet;\n    var newMutatedKeys = previousChanges ? previousChanges.mutatedKeys : this.mutatedKeys;\n    var newDocumentSet = oldDocumentSet;\n    var needsRefill = false; // Track the last doc in a (full) limit. This is necessary, because some\n    // update (a delete, or an update moving a doc past the old limit) might\n    // mean there is some other document in the local cache that either should\n    // come (1) between the old last limit doc and the new last document, in the\n    // case of updates, or (2) after the new last document, in the case of\n    // deletes. So we keep this doc at the old limit to compare the updates to.\n    //\n    // Note that this should never get used in a refill (when previousChanges is\n    // set), because there will only be adds -- no deletes or updates.\n\n    var lastDocInLimit = hasLimitToFirst(this.query) && oldDocumentSet.size === this.query.limit ? oldDocumentSet.last() : null;\n    var firstDocInLimit = hasLimitToLast(this.query) && oldDocumentSet.size === this.query.limit ? oldDocumentSet.first() : null;\n    docChanges.inorderTraversal(function (key, entry) {\n      var oldDoc = oldDocumentSet.get(key);\n      var newDoc = queryMatches(_this.query, entry) ? entry : null;\n      var oldDocHadPendingMutations = oldDoc ? _this.mutatedKeys.has(oldDoc.key) : false;\n      var newDocHasPendingMutations = newDoc ? newDoc.hasLocalMutations || // We only consider committed mutations for documents that were\n      // mutated during the lifetime of the view.\n      _this.mutatedKeys.has(newDoc.key) && newDoc.hasCommittedMutations : false;\n      var changeApplied = false; // Calculate change\n\n      if (oldDoc && newDoc) {\n        var docsEqual = oldDoc.data.isEqual(newDoc.data);\n\n        if (!docsEqual) {\n          if (!_this.shouldWaitForSyncedDocument(oldDoc, newDoc)) {\n            changeSet.track({\n              type: 2\n              /* Modified */\n              ,\n              doc: newDoc\n            });\n            changeApplied = true;\n\n            if (lastDocInLimit && _this.docComparator(newDoc, lastDocInLimit) > 0 || firstDocInLimit && _this.docComparator(newDoc, firstDocInLimit) < 0) {\n              // This doc moved from inside the limit to outside the limit.\n              // That means there may be some other doc in the local cache\n              // that should be included instead.\n              needsRefill = true;\n            }\n          }\n        } else if (oldDocHadPendingMutations !== newDocHasPendingMutations) {\n          changeSet.track({\n            type: 3\n            /* Metadata */\n            ,\n            doc: newDoc\n          });\n          changeApplied = true;\n        }\n      } else if (!oldDoc && newDoc) {\n        changeSet.track({\n          type: 0\n          /* Added */\n          ,\n          doc: newDoc\n        });\n        changeApplied = true;\n      } else if (oldDoc && !newDoc) {\n        changeSet.track({\n          type: 1\n          /* Removed */\n          ,\n          doc: oldDoc\n        });\n        changeApplied = true;\n\n        if (lastDocInLimit || firstDocInLimit) {\n          // A doc was removed from a full limit query. We'll need to\n          // requery from the local cache to see if we know about some other\n          // doc that should be in the results.\n          needsRefill = true;\n        }\n      }\n\n      if (changeApplied) {\n        if (newDoc) {\n          newDocumentSet = newDocumentSet.add(newDoc);\n\n          if (newDocHasPendingMutations) {\n            newMutatedKeys = newMutatedKeys.add(key);\n          } else {\n            newMutatedKeys = newMutatedKeys.delete(key);\n          }\n        } else {\n          newDocumentSet = newDocumentSet.delete(key);\n          newMutatedKeys = newMutatedKeys.delete(key);\n        }\n      }\n    }); // Drop documents out to meet limit/limitToLast requirement.\n\n    if (hasLimitToFirst(this.query) || hasLimitToLast(this.query)) {\n      while (newDocumentSet.size > this.query.limit) {\n        var oldDoc = hasLimitToFirst(this.query) ? newDocumentSet.last() : newDocumentSet.first();\n        newDocumentSet = newDocumentSet.delete(oldDoc.key);\n        newMutatedKeys = newMutatedKeys.delete(oldDoc.key);\n        changeSet.track({\n          type: 1\n          /* Removed */\n          ,\n          doc: oldDoc\n        });\n      }\n    }\n\n    return {\n      documentSet: newDocumentSet,\n      changeSet: changeSet,\n      needsRefill: needsRefill,\n      mutatedKeys: newMutatedKeys\n    };\n  };\n\n  View.prototype.shouldWaitForSyncedDocument = function (oldDoc, newDoc) {\n    // We suppress the initial change event for documents that were modified as\n    // part of a write acknowledgment (e.g. when the value of a server transform\n    // is applied) as Watch will send us the same document again.\n    // By suppressing the event, we only raise two user visible events (one with\n    // `hasPendingWrites` and the final state of the document) instead of three\n    // (one with `hasPendingWrites`, the modified document with\n    // `hasPendingWrites` and the final state of the document).\n    return oldDoc.hasLocalMutations && newDoc.hasCommittedMutations && !newDoc.hasLocalMutations;\n  };\n  /**\r\n   * Updates the view with the given ViewDocumentChanges and optionally updates\r\n   * limbo docs and sync state from the provided target change.\r\n   * @param docChanges - The set of changes to make to the view's docs.\r\n   * @param updateLimboDocuments - Whether to update limbo documents based on\r\n   *        this change.\r\n   * @param targetChange - A target change to apply for computing limbo docs and\r\n   *        sync state.\r\n   * @returns A new ViewChange with the given docs, changes, and sync state.\r\n   */\n  // PORTING NOTE: The iOS/Android clients always compute limbo document changes.\n\n\n  View.prototype.applyChanges = function (docChanges, updateLimboDocuments, targetChange) {\n    var _this = this;\n\n    var oldDocs = this.documentSet;\n    this.documentSet = docChanges.documentSet;\n    this.mutatedKeys = docChanges.mutatedKeys; // Sort changes based on type and query comparator\n\n    var changes = docChanges.changeSet.getChanges();\n    changes.sort(function (c1, c2) {\n      return compareChangeType(c1.type, c2.type) || _this.docComparator(c1.doc, c2.doc);\n    });\n    this.applyTargetChange(targetChange);\n    var limboChanges = updateLimboDocuments ? this.updateLimboDocuments() : [];\n    var synced = this.limboDocuments.size === 0 && this.current;\n    var newSyncState = synced ? 1\n    /* Synced */\n    : 0\n    /* Local */\n    ;\n    var syncStateChanged = newSyncState !== this.syncState;\n    this.syncState = newSyncState;\n\n    if (changes.length === 0 && !syncStateChanged) {\n      // no changes\n      return {\n        limboChanges: limboChanges\n      };\n    } else {\n      var snap = new ViewSnapshot(this.query, docChanges.documentSet, oldDocs, changes, docChanges.mutatedKeys, newSyncState === 0\n      /* Local */\n      , syncStateChanged,\n      /* excludesMetadataChanges= */\n      false);\n      return {\n        snapshot: snap,\n        limboChanges: limboChanges\n      };\n    }\n  };\n  /**\r\n   * Applies an OnlineState change to the view, potentially generating a\r\n   * ViewChange if the view's syncState changes as a result.\r\n   */\n\n\n  View.prototype.applyOnlineStateChange = function (onlineState) {\n    if (this.current && onlineState === \"Offline\"\n    /* Offline */\n    ) {\n        // If we're offline, set `current` to false and then call applyChanges()\n        // to refresh our syncState and generate a ViewChange as appropriate. We\n        // are guaranteed to get a new TargetChange that sets `current` back to\n        // true once the client is back online.\n        this.current = false;\n        return this.applyChanges({\n          documentSet: this.documentSet,\n          changeSet: new DocumentChangeSet(),\n          mutatedKeys: this.mutatedKeys,\n          needsRefill: false\n        },\n        /* updateLimboDocuments= */\n        false);\n      } else {\n      // No effect, just return a no-op ViewChange.\n      return {\n        limboChanges: []\n      };\n    }\n  };\n  /**\r\n   * Returns whether the doc for the given key should be in limbo.\r\n   */\n\n\n  View.prototype.shouldBeInLimbo = function (key) {\n    // If the remote end says it's part of this query, it's not in limbo.\n    if (this._syncedDocuments.has(key)) {\n      return false;\n    } // The local store doesn't think it's a result, so it shouldn't be in limbo.\n\n\n    if (!this.documentSet.has(key)) {\n      return false;\n    } // If there are local changes to the doc, they might explain why the server\n    // doesn't know that it's part of the query. So don't put it in limbo.\n    // TODO(klimt): Ideally, we would only consider changes that might actually\n    // affect this specific query.\n\n\n    if (this.documentSet.get(key).hasLocalMutations) {\n      return false;\n    } // Everything else is in limbo.\n\n\n    return true;\n  };\n  /**\r\n   * Updates syncedDocuments, current, and limbo docs based on the given change.\r\n   * Returns the list of changes to which docs are in limbo.\r\n   */\n\n\n  View.prototype.applyTargetChange = function (targetChange) {\n    var _this = this;\n\n    if (targetChange) {\n      targetChange.addedDocuments.forEach(function (key) {\n        return _this._syncedDocuments = _this._syncedDocuments.add(key);\n      });\n      targetChange.modifiedDocuments.forEach(function (key) {});\n      targetChange.removedDocuments.forEach(function (key) {\n        return _this._syncedDocuments = _this._syncedDocuments.delete(key);\n      });\n      this.current = targetChange.current;\n    }\n  };\n\n  View.prototype.updateLimboDocuments = function () {\n    var _this = this; // We can only determine limbo documents when we're in-sync with the server.\n\n\n    if (!this.current) {\n      return [];\n    } // TODO(klimt): Do this incrementally so that it's not quadratic when\n    // updating many documents.\n\n\n    var oldLimboDocuments = this.limboDocuments;\n    this.limboDocuments = documentKeySet();\n    this.documentSet.forEach(function (doc) {\n      if (_this.shouldBeInLimbo(doc.key)) {\n        _this.limboDocuments = _this.limboDocuments.add(doc.key);\n      }\n    }); // Diff the new limbo docs with the old limbo docs.\n\n    var changes = [];\n    oldLimboDocuments.forEach(function (key) {\n      if (!_this.limboDocuments.has(key)) {\n        changes.push(new RemovedLimboDocument(key));\n      }\n    });\n    this.limboDocuments.forEach(function (key) {\n      if (!oldLimboDocuments.has(key)) {\n        changes.push(new AddedLimboDocument(key));\n      }\n    });\n    return changes;\n  };\n  /**\r\n   * Update the in-memory state of the current view with the state read from\r\n   * persistence.\r\n   *\r\n   * We update the query view whenever a client's primary status changes:\r\n   * - When a client transitions from primary to secondary, it can miss\r\n   *   LocalStorage updates and its query views may temporarily not be\r\n   *   synchronized with the state on disk.\r\n   * - For secondary to primary transitions, the client needs to update the list\r\n   *   of `syncedDocuments` since secondary clients update their query views\r\n   *   based purely on synthesized RemoteEvents.\r\n   *\r\n   * @param queryResult.documents - The documents that match the query according\r\n   * to the LocalStore.\r\n   * @param queryResult.remoteKeys - The keys of the documents that match the\r\n   * query according to the backend.\r\n   *\r\n   * @returns The ViewChange that resulted from this synchronization.\r\n   */\n  // PORTING NOTE: Multi-tab only.\n\n\n  View.prototype.synchronizeWithPersistedState = function (queryResult) {\n    this._syncedDocuments = queryResult.remoteKeys;\n    this.limboDocuments = documentKeySet();\n    var docChanges = this.computeDocChanges(queryResult.documents);\n    return this.applyChanges(docChanges,\n    /*updateLimboDocuments=*/\n    true);\n  };\n  /**\r\n   * Returns a view snapshot as if this query was just listened to. Contains\r\n   * a document add for every existing document and the `fromCache` and\r\n   * `hasPendingWrites` status of the already established view.\r\n   */\n  // PORTING NOTE: Multi-tab only.\n\n\n  View.prototype.computeInitialSnapshot = function () {\n    return ViewSnapshot.fromInitialDocuments(this.query, this.documentSet, this.mutatedKeys, this.syncState === 0\n    /* Local */\n    );\n  };\n\n  return View;\n}();\n\nfunction compareChangeType(c1, c2) {\n  var order = function (change) {\n    switch (change) {\n      case 0\n      /* Added */\n      :\n        return 1;\n\n      case 2\n      /* Modified */\n      :\n        return 2;\n\n      case 3\n      /* Metadata */\n      :\n        // A metadata change is converted to a modified change at the public\n        // api layer.  Since we sort by document key and then change type,\n        // metadata and modified changes must be sorted equivalently.\n        return 2;\n\n      case 1\n      /* Removed */\n      :\n        return 0;\n\n      default:\n        return fail();\n    }\n  };\n\n  return order(c1) - order(c2);\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$3 = 'SyncEngine';\n/**\r\n * QueryView contains all of the data that SyncEngine needs to keep track of for\r\n * a particular query.\r\n */\n\nvar QueryView =\n/** @class */\nfunction () {\n  function QueryView(\n  /**\r\n   * The query itself.\r\n   */\n  query,\n  /**\r\n   * The target number created by the client that is used in the watch\r\n   * stream to identify this query.\r\n   */\n  targetId,\n  /**\r\n   * The view is responsible for computing the final merged truth of what\r\n   * docs are in the query. It gets notified of local and remote changes,\r\n   * and applies the query filters and limits to determine the most correct\r\n   * possible results.\r\n   */\n  view) {\n    this.query = query;\n    this.targetId = targetId;\n    this.view = view;\n  }\n\n  return QueryView;\n}();\n/** Tracks a limbo resolution. */\n\n\nvar LimboResolution =\n/** @class */\nfunction () {\n  function LimboResolution(key) {\n    this.key = key;\n    /**\r\n     * Set to true once we've received a document. This is used in\r\n     * getRemoteKeysForTarget() and ultimately used by WatchChangeAggregator to\r\n     * decide whether it needs to manufacture a delete event for the target once\r\n     * the target is CURRENT.\r\n     */\n\n    this.receivedDocument = false;\n  }\n\n  return LimboResolution;\n}();\n/**\r\n * An implementation of `SyncEngine` coordinating with other parts of SDK.\r\n *\r\n * The parts of SyncEngine that act as a callback to RemoteStore need to be\r\n * registered individually. This is done in `syncEngineWrite()` and\r\n * `syncEngineListen()` (as well as `applyPrimaryState()`) as these methods\r\n * serve as entry points to RemoteStore's functionality.\r\n *\r\n * Note: some field defined in this class might have public access level, but\r\n * the class is not exported so they are only accessible from this module.\r\n * This is useful to implement optional features (like bundles) in free\r\n * functions, such that they are tree-shakeable.\r\n */\n\n\nvar SyncEngineImpl =\n/** @class */\nfunction () {\n  function SyncEngineImpl(localStore, remoteStore, eventManager, // PORTING NOTE: Manages state synchronization in multi-tab environments.\n  sharedClientState, currentUser, maxConcurrentLimboResolutions) {\n    this.localStore = localStore;\n    this.remoteStore = remoteStore;\n    this.eventManager = eventManager;\n    this.sharedClientState = sharedClientState;\n    this.currentUser = currentUser;\n    this.maxConcurrentLimboResolutions = maxConcurrentLimboResolutions;\n    this.syncEngineListener = {};\n    this.queryViewsByQuery = new ObjectMap(function (q) {\n      return canonifyQuery(q);\n    }, queryEquals);\n    this.queriesByTarget = new Map();\n    /**\r\n     * The keys of documents that are in limbo for which we haven't yet started a\r\n     * limbo resolution query. The strings in this set are the result of calling\r\n     * `key.path.canonicalString()` where `key` is a `DocumentKey` object.\r\n     *\r\n     * The `Set` type was chosen because it provides efficient lookup and removal\r\n     * of arbitrary elements and it also maintains insertion order, providing the\r\n     * desired queue-like FIFO semantics.\r\n     */\n\n    this.enqueuedLimboResolutions = new Set();\n    /**\r\n     * Keeps track of the target ID for each document that is in limbo with an\r\n     * active target.\r\n     */\n\n    this.activeLimboTargetsByKey = new SortedMap(DocumentKey.comparator);\n    /**\r\n     * Keeps track of the information about an active limbo resolution for each\r\n     * active target ID that was started for the purpose of limbo resolution.\r\n     */\n\n    this.activeLimboResolutionsByTarget = new Map();\n    this.limboDocumentRefs = new ReferenceSet();\n    /** Stores user completion handlers, indexed by User and BatchId. */\n\n    this.mutationUserCallbacks = {};\n    /** Stores user callbacks waiting for all pending writes to be acknowledged. */\n\n    this.pendingWritesCallbacks = new Map();\n    this.limboTargetIdGenerator = TargetIdGenerator.forSyncEngine();\n    this.onlineState = \"Unknown\"\n    /* Unknown */\n    ; // The primary state is set to `true` or `false` immediately after Firestore\n    // startup. In the interim, a client should only be considered primary if\n    // `isPrimary` is true.\n\n    this._isPrimaryClient = undefined;\n  }\n\n  Object.defineProperty(SyncEngineImpl.prototype, \"isPrimaryClient\", {\n    get: function () {\n      return this._isPrimaryClient === true;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  return SyncEngineImpl;\n}();\n\nfunction newSyncEngine(localStore, remoteStore, eventManager, // PORTING NOTE: Manages state synchronization in multi-tab environments.\nsharedClientState, currentUser, maxConcurrentLimboResolutions, isPrimary) {\n  var syncEngine = new SyncEngineImpl(localStore, remoteStore, eventManager, sharedClientState, currentUser, maxConcurrentLimboResolutions);\n\n  if (isPrimary) {\n    syncEngine._isPrimaryClient = true;\n  }\n\n  return syncEngine;\n}\n/**\r\n * Initiates the new listen, resolves promise when listen enqueued to the\r\n * server. All the subsequent view snapshots or errors are sent to the\r\n * subscribed handlers. Returns the initial snapshot.\r\n */\n\n\nfunction syncEngineListen(syncEngine, query) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, targetId, viewSnapshot, queryView, targetData, status_1;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = ensureWatchCallbacks(syncEngine);\n          queryView = syncEngineImpl.queryViewsByQuery.get(query);\n          if (!queryView) return [3\n          /*break*/\n          , 1]; // PORTING NOTE: With Multi-Tab Web, it is possible that a query view\n          // already exists when EventManager calls us for the first time. This\n          // happens when the primary tab is already listening to this query on\n          // behalf of another tab and the user of the primary also starts listening\n          // to the query. EventManager will not have an assigned target ID in this\n          // case and calls `listen` to obtain this ID.\n\n          targetId = queryView.targetId;\n          syncEngineImpl.sharedClientState.addLocalQueryTarget(targetId);\n          viewSnapshot = queryView.view.computeInitialSnapshot();\n          return [3\n          /*break*/\n          , 4];\n\n        case 1:\n          return [4\n          /*yield*/\n          , localStoreAllocateTarget(syncEngineImpl.localStore, queryToTarget(query))];\n\n        case 2:\n          targetData = _d.sent();\n          status_1 = syncEngineImpl.sharedClientState.addLocalQueryTarget(targetData.targetId);\n          targetId = targetData.targetId;\n          return [4\n          /*yield*/\n          , initializeViewAndComputeSnapshot(syncEngineImpl, query, targetId, status_1 === 'current')];\n\n        case 3:\n          viewSnapshot = _d.sent();\n\n          if (syncEngineImpl.isPrimaryClient) {\n            remoteStoreListen(syncEngineImpl.remoteStore, targetData);\n          }\n\n          _d.label = 4;\n\n        case 4:\n          return [2\n          /*return*/\n          , viewSnapshot];\n      }\n    });\n  });\n}\n/**\r\n * Registers a view for a previously unknown query and computes its initial\r\n * snapshot.\r\n */\n\n\nfunction initializeViewAndComputeSnapshot(syncEngineImpl, query, targetId, current) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var queryResult, view, viewDocChanges, synthesizedTargetChange, viewChange, data;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          // PORTING NOTE: On Web only, we inject the code that registers new Limbo\n          // targets based on view changes. This allows us to only depend on Limbo\n          // changes when user code includes queries.\n          syncEngineImpl.applyDocChanges = function (queryView, changes, remoteEvent) {\n            return applyDocChanges(syncEngineImpl, queryView, changes, remoteEvent);\n          };\n\n          return [4\n          /*yield*/\n          , localStoreExecuteQuery(syncEngineImpl.localStore, query,\n          /* usePreviousResults= */\n          true)];\n\n        case 1:\n          queryResult = _d.sent();\n          view = new View(query, queryResult.remoteKeys);\n          viewDocChanges = view.computeDocChanges(queryResult.documents);\n          synthesizedTargetChange = TargetChange.createSynthesizedTargetChangeForCurrentChange(targetId, current && syncEngineImpl.onlineState !== \"Offline\"\n          /* Offline */\n          );\n          viewChange = view.applyChanges(viewDocChanges,\n          /* updateLimboDocuments= */\n          syncEngineImpl.isPrimaryClient, synthesizedTargetChange);\n          updateTrackedLimbos(syncEngineImpl, targetId, viewChange.limboChanges);\n          data = new QueryView(query, targetId, view);\n          syncEngineImpl.queryViewsByQuery.set(query, data);\n\n          if (syncEngineImpl.queriesByTarget.has(targetId)) {\n            syncEngineImpl.queriesByTarget.get(targetId).push(query);\n          } else {\n            syncEngineImpl.queriesByTarget.set(targetId, [query]);\n          }\n\n          return [2\n          /*return*/\n          , viewChange.snapshot];\n      }\n    });\n  });\n}\n/** Stops listening to the query. */\n\n\nfunction syncEngineUnlisten(syncEngine, query) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, queryView, queries, targetRemainsActive;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          queryView = syncEngineImpl.queryViewsByQuery.get(query);\n          queries = syncEngineImpl.queriesByTarget.get(queryView.targetId);\n\n          if (queries.length > 1) {\n            syncEngineImpl.queriesByTarget.set(queryView.targetId, queries.filter(function (q) {\n              return !queryEquals(q, query);\n            }));\n            syncEngineImpl.queryViewsByQuery.delete(query);\n            return [2\n            /*return*/\n            ];\n          }\n\n          if (!syncEngineImpl.isPrimaryClient) return [3\n          /*break*/\n          , 3]; // We need to remove the local query target first to allow us to verify\n          // whether any other client is still interested in this target.\n\n          syncEngineImpl.sharedClientState.removeLocalQueryTarget(queryView.targetId);\n          targetRemainsActive = syncEngineImpl.sharedClientState.isActiveQueryTarget(queryView.targetId);\n          if (!!targetRemainsActive) return [3\n          /*break*/\n          , 2];\n          return [4\n          /*yield*/\n          , localStoreReleaseTarget(syncEngineImpl.localStore, queryView.targetId,\n          /*keepPersistedTargetData=*/\n          false).then(function () {\n            syncEngineImpl.sharedClientState.clearQueryState(queryView.targetId);\n            remoteStoreUnlisten(syncEngineImpl.remoteStore, queryView.targetId);\n            removeAndCleanupTarget(syncEngineImpl, queryView.targetId);\n          }).catch(ignoreIfPrimaryLeaseLoss)];\n\n        case 1:\n          _d.sent();\n\n          _d.label = 2;\n\n        case 2:\n          return [3\n          /*break*/\n          , 5];\n\n        case 3:\n          removeAndCleanupTarget(syncEngineImpl, queryView.targetId);\n          return [4\n          /*yield*/\n          , localStoreReleaseTarget(syncEngineImpl.localStore, queryView.targetId,\n          /*keepPersistedTargetData=*/\n          true)];\n\n        case 4:\n          _d.sent();\n\n          _d.label = 5;\n\n        case 5:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Initiates the write of local mutation batch which involves adding the\r\n * writes to the mutation queue, notifying the remote store about new\r\n * mutations and raising events for any changes this write caused.\r\n *\r\n * The promise returned by this call is resolved when the above steps\r\n * have completed, *not* when the write was acked by the backend. The\r\n * userCallback is resolved once the write was acked/rejected by the\r\n * backend (or failed locally for any other reason).\r\n */\n\n\nfunction syncEngineWrite(syncEngine, batch, userCallback) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, result, e_8, error;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = syncEngineEnsureWriteCallbacks(syncEngine);\n          _d.label = 1;\n\n        case 1:\n          _d.trys.push([1, 5,, 6]);\n\n          return [4\n          /*yield*/\n          , localStoreWriteLocally(syncEngineImpl.localStore, batch)];\n\n        case 2:\n          result = _d.sent();\n          syncEngineImpl.sharedClientState.addPendingMutation(result.batchId);\n          addMutationCallback(syncEngineImpl, result.batchId, userCallback);\n          return [4\n          /*yield*/\n          , syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, result.changes)];\n\n        case 3:\n          _d.sent();\n\n          return [4\n          /*yield*/\n          , fillWritePipeline(syncEngineImpl.remoteStore)];\n\n        case 4:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 5:\n          e_8 = _d.sent();\n          error = wrapInUserErrorIfRecoverable(e_8, \"Failed to persist write\");\n          userCallback.reject(error);\n          return [3\n          /*break*/\n          , 6];\n\n        case 6:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Applies one remote event to the sync engine, notifying any views of the\r\n * changes, and releasing any pending mutation batches that would become\r\n * visible because of the snapshot version the remote event contains.\r\n */\n\n\nfunction syncEngineApplyRemoteEvent(syncEngine, remoteEvent) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, changes, error_2;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          _d.label = 1;\n\n        case 1:\n          _d.trys.push([1, 4,, 6]);\n\n          return [4\n          /*yield*/\n          , localStoreApplyRemoteEventToLocalCache(syncEngineImpl.localStore, remoteEvent)];\n\n        case 2:\n          changes = _d.sent(); // Update `receivedDocument` as appropriate for any limbo targets.\n\n          remoteEvent.targetChanges.forEach(function (targetChange, targetId) {\n            var limboResolution = syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);\n\n            if (limboResolution) {\n              // Since this is a limbo resolution lookup, it's for a single document\n              // and it could be added, modified, or removed, but not a combination.\n              hardAssert(targetChange.addedDocuments.size + targetChange.modifiedDocuments.size + targetChange.removedDocuments.size <= 1);\n\n              if (targetChange.addedDocuments.size > 0) {\n                limboResolution.receivedDocument = true;\n              } else if (targetChange.modifiedDocuments.size > 0) {\n                hardAssert(limboResolution.receivedDocument);\n              } else if (targetChange.removedDocuments.size > 0) {\n                hardAssert(limboResolution.receivedDocument);\n                limboResolution.receivedDocument = false;\n              } else ;\n            }\n          });\n          return [4\n          /*yield*/\n          , syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes, remoteEvent)];\n\n        case 3:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 4:\n          error_2 = _d.sent();\n          return [4\n          /*yield*/\n          , ignoreIfPrimaryLeaseLoss(error_2)];\n\n        case 5:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 6:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Applies an OnlineState change to the sync engine and notifies any views of\r\n * the change.\r\n */\n\n\nfunction syncEngineApplyOnlineStateChange(syncEngine, onlineState, source) {\n  var syncEngineImpl = debugCast(syncEngine); // If we are the secondary client, we explicitly ignore the remote store's\n  // online state (the local client may go offline, even though the primary\n  // tab remains online) and only apply the primary tab's online state from\n  // SharedClientState.\n\n  if (syncEngineImpl.isPrimaryClient && source === 0\n  /* RemoteStore */\n  || !syncEngineImpl.isPrimaryClient && source === 1\n  /* SharedClientState */\n  ) {\n    var newViewSnapshots_1 = [];\n    syncEngineImpl.queryViewsByQuery.forEach(function (query, queryView) {\n      var viewChange = queryView.view.applyOnlineStateChange(onlineState);\n\n      if (viewChange.snapshot) {\n        newViewSnapshots_1.push(viewChange.snapshot);\n      }\n    });\n    eventManagerOnOnlineStateChange(syncEngineImpl.eventManager, onlineState);\n\n    if (newViewSnapshots_1.length) {\n      syncEngineImpl.syncEngineListener.onWatchChange(newViewSnapshots_1);\n    }\n\n    syncEngineImpl.onlineState = onlineState;\n\n    if (syncEngineImpl.isPrimaryClient) {\n      syncEngineImpl.sharedClientState.setOnlineState(onlineState);\n    }\n  }\n}\n/**\r\n * Rejects the listen for the given targetID. This can be triggered by the\r\n * backend for any active target.\r\n *\r\n * @param syncEngine - The sync engine implementation.\r\n * @param targetId - The targetID corresponds to one previously initiated by the\r\n * user as part of TargetData passed to listen() on RemoteStore.\r\n * @param err - A description of the condition that has forced the rejection.\r\n * Nearly always this will be an indication that the user is no longer\r\n * authorized to see the data matching the target.\r\n */\n\n\nfunction syncEngineRejectListen(syncEngine, targetId, err) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, limboResolution, limboKey, documentUpdates, resolvedLimboDocuments, event_2;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine); // PORTING NOTE: Multi-tab only.\n\n          syncEngineImpl.sharedClientState.updateQueryState(targetId, 'rejected', err);\n          limboResolution = syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);\n          limboKey = limboResolution && limboResolution.key;\n          if (!limboKey) return [3\n          /*break*/\n          , 2];\n          documentUpdates = new SortedMap(DocumentKey.comparator);\n          documentUpdates = documentUpdates.insert(limboKey, MutableDocument.newNoDocument(limboKey, SnapshotVersion.min()));\n          resolvedLimboDocuments = documentKeySet().add(limboKey);\n          event_2 = new RemoteEvent(SnapshotVersion.min(),\n          /* targetChanges= */\n          new Map(),\n          /* targetMismatches= */\n          new SortedSet(primitiveComparator), documentUpdates, resolvedLimboDocuments);\n          return [4\n          /*yield*/\n          , syncEngineApplyRemoteEvent(syncEngineImpl, event_2)];\n\n        case 1:\n          _d.sent(); // Since this query failed, we won't want to manually unlisten to it.\n          // We only remove it from bookkeeping after we successfully applied the\n          // RemoteEvent. If `applyRemoteEvent()` throws, we want to re-listen to\n          // this query when the RemoteStore restarts the Watch stream, which should\n          // re-trigger the target failure.\n\n\n          syncEngineImpl.activeLimboTargetsByKey = syncEngineImpl.activeLimboTargetsByKey.remove(limboKey);\n          syncEngineImpl.activeLimboResolutionsByTarget.delete(targetId);\n          pumpEnqueuedLimboResolutions(syncEngineImpl);\n          return [3\n          /*break*/\n          , 4];\n\n        case 2:\n          return [4\n          /*yield*/\n          , localStoreReleaseTarget(syncEngineImpl.localStore, targetId,\n          /* keepPersistedTargetData */\n          false).then(function () {\n            return removeAndCleanupTarget(syncEngineImpl, targetId, err);\n          }).catch(ignoreIfPrimaryLeaseLoss)];\n\n        case 3:\n          _d.sent();\n\n          _d.label = 4;\n\n        case 4:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction syncEngineApplySuccessfulWrite(syncEngine, mutationBatchResult) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, batchId, changes, error_3;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          batchId = mutationBatchResult.batch.batchId;\n          _d.label = 1;\n\n        case 1:\n          _d.trys.push([1, 4,, 6]);\n\n          return [4\n          /*yield*/\n          , localStoreAcknowledgeBatch(syncEngineImpl.localStore, mutationBatchResult)];\n\n        case 2:\n          changes = _d.sent(); // The local store may or may not be able to apply the write result and\n          // raise events immediately (depending on whether the watcher is caught\n          // up), so we raise user callbacks first so that they consistently happen\n          // before listen events.\n\n          processUserCallback(syncEngineImpl, batchId,\n          /*error=*/\n          null);\n          triggerPendingWritesCallbacks(syncEngineImpl, batchId);\n          syncEngineImpl.sharedClientState.updateMutationState(batchId, 'acknowledged');\n          return [4\n          /*yield*/\n          , syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes)];\n\n        case 3:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 4:\n          error_3 = _d.sent();\n          return [4\n          /*yield*/\n          , ignoreIfPrimaryLeaseLoss(error_3)];\n\n        case 5:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 6:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction syncEngineRejectFailedWrite(syncEngine, batchId, error) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, changes, error_4;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          _d.label = 1;\n\n        case 1:\n          _d.trys.push([1, 4,, 6]);\n\n          return [4\n          /*yield*/\n          , localStoreRejectBatch(syncEngineImpl.localStore, batchId)];\n\n        case 2:\n          changes = _d.sent(); // The local store may or may not be able to apply the write result and\n          // raise events immediately (depending on whether the watcher is caught up),\n          // so we raise user callbacks first so that they consistently happen before\n          // listen events.\n\n          processUserCallback(syncEngineImpl, batchId, error);\n          triggerPendingWritesCallbacks(syncEngineImpl, batchId);\n          syncEngineImpl.sharedClientState.updateMutationState(batchId, 'rejected', error);\n          return [4\n          /*yield*/\n          , syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes)];\n\n        case 3:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 4:\n          error_4 = _d.sent();\n          return [4\n          /*yield*/\n          , ignoreIfPrimaryLeaseLoss(error_4)];\n\n        case 5:\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 6:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Registers a user callback that resolves when all pending mutations at the moment of calling\r\n * are acknowledged .\r\n */\n\n\nfunction syncEngineRegisterPendingWritesCallback(syncEngine, callback) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, highestBatchId, callbacks, e_9, firestoreError;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n\n          if (!canUseNetwork(syncEngineImpl.remoteStore)) {\n            logDebug(LOG_TAG$3, 'The network is disabled. The task returned by ' + \"'awaitPendingWrites()' will not complete until the network is enabled.\");\n          }\n\n          _d.label = 1;\n\n        case 1:\n          _d.trys.push([1, 3,, 4]);\n\n          return [4\n          /*yield*/\n          , localStoreGetHighestUnacknowledgedBatchId(syncEngineImpl.localStore)];\n\n        case 2:\n          highestBatchId = _d.sent();\n\n          if (highestBatchId === BATCHID_UNKNOWN) {\n            // Trigger the callback right away if there is no pending writes at the moment.\n            callback.resolve();\n            return [2\n            /*return*/\n            ];\n          }\n\n          callbacks = syncEngineImpl.pendingWritesCallbacks.get(highestBatchId) || [];\n          callbacks.push(callback);\n          syncEngineImpl.pendingWritesCallbacks.set(highestBatchId, callbacks);\n          return [3\n          /*break*/\n          , 4];\n\n        case 3:\n          e_9 = _d.sent();\n          firestoreError = wrapInUserErrorIfRecoverable(e_9, 'Initialization of waitForPendingWrites() operation failed');\n          callback.reject(firestoreError);\n          return [3\n          /*break*/\n          , 4];\n\n        case 4:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Triggers the callbacks that are waiting for this batch id to get acknowledged by server,\r\n * if there are any.\r\n */\n\n\nfunction triggerPendingWritesCallbacks(syncEngineImpl, batchId) {\n  (syncEngineImpl.pendingWritesCallbacks.get(batchId) || []).forEach(function (callback) {\n    callback.resolve();\n  });\n  syncEngineImpl.pendingWritesCallbacks.delete(batchId);\n}\n/** Reject all outstanding callbacks waiting for pending writes to complete. */\n\n\nfunction rejectOutstandingPendingWritesCallbacks(syncEngineImpl, errorMessage) {\n  syncEngineImpl.pendingWritesCallbacks.forEach(function (callbacks) {\n    callbacks.forEach(function (callback) {\n      callback.reject(new FirestoreError(Code.CANCELLED, errorMessage));\n    });\n  });\n  syncEngineImpl.pendingWritesCallbacks.clear();\n}\n\nfunction addMutationCallback(syncEngineImpl, batchId, callback) {\n  var newCallbacks = syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()];\n\n  if (!newCallbacks) {\n    newCallbacks = new SortedMap(primitiveComparator);\n  }\n\n  newCallbacks = newCallbacks.insert(batchId, callback);\n  syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()] = newCallbacks;\n}\n/**\r\n * Resolves or rejects the user callback for the given batch and then discards\r\n * it.\r\n */\n\n\nfunction processUserCallback(syncEngine, batchId, error) {\n  var syncEngineImpl = debugCast(syncEngine);\n  var newCallbacks = syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()]; // NOTE: Mutations restored from persistence won't have callbacks, so it's\n  // okay for there to be no callback for this ID.\n\n  if (newCallbacks) {\n    var callback = newCallbacks.get(batchId);\n\n    if (callback) {\n      if (error) {\n        callback.reject(error);\n      } else {\n        callback.resolve();\n      }\n\n      newCallbacks = newCallbacks.remove(batchId);\n    }\n\n    syncEngineImpl.mutationUserCallbacks[syncEngineImpl.currentUser.toKey()] = newCallbacks;\n  }\n}\n\nfunction removeAndCleanupTarget(syncEngineImpl, targetId, error) {\n  if (error === void 0) {\n    error = null;\n  }\n\n  syncEngineImpl.sharedClientState.removeLocalQueryTarget(targetId);\n\n  for (var _i = 0, _d = syncEngineImpl.queriesByTarget.get(targetId); _i < _d.length; _i++) {\n    var query_2 = _d[_i];\n    syncEngineImpl.queryViewsByQuery.delete(query_2);\n\n    if (error) {\n      syncEngineImpl.syncEngineListener.onWatchError(query_2, error);\n    }\n  }\n\n  syncEngineImpl.queriesByTarget.delete(targetId);\n\n  if (syncEngineImpl.isPrimaryClient) {\n    var limboKeys = syncEngineImpl.limboDocumentRefs.removeReferencesForId(targetId);\n    limboKeys.forEach(function (limboKey) {\n      var isReferenced = syncEngineImpl.limboDocumentRefs.containsKey(limboKey);\n\n      if (!isReferenced) {\n        // We removed the last reference for this key\n        removeLimboTarget(syncEngineImpl, limboKey);\n      }\n    });\n  }\n}\n\nfunction removeLimboTarget(syncEngineImpl, key) {\n  syncEngineImpl.enqueuedLimboResolutions.delete(key.path.canonicalString()); // It's possible that the target already got removed because the query failed. In that case,\n  // the key won't exist in `limboTargetsByKey`. Only do the cleanup if we still have the target.\n\n  var limboTargetId = syncEngineImpl.activeLimboTargetsByKey.get(key);\n\n  if (limboTargetId === null) {\n    // This target already got removed, because the query failed.\n    return;\n  }\n\n  remoteStoreUnlisten(syncEngineImpl.remoteStore, limboTargetId);\n  syncEngineImpl.activeLimboTargetsByKey = syncEngineImpl.activeLimboTargetsByKey.remove(key);\n  syncEngineImpl.activeLimboResolutionsByTarget.delete(limboTargetId);\n  pumpEnqueuedLimboResolutions(syncEngineImpl);\n}\n\nfunction updateTrackedLimbos(syncEngineImpl, targetId, limboChanges) {\n  for (var _i = 0, limboChanges_1 = limboChanges; _i < limboChanges_1.length; _i++) {\n    var limboChange = limboChanges_1[_i];\n\n    if (limboChange instanceof AddedLimboDocument) {\n      syncEngineImpl.limboDocumentRefs.addReference(limboChange.key, targetId);\n      trackLimboChange(syncEngineImpl, limboChange);\n    } else if (limboChange instanceof RemovedLimboDocument) {\n      logDebug(LOG_TAG$3, 'Document no longer in limbo: ' + limboChange.key);\n      syncEngineImpl.limboDocumentRefs.removeReference(limboChange.key, targetId);\n      var isReferenced = syncEngineImpl.limboDocumentRefs.containsKey(limboChange.key);\n\n      if (!isReferenced) {\n        // We removed the last reference for this key\n        removeLimboTarget(syncEngineImpl, limboChange.key);\n      }\n    } else {\n      fail();\n    }\n  }\n}\n\nfunction trackLimboChange(syncEngineImpl, limboChange) {\n  var key = limboChange.key;\n  var keyString = key.path.canonicalString();\n\n  if (!syncEngineImpl.activeLimboTargetsByKey.get(key) && !syncEngineImpl.enqueuedLimboResolutions.has(keyString)) {\n    logDebug(LOG_TAG$3, 'New document in limbo: ' + key);\n    syncEngineImpl.enqueuedLimboResolutions.add(keyString);\n    pumpEnqueuedLimboResolutions(syncEngineImpl);\n  }\n}\n/**\r\n * Starts listens for documents in limbo that are enqueued for resolution,\r\n * subject to a maximum number of concurrent resolutions.\r\n *\r\n * Without bounding the number of concurrent resolutions, the server can fail\r\n * with \"resource exhausted\" errors which can lead to pathological client\r\n * behavior as seen in https://github.com/firebase/firebase-js-sdk/issues/2683.\r\n */\n\n\nfunction pumpEnqueuedLimboResolutions(syncEngineImpl) {\n  while (syncEngineImpl.enqueuedLimboResolutions.size > 0 && syncEngineImpl.activeLimboTargetsByKey.size < syncEngineImpl.maxConcurrentLimboResolutions) {\n    var keyString = syncEngineImpl.enqueuedLimboResolutions.values().next().value;\n    syncEngineImpl.enqueuedLimboResolutions.delete(keyString);\n    var key = new DocumentKey(ResourcePath.fromString(keyString));\n    var limboTargetId = syncEngineImpl.limboTargetIdGenerator.next();\n    syncEngineImpl.activeLimboResolutionsByTarget.set(limboTargetId, new LimboResolution(key));\n    syncEngineImpl.activeLimboTargetsByKey = syncEngineImpl.activeLimboTargetsByKey.insert(key, limboTargetId);\n    remoteStoreListen(syncEngineImpl.remoteStore, new TargetData(queryToTarget(newQueryForPath(key.path)), limboTargetId, 2\n    /* LimboResolution */\n    , ListenSequence.INVALID));\n  }\n}\n\nfunction syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngine, changes, remoteEvent) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, newSnaps, docChangesInAllViews, queriesProcessed;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          newSnaps = [];\n          docChangesInAllViews = [];\n          queriesProcessed = [];\n\n          if (syncEngineImpl.queryViewsByQuery.isEmpty()) {\n            // Return early since `onWatchChange()` might not have been assigned yet.\n            return [2\n            /*return*/\n            ];\n          }\n\n          syncEngineImpl.queryViewsByQuery.forEach(function (_, queryView) {\n            queriesProcessed.push(syncEngineImpl.applyDocChanges(queryView, changes, remoteEvent).then(function (viewSnapshot) {\n              if (viewSnapshot) {\n                if (syncEngineImpl.isPrimaryClient) {\n                  syncEngineImpl.sharedClientState.updateQueryState(queryView.targetId, viewSnapshot.fromCache ? 'not-current' : 'current');\n                }\n\n                newSnaps.push(viewSnapshot);\n                var docChanges = LocalViewChanges.fromSnapshot(queryView.targetId, viewSnapshot);\n                docChangesInAllViews.push(docChanges);\n              }\n            }));\n          });\n          return [4\n          /*yield*/\n          , Promise.all(queriesProcessed)];\n\n        case 1:\n          _d.sent();\n\n          syncEngineImpl.syncEngineListener.onWatchChange(newSnaps);\n          return [4\n          /*yield*/\n          , localStoreNotifyLocalViewChanges(syncEngineImpl.localStore, docChangesInAllViews)];\n\n        case 2:\n          _d.sent();\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction applyDocChanges(syncEngineImpl, queryView, changes, remoteEvent) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var viewDocChanges, targetChange, viewChange;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          viewDocChanges = queryView.view.computeDocChanges(changes);\n          if (!viewDocChanges.needsRefill) return [3\n          /*break*/\n          , 2];\n          return [4\n          /*yield*/\n          , localStoreExecuteQuery(syncEngineImpl.localStore, queryView.query,\n          /* usePreviousResults= */\n          false).then(function (_d) {\n            var documents = _d.documents;\n            return queryView.view.computeDocChanges(documents, viewDocChanges);\n          })];\n\n        case 1:\n          // The query has a limit and some docs were removed, so we need\n          // to re-run the query against the local store to make sure we\n          // didn't lose any good docs that had been past the limit.\n          viewDocChanges = _d.sent();\n          _d.label = 2;\n\n        case 2:\n          targetChange = remoteEvent && remoteEvent.targetChanges.get(queryView.targetId);\n          viewChange = queryView.view.applyChanges(viewDocChanges,\n          /* updateLimboDocuments= */\n          syncEngineImpl.isPrimaryClient, targetChange);\n          updateTrackedLimbos(syncEngineImpl, queryView.targetId, viewChange.limboChanges);\n          return [2\n          /*return*/\n          , viewChange.snapshot];\n      }\n    });\n  });\n}\n\nfunction syncEngineHandleCredentialChange(syncEngine, user) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, userChanged, result;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          userChanged = !syncEngineImpl.currentUser.isEqual(user);\n          if (!userChanged) return [3\n          /*break*/\n          , 3];\n          logDebug(LOG_TAG$3, 'User change. New user:', user.toKey());\n          return [4\n          /*yield*/\n          , localStoreHandleUserChange(syncEngineImpl.localStore, user)];\n\n        case 1:\n          result = _d.sent();\n          syncEngineImpl.currentUser = user; // Fails tasks waiting for pending writes requested by previous user.\n\n          rejectOutstandingPendingWritesCallbacks(syncEngineImpl, \"'waitForPendingWrites' promise is rejected due to a user change.\"); // TODO(b/114226417): Consider calling this only in the primary tab.\n\n          syncEngineImpl.sharedClientState.handleUserChange(user, result.removedBatchIds, result.addedBatchIds);\n          return [4\n          /*yield*/\n          , syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, result.affectedDocuments)];\n\n        case 2:\n          _d.sent();\n\n          _d.label = 3;\n\n        case 3:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction syncEngineGetRemoteKeysForTarget(syncEngine, targetId) {\n  var syncEngineImpl = debugCast(syncEngine);\n  var limboResolution = syncEngineImpl.activeLimboResolutionsByTarget.get(targetId);\n\n  if (limboResolution && limboResolution.receivedDocument) {\n    return documentKeySet().add(limboResolution.key);\n  } else {\n    var keySet = documentKeySet();\n    var queries = syncEngineImpl.queriesByTarget.get(targetId);\n\n    if (!queries) {\n      return keySet;\n    }\n\n    for (var _i = 0, queries_1 = queries; _i < queries_1.length; _i++) {\n      var query_3 = queries_1[_i];\n      var queryView = syncEngineImpl.queryViewsByQuery.get(query_3);\n      keySet = keySet.unionWith(queryView.view.syncedDocuments);\n    }\n\n    return keySet;\n  }\n}\n/**\r\n * Reconcile the list of synced documents in an existing view with those\r\n * from persistence.\r\n */\n\n\nfunction synchronizeViewAndComputeSnapshot(syncEngine, queryView) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, queryResult, viewSnapshot;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          return [4\n          /*yield*/\n          , localStoreExecuteQuery(syncEngineImpl.localStore, queryView.query,\n          /* usePreviousResults= */\n          true)];\n\n        case 1:\n          queryResult = _d.sent();\n          viewSnapshot = queryView.view.synchronizeWithPersistedState(queryResult);\n\n          if (syncEngineImpl.isPrimaryClient) {\n            updateTrackedLimbos(syncEngineImpl, queryView.targetId, viewSnapshot.limboChanges);\n          }\n\n          return [2\n          /*return*/\n          , viewSnapshot];\n      }\n    });\n  });\n}\n/**\r\n * Retrieves newly changed documents from remote document cache and raises\r\n * snapshots if needed.\r\n */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction syncEngineSynchronizeWithChangedDocuments(syncEngine) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl;\n    return tslib.__generator(this, function (_d) {\n      syncEngineImpl = debugCast(syncEngine);\n      return [2\n      /*return*/\n      , localStoreGetNewDocumentChanges(syncEngineImpl.localStore).then(function (changes) {\n        return syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes);\n      })];\n    });\n  });\n}\n/** Applies a mutation state to an existing batch.  */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction syncEngineApplyBatchState(syncEngine, batchId, batchState, error) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, documents;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          return [4\n          /*yield*/\n          , localStoreLookupMutationDocuments(syncEngineImpl.localStore, batchId)];\n\n        case 1:\n          documents = _d.sent();\n\n          if (documents === null) {\n            // A throttled tab may not have seen the mutation before it was completed\n            // and removed from the mutation queue, in which case we won't have cached\n            // the affected documents. In this case we can safely ignore the update\n            // since that means we didn't apply the mutation locally at all (if we\n            // had, we would have cached the affected documents), and so we will just\n            // see any resulting document changes via normal remote document updates\n            // as applicable.\n            logDebug(LOG_TAG$3, 'Cannot apply mutation batch with id: ' + batchId);\n            return [2\n            /*return*/\n            ];\n          }\n\n          if (!(batchState === 'pending')) return [3\n          /*break*/\n          , 3]; // If we are the primary client, we need to send this write to the\n          // backend. Secondary clients will ignore these writes since their remote\n          // connection is disabled.\n\n          return [4\n          /*yield*/\n          , fillWritePipeline(syncEngineImpl.remoteStore)];\n\n        case 2:\n          // If we are the primary client, we need to send this write to the\n          // backend. Secondary clients will ignore these writes since their remote\n          // connection is disabled.\n          _d.sent();\n\n          return [3\n          /*break*/\n          , 4];\n\n        case 3:\n          if (batchState === 'acknowledged' || batchState === 'rejected') {\n            // NOTE: Both these methods are no-ops for batches that originated from\n            // other clients.\n            processUserCallback(syncEngineImpl, batchId, error ? error : null);\n            triggerPendingWritesCallbacks(syncEngineImpl, batchId);\n            localStoreRemoveCachedMutationBatchMetadata(syncEngineImpl.localStore, batchId);\n          } else {\n            fail();\n          }\n\n          _d.label = 4;\n\n        case 4:\n          return [4\n          /*yield*/\n          , syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, documents)];\n\n        case 5:\n          _d.sent();\n\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/** Applies a query target change from a different tab. */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction syncEngineApplyPrimaryState(syncEngine, isPrimary) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, activeTargets, activeQueries, _i, activeQueries_1, targetData, activeTargets_1, p_1;\n\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          ensureWatchCallbacks(syncEngineImpl);\n          syncEngineEnsureWriteCallbacks(syncEngineImpl);\n          if (!(isPrimary === true && syncEngineImpl._isPrimaryClient !== true)) return [3\n          /*break*/\n          , 3];\n          activeTargets = syncEngineImpl.sharedClientState.getAllActiveQueryTargets();\n          return [4\n          /*yield*/\n          , synchronizeQueryViewsAndRaiseSnapshots(syncEngineImpl, activeTargets.toArray())];\n\n        case 1:\n          activeQueries = _d.sent();\n          syncEngineImpl._isPrimaryClient = true;\n          return [4\n          /*yield*/\n          , remoteStoreApplyPrimaryState(syncEngineImpl.remoteStore, true)];\n\n        case 2:\n          _d.sent();\n\n          for (_i = 0, activeQueries_1 = activeQueries; _i < activeQueries_1.length; _i++) {\n            targetData = activeQueries_1[_i];\n            remoteStoreListen(syncEngineImpl.remoteStore, targetData);\n          }\n\n          return [3\n          /*break*/\n          , 7];\n\n        case 3:\n          if (!(isPrimary === false && syncEngineImpl._isPrimaryClient !== false)) return [3\n          /*break*/\n          , 7];\n          activeTargets_1 = [];\n          p_1 = Promise.resolve();\n          syncEngineImpl.queriesByTarget.forEach(function (_, targetId) {\n            if (syncEngineImpl.sharedClientState.isLocalQueryTarget(targetId)) {\n              activeTargets_1.push(targetId);\n            } else {\n              p_1 = p_1.then(function () {\n                removeAndCleanupTarget(syncEngineImpl, targetId);\n                return localStoreReleaseTarget(syncEngineImpl.localStore, targetId,\n                /*keepPersistedTargetData=*/\n                true);\n              });\n            }\n\n            remoteStoreUnlisten(syncEngineImpl.remoteStore, targetId);\n          });\n          return [4\n          /*yield*/\n          , p_1];\n\n        case 4:\n          _d.sent();\n\n          return [4\n          /*yield*/\n          , synchronizeQueryViewsAndRaiseSnapshots(syncEngineImpl, activeTargets_1)];\n\n        case 5:\n          _d.sent();\n\n          resetLimboDocuments(syncEngineImpl);\n          syncEngineImpl._isPrimaryClient = false;\n          return [4\n          /*yield*/\n          , remoteStoreApplyPrimaryState(syncEngineImpl.remoteStore, false)];\n\n        case 6:\n          _d.sent();\n\n          _d.label = 7;\n\n        case 7:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n} // PORTING NOTE: Multi-Tab only.\n\n\nfunction resetLimboDocuments(syncEngine) {\n  var syncEngineImpl = debugCast(syncEngine);\n  syncEngineImpl.activeLimboResolutionsByTarget.forEach(function (_, targetId) {\n    remoteStoreUnlisten(syncEngineImpl.remoteStore, targetId);\n  });\n  syncEngineImpl.limboDocumentRefs.removeAllReferences();\n  syncEngineImpl.activeLimboResolutionsByTarget = new Map();\n  syncEngineImpl.activeLimboTargetsByKey = new SortedMap(DocumentKey.comparator);\n}\n/**\r\n * Reconcile the query views of the provided query targets with the state from\r\n * persistence. Raises snapshots for any changes that affect the local\r\n * client and returns the updated state of all target's query data.\r\n *\r\n * @param syncEngine - The sync engine implementation\r\n * @param targets - the list of targets with views that need to be recomputed\r\n * @param transitionToPrimary - `true` iff the tab transitions from a secondary\r\n * tab to a primary tab\r\n */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction synchronizeQueryViewsAndRaiseSnapshots(syncEngine, targets, transitionToPrimary) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, activeQueries, newViewSnapshots, _i, targets_1, targetId, targetData, queries, _d, queries_2, query_4, queryView, viewChange, target;\n\n    return tslib.__generator(this, function (_e) {\n      switch (_e.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n          activeQueries = [];\n          newViewSnapshots = [];\n          _i = 0, targets_1 = targets;\n          _e.label = 1;\n\n        case 1:\n          if (!(_i < targets_1.length)) return [3\n          /*break*/\n          , 13];\n          targetId = targets_1[_i];\n          targetData = void 0;\n          queries = syncEngineImpl.queriesByTarget.get(targetId);\n          if (!(queries && queries.length !== 0)) return [3\n          /*break*/\n          , 7];\n          return [4\n          /*yield*/\n          , localStoreAllocateTarget(syncEngineImpl.localStore, queryToTarget(queries[0]))];\n\n        case 2:\n          // For queries that have a local View, we fetch their current state\n          // from LocalStore (as the resume token and the snapshot version\n          // might have changed) and reconcile their views with the persisted\n          // state (the list of syncedDocuments may have gotten out of sync).\n          targetData = _e.sent();\n          _d = 0, queries_2 = queries;\n          _e.label = 3;\n\n        case 3:\n          if (!(_d < queries_2.length)) return [3\n          /*break*/\n          , 6];\n          query_4 = queries_2[_d];\n          queryView = syncEngineImpl.queryViewsByQuery.get(query_4);\n          return [4\n          /*yield*/\n          , synchronizeViewAndComputeSnapshot(syncEngineImpl, queryView)];\n\n        case 4:\n          viewChange = _e.sent();\n\n          if (viewChange.snapshot) {\n            newViewSnapshots.push(viewChange.snapshot);\n          }\n\n          _e.label = 5;\n\n        case 5:\n          _d++;\n          return [3\n          /*break*/\n          , 3];\n\n        case 6:\n          return [3\n          /*break*/\n          , 11];\n\n        case 7:\n          return [4\n          /*yield*/\n          , localStoreGetCachedTarget(syncEngineImpl.localStore, targetId)];\n\n        case 8:\n          target = _e.sent();\n          return [4\n          /*yield*/\n          , localStoreAllocateTarget(syncEngineImpl.localStore, target)];\n\n        case 9:\n          targetData = _e.sent();\n          return [4\n          /*yield*/\n          , initializeViewAndComputeSnapshot(syncEngineImpl, synthesizeTargetToQuery(target), targetId,\n          /*current=*/\n          false)];\n\n        case 10:\n          _e.sent();\n\n          _e.label = 11;\n\n        case 11:\n          activeQueries.push(targetData);\n          _e.label = 12;\n\n        case 12:\n          _i++;\n          return [3\n          /*break*/\n          , 1];\n\n        case 13:\n          syncEngineImpl.syncEngineListener.onWatchChange(newViewSnapshots);\n          return [2\n          /*return*/\n          , activeQueries];\n      }\n    });\n  });\n}\n/**\r\n * Creates a `Query` object from the specified `Target`. There is no way to\r\n * obtain the original `Query`, so we synthesize a `Query` from the `Target`\r\n * object.\r\n *\r\n * The synthesized result might be different from the original `Query`, but\r\n * since the synthesized `Query` should return the same results as the\r\n * original one (only the presentation of results might differ), the potential\r\n * difference will not cause issues.\r\n */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction synthesizeTargetToQuery(target) {\n  return newQuery(target.path, target.collectionGroup, target.orderBy, target.filters, target.limit, \"F\"\n  /* First */\n  , target.startAt, target.endAt);\n}\n/** Returns the IDs of the clients that are currently active. */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction syncEngineGetActiveClients(syncEngine) {\n  var syncEngineImpl = debugCast(syncEngine);\n  return localStoreGetActiveClients(syncEngineImpl.localStore);\n}\n/** Applies a query target change from a different tab. */\n// PORTING NOTE: Multi-Tab only.\n\n\nfunction syncEngineApplyTargetState(syncEngine, targetId, state, error) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, _d, changes, synthesizedRemoteEvent;\n\n    return tslib.__generator(this, function (_e) {\n      switch (_e.label) {\n        case 0:\n          syncEngineImpl = debugCast(syncEngine);\n\n          if (syncEngineImpl._isPrimaryClient) {\n            // If we receive a target state notification via WebStorage, we are\n            // either already secondary or another tab has taken the primary lease.\n            logDebug(LOG_TAG$3, 'Ignoring unexpected query state notification.');\n            return [2\n            /*return*/\n            ];\n          }\n\n          if (!syncEngineImpl.queriesByTarget.has(targetId)) return [3\n          /*break*/\n          , 7];\n          _d = state;\n\n          switch (_d) {\n            case 'current':\n              return [3\n              /*break*/\n              , 1];\n\n            case 'not-current':\n              return [3\n              /*break*/\n              , 1];\n\n            case 'rejected':\n              return [3\n              /*break*/\n              , 4];\n          }\n\n          return [3\n          /*break*/\n          , 6];\n\n        case 1:\n          return [4\n          /*yield*/\n          , localStoreGetNewDocumentChanges(syncEngineImpl.localStore)];\n\n        case 2:\n          changes = _e.sent();\n          synthesizedRemoteEvent = RemoteEvent.createSynthesizedRemoteEventForCurrentChange(targetId, state === 'current');\n          return [4\n          /*yield*/\n          , syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngineImpl, changes, synthesizedRemoteEvent)];\n\n        case 3:\n          _e.sent();\n\n          return [3\n          /*break*/\n          , 7];\n\n        case 4:\n          return [4\n          /*yield*/\n          , localStoreReleaseTarget(syncEngineImpl.localStore, targetId,\n          /* keepPersistedTargetData */\n          true)];\n\n        case 5:\n          _e.sent();\n\n          removeAndCleanupTarget(syncEngineImpl, targetId, error);\n          return [3\n          /*break*/\n          , 7];\n\n        case 6:\n          fail();\n          _e.label = 7;\n\n        case 7:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/** Adds or removes Watch targets for queries from different tabs. */\n\n\nfunction syncEngineApplyActiveTargetsChange(syncEngine, added, removed) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var syncEngineImpl, _i, added_1, targetId, target, targetData, _loop_5, _d, removed_1, targetId;\n\n    return tslib.__generator(this, function (_e) {\n      switch (_e.label) {\n        case 0:\n          syncEngineImpl = ensureWatchCallbacks(syncEngine);\n\n          if (!syncEngineImpl._isPrimaryClient) {\n            return [2\n            /*return*/\n            ];\n          }\n\n          _i = 0, added_1 = added;\n          _e.label = 1;\n\n        case 1:\n          if (!(_i < added_1.length)) return [3\n          /*break*/\n          , 6];\n          targetId = added_1[_i];\n\n          if (syncEngineImpl.queriesByTarget.has(targetId)) {\n            // A target might have been added in a previous attempt\n            logDebug(LOG_TAG$3, 'Adding an already active target ' + targetId);\n            return [3\n            /*break*/\n            , 5];\n          }\n\n          return [4\n          /*yield*/\n          , localStoreGetCachedTarget(syncEngineImpl.localStore, targetId)];\n\n        case 2:\n          target = _e.sent();\n          return [4\n          /*yield*/\n          , localStoreAllocateTarget(syncEngineImpl.localStore, target)];\n\n        case 3:\n          targetData = _e.sent();\n          return [4\n          /*yield*/\n          , initializeViewAndComputeSnapshot(syncEngineImpl, synthesizeTargetToQuery(target), targetData.targetId,\n          /*current=*/\n          false)];\n\n        case 4:\n          _e.sent();\n\n          remoteStoreListen(syncEngineImpl.remoteStore, targetData);\n          _e.label = 5;\n\n        case 5:\n          _i++;\n          return [3\n          /*break*/\n          , 1];\n\n        case 6:\n          _loop_5 = function (targetId) {\n            return tslib.__generator(this, function (_f) {\n              switch (_f.label) {\n                case 0:\n                  // Check that the target is still active since the target might have been\n                  // removed if it has been rejected by the backend.\n                  if (!syncEngineImpl.queriesByTarget.has(targetId)) {\n                    return [2\n                    /*return*/\n                    , \"continue\"];\n                  } // Release queries that are still active.\n\n\n                  return [4\n                  /*yield*/\n                  , localStoreReleaseTarget(syncEngineImpl.localStore, targetId,\n                  /* keepPersistedTargetData */\n                  false).then(function () {\n                    remoteStoreUnlisten(syncEngineImpl.remoteStore, targetId);\n                    removeAndCleanupTarget(syncEngineImpl, targetId);\n                  }).catch(ignoreIfPrimaryLeaseLoss)];\n\n                case 1:\n                  // Release queries that are still active.\n                  _f.sent();\n\n                  return [2\n                  /*return*/\n                  ];\n              }\n            });\n          };\n\n          _d = 0, removed_1 = removed;\n          _e.label = 7;\n\n        case 7:\n          if (!(_d < removed_1.length)) return [3\n          /*break*/\n          , 10];\n          targetId = removed_1[_d];\n          return [5\n          /*yield**/\n          , _loop_5(targetId)];\n\n        case 8:\n          _e.sent();\n\n          _e.label = 9;\n\n        case 9:\n          _d++;\n          return [3\n          /*break*/\n          , 7];\n\n        case 10:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction ensureWatchCallbacks(syncEngine) {\n  var syncEngineImpl = debugCast(syncEngine);\n  syncEngineImpl.remoteStore.remoteSyncer.applyRemoteEvent = syncEngineApplyRemoteEvent.bind(null, syncEngineImpl);\n  syncEngineImpl.remoteStore.remoteSyncer.getRemoteKeysForTarget = syncEngineGetRemoteKeysForTarget.bind(null, syncEngineImpl);\n  syncEngineImpl.remoteStore.remoteSyncer.rejectListen = syncEngineRejectListen.bind(null, syncEngineImpl);\n  syncEngineImpl.syncEngineListener.onWatchChange = eventManagerOnWatchChange.bind(null, syncEngineImpl.eventManager);\n  syncEngineImpl.syncEngineListener.onWatchError = eventManagerOnWatchError.bind(null, syncEngineImpl.eventManager);\n  return syncEngineImpl;\n}\n\nfunction syncEngineEnsureWriteCallbacks(syncEngine) {\n  var syncEngineImpl = debugCast(syncEngine);\n  syncEngineImpl.remoteStore.remoteSyncer.applySuccessfulWrite = syncEngineApplySuccessfulWrite.bind(null, syncEngineImpl);\n  syncEngineImpl.remoteStore.remoteSyncer.rejectFailedWrite = syncEngineRejectFailedWrite.bind(null, syncEngineImpl);\n  return syncEngineImpl;\n}\n/**\r\n * Loads a Firestore bundle into the SDK. The returned promise resolves when\r\n * the bundle finished loading.\r\n *\r\n * @param syncEngine - SyncEngine to use.\r\n * @param bundleReader - Bundle to load into the SDK.\r\n * @param task - LoadBundleTask used to update the loading progress to public API.\r\n */\n\n\nfunction syncEngineLoadBundle(syncEngine, bundleReader, task) {\n  var syncEngineImpl = debugCast(syncEngine); // eslint-disable-next-line @typescript-eslint/no-floating-promises\n\n  loadBundleImpl(syncEngineImpl, bundleReader, task).then(function () {\n    syncEngineImpl.sharedClientState.notifyBundleLoaded();\n  });\n}\n\nfunction loadBundleImpl(syncEngine, reader, task) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var metadata, skip, loader, element, progress, result, e_10;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          _d.trys.push([0, 13,, 14]);\n\n          return [4\n          /*yield*/\n          , reader.getMetadata()];\n\n        case 1:\n          metadata = _d.sent();\n          return [4\n          /*yield*/\n          , localStoreHasNewerBundle(syncEngine.localStore, metadata)];\n\n        case 2:\n          skip = _d.sent();\n          if (!skip) return [3\n          /*break*/\n          , 4];\n          return [4\n          /*yield*/\n          , reader.close()];\n\n        case 3:\n          _d.sent();\n\n          task._completeWith(bundleSuccessProgress(metadata));\n\n          return [2\n          /*return*/\n          ];\n\n        case 4:\n          task._updateProgress(bundleInitialProgress(metadata));\n\n          loader = new BundleLoader(metadata, syncEngine.localStore, reader.serializer);\n          return [4\n          /*yield*/\n          , reader.nextElement()];\n\n        case 5:\n          element = _d.sent();\n          _d.label = 6;\n\n        case 6:\n          if (!element) return [3\n          /*break*/\n          , 9];\n          return [4\n          /*yield*/\n          , loader.addSizedElement(element)];\n\n        case 7:\n          progress = _d.sent();\n\n          if (progress) {\n            task._updateProgress(progress);\n          }\n\n          return [4\n          /*yield*/\n          , reader.nextElement()];\n\n        case 8:\n          element = _d.sent();\n          return [3\n          /*break*/\n          , 6];\n\n        case 9:\n          return [4\n          /*yield*/\n          , loader.complete()];\n\n        case 10:\n          result = _d.sent(); // TODO(b/160876443): This currently raises snapshots with\n          // `fromCache=false` if users already listen to some queries and bundles\n          // has newer version.\n\n          return [4\n          /*yield*/\n          , syncEngineEmitNewSnapsAndNotifyLocalStore(syncEngine, result.changedDocs,\n          /* remoteEvent */\n          undefined)];\n\n        case 11:\n          // TODO(b/160876443): This currently raises snapshots with\n          // `fromCache=false` if users already listen to some queries and bundles\n          // has newer version.\n          _d.sent(); // Save metadata, so loading the same bundle will skip.\n\n\n          return [4\n          /*yield*/\n          , localStoreSaveBundle(syncEngine.localStore, metadata)];\n\n        case 12:\n          // Save metadata, so loading the same bundle will skip.\n          _d.sent();\n\n          task._completeWith(result.progress);\n\n          return [3\n          /*break*/\n          , 14];\n\n        case 13:\n          e_10 = _d.sent();\n          logWarn(LOG_TAG$3, \"Loading bundle failed with \" + e_10);\n\n          task._failWith(e_10);\n\n          return [3\n          /*break*/\n          , 14];\n\n        case 14:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Provides all components needed for Firestore with in-memory persistence.\r\n * Uses EagerGC garbage collection.\r\n */\n\n\nvar MemoryOfflineComponentProvider =\n/** @class */\nfunction () {\n  function MemoryOfflineComponentProvider() {\n    this.synchronizeTabs = false;\n  }\n\n  MemoryOfflineComponentProvider.prototype.initialize = function (cfg) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            this.serializer = newSerializer(cfg.databaseInfo.databaseId);\n            this.sharedClientState = this.createSharedClientState(cfg);\n            this.persistence = this.createPersistence(cfg);\n            return [4\n            /*yield*/\n            , this.persistence.start()];\n\n          case 1:\n            _d.sent();\n\n            this.gcScheduler = this.createGarbageCollectionScheduler(cfg);\n            this.localStore = this.createLocalStore(cfg);\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  MemoryOfflineComponentProvider.prototype.createGarbageCollectionScheduler = function (cfg) {\n    return null;\n  };\n\n  MemoryOfflineComponentProvider.prototype.createLocalStore = function (cfg) {\n    return newLocalStore(this.persistence, new QueryEngine(), cfg.initialUser, this.serializer);\n  };\n\n  MemoryOfflineComponentProvider.prototype.createPersistence = function (cfg) {\n    return new MemoryPersistence(MemoryEagerDelegate.factory, this.serializer);\n  };\n\n  MemoryOfflineComponentProvider.prototype.createSharedClientState = function (cfg) {\n    return new MemorySharedClientState();\n  };\n\n  MemoryOfflineComponentProvider.prototype.terminate = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            if (this.gcScheduler) {\n              this.gcScheduler.stop();\n            }\n\n            return [4\n            /*yield*/\n            , this.sharedClientState.shutdown()];\n\n          case 1:\n            _d.sent();\n\n            return [4\n            /*yield*/\n            , this.persistence.shutdown()];\n\n          case 2:\n            _d.sent();\n\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  return MemoryOfflineComponentProvider;\n}();\n/**\r\n * Provides all components needed for Firestore with IndexedDB persistence.\r\n */\n\n\nvar IndexedDbOfflineComponentProvider =\n/** @class */\nfunction (_super) {\n  tslib.__extends(IndexedDbOfflineComponentProvider, _super);\n\n  function IndexedDbOfflineComponentProvider(onlineComponentProvider, cacheSizeBytes, forceOwnership) {\n    var _this = _super.call(this) || this;\n\n    _this.onlineComponentProvider = onlineComponentProvider;\n    _this.cacheSizeBytes = cacheSizeBytes;\n    _this.forceOwnership = forceOwnership;\n    _this.synchronizeTabs = false;\n    return _this;\n  }\n\n  IndexedDbOfflineComponentProvider.prototype.initialize = function (cfg) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , _super.prototype.initialize.call(this, cfg)];\n\n          case 1:\n            _d.sent();\n\n            return [4\n            /*yield*/\n            , localStoreSynchronizeLastDocumentChangeReadTime(this.localStore)];\n\n          case 2:\n            _d.sent();\n\n            return [4\n            /*yield*/\n            , this.onlineComponentProvider.initialize(this, cfg)];\n\n          case 3:\n            _d.sent(); // Enqueue writes from a previous session\n\n\n            return [4\n            /*yield*/\n            , syncEngineEnsureWriteCallbacks(this.onlineComponentProvider.syncEngine)];\n\n          case 4:\n            // Enqueue writes from a previous session\n            _d.sent();\n\n            return [4\n            /*yield*/\n            , fillWritePipeline(this.onlineComponentProvider.remoteStore)];\n\n          case 5:\n            _d.sent();\n\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  IndexedDbOfflineComponentProvider.prototype.createLocalStore = function (cfg) {\n    return newLocalStore(this.persistence, new QueryEngine(), cfg.initialUser, this.serializer);\n  };\n\n  IndexedDbOfflineComponentProvider.prototype.createGarbageCollectionScheduler = function (cfg) {\n    var garbageCollector = this.persistence.referenceDelegate.garbageCollector;\n    return new LruScheduler(garbageCollector, cfg.asyncQueue);\n  };\n\n  IndexedDbOfflineComponentProvider.prototype.createPersistence = function (cfg) {\n    var persistenceKey = indexedDbStoragePrefix(cfg.databaseInfo.databaseId, cfg.databaseInfo.persistenceKey);\n    var lruParams = this.cacheSizeBytes !== undefined ? LruParams.withCacheSize(this.cacheSizeBytes) : LruParams.DEFAULT;\n    return new IndexedDbPersistence(this.synchronizeTabs, persistenceKey, cfg.clientId, lruParams, cfg.asyncQueue, getWindow(), getDocument(), this.serializer, this.sharedClientState, !!this.forceOwnership);\n  };\n\n  IndexedDbOfflineComponentProvider.prototype.createSharedClientState = function (cfg) {\n    return new MemorySharedClientState();\n  };\n\n  return IndexedDbOfflineComponentProvider;\n}(MemoryOfflineComponentProvider);\n/**\r\n * Provides all components needed for Firestore with multi-tab IndexedDB\r\n * persistence.\r\n *\r\n * In the legacy client, this provider is used to provide both multi-tab and\r\n * non-multi-tab persistence since we cannot tell at build time whether\r\n * `synchronizeTabs` will be enabled.\r\n */\n\n\nvar MultiTabOfflineComponentProvider =\n/** @class */\nfunction (_super) {\n  tslib.__extends(MultiTabOfflineComponentProvider, _super);\n\n  function MultiTabOfflineComponentProvider(onlineComponentProvider, cacheSizeBytes) {\n    var _this = _super.call(this, onlineComponentProvider, cacheSizeBytes,\n    /* forceOwnership= */\n    false) || this;\n\n    _this.onlineComponentProvider = onlineComponentProvider;\n    _this.cacheSizeBytes = cacheSizeBytes;\n    _this.synchronizeTabs = true;\n    return _this;\n  }\n\n  MultiTabOfflineComponentProvider.prototype.initialize = function (cfg) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var syncEngine;\n\n      var _this = this;\n\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , _super.prototype.initialize.call(this, cfg)];\n\n          case 1:\n            _d.sent();\n\n            syncEngine = this.onlineComponentProvider.syncEngine;\n            if (!(this.sharedClientState instanceof WebStorageSharedClientState)) return [3\n            /*break*/\n            , 3];\n            this.sharedClientState.syncEngine = {\n              applyBatchState: syncEngineApplyBatchState.bind(null, syncEngine),\n              applyTargetState: syncEngineApplyTargetState.bind(null, syncEngine),\n              applyActiveTargetsChange: syncEngineApplyActiveTargetsChange.bind(null, syncEngine),\n              getActiveClients: syncEngineGetActiveClients.bind(null, syncEngine),\n              synchronizeWithChangedDocuments: syncEngineSynchronizeWithChangedDocuments.bind(null, syncEngine)\n            };\n            return [4\n            /*yield*/\n            , this.sharedClientState.start()];\n\n          case 2:\n            _d.sent();\n\n            _d.label = 3;\n\n          case 3:\n            // NOTE: This will immediately call the listener, so we make sure to\n            // set it after localStore / remoteStore are started.\n            return [4\n            /*yield*/\n            , this.persistence.setPrimaryStateListener(function (isPrimary) {\n              return tslib.__awaiter(_this, void 0, void 0, function () {\n                return tslib.__generator(this, function (_d) {\n                  switch (_d.label) {\n                    case 0:\n                      return [4\n                      /*yield*/\n                      , syncEngineApplyPrimaryState(this.onlineComponentProvider.syncEngine, isPrimary)];\n\n                    case 1:\n                      _d.sent();\n\n                      if (this.gcScheduler) {\n                        if (isPrimary && !this.gcScheduler.started) {\n                          this.gcScheduler.start(this.localStore);\n                        } else if (!isPrimary) {\n                          this.gcScheduler.stop();\n                        }\n                      }\n\n                      return [2\n                      /*return*/\n                      ];\n                  }\n                });\n              });\n            })];\n\n          case 4:\n            // NOTE: This will immediately call the listener, so we make sure to\n            // set it after localStore / remoteStore are started.\n            _d.sent();\n\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  MultiTabOfflineComponentProvider.prototype.createSharedClientState = function (cfg) {\n    var window = getWindow();\n\n    if (!WebStorageSharedClientState.isAvailable(window)) {\n      throw new FirestoreError(Code.UNIMPLEMENTED, 'IndexedDB persistence is only available on platforms that support LocalStorage.');\n    }\n\n    var persistenceKey = indexedDbStoragePrefix(cfg.databaseInfo.databaseId, cfg.databaseInfo.persistenceKey);\n    return new WebStorageSharedClientState(window, cfg.asyncQueue, persistenceKey, cfg.clientId, cfg.initialUser);\n  };\n\n  return MultiTabOfflineComponentProvider;\n}(IndexedDbOfflineComponentProvider);\n/**\r\n * Initializes and wires the components that are needed to interface with the\r\n * network.\r\n */\n\n\nvar OnlineComponentProvider =\n/** @class */\nfunction () {\n  function OnlineComponentProvider() {}\n\n  OnlineComponentProvider.prototype.initialize = function (offlineComponentProvider, cfg) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var _this = this;\n\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            if (this.localStore) {\n              // OnlineComponentProvider may get initialized multiple times if\n              // multi-tab persistence is used.\n              return [2\n              /*return*/\n              ];\n            }\n\n            this.localStore = offlineComponentProvider.localStore;\n            this.sharedClientState = offlineComponentProvider.sharedClientState;\n            this.datastore = this.createDatastore(cfg);\n            this.remoteStore = this.createRemoteStore(cfg);\n            this.eventManager = this.createEventManager(cfg);\n            this.syncEngine = this.createSyncEngine(cfg,\n            /* startAsPrimary=*/\n            !offlineComponentProvider.synchronizeTabs);\n\n            this.sharedClientState.onlineStateHandler = function (onlineState) {\n              return syncEngineApplyOnlineStateChange(_this.syncEngine, onlineState, 1\n              /* SharedClientState */\n              );\n            };\n\n            this.remoteStore.remoteSyncer.handleCredentialChange = syncEngineHandleCredentialChange.bind(null, this.syncEngine);\n            return [4\n            /*yield*/\n            , remoteStoreApplyPrimaryState(this.remoteStore, this.syncEngine.isPrimaryClient)];\n\n          case 1:\n            _d.sent();\n\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  OnlineComponentProvider.prototype.createEventManager = function (cfg) {\n    return newEventManager();\n  };\n\n  OnlineComponentProvider.prototype.createDatastore = function (cfg) {\n    var serializer = newSerializer(cfg.databaseInfo.databaseId);\n    var connection = newConnection(cfg.databaseInfo);\n    return newDatastore(cfg.credentials, connection, serializer);\n  };\n\n  OnlineComponentProvider.prototype.createRemoteStore = function (cfg) {\n    var _this = this;\n\n    return newRemoteStore(this.localStore, this.datastore, cfg.asyncQueue, function (onlineState) {\n      return syncEngineApplyOnlineStateChange(_this.syncEngine, onlineState, 0\n      /* RemoteStore */\n      );\n    }, newConnectivityMonitor());\n  };\n\n  OnlineComponentProvider.prototype.createSyncEngine = function (cfg, startAsPrimary) {\n    return newSyncEngine(this.localStore, this.remoteStore, this.eventManager, this.sharedClientState, cfg.initialUser, cfg.maxConcurrentLimboResolutions, startAsPrimary);\n  };\n\n  OnlineComponentProvider.prototype.terminate = function () {\n    return remoteStoreShutdown(this.remoteStore);\n  };\n\n  return OnlineComponentProvider;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * How many bytes to read each time when `ReadableStreamReader.read()` is\r\n * called. Only applicable for byte streams that we control (e.g. those backed\r\n * by an UInt8Array).\r\n */\n\n\nvar DEFAULT_BYTES_PER_READ = 10240;\n/**\r\n * Builds a `ByteStreamReader` from a UInt8Array.\r\n * @param source - The data source to use.\r\n * @param bytesPerRead - How many bytes each `read()` from the returned reader\r\n *        will read.\r\n */\n\nfunction toByteStreamReaderHelper(source, bytesPerRead) {\n  if (bytesPerRead === void 0) {\n    bytesPerRead = DEFAULT_BYTES_PER_READ;\n  }\n\n  var readFrom = 0;\n  var reader = {\n    read: function () {\n      return tslib.__awaiter(this, void 0, void 0, function () {\n        var result;\n        return tslib.__generator(this, function (_d) {\n          if (readFrom < source.byteLength) {\n            result = {\n              value: source.slice(readFrom, readFrom + bytesPerRead),\n              done: false\n            };\n            readFrom += bytesPerRead;\n            return [2\n            /*return*/\n            , result];\n          }\n\n          return [2\n          /*return*/\n          , {\n            done: true\n          }];\n        });\n      });\n    },\n    cancel: function () {\n      return tslib.__awaiter(this, void 0, void 0, function () {\n        return tslib.__generator(this, function (_d) {\n          return [2\n          /*return*/\n          ];\n        });\n      });\n    },\n    releaseLock: function () {},\n    closed: Promise.reject('unimplemented')\n  };\n  return reader;\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction validateNonEmptyArgument(functionName, argumentName, argument) {\n  if (!argument) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Function \" + functionName + \"() cannot be called with an empty \" + argumentName + \".\");\n  }\n}\n\nfunction validateSetOptions(methodName, options) {\n  if (options === undefined) {\n    return {\n      merge: false\n    };\n  }\n\n  if (options.mergeFields !== undefined && options.merge !== undefined) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid options passed to function \" + methodName + \"(): You cannot \" + 'specify both \"merge\" and \"mergeFields\".');\n  }\n\n  return options;\n}\n/**\r\n * Validates that two boolean options are not set at the same time.\r\n */\n\n\nfunction validateIsNotUsedTogether(optionName1, argument1, optionName2, argument2) {\n  if (argument1 === true && argument2 === true) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, optionName1 + \" and \" + optionName2 + \" cannot be used together.\");\n  }\n}\n/**\r\n * Validates that `path` refers to a document (indicated by the fact it contains\r\n * an even numbers of segments).\r\n */\n\n\nfunction validateDocumentPath(path) {\n  if (!DocumentKey.isDocumentKey(path)) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid document reference. Document references must have an even number of segments, but \" + path + \" has \" + path.length + \".\");\n  }\n}\n/**\r\n * Validates that `path` refers to a collection (indicated by the fact it\r\n * contains an odd numbers of segments).\r\n */\n\n\nfunction validateCollectionPath(path) {\n  if (DocumentKey.isDocumentKey(path)) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid collection reference. Collection references must have an odd number of segments, but \" + path + \" has \" + path.length + \".\");\n  }\n}\n/**\r\n * Returns true if it's a non-null object without a custom prototype\r\n * (i.e. excludes Array, Date, etc.).\r\n */\n\n\nfunction isPlainObject(input) {\n  return typeof input === 'object' && input !== null && (Object.getPrototypeOf(input) === Object.prototype || Object.getPrototypeOf(input) === null);\n}\n/** Returns a string describing the type / value of the provided input. */\n\n\nfunction valueDescription(input) {\n  if (input === undefined) {\n    return 'undefined';\n  } else if (input === null) {\n    return 'null';\n  } else if (typeof input === 'string') {\n    if (input.length > 20) {\n      input = input.substring(0, 20) + \"...\";\n    }\n\n    return JSON.stringify(input);\n  } else if (typeof input === 'number' || typeof input === 'boolean') {\n    return '' + input;\n  } else if (typeof input === 'object') {\n    if (input instanceof Array) {\n      return 'an array';\n    } else {\n      var customObjectName = tryGetCustomObjectType(input);\n\n      if (customObjectName) {\n        return \"a custom \" + customObjectName + \" object\";\n      } else {\n        return 'an object';\n      }\n    }\n  } else if (typeof input === 'function') {\n    return 'a function';\n  } else {\n    return fail();\n  }\n}\n/** Hacky method to try to get the constructor name for an object. */\n\n\nfunction tryGetCustomObjectType(input) {\n  if (input.constructor) {\n    var funcNameRegex = /function\\s+([^\\s(]+)\\s*\\(/;\n    var results = funcNameRegex.exec(input.constructor.toString());\n\n    if (results && results.length > 1) {\n      return results[1];\n    }\n  }\n\n  return null;\n}\n/**\r\n * Casts `obj` to `T`, optionally unwrapping Compat types to expose the\r\n * underlying instance. Throws if  `obj` is not an instance of `T`.\r\n *\r\n * This cast is used in the Lite and Full SDK to verify instance types for\r\n * arguments passed to the public API.\r\n */\n\n\nfunction cast(obj, // eslint-disable-next-line @typescript-eslint/no-explicit-any\nconstructor) {\n  if ('_delegate' in obj) {\n    // Unwrap Compat types\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    obj = obj._delegate;\n  }\n\n  if (!(obj instanceof constructor)) {\n    if (constructor.name === obj.constructor.name) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Type does not match the expected instance. Did you pass a ' + \"reference from a different Firestore SDK?\");\n    } else {\n      var description = valueDescription(obj);\n      throw new FirestoreError(Code.INVALID_ARGUMENT, \"Expected type '\" + constructor.name + \"', but it was: \" + description);\n    }\n  }\n\n  return obj;\n}\n\nfunction validatePositiveNumber(functionName, n) {\n  if (n <= 0) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Function \" + functionName + \"() requires a positive number, but it was: \" + n + \".\");\n  }\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * On Node, only supported data source is a `Uint8Array` for now.\r\n */\n\n\nfunction toByteStreamReader(source, bytesPerRead) {\n  if (!(source instanceof Uint8Array)) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"NodePlatform.toByteStreamReader expects source to be Uint8Array, got \" + valueDescription(source));\n  }\n\n  return toByteStreamReaderHelper(source, bytesPerRead);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/*\r\n * A wrapper implementation of Observer<T> that will dispatch events\r\n * asynchronously. To allow immediate silencing, a mute call is added which\r\n * causes events scheduled to no longer be raised.\r\n */\n\n\nvar AsyncObserver =\n/** @class */\nfunction () {\n  function AsyncObserver(observer) {\n    this.observer = observer;\n    /**\r\n     * When set to true, will not raise future events. Necessary to deal with\r\n     * async detachment of listener.\r\n     */\n\n    this.muted = false;\n  }\n\n  AsyncObserver.prototype.next = function (value) {\n    if (this.observer.next) {\n      this.scheduleEvent(this.observer.next, value);\n    }\n  };\n\n  AsyncObserver.prototype.error = function (error) {\n    if (this.observer.error) {\n      this.scheduleEvent(this.observer.error, error);\n    } else {\n      console.error('Uncaught Error in snapshot listener:', error);\n    }\n  };\n\n  AsyncObserver.prototype.mute = function () {\n    this.muted = true;\n  };\n\n  AsyncObserver.prototype.scheduleEvent = function (eventHandler, event) {\n    var _this = this;\n\n    if (!this.muted) {\n      setTimeout(function () {\n        if (!_this.muted) {\n          eventHandler(event);\n        }\n      }, 0);\n    }\n  };\n\n  return AsyncObserver;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A complete element in the bundle stream, together with the byte length it\r\n * occupies in the stream.\r\n */\n\n\nvar SizedBundleElement =\n/** @class */\nfunction () {\n  function SizedBundleElement(payload, // How many bytes this element takes to store in the bundle.\n  byteLength) {\n    this.payload = payload;\n    this.byteLength = byteLength;\n  }\n\n  SizedBundleElement.prototype.isBundleMetadata = function () {\n    return 'metadata' in this.payload;\n  };\n\n  return SizedBundleElement;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A class representing a bundle.\r\n *\r\n * Takes a bundle stream or buffer, and presents abstractions to read bundled\r\n * elements out of the underlying content.\r\n */\n\n\nvar BundleReaderImpl =\n/** @class */\nfunction () {\n  function BundleReaderImpl(\n  /** The reader to read from underlying binary bundle data source. */\n  reader, serializer) {\n    var _this = this;\n\n    this.reader = reader;\n    this.serializer = serializer;\n    /** Cached bundle metadata. */\n\n    this.metadata = new Deferred();\n    /**\r\n     * Internal buffer to hold bundle content, accumulating incomplete element\r\n     * content.\r\n     */\n\n    this.buffer = new Uint8Array();\n    this.textDecoder = newTextDecoder(); // Read the metadata (which is the first element).\n\n    this.nextElementImpl().then(function (element) {\n      if (element && element.isBundleMetadata()) {\n        _this.metadata.resolve(element.payload.metadata);\n      } else {\n        _this.metadata.reject(new Error(\"The first element of the bundle is not a metadata, it is\\n             \" + JSON.stringify(element === null || element === void 0 ? void 0 : element.payload)));\n      }\n    }, function (error) {\n      return _this.metadata.reject(error);\n    });\n  }\n\n  BundleReaderImpl.prototype.close = function () {\n    return this.reader.cancel();\n  };\n\n  BundleReaderImpl.prototype.getMetadata = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        return [2\n        /*return*/\n        , this.metadata.promise];\n      });\n    });\n  };\n\n  BundleReaderImpl.prototype.nextElement = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            // Makes sure metadata is read before proceeding.\n            return [4\n            /*yield*/\n            , this.getMetadata()];\n\n          case 1:\n            // Makes sure metadata is read before proceeding.\n            _d.sent();\n\n            return [2\n            /*return*/\n            , this.nextElementImpl()];\n        }\n      });\n    });\n  };\n  /**\r\n   * Reads from the head of internal buffer, and pulling more data from\r\n   * underlying stream if a complete element cannot be found, until an\r\n   * element(including the prefixed length and the JSON string) is found.\r\n   *\r\n   * Once a complete element is read, it is dropped from internal buffer.\r\n   *\r\n   * Returns either the bundled element, or null if we have reached the end of\r\n   * the stream.\r\n   */\n\n\n  BundleReaderImpl.prototype.nextElementImpl = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var lengthBuffer, lengthString, length, jsonString;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , this.readLength()];\n\n          case 1:\n            lengthBuffer = _d.sent();\n\n            if (lengthBuffer === null) {\n              return [2\n              /*return*/\n              , null];\n            }\n\n            lengthString = this.textDecoder.decode(lengthBuffer);\n            length = Number(lengthString);\n\n            if (isNaN(length)) {\n              this.raiseError(\"length string (\" + lengthString + \") is not valid number\");\n            }\n\n            return [4\n            /*yield*/\n            , this.readJsonString(length)];\n\n          case 2:\n            jsonString = _d.sent();\n            return [2\n            /*return*/\n            , new SizedBundleElement(JSON.parse(jsonString), lengthBuffer.length + length)];\n        }\n      });\n    });\n  };\n  /** First index of '{' from the underlying buffer. */\n\n\n  BundleReaderImpl.prototype.indexOfOpenBracket = function () {\n    return this.buffer.findIndex(function (v) {\n      return v === '{'.charCodeAt(0);\n    });\n  };\n  /**\r\n   * Reads from the beginning of the internal buffer, until the first '{', and\r\n   * return the content.\r\n   *\r\n   * If reached end of the stream, returns a null.\r\n   */\n\n\n  BundleReaderImpl.prototype.readLength = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var done, position, result;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            if (!(this.indexOfOpenBracket() < 0)) return [3\n            /*break*/\n            , 2];\n            return [4\n            /*yield*/\n            , this.pullMoreDataToBuffer()];\n\n          case 1:\n            done = _d.sent();\n\n            if (done) {\n              return [3\n              /*break*/\n              , 2];\n            }\n\n            return [3\n            /*break*/\n            , 0];\n\n          case 2:\n            // Broke out of the loop because underlying stream is closed, and there\n            // happens to be no more data to process.\n            if (this.buffer.length === 0) {\n              return [2\n              /*return*/\n              , null];\n            }\n\n            position = this.indexOfOpenBracket(); // Broke out of the loop because underlying stream is closed, but still\n            // cannot find an open bracket.\n\n            if (position < 0) {\n              this.raiseError('Reached the end of bundle when a length string is expected.');\n            }\n\n            result = this.buffer.slice(0, position); // Update the internal buffer to drop the read length.\n\n            this.buffer = this.buffer.slice(position);\n            return [2\n            /*return*/\n            , result];\n        }\n      });\n    });\n  };\n  /**\r\n   * Reads from a specified position from the internal buffer, for a specified\r\n   * number of bytes, pulling more data from the underlying stream if needed.\r\n   *\r\n   * Returns a string decoded from the read bytes.\r\n   */\n\n\n  BundleReaderImpl.prototype.readJsonString = function (length) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var done, result;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            if (!(this.buffer.length < length)) return [3\n            /*break*/\n            , 2];\n            return [4\n            /*yield*/\n            , this.pullMoreDataToBuffer()];\n\n          case 1:\n            done = _d.sent();\n\n            if (done) {\n              this.raiseError('Reached the end of bundle when more is expected.');\n            }\n\n            return [3\n            /*break*/\n            , 0];\n\n          case 2:\n            result = this.textDecoder.decode(this.buffer.slice(0, length)); // Update the internal buffer to drop the read json string.\n\n            this.buffer = this.buffer.slice(length);\n            return [2\n            /*return*/\n            , result];\n        }\n      });\n    });\n  };\n\n  BundleReaderImpl.prototype.raiseError = function (message) {\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.reader.cancel();\n    throw new Error(\"Invalid bundle format: \" + message);\n  };\n  /**\r\n   * Pulls more data from underlying stream to internal buffer.\r\n   * Returns a boolean indicating whether the stream is finished.\r\n   */\n\n\n  BundleReaderImpl.prototype.pullMoreDataToBuffer = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var result, newBuffer;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , this.reader.read()];\n\n          case 1:\n            result = _d.sent();\n\n            if (!result.done) {\n              newBuffer = new Uint8Array(this.buffer.length + result.value.length);\n              newBuffer.set(this.buffer);\n              newBuffer.set(result.value, this.buffer.length);\n              this.buffer = newBuffer;\n            }\n\n            return [2\n            /*return*/\n            , result.done];\n        }\n      });\n    });\n  };\n\n  return BundleReaderImpl;\n}();\n\nfunction newBundleReader(reader, serializer) {\n  return new BundleReaderImpl(reader, serializer);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Internal transaction object responsible for accumulating the mutations to\r\n * perform and the base versions for any documents read.\r\n */\n\n\nvar Transaction$3 =\n/** @class */\nfunction () {\n  function Transaction$3(datastore) {\n    this.datastore = datastore; // The version of each document that was read during this transaction.\n\n    this.readVersions = new Map();\n    this.mutations = [];\n    this.committed = false;\n    /**\r\n     * A deferred usage error that occurred previously in this transaction that\r\n     * will cause the transaction to fail once it actually commits.\r\n     */\n\n    this.lastWriteError = null;\n    /**\r\n     * Set of documents that have been written in the transaction.\r\n     *\r\n     * When there's more than one write to the same key in a transaction, any\r\n     * writes after the first are handled differently.\r\n     */\n\n    this.writtenDocs = new Set();\n  }\n\n  Transaction$3.prototype.lookup = function (keys) {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var docs;\n\n      var _this = this;\n\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            this.ensureCommitNotCalled();\n\n            if (this.mutations.length > 0) {\n              throw new FirestoreError(Code.INVALID_ARGUMENT, 'Firestore transactions require all reads to be executed before all writes.');\n            }\n\n            return [4\n            /*yield*/\n            , invokeBatchGetDocumentsRpc(this.datastore, keys)];\n\n          case 1:\n            docs = _d.sent();\n            docs.forEach(function (doc) {\n              return _this.recordVersion(doc);\n            });\n            return [2\n            /*return*/\n            , docs];\n        }\n      });\n    });\n  };\n\n  Transaction$3.prototype.set = function (key, data) {\n    this.write(data.toMutation(key, this.precondition(key)));\n    this.writtenDocs.add(key.toString());\n  };\n\n  Transaction$3.prototype.update = function (key, data) {\n    try {\n      this.write(data.toMutation(key, this.preconditionForUpdate(key)));\n    } catch (e) {\n      this.lastWriteError = e;\n    }\n\n    this.writtenDocs.add(key.toString());\n  };\n\n  Transaction$3.prototype.delete = function (key) {\n    this.write(new DeleteMutation(key, this.precondition(key)));\n    this.writtenDocs.add(key.toString());\n  };\n\n  Transaction$3.prototype.commit = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var unwritten;\n\n      var _this = this;\n\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            this.ensureCommitNotCalled();\n\n            if (this.lastWriteError) {\n              throw this.lastWriteError;\n            }\n\n            unwritten = this.readVersions; // For each mutation, note that the doc was written.\n\n            this.mutations.forEach(function (mutation) {\n              unwritten.delete(mutation.key.toString());\n            }); // For each document that was read but not written to, we want to perform\n            // a `verify` operation.\n\n            unwritten.forEach(function (_, path) {\n              var key = DocumentKey.fromPath(path);\n\n              _this.mutations.push(new VerifyMutation(key, _this.precondition(key)));\n            });\n            return [4\n            /*yield*/\n            , invokeCommitRpc(this.datastore, this.mutations)];\n\n          case 1:\n            _d.sent();\n\n            this.committed = true;\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  Transaction$3.prototype.recordVersion = function (doc) {\n    var docVersion;\n\n    if (doc.isFoundDocument()) {\n      docVersion = doc.version;\n    } else if (doc.isNoDocument()) {\n      // For deleted docs, we must use baseVersion 0 when we overwrite them.\n      docVersion = SnapshotVersion.min();\n    } else {\n      throw fail();\n    }\n\n    var existingVersion = this.readVersions.get(doc.key.toString());\n\n    if (existingVersion) {\n      if (!docVersion.isEqual(existingVersion)) {\n        // This transaction will fail no matter what.\n        throw new FirestoreError(Code.ABORTED, 'Document version changed between two reads.');\n      }\n    } else {\n      this.readVersions.set(doc.key.toString(), docVersion);\n    }\n  };\n  /**\r\n   * Returns the version of this document when it was read in this transaction,\r\n   * as a precondition, or no precondition if it was not read.\r\n   */\n\n\n  Transaction$3.prototype.precondition = function (key) {\n    var version = this.readVersions.get(key.toString());\n\n    if (!this.writtenDocs.has(key.toString()) && version) {\n      return Precondition.updateTime(version);\n    } else {\n      return Precondition.none();\n    }\n  };\n  /**\r\n   * Returns the precondition for a document if the operation is an update.\r\n   */\n\n\n  Transaction$3.prototype.preconditionForUpdate = function (key) {\n    var version = this.readVersions.get(key.toString()); // The first time a document is written, we want to take into account the\n    // read time and existence\n\n    if (!this.writtenDocs.has(key.toString()) && version) {\n      if (version.isEqual(SnapshotVersion.min())) {\n        // The document doesn't exist, so fail the transaction.\n        // This has to be validated locally because you can't send a\n        // precondition that a document does not exist without changing the\n        // semantics of the backend write to be an insert. This is the reverse\n        // of what we want, since we want to assert that the document doesn't\n        // exist but then send the update and have it fail. Since we can't\n        // express that to the backend, we have to validate locally.\n        // Note: this can change once we can send separate verify writes in the\n        // transaction.\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Can't update a document that doesn't exist.\");\n      } // Document exists, base precondition on document update time.\n\n\n      return Precondition.updateTime(version);\n    } else {\n      // Document was not read, so we just use the preconditions for a blind\n      // update.\n      return Precondition.exists(true);\n    }\n  };\n\n  Transaction$3.prototype.write = function (mutation) {\n    this.ensureCommitNotCalled();\n    this.mutations.push(mutation);\n  };\n\n  Transaction$3.prototype.ensureCommitNotCalled = function () {};\n\n  return Transaction$3;\n}();\n/**\r\n * @license\r\n * Copyright 2019 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar DEFAULT_MAX_ATTEMPTS_COUNT = 5;\n/**\r\n * TransactionRunner encapsulates the logic needed to run and retry transactions\r\n * with backoff.\r\n */\n\nvar TransactionRunner =\n/** @class */\nfunction () {\n  function TransactionRunner(asyncQueue, datastore, updateFunction, deferred) {\n    this.asyncQueue = asyncQueue;\n    this.datastore = datastore;\n    this.updateFunction = updateFunction;\n    this.deferred = deferred;\n    this.attemptsRemaining = DEFAULT_MAX_ATTEMPTS_COUNT;\n    this.backoff = new ExponentialBackoff(this.asyncQueue, \"transaction_retry\"\n    /* TransactionRetry */\n    );\n  }\n  /** Runs the transaction and sets the result on deferred. */\n\n\n  TransactionRunner.prototype.run = function () {\n    this.attemptsRemaining -= 1;\n    this.runWithBackOff();\n  };\n\n  TransactionRunner.prototype.runWithBackOff = function () {\n    var _this = this;\n\n    this.backoff.backoffAndRun(function () {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        var transaction, userPromise;\n\n        var _this = this;\n\n        return tslib.__generator(this, function (_d) {\n          transaction = new Transaction$3(this.datastore);\n          userPromise = this.tryRunUpdateFunction(transaction);\n\n          if (userPromise) {\n            userPromise.then(function (result) {\n              _this.asyncQueue.enqueueAndForget(function () {\n                return transaction.commit().then(function () {\n                  _this.deferred.resolve(result);\n                }).catch(function (commitError) {\n                  _this.handleTransactionError(commitError);\n                });\n              });\n            }).catch(function (userPromiseError) {\n              _this.handleTransactionError(userPromiseError);\n            });\n          }\n\n          return [2\n          /*return*/\n          ];\n        });\n      });\n    });\n  };\n\n  TransactionRunner.prototype.tryRunUpdateFunction = function (transaction) {\n    try {\n      var userPromise = this.updateFunction(transaction);\n\n      if (isNullOrUndefined(userPromise) || !userPromise.catch || !userPromise.then) {\n        this.deferred.reject(Error('Transaction callback must return a Promise'));\n        return null;\n      }\n\n      return userPromise;\n    } catch (error) {\n      // Do not retry errors thrown by user provided updateFunction.\n      this.deferred.reject(error);\n      return null;\n    }\n  };\n\n  TransactionRunner.prototype.handleTransactionError = function (error) {\n    var _this = this;\n\n    if (this.attemptsRemaining > 0 && this.isRetryableTransactionError(error)) {\n      this.attemptsRemaining -= 1;\n      this.asyncQueue.enqueueAndForget(function () {\n        _this.runWithBackOff();\n\n        return Promise.resolve();\n      });\n    } else {\n      this.deferred.reject(error);\n    }\n  };\n\n  TransactionRunner.prototype.isRetryableTransactionError = function (error) {\n    if (error.name === 'FirebaseError') {\n      // In transactions, the backend will fail outdated reads with FAILED_PRECONDITION and\n      // non-matching document versions with ABORTED. These errors should be retried.\n      var code = error.code;\n      return code === 'aborted' || code === 'failed-precondition' || !isPermanentError(code);\n    }\n\n    return false;\n  };\n\n  return TransactionRunner;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$2 = 'FirestoreClient';\nvar MAX_CONCURRENT_LIMBO_RESOLUTIONS = 100;\n/**\r\n * FirestoreClient is a top-level class that constructs and owns all of the\r\n * pieces of the client SDK architecture. It is responsible for creating the\r\n * async queue that is shared by all of the other components in the system.\r\n */\n\nvar FirestoreClient =\n/** @class */\nfunction () {\n  function FirestoreClient(credentials,\n  /**\r\n   * Asynchronous queue responsible for all of our internal processing. When\r\n   * we get incoming work from the user (via public API) or the network\r\n   * (incoming GRPC messages), we should always schedule onto this queue.\r\n   * This ensures all of our work is properly serialized (e.g. we don't\r\n   * start processing a new operation while the previous one is waiting for\r\n   * an async I/O to complete).\r\n   */\n  asyncQueue, databaseInfo) {\n    var _this = this;\n\n    this.credentials = credentials;\n    this.asyncQueue = asyncQueue;\n    this.databaseInfo = databaseInfo;\n    this.user = User.UNAUTHENTICATED;\n    this.clientId = AutoId.newId();\n\n    this.credentialListener = function () {\n      return Promise.resolve();\n    };\n\n    this.credentials.setChangeListener(asyncQueue, function (user) {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              logDebug(LOG_TAG$2, 'Received user=', user.uid);\n              return [4\n              /*yield*/\n              , this.credentialListener(user)];\n\n            case 1:\n              _d.sent();\n\n              this.user = user;\n              return [2\n              /*return*/\n              ];\n          }\n        });\n      });\n    });\n  }\n\n  FirestoreClient.prototype.getConfiguration = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      return tslib.__generator(this, function (_d) {\n        return [2\n        /*return*/\n        , {\n          asyncQueue: this.asyncQueue,\n          databaseInfo: this.databaseInfo,\n          clientId: this.clientId,\n          credentials: this.credentials,\n          initialUser: this.user,\n          maxConcurrentLimboResolutions: MAX_CONCURRENT_LIMBO_RESOLUTIONS\n        }];\n      });\n    });\n  };\n\n  FirestoreClient.prototype.setCredentialChangeListener = function (listener) {\n    this.credentialListener = listener;\n  };\n  /**\r\n   * Checks that the client has not been terminated. Ensures that other methods on\r\n   * this class cannot be called after the client is terminated.\r\n   */\n\n\n  FirestoreClient.prototype.verifyNotTerminated = function () {\n    if (this.asyncQueue.isShuttingDown) {\n      throw new FirestoreError(Code.FAILED_PRECONDITION, 'The client has already been terminated.');\n    }\n  };\n\n  FirestoreClient.prototype.terminate = function () {\n    var _this = this;\n\n    this.asyncQueue.enterRestrictedMode();\n    var deferred = new Deferred();\n    this.asyncQueue.enqueueAndForgetEvenWhileRestricted(function () {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        var e_11, firestoreError;\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              _d.trys.push([0, 5,, 6]);\n\n              if (!this.onlineComponents) return [3\n              /*break*/\n              , 2];\n              return [4\n              /*yield*/\n              , this.onlineComponents.terminate()];\n\n            case 1:\n              _d.sent();\n\n              _d.label = 2;\n\n            case 2:\n              if (!this.offlineComponents) return [3\n              /*break*/\n              , 4];\n              return [4\n              /*yield*/\n              , this.offlineComponents.terminate()];\n\n            case 3:\n              _d.sent();\n\n              _d.label = 4;\n\n            case 4:\n              // `removeChangeListener` must be called after shutting down the\n              // RemoteStore as it will prevent the RemoteStore from retrieving\n              // auth tokens.\n              this.credentials.removeChangeListener();\n              deferred.resolve();\n              return [3\n              /*break*/\n              , 6];\n\n            case 5:\n              e_11 = _d.sent();\n              firestoreError = wrapInUserErrorIfRecoverable(e_11, \"Failed to shutdown persistence\");\n              deferred.reject(firestoreError);\n              return [3\n              /*break*/\n              , 6];\n\n            case 6:\n              return [2\n              /*return*/\n              ];\n          }\n        });\n      });\n    });\n    return deferred.promise;\n  };\n\n  return FirestoreClient;\n}();\n\nfunction setOfflineComponentProvider(client, offlineComponentProvider) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var configuration, currentUser;\n\n    var _this = this;\n\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          client.asyncQueue.verifyOperationInProgress();\n          logDebug(LOG_TAG$2, 'Initializing OfflineComponentProvider');\n          return [4\n          /*yield*/\n          , client.getConfiguration()];\n\n        case 1:\n          configuration = _d.sent();\n          return [4\n          /*yield*/\n          , offlineComponentProvider.initialize(configuration)];\n\n        case 2:\n          _d.sent();\n\n          currentUser = configuration.initialUser;\n          client.setCredentialChangeListener(function (user) {\n            return tslib.__awaiter(_this, void 0, void 0, function () {\n              return tslib.__generator(this, function (_d) {\n                switch (_d.label) {\n                  case 0:\n                    if (!!currentUser.isEqual(user)) return [3\n                    /*break*/\n                    , 2];\n                    return [4\n                    /*yield*/\n                    , localStoreHandleUserChange(offlineComponentProvider.localStore, user)];\n\n                  case 1:\n                    _d.sent();\n\n                    currentUser = user;\n                    _d.label = 2;\n\n                  case 2:\n                    return [2\n                    /*return*/\n                    ];\n                }\n              });\n            });\n          }); // When a user calls clearPersistence() in one client, all other clients\n          // need to be terminated to allow the delete to succeed.\n\n          offlineComponentProvider.persistence.setDatabaseDeletedListener(function () {\n            return client.terminate();\n          });\n          client.offlineComponents = offlineComponentProvider;\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction setOnlineComponentProvider(client, onlineComponentProvider) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var offlineComponentProvider, configuration;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          client.asyncQueue.verifyOperationInProgress();\n          return [4\n          /*yield*/\n          , ensureOfflineComponents(client)];\n\n        case 1:\n          offlineComponentProvider = _d.sent();\n          logDebug(LOG_TAG$2, 'Initializing OnlineComponentProvider');\n          return [4\n          /*yield*/\n          , client.getConfiguration()];\n\n        case 2:\n          configuration = _d.sent();\n          return [4\n          /*yield*/\n          , onlineComponentProvider.initialize(offlineComponentProvider, configuration)];\n\n        case 3:\n          _d.sent(); // The CredentialChangeListener of the online component provider takes\n          // precedence over the offline component provider.\n\n\n          client.setCredentialChangeListener(function (user) {\n            return remoteStoreHandleCredentialChange(onlineComponentProvider.remoteStore, user);\n          });\n          client.onlineComponents = onlineComponentProvider;\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n\nfunction ensureOfflineComponents(client) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          if (!!client.offlineComponents) return [3\n          /*break*/\n          , 2];\n          logDebug(LOG_TAG$2, 'Using default OfflineComponentProvider');\n          return [4\n          /*yield*/\n          , setOfflineComponentProvider(client, new MemoryOfflineComponentProvider())];\n\n        case 1:\n          _d.sent();\n\n          _d.label = 2;\n\n        case 2:\n          return [2\n          /*return*/\n          , client.offlineComponents];\n      }\n    });\n  });\n}\n\nfunction ensureOnlineComponents(client) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          if (!!client.onlineComponents) return [3\n          /*break*/\n          , 2];\n          logDebug(LOG_TAG$2, 'Using default OnlineComponentProvider');\n          return [4\n          /*yield*/\n          , setOnlineComponentProvider(client, new OnlineComponentProvider())];\n\n        case 1:\n          _d.sent();\n\n          _d.label = 2;\n\n        case 2:\n          return [2\n          /*return*/\n          , client.onlineComponents];\n      }\n    });\n  });\n}\n\nfunction getPersistence(client) {\n  return ensureOfflineComponents(client).then(function (c) {\n    return c.persistence;\n  });\n}\n\nfunction getLocalStore(client) {\n  return ensureOfflineComponents(client).then(function (c) {\n    return c.localStore;\n  });\n}\n\nfunction getRemoteStore(client) {\n  return ensureOnlineComponents(client).then(function (c) {\n    return c.remoteStore;\n  });\n}\n\nfunction getSyncEngine(client) {\n  return ensureOnlineComponents(client).then(function (c) {\n    return c.syncEngine;\n  });\n}\n\nfunction getDatastore(client) {\n  return ensureOnlineComponents(client).then(function (c) {\n    return c.datastore;\n  });\n}\n\nfunction getEventManager(client) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var onlineComponentProvider, eventManager;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          return [4\n          /*yield*/\n          , ensureOnlineComponents(client)];\n\n        case 1:\n          onlineComponentProvider = _d.sent();\n          eventManager = onlineComponentProvider.eventManager;\n          eventManager.onListen = syncEngineListen.bind(null, onlineComponentProvider.syncEngine);\n          eventManager.onUnlisten = syncEngineUnlisten.bind(null, onlineComponentProvider.syncEngine);\n          return [2\n          /*return*/\n          , eventManager];\n      }\n    });\n  });\n}\n/** Enables the network connection and re-enqueues all pending operations. */\n\n\nfunction firestoreClientEnableNetwork(client) {\n  var _this = this;\n\n  return client.asyncQueue.enqueue(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var persistence, remoteStore;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getPersistence(client)];\n\n          case 1:\n            persistence = _d.sent();\n            return [4\n            /*yield*/\n            , getRemoteStore(client)];\n\n          case 2:\n            remoteStore = _d.sent();\n            persistence.setNetworkEnabled(true);\n            return [2\n            /*return*/\n            , remoteStoreEnableNetwork(remoteStore)];\n        }\n      });\n    });\n  });\n}\n/** Disables the network connection. Pending operations will not complete. */\n\n\nfunction firestoreClientDisableNetwork(client) {\n  var _this = this;\n\n  return client.asyncQueue.enqueue(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var persistence, remoteStore;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getPersistence(client)];\n\n          case 1:\n            persistence = _d.sent();\n            return [4\n            /*yield*/\n            , getRemoteStore(client)];\n\n          case 2:\n            remoteStore = _d.sent();\n            persistence.setNetworkEnabled(false);\n            return [2\n            /*return*/\n            , remoteStoreDisableNetwork(remoteStore)];\n        }\n      });\n    });\n  });\n}\n/**\r\n * Returns a Promise that resolves when all writes that were pending at the time\r\n * this method was called received server acknowledgement. An acknowledgement\r\n * can be either acceptance or rejection.\r\n */\n\n\nfunction firestoreClientWaitForPendingWrites(client) {\n  var _this = this;\n\n  var deferred = new Deferred();\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var syncEngine;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getSyncEngine(client)];\n\n          case 1:\n            syncEngine = _d.sent();\n            return [2\n            /*return*/\n            , syncEngineRegisterPendingWritesCallback(syncEngine, deferred)];\n        }\n      });\n    });\n  });\n  return deferred.promise;\n}\n\nfunction firestoreClientListen(client, query, options, observer) {\n  var _this = this;\n\n  var wrappedObserver = new AsyncObserver(observer);\n  var listener = new QueryListener(query, wrappedObserver, options);\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var eventManager;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getEventManager(client)];\n\n          case 1:\n            eventManager = _d.sent();\n            return [2\n            /*return*/\n            , eventManagerListen(eventManager, listener)];\n        }\n      });\n    });\n  });\n  return function () {\n    wrappedObserver.mute();\n    client.asyncQueue.enqueueAndForget(function () {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        var eventManager;\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              return [4\n              /*yield*/\n              , getEventManager(client)];\n\n            case 1:\n              eventManager = _d.sent();\n              return [2\n              /*return*/\n              , eventManagerUnlisten(eventManager, listener)];\n          }\n        });\n      });\n    });\n  };\n}\n\nfunction firestoreClientGetDocumentFromLocalCache(client, docKey) {\n  var _this = this;\n\n  var deferred = new Deferred();\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var localStore;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getLocalStore(client)];\n\n          case 1:\n            localStore = _d.sent();\n            return [2\n            /*return*/\n            , readDocumentFromCache(localStore, docKey, deferred)];\n        }\n      });\n    });\n  });\n  return deferred.promise;\n}\n\nfunction firestoreClientGetDocumentViaSnapshotListener(client, key, options) {\n  var _this = this;\n\n  if (options === void 0) {\n    options = {};\n  }\n\n  var deferred = new Deferred();\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var eventManager;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getEventManager(client)];\n\n          case 1:\n            eventManager = _d.sent();\n            return [2\n            /*return*/\n            , readDocumentViaSnapshotListener(eventManager, client.asyncQueue, key, options, deferred)];\n        }\n      });\n    });\n  });\n  return deferred.promise;\n}\n\nfunction firestoreClientGetDocumentsFromLocalCache(client, query) {\n  var _this = this;\n\n  var deferred = new Deferred();\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var localStore;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getLocalStore(client)];\n\n          case 1:\n            localStore = _d.sent();\n            return [2\n            /*return*/\n            , executeQueryFromCache(localStore, query, deferred)];\n        }\n      });\n    });\n  });\n  return deferred.promise;\n}\n\nfunction firestoreClientGetDocumentsViaSnapshotListener(client, query, options) {\n  var _this = this;\n\n  if (options === void 0) {\n    options = {};\n  }\n\n  var deferred = new Deferred();\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var eventManager;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getEventManager(client)];\n\n          case 1:\n            eventManager = _d.sent();\n            return [2\n            /*return*/\n            , executeQueryViaSnapshotListener(eventManager, client.asyncQueue, query, options, deferred)];\n        }\n      });\n    });\n  });\n  return deferred.promise;\n}\n\nfunction firestoreClientWrite(client, mutations) {\n  var _this = this;\n\n  var deferred = new Deferred();\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var syncEngine;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getSyncEngine(client)];\n\n          case 1:\n            syncEngine = _d.sent();\n            return [2\n            /*return*/\n            , syncEngineWrite(syncEngine, mutations, deferred)];\n        }\n      });\n    });\n  });\n  return deferred.promise;\n}\n\nfunction firestoreClientAddSnapshotsInSyncListener(client, observer) {\n  var _this = this;\n\n  var wrappedObserver = new AsyncObserver(observer);\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var eventManager;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getEventManager(client)];\n\n          case 1:\n            eventManager = _d.sent();\n            return [2\n            /*return*/\n            , addSnapshotsInSyncListener(eventManager, wrappedObserver)];\n        }\n      });\n    });\n  });\n  return function () {\n    wrappedObserver.mute();\n    client.asyncQueue.enqueueAndForget(function () {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        var eventManager;\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              return [4\n              /*yield*/\n              , getEventManager(client)];\n\n            case 1:\n              eventManager = _d.sent();\n              return [2\n              /*return*/\n              , removeSnapshotsInSyncListener(eventManager, wrappedObserver)];\n          }\n        });\n      });\n    });\n  };\n}\n/**\r\n * Takes an updateFunction in which a set of reads and writes can be performed\r\n * atomically. In the updateFunction, the client can read and write values\r\n * using the supplied transaction object. After the updateFunction, all\r\n * changes will be committed. If a retryable error occurs (ex: some other\r\n * client has changed any of the data referenced), then the updateFunction\r\n * will be called again after a backoff. If the updateFunction still fails\r\n * after all retries, then the transaction will be rejected.\r\n *\r\n * The transaction object passed to the updateFunction contains methods for\r\n * accessing documents and collections. Unlike other datastore access, data\r\n * accessed with the transaction will not reflect local changes that have not\r\n * been committed. For this reason, it is required that all reads are\r\n * performed before any writes. Transactions must be performed while online.\r\n */\n\n\nfunction firestoreClientTransaction(client, updateFunction) {\n  var _this = this;\n\n  var deferred = new Deferred();\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var datastore;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            return [4\n            /*yield*/\n            , getDatastore(client)];\n\n          case 1:\n            datastore = _d.sent();\n            new TransactionRunner(client.asyncQueue, datastore, updateFunction, deferred).run();\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  });\n  return deferred.promise;\n}\n\nfunction readDocumentFromCache(localStore, docKey, result) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var document_4, e_12, firestoreError;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          _d.trys.push([0, 2,, 3]);\n\n          return [4\n          /*yield*/\n          , localStoreReadDocument(localStore, docKey)];\n\n        case 1:\n          document_4 = _d.sent();\n\n          if (document_4.isFoundDocument()) {\n            result.resolve(document_4);\n          } else if (document_4.isNoDocument()) {\n            result.resolve(null);\n          } else {\n            result.reject(new FirestoreError(Code.UNAVAILABLE, 'Failed to get document from cache. (However, this document may ' + \"exist on the server. Run again without setting 'source' in \" + 'the GetOptions to attempt to retrieve the document from the ' + 'server.)'));\n          }\n\n          return [3\n          /*break*/\n          , 3];\n\n        case 2:\n          e_12 = _d.sent();\n          firestoreError = wrapInUserErrorIfRecoverable(e_12, \"Failed to get document '\" + docKey + \" from cache\");\n          result.reject(firestoreError);\n          return [3\n          /*break*/\n          , 3];\n\n        case 3:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Retrieves a latency-compensated document from the backend via a\r\n * SnapshotListener.\r\n */\n\n\nfunction readDocumentViaSnapshotListener(eventManager, asyncQueue, key, options, result) {\n  var wrappedObserver = new AsyncObserver({\n    next: function (snap) {\n      // Remove query first before passing event to user to avoid\n      // user actions affecting the now stale query.\n      asyncQueue.enqueueAndForget(function () {\n        return eventManagerUnlisten(eventManager, listener);\n      });\n      var exists = snap.docs.has(key);\n\n      if (!exists && snap.fromCache) {\n        // TODO(dimond): If we're online and the document doesn't\n        // exist then we resolve with a doc.exists set to false. If\n        // we're offline however, we reject the Promise in this\n        // case. Two options: 1) Cache the negative response from\n        // the server so we can deliver that even when you're\n        // offline 2) Actually reject the Promise in the online case\n        // if the document doesn't exist.\n        result.reject(new FirestoreError(Code.UNAVAILABLE, 'Failed to get document because the client is offline.'));\n      } else if (exists && snap.fromCache && options && options.source === 'server') {\n        result.reject(new FirestoreError(Code.UNAVAILABLE, 'Failed to get document from server. (However, this ' + 'document does exist in the local cache. Run again ' + 'without setting source to \"server\" to ' + 'retrieve the cached document.)'));\n      } else {\n        result.resolve(snap);\n      }\n    },\n    error: function (e) {\n      return result.reject(e);\n    }\n  });\n  var listener = new QueryListener(newQueryForPath(key.path), wrappedObserver, {\n    includeMetadataChanges: true,\n    waitForSyncWhenOnline: true\n  });\n  return eventManagerListen(eventManager, listener);\n}\n\nfunction executeQueryFromCache(localStore, query, result) {\n  return tslib.__awaiter(this, void 0, void 0, function () {\n    var queryResult, view, viewDocChanges, viewChange, e_13, firestoreError;\n    return tslib.__generator(this, function (_d) {\n      switch (_d.label) {\n        case 0:\n          _d.trys.push([0, 2,, 3]);\n\n          return [4\n          /*yield*/\n          , localStoreExecuteQuery(localStore, query,\n          /* usePreviousResults= */\n          true)];\n\n        case 1:\n          queryResult = _d.sent();\n          view = new View(query, queryResult.remoteKeys);\n          viewDocChanges = view.computeDocChanges(queryResult.documents);\n          viewChange = view.applyChanges(viewDocChanges,\n          /* updateLimboDocuments= */\n          false);\n          result.resolve(viewChange.snapshot);\n          return [3\n          /*break*/\n          , 3];\n\n        case 2:\n          e_13 = _d.sent();\n          firestoreError = wrapInUserErrorIfRecoverable(e_13, \"Failed to execute query '\" + query + \" against cache\");\n          result.reject(firestoreError);\n          return [3\n          /*break*/\n          , 3];\n\n        case 3:\n          return [2\n          /*return*/\n          ];\n      }\n    });\n  });\n}\n/**\r\n * Retrieves a latency-compensated query snapshot from the backend via a\r\n * SnapshotListener.\r\n */\n\n\nfunction executeQueryViaSnapshotListener(eventManager, asyncQueue, query, options, result) {\n  var wrappedObserver = new AsyncObserver({\n    next: function (snapshot) {\n      // Remove query first before passing event to user to avoid\n      // user actions affecting the now stale query.\n      asyncQueue.enqueueAndForget(function () {\n        return eventManagerUnlisten(eventManager, listener);\n      });\n\n      if (snapshot.fromCache && options.source === 'server') {\n        result.reject(new FirestoreError(Code.UNAVAILABLE, 'Failed to get documents from server. (However, these ' + 'documents may exist in the local cache. Run again ' + 'without setting source to \"server\" to ' + 'retrieve the cached documents.)'));\n      } else {\n        result.resolve(snapshot);\n      }\n    },\n    error: function (e) {\n      return result.reject(e);\n    }\n  });\n  var listener = new QueryListener(query, wrappedObserver, {\n    includeMetadataChanges: true,\n    waitForSyncWhenOnline: true\n  });\n  return eventManagerListen(eventManager, listener);\n}\n\nfunction firestoreClientLoadBundle(client, databaseId, data, resultTask) {\n  var _this = this;\n\n  var reader = createBundleReader(data, newSerializer(databaseId));\n  client.asyncQueue.enqueueAndForget(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var _d;\n\n      return tslib.__generator(this, function (_e) {\n        switch (_e.label) {\n          case 0:\n            _d = syncEngineLoadBundle;\n            return [4\n            /*yield*/\n            , getSyncEngine(client)];\n\n          case 1:\n            _d.apply(void 0, [_e.sent(), reader, resultTask]);\n\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  });\n}\n\nfunction firestoreClientGetNamedQuery(client, queryName) {\n  var _this = this;\n\n  return client.asyncQueue.enqueue(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var _d;\n\n      return tslib.__generator(this, function (_e) {\n        switch (_e.label) {\n          case 0:\n            _d = localStoreGetNamedQuery;\n            return [4\n            /*yield*/\n            , getLocalStore(client)];\n\n          case 1:\n            return [2\n            /*return*/\n            , _d.apply(void 0, [_e.sent(), queryName])];\n        }\n      });\n    });\n  });\n}\n\nfunction createBundleReader(data, serializer) {\n  var content;\n\n  if (typeof data === 'string') {\n    content = newTextEncoder().encode(data);\n  } else {\n    content = data;\n  }\n\n  return newBundleReader(toByteStreamReader(content), serializer);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar DatabaseInfo =\n/** @class */\nfunction () {\n  /**\r\n   * Constructs a DatabaseInfo using the provided host, databaseId and\r\n   * persistenceKey.\r\n   *\r\n   * @param databaseId - The database to use.\r\n   * @param appId - The Firebase App Id.\r\n   * @param persistenceKey - A unique identifier for this Firestore's local\r\n   * storage (used in conjunction with the databaseId).\r\n   * @param host - The Firestore backend host to connect to.\r\n   * @param ssl - Whether to use SSL when connecting.\r\n   * @param forceLongPolling - Whether to use the forceLongPolling option\r\n   * when using WebChannel as the network transport.\r\n   * @param autoDetectLongPolling - Whether to use the detectBufferingProxy\r\n   * option when using WebChannel as the network transport.\r\n   * @param useFetchStreams Whether to use the Fetch API instead of\r\n   * XMLHTTPRequest\r\n   */\n  function DatabaseInfo(databaseId, appId, persistenceKey, host, ssl, forceLongPolling, autoDetectLongPolling, useFetchStreams) {\n    this.databaseId = databaseId;\n    this.appId = appId;\n    this.persistenceKey = persistenceKey;\n    this.host = host;\n    this.ssl = ssl;\n    this.forceLongPolling = forceLongPolling;\n    this.autoDetectLongPolling = autoDetectLongPolling;\n    this.useFetchStreams = useFetchStreams;\n  }\n\n  return DatabaseInfo;\n}();\n/** The default database name for a project. */\n\n\nvar DEFAULT_DATABASE_NAME = '(default)';\n/** Represents the database ID a Firestore client is associated with. */\n\nvar DatabaseId =\n/** @class */\nfunction () {\n  function DatabaseId(projectId, database) {\n    this.projectId = projectId;\n    this.database = database ? database : DEFAULT_DATABASE_NAME;\n  }\n\n  Object.defineProperty(DatabaseId.prototype, \"isDefaultDatabase\", {\n    get: function () {\n      return this.database === DEFAULT_DATABASE_NAME;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  DatabaseId.prototype.isEqual = function (other) {\n    return other instanceof DatabaseId && other.projectId === this.projectId && other.database === this.database;\n  };\n\n  return DatabaseId;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG$1 = 'ComponentProvider';\n/**\r\n * An instance map that ensures only one Datastore exists per Firestore\r\n * instance.\r\n */\n\nvar datastoreInstances = new Map();\n/**\r\n * Removes all components associated with the provided instance. Must be called\r\n * when the `Firestore` instance is terminated.\r\n */\n\nfunction removeComponents(firestore) {\n  var datastore = datastoreInstances.get(firestore);\n\n  if (datastore) {\n    logDebug(LOG_TAG$1, 'Removing Datastore');\n    datastoreInstances.delete(firestore);\n    datastore.terminate();\n  }\n}\n\nfunction makeDatabaseInfo(databaseId, appId, persistenceKey, settings) {\n  return new DatabaseInfo(databaseId, appId, persistenceKey, settings.host, settings.ssl, settings.experimentalForceLongPolling, settings.experimentalAutoDetectLongPolling, settings.useFetchStreams);\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar OAuthToken =\n/** @class */\nfunction () {\n  function OAuthToken(value, user) {\n    this.user = user;\n    this.type = 'OAuth';\n    this.authHeaders = {}; // Set the headers using Object Literal notation to avoid minification\n\n    this.authHeaders['Authorization'] = \"Bearer \" + value;\n  }\n\n  return OAuthToken;\n}();\n/** A CredentialsProvider that always yields an empty token. */\n\n\nvar EmptyCredentialsProvider =\n/** @class */\nfunction () {\n  function EmptyCredentialsProvider() {\n    /**\r\n     * Stores the listener registered with setChangeListener()\r\n     * This isn't actually necessary since the UID never changes, but we use this\r\n     * to verify the listen contract is adhered to in tests.\r\n     */\n    this.changeListener = null;\n  }\n\n  EmptyCredentialsProvider.prototype.getToken = function () {\n    return Promise.resolve(null);\n  };\n\n  EmptyCredentialsProvider.prototype.invalidateToken = function () {};\n\n  EmptyCredentialsProvider.prototype.setChangeListener = function (asyncQueue, changeListener) {\n    this.changeListener = changeListener; // Fire with initial user.\n\n    asyncQueue.enqueueRetryable(function () {\n      return changeListener(User.UNAUTHENTICATED);\n    });\n  };\n\n  EmptyCredentialsProvider.prototype.removeChangeListener = function () {\n    this.changeListener = null;\n  };\n\n  return EmptyCredentialsProvider;\n}();\n/**\r\n * A CredentialsProvider that always returns a constant token. Used for\r\n * emulator token mocking.\r\n */\n\n\nvar EmulatorCredentialsProvider =\n/** @class */\nfunction () {\n  function EmulatorCredentialsProvider(token) {\n    this.token = token;\n    /**\r\n     * Stores the listener registered with setChangeListener()\r\n     * This isn't actually necessary since the UID never changes, but we use this\r\n     * to verify the listen contract is adhered to in tests.\r\n     */\n\n    this.changeListener = null;\n  }\n\n  EmulatorCredentialsProvider.prototype.getToken = function () {\n    return Promise.resolve(this.token);\n  };\n\n  EmulatorCredentialsProvider.prototype.invalidateToken = function () {};\n\n  EmulatorCredentialsProvider.prototype.setChangeListener = function (asyncQueue, changeListener) {\n    var _this = this;\n\n    this.changeListener = changeListener; // Fire with initial user.\n\n    asyncQueue.enqueueRetryable(function () {\n      return changeListener(_this.token.user);\n    });\n  };\n\n  EmulatorCredentialsProvider.prototype.removeChangeListener = function () {\n    this.changeListener = null;\n  };\n\n  return EmulatorCredentialsProvider;\n}();\n\nvar FirebaseCredentialsProvider =\n/** @class */\nfunction () {\n  function FirebaseCredentialsProvider(authProvider) {\n    var _this = this;\n    /** Tracks the current User. */\n\n\n    this.currentUser = User.UNAUTHENTICATED;\n    /** Promise that allows blocking on the initialization of Firebase Auth. */\n\n    this.authDeferred = new Deferred();\n    /**\r\n     * Counter used to detect if the token changed while a getToken request was\r\n     * outstanding.\r\n     */\n\n    this.tokenCounter = 0;\n    this.forceRefresh = false;\n    this.auth = null;\n    this.asyncQueue = null;\n\n    this.tokenListener = function () {\n      _this.tokenCounter++;\n      _this.currentUser = _this.getUser();\n\n      _this.authDeferred.resolve();\n\n      if (_this.changeListener) {\n        _this.asyncQueue.enqueueRetryable(function () {\n          return _this.changeListener(_this.currentUser);\n        });\n      }\n    };\n\n    var registerAuth = function (auth) {\n      logDebug('FirebaseCredentialsProvider', 'Auth detected');\n      _this.auth = auth;\n\n      _this.auth.addAuthTokenListener(_this.tokenListener);\n    };\n\n    authProvider.onInit(function (auth) {\n      return registerAuth(auth);\n    }); // Our users can initialize Auth right after Firestore, so we give it\n    // a chance to register itself with the component framework before we\n    // determine whether to start up in unauthenticated mode.\n\n    setTimeout(function () {\n      if (!_this.auth) {\n        var auth = authProvider.getImmediate({\n          optional: true\n        });\n\n        if (auth) {\n          registerAuth(auth);\n        } else {\n          // If auth is still not available, proceed with `null` user\n          logDebug('FirebaseCredentialsProvider', 'Auth not yet detected');\n\n          _this.authDeferred.resolve();\n        }\n      }\n    }, 0);\n  }\n\n  FirebaseCredentialsProvider.prototype.getToken = function () {\n    var _this = this; // Take note of the current value of the tokenCounter so that this method\n    // can fail (with an ABORTED error) if there is a token change while the\n    // request is outstanding.\n\n\n    var initialTokenCounter = this.tokenCounter;\n    var forceRefresh = this.forceRefresh;\n    this.forceRefresh = false;\n\n    if (!this.auth) {\n      return Promise.resolve(null);\n    }\n\n    return this.auth.getToken(forceRefresh).then(function (tokenData) {\n      // Cancel the request since the token changed while the request was\n      // outstanding so the response is potentially for a previous user (which\n      // user, we can't be sure).\n      if (_this.tokenCounter !== initialTokenCounter) {\n        logDebug('FirebaseCredentialsProvider', 'getToken aborted due to token change.');\n        return _this.getToken();\n      } else {\n        if (tokenData) {\n          hardAssert(typeof tokenData.accessToken === 'string');\n          return new OAuthToken(tokenData.accessToken, _this.currentUser);\n        } else {\n          return null;\n        }\n      }\n    });\n  };\n\n  FirebaseCredentialsProvider.prototype.invalidateToken = function () {\n    this.forceRefresh = true;\n  };\n\n  FirebaseCredentialsProvider.prototype.setChangeListener = function (asyncQueue, changeListener) {\n    var _this = this;\n\n    this.asyncQueue = asyncQueue; // Blocks the AsyncQueue until the next user is available.\n\n    this.asyncQueue.enqueueRetryable(function () {\n      return tslib.__awaiter(_this, void 0, void 0, function () {\n        return tslib.__generator(this, function (_d) {\n          switch (_d.label) {\n            case 0:\n              return [4\n              /*yield*/\n              , this.authDeferred.promise];\n\n            case 1:\n              _d.sent();\n\n              return [4\n              /*yield*/\n              , changeListener(this.currentUser)];\n\n            case 2:\n              _d.sent();\n\n              this.changeListener = changeListener;\n              return [2\n              /*return*/\n              ];\n          }\n        });\n      });\n    });\n  };\n\n  FirebaseCredentialsProvider.prototype.removeChangeListener = function () {\n    if (this.auth) {\n      this.auth.removeAuthTokenListener(this.tokenListener);\n    }\n\n    this.changeListener = function () {\n      return Promise.resolve();\n    };\n  }; // Auth.getUid() can return null even with a user logged in. It is because\n  // getUid() is synchronous, but the auth code populating Uid is asynchronous.\n  // This method should only be called in the AuthTokenListener callback\n  // to guarantee to get the actual user.\n\n\n  FirebaseCredentialsProvider.prototype.getUser = function () {\n    var currentUid = this.auth && this.auth.getUid();\n    hardAssert(currentUid === null || typeof currentUid === 'string');\n    return new User(currentUid);\n  };\n\n  return FirebaseCredentialsProvider;\n}();\n/*\r\n * FirstPartyToken provides a fresh token each time its value\r\n * is requested, because if the token is too old, requests will be rejected.\r\n * Technically this may no longer be necessary since the SDK should gracefully\r\n * recover from unauthenticated errors (see b/33147818 for context), but it's\r\n * safer to keep the implementation as-is.\r\n */\n\n\nvar FirstPartyToken =\n/** @class */\nfunction () {\n  function FirstPartyToken(gapi, sessionIndex, iamToken) {\n    this.gapi = gapi;\n    this.sessionIndex = sessionIndex;\n    this.iamToken = iamToken;\n    this.type = 'FirstParty';\n    this.user = User.FIRST_PARTY;\n  }\n\n  Object.defineProperty(FirstPartyToken.prototype, \"authHeaders\", {\n    get: function () {\n      var headers = {\n        'X-Goog-AuthUser': this.sessionIndex\n      }; // Use array notation to prevent minification\n\n      var authHeader = this.gapi['auth']['getAuthHeaderValueForFirstParty']([]);\n\n      if (authHeader) {\n        headers['Authorization'] = authHeader;\n      }\n\n      if (this.iamToken) {\n        headers['X-Goog-Iam-Authorization-Token'] = this.iamToken;\n      }\n\n      return headers;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  return FirstPartyToken;\n}();\n/*\r\n * Provides user credentials required for the Firestore JavaScript SDK\r\n * to authenticate the user, using technique that is only available\r\n * to applications hosted by Google.\r\n */\n\n\nvar FirstPartyCredentialsProvider =\n/** @class */\nfunction () {\n  function FirstPartyCredentialsProvider(gapi, sessionIndex, iamToken) {\n    this.gapi = gapi;\n    this.sessionIndex = sessionIndex;\n    this.iamToken = iamToken;\n  }\n\n  FirstPartyCredentialsProvider.prototype.getToken = function () {\n    return Promise.resolve(new FirstPartyToken(this.gapi, this.sessionIndex, this.iamToken));\n  };\n\n  FirstPartyCredentialsProvider.prototype.setChangeListener = function (asyncQueue, changeListener) {\n    // Fire with initial uid.\n    asyncQueue.enqueueRetryable(function () {\n      return changeListener(User.FIRST_PARTY);\n    });\n  };\n\n  FirstPartyCredentialsProvider.prototype.removeChangeListener = function () {};\n\n  FirstPartyCredentialsProvider.prototype.invalidateToken = function () {};\n\n  return FirstPartyCredentialsProvider;\n}();\n/**\r\n * Builds a CredentialsProvider depending on the type of\r\n * the credentials passed in.\r\n */\n\n\nfunction makeCredentialsProvider(credentials) {\n  if (!credentials) {\n    return new EmptyCredentialsProvider();\n  }\n\n  switch (credentials['type']) {\n    case 'gapi':\n      var client = credentials['client']; // Make sure this really is a Gapi client.\n\n      hardAssert(!!(typeof client === 'object' && client !== null && client['auth'] && client['auth']['getAuthHeaderValueForFirstParty']));\n      return new FirstPartyCredentialsProvider(client, credentials['sessionIndex'] || '0', credentials['iamToken'] || null);\n\n    case 'provider':\n      return credentials['client'];\n\n    default:\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'makeCredentialsProvider failed due to invalid credential type');\n  }\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// settings() defaults:\n\n\nvar DEFAULT_HOST = 'firestore.googleapis.com';\nvar DEFAULT_SSL = true;\n/**\r\n * A concrete type describing all the values that can be applied via a\r\n * user-supplied firestore.Settings object. This is a separate type so that\r\n * defaults can be supplied and the value can be checked for equality.\r\n */\n\nvar FirestoreSettingsImpl =\n/** @class */\nfunction () {\n  function FirestoreSettingsImpl(settings) {\n    var _a;\n\n    if (settings.host === undefined) {\n      if (settings.ssl !== undefined) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Can't provide ssl option if host option is not set\");\n      }\n\n      this.host = DEFAULT_HOST;\n      this.ssl = DEFAULT_SSL;\n    } else {\n      this.host = settings.host;\n      this.ssl = (_a = settings.ssl) !== null && _a !== void 0 ? _a : DEFAULT_SSL;\n    }\n\n    this.credentials = settings.credentials;\n    this.ignoreUndefinedProperties = !!settings.ignoreUndefinedProperties;\n\n    if (settings.cacheSizeBytes === undefined) {\n      this.cacheSizeBytes = LRU_DEFAULT_CACHE_SIZE_BYTES;\n    } else {\n      if (settings.cacheSizeBytes !== LRU_COLLECTION_DISABLED && settings.cacheSizeBytes < LRU_MINIMUM_CACHE_SIZE_BYTES) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"cacheSizeBytes must be at least \" + LRU_MINIMUM_CACHE_SIZE_BYTES);\n      } else {\n        this.cacheSizeBytes = settings.cacheSizeBytes;\n      }\n    }\n\n    this.experimentalForceLongPolling = !!settings.experimentalForceLongPolling;\n    this.experimentalAutoDetectLongPolling = !!settings.experimentalAutoDetectLongPolling;\n    this.useFetchStreams = !!settings.useFetchStreams;\n    validateIsNotUsedTogether('experimentalForceLongPolling', settings.experimentalForceLongPolling, 'experimentalAutoDetectLongPolling', settings.experimentalAutoDetectLongPolling);\n  }\n\n  FirestoreSettingsImpl.prototype.isEqual = function (other) {\n    return this.host === other.host && this.ssl === other.ssl && this.credentials === other.credentials && this.cacheSizeBytes === other.cacheSizeBytes && this.experimentalForceLongPolling === other.experimentalForceLongPolling && this.experimentalAutoDetectLongPolling === other.experimentalAutoDetectLongPolling && this.ignoreUndefinedProperties === other.ignoreUndefinedProperties && this.useFetchStreams === other.useFetchStreams;\n  };\n\n  return FirestoreSettingsImpl;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * The Cloud Firestore service interface.\r\n *\r\n * Do not call this constructor directly. Instead, use {@link getFirestore}.\r\n */\n\n\nvar Firestore$2 =\n/** @class */\nfunction () {\n  /** @hideconstructor */\n  function Firestore$2(databaseIdOrApp, authProvider) {\n    /**\r\n     * Whether it's a Firestore or Firestore Lite instance.\r\n     */\n    this.type = 'firestore-lite';\n    this._persistenceKey = '(lite)';\n    this._settings = new FirestoreSettingsImpl({});\n    this._settingsFrozen = false;\n\n    if (databaseIdOrApp instanceof DatabaseId) {\n      this._databaseId = databaseIdOrApp;\n      this._credentials = new EmptyCredentialsProvider();\n    } else {\n      this._app = databaseIdOrApp;\n      this._databaseId = databaseIdFromApp(databaseIdOrApp);\n      this._credentials = new FirebaseCredentialsProvider(authProvider);\n    }\n  }\n\n  Object.defineProperty(Firestore$2.prototype, \"app\", {\n    /**\r\n     * The {@link @firebase/app#FirebaseApp} associated with this `Firestore` service\r\n     * instance.\r\n     */\n    get: function () {\n      if (!this._app) {\n        throw new FirestoreError(Code.FAILED_PRECONDITION, \"Firestore was not initialized using the Firebase SDK. 'app' is \" + 'not available');\n      }\n\n      return this._app;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(Firestore$2.prototype, \"_initialized\", {\n    get: function () {\n      return this._settingsFrozen;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(Firestore$2.prototype, \"_terminated\", {\n    get: function () {\n      return this._terminateTask !== undefined;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  Firestore$2.prototype._setSettings = function (settings) {\n    if (this._settingsFrozen) {\n      throw new FirestoreError(Code.FAILED_PRECONDITION, 'Firestore has already been started and its settings can no longer ' + 'be changed. You can only modify settings before calling any other ' + 'methods on a Firestore object.');\n    }\n\n    this._settings = new FirestoreSettingsImpl(settings);\n\n    if (settings.credentials !== undefined) {\n      this._credentials = makeCredentialsProvider(settings.credentials);\n    }\n  };\n\n  Firestore$2.prototype._getSettings = function () {\n    return this._settings;\n  };\n\n  Firestore$2.prototype._freezeSettings = function () {\n    this._settingsFrozen = true;\n    return this._settings;\n  };\n\n  Firestore$2.prototype._delete = function () {\n    if (!this._terminateTask) {\n      this._terminateTask = this._terminate();\n    }\n\n    return this._terminateTask;\n  };\n  /** Returns a JSON-serializable representation of this Firestore instance. */\n\n\n  Firestore$2.prototype.toJSON = function () {\n    return {\n      app: this._app,\n      databaseId: this._databaseId,\n      settings: this._settings\n    };\n  };\n  /**\r\n   * Terminates all components used by this client. Subclasses can override\r\n   * this method to clean up their own dependencies, but must also call this\r\n   * method.\r\n   *\r\n   * Only ever called once.\r\n   */\n\n\n  Firestore$2.prototype._terminate = function () {\n    removeComponents(this);\n    return Promise.resolve();\n  };\n\n  return Firestore$2;\n}();\n\nfunction databaseIdFromApp(app) {\n  if (!Object.prototype.hasOwnProperty.apply(app.options, ['projectId'])) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, '\"projectId\" not provided in firebase.initializeApp.');\n  }\n\n  return new DatabaseId(app.options.projectId);\n}\n/**\r\n * Modify this instance to communicate with the Cloud Firestore emulator.\r\n *\r\n * Note: This must be called before this instance has been used to do any\r\n * operations.\r\n *\r\n * @param firestore - The Firestore instance to configure to connect to the\r\n * emulator.\r\n * @param host - the emulator host (ex: localhost).\r\n * @param port - the emulator port (ex: 9000).\r\n * @param options.mockUserToken - the mock auth token to use for unit testing\r\n * Security Rules.\r\n */\n\n\nfunction connectFirestoreEmulator(firestore, host, port, options) {\n  if (options === void 0) {\n    options = {};\n  }\n\n  firestore = cast(firestore, Firestore$2);\n\n  var settings = firestore._getSettings();\n\n  if (settings.host !== DEFAULT_HOST && settings.host !== host) {\n    logWarn('Host has been set in both settings() and useEmulator(), emulator host ' + 'will be used');\n  }\n\n  firestore._setSettings(Object.assign(Object.assign({}, settings), {\n    host: host + \":\" + port,\n    ssl: false\n  }));\n\n  if (options.mockUserToken) {\n    // Let createMockUserToken validate first (catches common mistakes like\n    // invalid field \"uid\" and missing field \"sub\" / \"user_id\".)\n    var token = util.createMockUserToken(options.mockUserToken);\n    var uid = options.mockUserToken.sub || options.mockUserToken.user_id;\n\n    if (!uid) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, \"mockUserToken must contain 'sub' or 'user_id' field!\");\n    }\n\n    firestore._credentials = new EmulatorCredentialsProvider(new OAuthToken(token, new User(uid)));\n  }\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A `DocumentReference` refers to a document location in a Firestore database\r\n * and can be used to write, read, or listen to the location. The document at\r\n * the referenced location may or may not exist.\r\n */\n\n\nvar DocumentReference$1 =\n/** @class */\nfunction () {\n  /** @hideconstructor */\n  function DocumentReference$1(firestore,\n  /**\r\n   * If provided, the `FirestoreDataConverter` associated with this instance.\r\n   */\n  converter, _key) {\n    this.converter = converter;\n    this._key = _key;\n    /** The type of this Firestore reference. */\n\n    this.type = 'document';\n    this.firestore = firestore;\n  }\n\n  Object.defineProperty(DocumentReference$1.prototype, \"_path\", {\n    get: function () {\n      return this._key.path;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentReference$1.prototype, \"id\", {\n    /**\r\n     * The document's identifier within its collection.\r\n     */\n    get: function () {\n      return this._key.path.lastSegment();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentReference$1.prototype, \"path\", {\n    /**\r\n     * A string representing the path of the referenced document (relative\r\n     * to the root of the database).\r\n     */\n    get: function () {\n      return this._key.path.canonicalString();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentReference$1.prototype, \"parent\", {\n    /**\r\n     * The collection this `DocumentReference` belongs to.\r\n     */\n    get: function () {\n      return new CollectionReference$1(this.firestore, this.converter, this._key.path.popLast());\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  DocumentReference$1.prototype.withConverter = function (converter) {\n    return new DocumentReference$1(this.firestore, converter, this._key);\n  };\n\n  return DocumentReference$1;\n}();\n/**\r\n * A `Query` refers to a Query which you can read or listen to. You can also\r\n * construct refined `Query` objects by adding filters and ordering.\r\n */\n\n\nvar Query$1 =\n/** @class */\nfunction () {\n  // This is the lite version of the Query class in the main SDK.\n\n  /** @hideconstructor protected */\n  function Query$1(firestore,\n  /**\r\n   * If provided, the `FirestoreDataConverter` associated with this instance.\r\n   */\n  converter, _query) {\n    this.converter = converter;\n    this._query = _query;\n    /** The type of this Firestore reference. */\n\n    this.type = 'query';\n    this.firestore = firestore;\n  }\n\n  Query$1.prototype.withConverter = function (converter) {\n    return new Query$1(this.firestore, converter, this._query);\n  };\n\n  return Query$1;\n}();\n/**\r\n * A `CollectionReference` object can be used for adding documents, getting\r\n * document references, and querying for documents (using {@link query}).\r\n */\n\n\nvar CollectionReference$1 =\n/** @class */\nfunction (_super) {\n  tslib.__extends(CollectionReference$1, _super);\n  /** @hideconstructor */\n\n\n  function CollectionReference$1(firestore, converter, _path) {\n    var _this = _super.call(this, firestore, converter, newQueryForPath(_path)) || this;\n\n    _this._path = _path;\n    /** The type of this Firestore reference. */\n\n    _this.type = 'collection';\n    return _this;\n  }\n\n  Object.defineProperty(CollectionReference$1.prototype, \"id\", {\n    /** The collection's identifier. */\n    get: function () {\n      return this._query.path.lastSegment();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(CollectionReference$1.prototype, \"path\", {\n    /**\r\n     * A string representing the path of the referenced collection (relative\r\n     * to the root of the database).\r\n     */\n    get: function () {\n      return this._query.path.canonicalString();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(CollectionReference$1.prototype, \"parent\", {\n    /**\r\n     * A reference to the containing `DocumentReference` if this is a\r\n     * subcollection. If this isn't a subcollection, the reference is null.\r\n     */\n    get: function () {\n      var parentPath = this._path.popLast();\n\n      if (parentPath.isEmpty()) {\n        return null;\n      } else {\n        return new DocumentReference$1(this.firestore,\n        /* converter= */\n        null, new DocumentKey(parentPath));\n      }\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  CollectionReference$1.prototype.withConverter = function (converter) {\n    return new CollectionReference$1(this.firestore, converter, this._path);\n  };\n\n  return CollectionReference$1;\n}(Query$1);\n\nfunction collection(parent, path) {\n  var pathSegments = [];\n\n  for (var _i = 2; _i < arguments.length; _i++) {\n    pathSegments[_i - 2] = arguments[_i];\n  }\n\n  parent = util.getModularInstance(parent);\n  validateNonEmptyArgument('collection', 'path', path);\n\n  if (parent instanceof Firestore$2) {\n    var absolutePath = ResourcePath.fromString.apply(ResourcePath, tslib.__spreadArray([path], pathSegments));\n    validateCollectionPath(absolutePath);\n    return new CollectionReference$1(parent,\n    /* converter= */\n    null, absolutePath);\n  } else {\n    if (!(parent instanceof DocumentReference$1) && !(parent instanceof CollectionReference$1)) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Expected first argument to collection() to be a CollectionReference, ' + 'a DocumentReference or FirebaseFirestore');\n    }\n\n    var absolutePath = ResourcePath.fromString.apply(ResourcePath, tslib.__spreadArray([parent.path], pathSegments)).child(ResourcePath.fromString(path));\n    validateCollectionPath(absolutePath);\n    return new CollectionReference$1(parent.firestore,\n    /* converter= */\n    null, absolutePath);\n  }\n} // TODO(firestorelite): Consider using ErrorFactory -\n// https://github.com/firebase/firebase-js-sdk/blob/0131e1f/packages/util/src/errors.ts#L106\n\n/**\r\n * Creates and returns a new `Query` instance that includes all documents in the\r\n * database that are contained in a collection or subcollection with the\r\n * given `collectionId`.\r\n *\r\n * @param firestore - A reference to the root Firestore instance.\r\n * @param collectionId - Identifies the collections to query over. Every\r\n * collection or subcollection with this ID as the last segment of its path\r\n * will be included. Cannot contain a slash.\r\n * @returns The created `Query`.\r\n */\n\n\nfunction collectionGroup(firestore, collectionId) {\n  firestore = cast(firestore, Firestore$2);\n  validateNonEmptyArgument('collectionGroup', 'collection id', collectionId);\n\n  if (collectionId.indexOf('/') >= 0) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid collection ID '\" + collectionId + \"' passed to function \" + \"collectionGroup(). Collection IDs must not contain '/'.\");\n  }\n\n  return new Query$1(firestore,\n  /* converter= */\n  null, newQueryForCollectionGroup(collectionId));\n}\n\nfunction doc(parent, path) {\n  var pathSegments = [];\n\n  for (var _i = 2; _i < arguments.length; _i++) {\n    pathSegments[_i - 2] = arguments[_i];\n  }\n\n  parent = util.getModularInstance(parent); // We allow omission of 'pathString' but explicitly prohibit passing in both\n  // 'undefined' and 'null'.\n\n  if (arguments.length === 1) {\n    path = AutoId.newId();\n  }\n\n  validateNonEmptyArgument('doc', 'path', path);\n\n  if (parent instanceof Firestore$2) {\n    var absolutePath = ResourcePath.fromString.apply(ResourcePath, tslib.__spreadArray([path], pathSegments));\n    validateDocumentPath(absolutePath);\n    return new DocumentReference$1(parent,\n    /* converter= */\n    null, new DocumentKey(absolutePath));\n  } else {\n    if (!(parent instanceof DocumentReference$1) && !(parent instanceof CollectionReference$1)) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Expected first argument to collection() to be a CollectionReference, ' + 'a DocumentReference or FirebaseFirestore');\n    }\n\n    var absolutePath = parent._path.child(ResourcePath.fromString.apply(ResourcePath, tslib.__spreadArray([path], pathSegments)));\n\n    validateDocumentPath(absolutePath);\n    return new DocumentReference$1(parent.firestore, parent instanceof CollectionReference$1 ? parent.converter : null, new DocumentKey(absolutePath));\n  }\n}\n/**\r\n * Returns true if the provided references are equal.\r\n *\r\n * @param left - A reference to compare.\r\n * @param right - A reference to compare.\r\n * @returns true if the references point to the same location in the same\r\n * Firestore database.\r\n */\n\n\nfunction refEqual(left, right) {\n  left = util.getModularInstance(left);\n  right = util.getModularInstance(right);\n\n  if ((left instanceof DocumentReference$1 || left instanceof CollectionReference$1) && (right instanceof DocumentReference$1 || right instanceof CollectionReference$1)) {\n    return left.firestore === right.firestore && left.path === right.path && left.converter === right.converter;\n  }\n\n  return false;\n}\n/**\r\n * Returns true if the provided queries point to the same collection and apply\r\n * the same constraints.\r\n *\r\n * @param left - A `Query` to compare.\r\n * @param right - A `Query` to compare.\r\n * @returns true if the references point to the same location in the same\r\n * Firestore database.\r\n */\n\n\nfunction queryEqual(left, right) {\n  left = util.getModularInstance(left);\n  right = util.getModularInstance(right);\n\n  if (left instanceof Query$1 && right instanceof Query$1) {\n    return left.firestore === right.firestore && queryEquals(left._query, right._query) && left.converter === right.converter;\n  }\n\n  return false;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar LOG_TAG = 'AsyncQueue';\n\nvar AsyncQueueImpl =\n/** @class */\nfunction () {\n  function AsyncQueueImpl() {\n    var _this = this; // The last promise in the queue.\n\n\n    this.tail = Promise.resolve(); // A list of retryable operations. Retryable operations are run in order and\n    // retried with backoff.\n\n    this.retryableOps = []; // Is this AsyncQueue being shut down? Once it is set to true, it will not\n    // be changed again.\n\n    this._isShuttingDown = false; // Operations scheduled to be queued in the future. Operations are\n    // automatically removed after they are run or canceled.\n\n    this.delayedOperations = []; // visible for testing\n\n    this.failure = null; // Flag set while there's an outstanding AsyncQueue operation, used for\n    // assertion sanity-checks.\n\n    this.operationInProgress = false; // Enabled during shutdown on Safari to prevent future access to IndexedDB.\n\n    this.skipNonRestrictedTasks = false; // List of TimerIds to fast-forward delays for.\n\n    this.timerIdsToSkip = []; // Backoff timer used to schedule retries for retryable operations\n\n    this.backoff = new ExponentialBackoff(this, \"async_queue_retry\"\n    /* AsyncQueueRetry */\n    ); // Visibility handler that triggers an immediate retry of all retryable\n    // operations. Meant to speed up recovery when we regain file system access\n    // after page comes into foreground.\n\n    this.visibilityHandler = function () {\n      _this.backoff.skipBackoff();\n    };\n  }\n\n  Object.defineProperty(AsyncQueueImpl.prototype, \"isShuttingDown\", {\n    get: function () {\n      return this._isShuttingDown;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Adds a new operation to the queue without waiting for it to complete (i.e.\r\n   * we ignore the Promise result).\r\n   */\n\n  AsyncQueueImpl.prototype.enqueueAndForget = function (op) {\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.enqueue(op);\n  };\n\n  AsyncQueueImpl.prototype.enqueueAndForgetEvenWhileRestricted = function (op) {\n    this.verifyNotFailed(); // eslint-disable-next-line @typescript-eslint/no-floating-promises\n\n    this.enqueueInternal(op);\n  };\n\n  AsyncQueueImpl.prototype.enterRestrictedMode = function (purgeExistingTasks) {\n    if (!this._isShuttingDown) {\n      this._isShuttingDown = true;\n      this.skipNonRestrictedTasks = purgeExistingTasks || false;\n    }\n  };\n\n  AsyncQueueImpl.prototype.enqueue = function (op) {\n    var _this = this;\n\n    this.verifyNotFailed();\n\n    if (this._isShuttingDown) {\n      // Return a Promise which never resolves.\n      return new Promise(function () {});\n    } // Create a deferred Promise that we can return to the callee. This\n    // allows us to return a \"hanging Promise\" only to the callee and still\n    // advance the queue even when the operation is not run.\n\n\n    var task = new Deferred();\n    return this.enqueueInternal(function () {\n      if (_this._isShuttingDown && _this.skipNonRestrictedTasks) {\n        // We do not resolve 'task'\n        return Promise.resolve();\n      }\n\n      op().then(task.resolve, task.reject);\n      return task.promise;\n    }).then(function () {\n      return task.promise;\n    });\n  };\n\n  AsyncQueueImpl.prototype.enqueueRetryable = function (op) {\n    var _this = this;\n\n    this.enqueueAndForget(function () {\n      _this.retryableOps.push(op);\n\n      return _this.retryNextOp();\n    });\n  };\n  /**\r\n   * Runs the next operation from the retryable queue. If the operation fails,\r\n   * reschedules with backoff.\r\n   */\n\n\n  AsyncQueueImpl.prototype.retryNextOp = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var e_14;\n\n      var _this = this;\n\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            if (this.retryableOps.length === 0) {\n              return [2\n              /*return*/\n              ];\n            }\n\n            _d.label = 1;\n\n          case 1:\n            _d.trys.push([1, 3,, 4]);\n\n            return [4\n            /*yield*/\n            , this.retryableOps[0]()];\n\n          case 2:\n            _d.sent();\n\n            this.retryableOps.shift();\n            this.backoff.reset();\n            return [3\n            /*break*/\n            , 4];\n\n          case 3:\n            e_14 = _d.sent();\n\n            if (isIndexedDbTransactionError(e_14)) {\n              logDebug(LOG_TAG, 'Operation failed with retryable error: ' + e_14);\n            } else {\n              throw e_14; // Failure will be handled by AsyncQueue\n            }\n\n            return [3\n            /*break*/\n            , 4];\n\n          case 4:\n            if (this.retryableOps.length > 0) {\n              // If there are additional operations, we re-schedule `retryNextOp()`.\n              // This is necessary to run retryable operations that failed during\n              // their initial attempt since we don't know whether they are already\n              // enqueued. If, for example, `op1`, `op2`, `op3` are enqueued and `op1`\n              // needs to  be re-run, we will run `op1`, `op1`, `op2` using the\n              // already enqueued calls to `retryNextOp()`. `op3()` will then run in the\n              // call scheduled here.\n              // Since `backoffAndRun()` cancels an existing backoff and schedules a\n              // new backoff on every call, there is only ever a single additional\n              // operation in the queue.\n              this.backoff.backoffAndRun(function () {\n                return _this.retryNextOp();\n              });\n            }\n\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n\n  AsyncQueueImpl.prototype.enqueueInternal = function (op) {\n    var _this = this;\n\n    var newTail = this.tail.then(function () {\n      _this.operationInProgress = true;\n      return op().catch(function (error) {\n        _this.failure = error;\n        _this.operationInProgress = false;\n        var message = getMessageOrStack(error);\n        logError('INTERNAL UNHANDLED ERROR: ', message); // Re-throw the error so that this.tail becomes a rejected Promise and\n        // all further attempts to chain (via .then) will just short-circuit\n        // and return the rejected Promise.\n\n        throw error;\n      }).then(function (result) {\n        _this.operationInProgress = false;\n        return result;\n      });\n    });\n    this.tail = newTail;\n    return newTail;\n  };\n\n  AsyncQueueImpl.prototype.enqueueAfterDelay = function (timerId, delayMs, op) {\n    var _this = this;\n\n    this.verifyNotFailed(); // Fast-forward delays for timerIds that have been overriden.\n\n    if (this.timerIdsToSkip.indexOf(timerId) > -1) {\n      delayMs = 0;\n    }\n\n    var delayedOp = DelayedOperation.createAndSchedule(this, timerId, delayMs, op, function (removedOp) {\n      return _this.removeDelayedOperation(removedOp);\n    });\n    this.delayedOperations.push(delayedOp);\n    return delayedOp;\n  };\n\n  AsyncQueueImpl.prototype.verifyNotFailed = function () {\n    if (this.failure) {\n      fail();\n    }\n  };\n\n  AsyncQueueImpl.prototype.verifyOperationInProgress = function () {};\n  /**\r\n   * Waits until all currently queued tasks are finished executing. Delayed\r\n   * operations are not run.\r\n   */\n\n\n  AsyncQueueImpl.prototype.drain = function () {\n    return tslib.__awaiter(this, void 0, void 0, function () {\n      var currentTail;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            currentTail = this.tail;\n            return [4\n            /*yield*/\n            , currentTail];\n\n          case 1:\n            _d.sent();\n\n            _d.label = 2;\n\n          case 2:\n            if (currentTail !== this.tail) return [3\n            /*break*/\n            , 0];\n            _d.label = 3;\n\n          case 3:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  };\n  /**\r\n   * For Tests: Determine if a delayed operation with a particular TimerId\r\n   * exists.\r\n   */\n\n\n  AsyncQueueImpl.prototype.containsDelayedOperation = function (timerId) {\n    for (var _i = 0, _d = this.delayedOperations; _i < _d.length; _i++) {\n      var op = _d[_i];\n\n      if (op.timerId === timerId) {\n        return true;\n      }\n    }\n\n    return false;\n  };\n  /**\r\n   * For Tests: Runs some or all delayed operations early.\r\n   *\r\n   * @param lastTimerId - Delayed operations up to and including this TimerId\r\n   * will be drained. Pass TimerId.All to run all delayed operations.\r\n   * @returns a Promise that resolves once all operations have been run.\r\n   */\n\n\n  AsyncQueueImpl.prototype.runAllDelayedOperationsUntil = function (lastTimerId) {\n    var _this = this; // Note that draining may generate more delayed ops, so we do that first.\n\n\n    return this.drain().then(function () {\n      // Run ops in the same order they'd run if they ran naturally.\n      _this.delayedOperations.sort(function (a, b) {\n        return a.targetTimeMs - b.targetTimeMs;\n      });\n\n      for (var _i = 0, _d = _this.delayedOperations; _i < _d.length; _i++) {\n        var op = _d[_i];\n        op.skipDelay();\n\n        if (lastTimerId !== \"all\"\n        /* All */\n        && op.timerId === lastTimerId) {\n          break;\n        }\n      }\n\n      return _this.drain();\n    });\n  };\n  /**\r\n   * For Tests: Skip all subsequent delays for a timer id.\r\n   */\n\n\n  AsyncQueueImpl.prototype.skipDelaysForTimerId = function (timerId) {\n    this.timerIdsToSkip.push(timerId);\n  };\n  /** Called once a DelayedOperation is run or canceled. */\n\n\n  AsyncQueueImpl.prototype.removeDelayedOperation = function (op) {\n    // NOTE: indexOf / slice are O(n), but delayedOperations is expected to be small.\n    var index = this.delayedOperations.indexOf(op);\n    this.delayedOperations.splice(index, 1);\n  };\n\n  return AsyncQueueImpl;\n}();\n\nfunction newAsyncQueue() {\n  return new AsyncQueueImpl();\n}\n/**\r\n * Chrome includes Error.message in Error.stack. Other browsers do not.\r\n * This returns expected output of message + stack when available.\r\n * @param error - Error or FirestoreError\r\n */\n\n\nfunction getMessageOrStack(error) {\n  var message = error.message || '';\n\n  if (error.stack) {\n    if (error.stack.includes(error.message)) {\n      message = error.stack;\n    } else {\n      message = error.message + '\\n' + error.stack;\n    }\n  }\n\n  return message;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Represents the task of loading a Firestore bundle. It provides progress of bundle\r\n * loading, as well as task completion and error events.\r\n *\r\n * The API is compatible with `Promise<LoadBundleTaskProgress>`.\r\n */\n\n\nvar LoadBundleTask =\n/** @class */\nfunction () {\n  function LoadBundleTask() {\n    this._progressObserver = {};\n    this._taskCompletionResolver = new Deferred();\n    this._lastProgress = {\n      taskState: 'Running',\n      totalBytes: 0,\n      totalDocuments: 0,\n      bytesLoaded: 0,\n      documentsLoaded: 0\n    };\n  }\n  /**\r\n   * Registers functions to listen to bundle loading progress events.\r\n   * @param next - Called when there is a progress update from bundle loading. Typically `next` calls occur\r\n   *   each time a Firestore document is loaded from the bundle.\r\n   * @param error - Called when an error occurs during bundle loading. The task aborts after reporting the\r\n   *   error, and there should be no more updates after this.\r\n   * @param complete - Called when the loading task is complete.\r\n   */\n\n\n  LoadBundleTask.prototype.onProgress = function (next, error, complete) {\n    this._progressObserver = {\n      next: next,\n      error: error,\n      complete: complete\n    };\n  };\n  /**\r\n   * Implements the `Promise<LoadBundleTaskProgress>.catch` interface.\r\n   *\r\n   * @param onRejected - Called when an error occurs during bundle loading.\r\n   */\n\n\n  LoadBundleTask.prototype.catch = function (onRejected) {\n    return this._taskCompletionResolver.promise.catch(onRejected);\n  };\n  /**\r\n   * Implements the `Promise<LoadBundleTaskProgress>.then` interface.\r\n   *\r\n   * @param onFulfilled - Called on the completion of the loading task with a final `LoadBundleTaskProgress` update.\r\n   *   The update will always have its `taskState` set to `\"Success\"`.\r\n   * @param onRejected - Called when an error occurs during bundle loading.\r\n   */\n\n\n  LoadBundleTask.prototype.then = function (onFulfilled, onRejected) {\n    return this._taskCompletionResolver.promise.then(onFulfilled, onRejected);\n  };\n  /**\r\n   * Notifies all observers that bundle loading has completed, with a provided\r\n   * `LoadBundleTaskProgress` object.\r\n   *\r\n   * @private\r\n   */\n\n\n  LoadBundleTask.prototype._completeWith = function (progress) {\n    this._updateProgress(progress);\n\n    if (this._progressObserver.complete) {\n      this._progressObserver.complete();\n    }\n\n    this._taskCompletionResolver.resolve(progress);\n  };\n  /**\r\n   * Notifies all observers that bundle loading has failed, with a provided\r\n   * `Error` as the reason.\r\n   *\r\n   * @private\r\n   */\n\n\n  LoadBundleTask.prototype._failWith = function (error) {\n    this._lastProgress.taskState = 'Error';\n\n    if (this._progressObserver.next) {\n      this._progressObserver.next(this._lastProgress);\n    }\n\n    if (this._progressObserver.error) {\n      this._progressObserver.error(error);\n    }\n\n    this._taskCompletionResolver.reject(error);\n  };\n  /**\r\n   * Notifies a progress update of loading a bundle.\r\n   * @param progress - The new progress.\r\n   *\r\n   * @private\r\n   */\n\n\n  LoadBundleTask.prototype._updateProgress = function (progress) {\n    this._lastProgress = progress;\n\n    if (this._progressObserver.next) {\n      this._progressObserver.next(progress);\n    }\n  };\n\n  return LoadBundleTask;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** DOMException error code constants. */\n\n\nvar DOM_EXCEPTION_INVALID_STATE = 11;\nvar DOM_EXCEPTION_ABORTED = 20;\nvar DOM_EXCEPTION_QUOTA_EXCEEDED = 22;\n/**\r\n * Constant used to indicate the LRU garbage collection should be disabled.\r\n * Set this value as the `cacheSizeBytes` on the settings passed to the\r\n * `Firestore` instance.\r\n */\n\nvar CACHE_SIZE_UNLIMITED = LRU_COLLECTION_DISABLED;\n/**\r\n * The Cloud Firestore service interface.\r\n *\r\n * Do not call this constructor directly. Instead, use {@link getFirestore}.\r\n */\n\nvar Firestore$1 =\n/** @class */\nfunction (_super) {\n  tslib.__extends(Firestore$1, _super);\n  /** @hideconstructor */\n\n\n  function Firestore$1(databaseIdOrApp, authProvider) {\n    var _this = _super.call(this, databaseIdOrApp, authProvider) || this;\n    /**\r\n     * Whether it's a Firestore or Firestore Lite instance.\r\n     */\n\n\n    _this.type = 'firestore';\n    _this._queue = newAsyncQueue();\n    _this._persistenceKey = 'name' in databaseIdOrApp ? databaseIdOrApp.name : '[DEFAULT]';\n    return _this;\n  }\n\n  Firestore$1.prototype._terminate = function () {\n    if (!this._firestoreClient) {\n      // The client must be initialized to ensure that all subsequent API\n      // usage throws an exception.\n      configureFirestore(this);\n    }\n\n    return this._firestoreClient.terminate();\n  };\n\n  return Firestore$1;\n}(Firestore$2);\n/**\r\n * @internal\r\n */\n\n\nfunction ensureFirestoreConfigured(firestore) {\n  if (!firestore._firestoreClient) {\n    configureFirestore(firestore);\n  }\n\n  firestore._firestoreClient.verifyNotTerminated();\n\n  return firestore._firestoreClient;\n}\n\nfunction configureFirestore(firestore) {\n  var _a;\n\n  var settings = firestore._freezeSettings();\n\n  var databaseInfo = makeDatabaseInfo(firestore._databaseId, ((_a = firestore._app) === null || _a === void 0 ? void 0 : _a.options.appId) || '', firestore._persistenceKey, settings);\n  firestore._firestoreClient = new FirestoreClient(firestore._credentials, firestore._queue, databaseInfo);\n}\n/**\r\n * Attempts to enable persistent storage, if possible.\r\n *\r\n * Must be called before any other functions (other than\r\n * {@link initializeFirestore}, {@link getFirestore} or\r\n * {@link clearIndexedDbPersistence}.\r\n *\r\n * If this fails, `enableIndexedDbPersistence()` will reject the promise it\r\n * returns. Note that even after this failure, the `Firestore` instance will\r\n * remain usable, however offline persistence will be disabled.\r\n *\r\n * There are several reasons why this can fail, which can be identified by\r\n * the `code` on the error.\r\n *\r\n *   * failed-precondition: The app is already open in another browser tab.\r\n *   * unimplemented: The browser is incompatible with the offline\r\n *     persistence implementation.\r\n *\r\n * @param firestore - The `Firestore` instance to enable persistence for.\r\n * @param persistenceSettings - Optional settings object to configure\r\n * persistence.\r\n * @returns A promise that represents successfully enabling persistent storage.\r\n */\n\n\nfunction enableIndexedDbPersistence(firestore, persistenceSettings) {\n  firestore = cast(firestore, Firestore$1);\n  verifyNotInitialized(firestore);\n  var client = ensureFirestoreConfigured(firestore);\n\n  var settings = firestore._freezeSettings();\n\n  var onlineComponentProvider = new OnlineComponentProvider();\n  var offlineComponentProvider = new IndexedDbOfflineComponentProvider(onlineComponentProvider, settings.cacheSizeBytes, persistenceSettings === null || persistenceSettings === void 0 ? void 0 : persistenceSettings.forceOwnership);\n  return setPersistenceProviders(client, onlineComponentProvider, offlineComponentProvider);\n}\n/**\r\n * Attempts to enable multi-tab persistent storage, if possible. If enabled\r\n * across all tabs, all operations share access to local persistence, including\r\n * shared execution of queries and latency-compensated local document updates\r\n * across all connected instances.\r\n *\r\n * If this fails, `enableMultiTabIndexedDbPersistence()` will reject the promise\r\n * it returns. Note that even after this failure, the `Firestore` instance will\r\n * remain usable, however offline persistence will be disabled.\r\n *\r\n * There are several reasons why this can fail, which can be identified by\r\n * the `code` on the error.\r\n *\r\n *   * failed-precondition: The app is already open in another browser tab and\r\n *     multi-tab is not enabled.\r\n *   * unimplemented: The browser is incompatible with the offline\r\n *     persistence implementation.\r\n *\r\n * @param firestore - The `Firestore` instance to enable persistence for.\r\n * @returns A promise that represents successfully enabling persistent\r\n * storage.\r\n */\n\n\nfunction enableMultiTabIndexedDbPersistence(firestore) {\n  firestore = cast(firestore, Firestore$1);\n  verifyNotInitialized(firestore);\n  var client = ensureFirestoreConfigured(firestore);\n\n  var settings = firestore._freezeSettings();\n\n  var onlineComponentProvider = new OnlineComponentProvider();\n  var offlineComponentProvider = new MultiTabOfflineComponentProvider(onlineComponentProvider, settings.cacheSizeBytes);\n  return setPersistenceProviders(client, onlineComponentProvider, offlineComponentProvider);\n}\n/**\r\n * Registers both the `OfflineComponentProvider` and `OnlineComponentProvider`.\r\n * If the operation fails with a recoverable error (see\r\n * `canRecoverFromIndexedDbError()` below), the returned Promise is rejected\r\n * but the client remains usable.\r\n */\n\n\nfunction setPersistenceProviders(client, onlineComponentProvider, offlineComponentProvider) {\n  var _this = this;\n\n  var persistenceResult = new Deferred();\n  return client.asyncQueue.enqueue(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var e_15;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            _d.trys.push([0, 3,, 4]);\n\n            return [4\n            /*yield*/\n            , setOfflineComponentProvider(client, offlineComponentProvider)];\n\n          case 1:\n            _d.sent();\n\n            return [4\n            /*yield*/\n            , setOnlineComponentProvider(client, onlineComponentProvider)];\n\n          case 2:\n            _d.sent();\n\n            persistenceResult.resolve();\n            return [3\n            /*break*/\n            , 4];\n\n          case 3:\n            e_15 = _d.sent();\n\n            if (!canFallbackFromIndexedDbError(e_15)) {\n              throw e_15;\n            }\n\n            console.warn('Error enabling offline persistence. Falling back to ' + 'persistence disabled: ' + e_15);\n            persistenceResult.reject(e_15);\n            return [3\n            /*break*/\n            , 4];\n\n          case 4:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  }).then(function () {\n    return persistenceResult.promise;\n  });\n}\n/**\r\n * Decides whether the provided error allows us to gracefully disable\r\n * persistence (as opposed to crashing the client).\r\n */\n\n\nfunction canFallbackFromIndexedDbError(error) {\n  if (error.name === 'FirebaseError') {\n    return error.code === Code.FAILED_PRECONDITION || error.code === Code.UNIMPLEMENTED;\n  } else if (typeof DOMException !== 'undefined' && error instanceof DOMException) {\n    // There are a few known circumstances where we can open IndexedDb but\n    // trying to read/write will fail (e.g. quota exceeded). For\n    // well-understood cases, we attempt to detect these and then gracefully\n    // fall back to memory persistence.\n    // NOTE: Rather than continue to add to this list, we could decide to\n    // always fall back, with the risk that we might accidentally hide errors\n    // representing actual SDK bugs.\n    return (// When the browser is out of quota we could get either quota exceeded\n      // or an aborted error depending on whether the error happened during\n      // schema migration.\n      error.code === DOM_EXCEPTION_QUOTA_EXCEEDED || error.code === DOM_EXCEPTION_ABORTED || // Firefox Private Browsing mode disables IndexedDb and returns\n      // INVALID_STATE for any usage.\n      error.code === DOM_EXCEPTION_INVALID_STATE\n    );\n  }\n\n  return true;\n}\n/**\r\n * Clears the persistent storage. This includes pending writes and cached\r\n * documents.\r\n *\r\n * Must be called while the `Firestore` instance is not started (after the app is\r\n * terminated or when the app is first initialized). On startup, this function\r\n * must be called before other functions (other than {@link\r\n * initializeFirestore} or {@link getFirestore})). If the `Firestore`\r\n * instance is still running, the promise will be rejected with the error code\r\n * of `failed-precondition`.\r\n *\r\n * Note: `clearIndexedDbPersistence()` is primarily intended to help write\r\n * reliable tests that use Cloud Firestore. It uses an efficient mechanism for\r\n * dropping existing data but does not attempt to securely overwrite or\r\n * otherwise make cached data unrecoverable. For applications that are sensitive\r\n * to the disclosure of cached data in between user sessions, we strongly\r\n * recommend not enabling persistence at all.\r\n *\r\n * @param firestore - The `Firestore` instance to clear persistence for.\r\n * @returns A promise that is resolved when the persistent storage is\r\n * cleared. Otherwise, the promise is rejected with an error.\r\n */\n\n\nfunction clearIndexedDbPersistence(firestore) {\n  var _this = this;\n\n  if (firestore._initialized && !firestore._terminated) {\n    throw new FirestoreError(Code.FAILED_PRECONDITION, 'Persistence can only be cleared before a Firestore instance is ' + 'initialized or after it is terminated.');\n  }\n\n  var deferred = new Deferred();\n\n  firestore._queue.enqueueAndForgetEvenWhileRestricted(function () {\n    return tslib.__awaiter(_this, void 0, void 0, function () {\n      var e_16;\n      return tslib.__generator(this, function (_d) {\n        switch (_d.label) {\n          case 0:\n            _d.trys.push([0, 2,, 3]);\n\n            return [4\n            /*yield*/\n            , indexedDbClearPersistence(indexedDbStoragePrefix(firestore._databaseId, firestore._persistenceKey))];\n\n          case 1:\n            _d.sent();\n\n            deferred.resolve();\n            return [3\n            /*break*/\n            , 3];\n\n          case 2:\n            e_16 = _d.sent();\n            deferred.reject(e_16);\n            return [3\n            /*break*/\n            , 3];\n\n          case 3:\n            return [2\n            /*return*/\n            ];\n        }\n      });\n    });\n  });\n\n  return deferred.promise;\n}\n/**\r\n * Waits until all currently pending writes for the active user have been\r\n * acknowledged by the backend.\r\n *\r\n * The returned Promise resolves immediately if there are no outstanding writes.\r\n * Otherwise, the Promise waits for all previously issued writes (including\r\n * those written in a previous app session), but it does not wait for writes\r\n * that were added after the function is called. If you want to wait for\r\n * additional writes, call `waitForPendingWrites()` again.\r\n *\r\n * Any outstanding `waitForPendingWrites()` Promises are rejected during user\r\n * changes.\r\n *\r\n * @returns A Promise which resolves when all currently pending writes have been\r\n * acknowledged by the backend.\r\n */\n\n\nfunction waitForPendingWrites(firestore) {\n  firestore = cast(firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientWaitForPendingWrites(client);\n}\n/**\r\n * Re-enables use of the network for this Firestore instance after a prior\r\n * call to {@link disableNetwork}.\r\n *\r\n * @returns A promise that is resolved once the network has been enabled.\r\n */\n\n\nfunction enableNetwork(firestore) {\n  firestore = cast(firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientEnableNetwork(client);\n}\n/**\r\n * Disables network usage for this instance. It can be re-enabled via {@link\r\n * enableNetwork}. While the network is disabled, any snapshot listeners,\r\n * `getDoc()` or `getDocs()` calls will return results from cache, and any write\r\n * operations will be queued until the network is restored.\r\n *\r\n * @returns A promise that is resolved once the network has been disabled.\r\n */\n\n\nfunction disableNetwork(firestore) {\n  firestore = cast(firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientDisableNetwork(client);\n}\n/**\r\n * Loads a Firestore bundle into the local cache.\r\n *\r\n * @param firestore - The `Firestore` instance to load bundles for for.\r\n * @param bundleData - An object representing the bundle to be loaded. Valid objects are\r\n *   `ArrayBuffer`, `ReadableStream<Uint8Array>` or `string`.\r\n *\r\n * @returns\r\n *   A `LoadBundleTask` object, which notifies callers with progress updates, and completion\r\n *   or error events. It can be used as a `Promise<LoadBundleTaskProgress>`.\r\n */\n\n\nfunction loadBundle(firestore, bundleData) {\n  firestore = cast(firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  var resultTask = new LoadBundleTask();\n  firestoreClientLoadBundle(client, firestore._databaseId, bundleData, resultTask);\n  return resultTask;\n}\n/**\r\n * Reads a Firestore `Query` from local cache, identified by the given name.\r\n *\r\n * The named queries are packaged  into bundles on the server side (along\r\n * with resulting documents), and loaded to local cache using `loadBundle`. Once in local\r\n * cache, use this method to extract a `Query` by name.\r\n */\n\n\nfunction namedQuery(firestore, name) {\n  firestore = cast(firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientGetNamedQuery(client, name).then(function (namedQuery) {\n    if (!namedQuery) {\n      return null;\n    }\n\n    return new Query$1(firestore, null, namedQuery.query);\n  });\n}\n\nfunction verifyNotInitialized(firestore) {\n  if (firestore._initialized || firestore._terminated) {\n    throw new FirestoreError(Code.FAILED_PRECONDITION, 'Firestore has already been started and persistence can no longer be ' + 'enabled. You can only enable persistence before calling any other ' + 'methods on a Firestore object.');\n  }\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A `FieldPath` refers to a field in a document. The path may consist of a\r\n * single field name (referring to a top-level field in the document), or a\r\n * list of field names (referring to a nested field in the document).\r\n *\r\n * Create a `FieldPath` by providing field names. If more than one field\r\n * name is provided, the path will point to a nested field in a document.\r\n */\n\n\nvar FieldPath =\n/** @class */\nfunction () {\n  /**\r\n   * Creates a FieldPath from the provided field names. If more than one field\r\n   * name is provided, the path will point to a nested field in a document.\r\n   *\r\n   * @param fieldNames - A list of field names.\r\n   */\n  function FieldPath() {\n    var fieldNames = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      fieldNames[_i] = arguments[_i];\n    }\n\n    for (var i = 0; i < fieldNames.length; ++i) {\n      if (fieldNames[i].length === 0) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid field name at argument $(i + 1). \" + 'Field names must not be empty.');\n      }\n    }\n\n    this._internalPath = new FieldPath$1(fieldNames);\n  }\n  /**\r\n   * Returns true if this `FieldPath` is equal to the provided one.\r\n   *\r\n   * @param other - The `FieldPath` to compare against.\r\n   * @returns true if this `FieldPath` is equal to the provided one.\r\n   */\n\n\n  FieldPath.prototype.isEqual = function (other) {\n    return this._internalPath.isEqual(other._internalPath);\n  };\n\n  return FieldPath;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An immutable object representing an array of bytes.\r\n */\n\n\nvar Bytes =\n/** @class */\nfunction () {\n  /** @hideconstructor */\n  function Bytes(byteString) {\n    this._byteString = byteString;\n  }\n  /**\r\n   * Creates a new `Bytes` object from the given Base64 string, converting it to\r\n   * bytes.\r\n   *\r\n   * @param base64 - The Base64 string used to create the `Bytes` object.\r\n   */\n\n\n  Bytes.fromBase64String = function (base64) {\n    try {\n      return new Bytes(ByteString.fromBase64String(base64));\n    } catch (e) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Failed to construct data from Base64 string: ' + e);\n    }\n  };\n  /**\r\n   * Creates a new `Bytes` object from the given Uint8Array.\r\n   *\r\n   * @param array - The Uint8Array used to create the `Bytes` object.\r\n   */\n\n\n  Bytes.fromUint8Array = function (array) {\n    return new Bytes(ByteString.fromUint8Array(array));\n  };\n  /**\r\n   * Returns the underlying bytes as a Base64-encoded string.\r\n   *\r\n   * @returns The Base64-encoded string created from the `Bytes` object.\r\n   */\n\n\n  Bytes.prototype.toBase64 = function () {\n    return this._byteString.toBase64();\n  };\n  /**\r\n   * Returns the underlying bytes in a new `Uint8Array`.\r\n   *\r\n   * @returns The Uint8Array created from the `Bytes` object.\r\n   */\n\n\n  Bytes.prototype.toUint8Array = function () {\n    return this._byteString.toUint8Array();\n  };\n  /**\r\n   * Returns a string representation of the `Bytes` object.\r\n   *\r\n   * @returns A string representation of the `Bytes` object.\r\n   */\n\n\n  Bytes.prototype.toString = function () {\n    return 'Bytes(base64: ' + this.toBase64() + ')';\n  };\n  /**\r\n   * Returns true if this `Bytes` object is equal to the provided one.\r\n   *\r\n   * @param other - The `Bytes` object to compare against.\r\n   * @returns true if this `Bytes` object is equal to the provided one.\r\n   */\n\n\n  Bytes.prototype.isEqual = function (other) {\n    return this._byteString.isEqual(other._byteString);\n  };\n\n  return Bytes;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Sentinel values that can be used when writing document fields with `set()`\r\n * or `update()`.\r\n */\n\n\nvar FieldValue =\n/** @class */\nfunction () {\n  /**\r\n   * @param _methodName - The public API endpoint that returns this class.\r\n   * @hideconstructor\r\n   */\n  function FieldValue(_methodName) {\n    this._methodName = _methodName;\n  }\n\n  return FieldValue;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * An immutable object representing a geographic location in Firestore. The\r\n * location is represented as latitude/longitude pair.\r\n *\r\n * Latitude values are in the range of [-90, 90].\r\n * Longitude values are in the range of [-180, 180].\r\n */\n\n\nvar GeoPoint =\n/** @class */\nfunction () {\n  /**\r\n   * Creates a new immutable `GeoPoint` object with the provided latitude and\r\n   * longitude values.\r\n   * @param latitude - The latitude as number between -90 and 90.\r\n   * @param longitude - The longitude as number between -180 and 180.\r\n   */\n  function GeoPoint(latitude, longitude) {\n    if (!isFinite(latitude) || latitude < -90 || latitude > 90) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Latitude must be a number between -90 and 90, but was: ' + latitude);\n    }\n\n    if (!isFinite(longitude) || longitude < -180 || longitude > 180) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Longitude must be a number between -180 and 180, but was: ' + longitude);\n    }\n\n    this._lat = latitude;\n    this._long = longitude;\n  }\n\n  Object.defineProperty(GeoPoint.prototype, \"latitude\", {\n    /**\r\n     * The latitude of this `GeoPoint` instance.\r\n     */\n    get: function () {\n      return this._lat;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(GeoPoint.prototype, \"longitude\", {\n    /**\r\n     * The longitude of this `GeoPoint` instance.\r\n     */\n    get: function () {\n      return this._long;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Returns true if this `GeoPoint` is equal to the provided one.\r\n   *\r\n   * @param other - The `GeoPoint` to compare against.\r\n   * @returns true if this `GeoPoint` is equal to the provided one.\r\n   */\n\n  GeoPoint.prototype.isEqual = function (other) {\n    return this._lat === other._lat && this._long === other._long;\n  };\n  /** Returns a JSON-serializable representation of this GeoPoint. */\n\n\n  GeoPoint.prototype.toJSON = function () {\n    return {\n      latitude: this._lat,\n      longitude: this._long\n    };\n  };\n  /**\r\n   * Actually private to JS consumers of our API, so this function is prefixed\r\n   * with an underscore.\r\n   */\n\n\n  GeoPoint.prototype._compareTo = function (other) {\n    return primitiveComparator(this._lat, other._lat) || primitiveComparator(this._long, other._long);\n  };\n\n  return GeoPoint;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nvar RESERVED_FIELD_REGEX = /^__.*__$/;\n/** The result of parsing document data (e.g. for a setData call). */\n\nvar ParsedSetData =\n/** @class */\nfunction () {\n  function ParsedSetData(data, fieldMask, fieldTransforms) {\n    this.data = data;\n    this.fieldMask = fieldMask;\n    this.fieldTransforms = fieldTransforms;\n  }\n\n  ParsedSetData.prototype.toMutation = function (key, precondition) {\n    if (this.fieldMask !== null) {\n      return new PatchMutation(key, this.data, this.fieldMask, precondition, this.fieldTransforms);\n    } else {\n      return new SetMutation(key, this.data, precondition, this.fieldTransforms);\n    }\n  };\n\n  return ParsedSetData;\n}();\n/** The result of parsing \"update\" data (i.e. for an updateData call). */\n\n\nvar ParsedUpdateData =\n/** @class */\nfunction () {\n  function ParsedUpdateData(data, // The fieldMask does not include document transforms.\n  fieldMask, fieldTransforms) {\n    this.data = data;\n    this.fieldMask = fieldMask;\n    this.fieldTransforms = fieldTransforms;\n  }\n\n  ParsedUpdateData.prototype.toMutation = function (key, precondition) {\n    return new PatchMutation(key, this.data, this.fieldMask, precondition, this.fieldTransforms);\n  };\n\n  return ParsedUpdateData;\n}();\n\nfunction isWrite(dataSource) {\n  switch (dataSource) {\n    case 0\n    /* Set */\n    : // fall through\n\n    case 2\n    /* MergeSet */\n    : // fall through\n\n    case 1\n    /* Update */\n    :\n      return true;\n\n    case 3\n    /* Argument */\n    :\n    case 4\n    /* ArrayArgument */\n    :\n      return false;\n\n    default:\n      throw fail();\n  }\n}\n/** A \"context\" object passed around while parsing user data. */\n\n\nvar ParseContextImpl =\n/** @class */\nfunction () {\n  /**\r\n   * Initializes a ParseContext with the given source and path.\r\n   *\r\n   * @param settings - The settings for the parser.\r\n   * @param databaseId - The database ID of the Firestore instance.\r\n   * @param serializer - The serializer to use to generate the Value proto.\r\n   * @param ignoreUndefinedProperties - Whether to ignore undefined properties\r\n   * rather than throw.\r\n   * @param fieldTransforms - A mutable list of field transforms encountered\r\n   * while parsing the data.\r\n   * @param fieldMask - A mutable list of field paths encountered while parsing\r\n   * the data.\r\n   *\r\n   * TODO(b/34871131): We don't support array paths right now, so path can be\r\n   * null to indicate the context represents any location within an array (in\r\n   * which case certain features will not work and errors will be somewhat\r\n   * compromised).\r\n   */\n  function ParseContextImpl(settings, databaseId, serializer, ignoreUndefinedProperties, fieldTransforms, fieldMask) {\n    this.settings = settings;\n    this.databaseId = databaseId;\n    this.serializer = serializer;\n    this.ignoreUndefinedProperties = ignoreUndefinedProperties; // Minor hack: If fieldTransforms is undefined, we assume this is an\n    // external call and we need to validate the entire path.\n\n    if (fieldTransforms === undefined) {\n      this.validatePath();\n    }\n\n    this.fieldTransforms = fieldTransforms || [];\n    this.fieldMask = fieldMask || [];\n  }\n\n  Object.defineProperty(ParseContextImpl.prototype, \"path\", {\n    get: function () {\n      return this.settings.path;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(ParseContextImpl.prototype, \"dataSource\", {\n    get: function () {\n      return this.settings.dataSource;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /** Returns a new context with the specified settings overwritten. */\n\n  ParseContextImpl.prototype.contextWith = function (configuration) {\n    return new ParseContextImpl(Object.assign(Object.assign({}, this.settings), configuration), this.databaseId, this.serializer, this.ignoreUndefinedProperties, this.fieldTransforms, this.fieldMask);\n  };\n\n  ParseContextImpl.prototype.childContextForField = function (field) {\n    var _a;\n\n    var childPath = (_a = this.path) === null || _a === void 0 ? void 0 : _a.child(field);\n    var context = this.contextWith({\n      path: childPath,\n      arrayElement: false\n    });\n    context.validatePathSegment(field);\n    return context;\n  };\n\n  ParseContextImpl.prototype.childContextForFieldPath = function (field) {\n    var _a;\n\n    var childPath = (_a = this.path) === null || _a === void 0 ? void 0 : _a.child(field);\n    var context = this.contextWith({\n      path: childPath,\n      arrayElement: false\n    });\n    context.validatePath();\n    return context;\n  };\n\n  ParseContextImpl.prototype.childContextForArray = function (index) {\n    // TODO(b/34871131): We don't support array paths right now; so make path\n    // undefined.\n    return this.contextWith({\n      path: undefined,\n      arrayElement: true\n    });\n  };\n\n  ParseContextImpl.prototype.createError = function (reason) {\n    return createError(reason, this.settings.methodName, this.settings.hasConverter || false, this.path, this.settings.targetDoc);\n  };\n  /** Returns 'true' if 'fieldPath' was traversed when creating this context. */\n\n\n  ParseContextImpl.prototype.contains = function (fieldPath) {\n    return this.fieldMask.find(function (field) {\n      return fieldPath.isPrefixOf(field);\n    }) !== undefined || this.fieldTransforms.find(function (transform) {\n      return fieldPath.isPrefixOf(transform.field);\n    }) !== undefined;\n  };\n\n  ParseContextImpl.prototype.validatePath = function () {\n    // TODO(b/34871131): Remove null check once we have proper paths for fields\n    // within arrays.\n    if (!this.path) {\n      return;\n    }\n\n    for (var i = 0; i < this.path.length; i++) {\n      this.validatePathSegment(this.path.get(i));\n    }\n  };\n\n  ParseContextImpl.prototype.validatePathSegment = function (segment) {\n    if (segment.length === 0) {\n      throw this.createError('Document fields must not be empty');\n    }\n\n    if (isWrite(this.dataSource) && RESERVED_FIELD_REGEX.test(segment)) {\n      throw this.createError('Document fields cannot begin and end with \"__\"');\n    }\n  };\n\n  return ParseContextImpl;\n}();\n/**\r\n * Helper for parsing raw user input (provided via the API) into internal model\r\n * classes.\r\n */\n\n\nvar UserDataReader =\n/** @class */\nfunction () {\n  function UserDataReader(databaseId, ignoreUndefinedProperties, serializer) {\n    this.databaseId = databaseId;\n    this.ignoreUndefinedProperties = ignoreUndefinedProperties;\n    this.serializer = serializer || newSerializer(databaseId);\n  }\n  /** Creates a new top-level parse context. */\n\n\n  UserDataReader.prototype.createContext = function (dataSource, methodName, targetDoc, hasConverter) {\n    if (hasConverter === void 0) {\n      hasConverter = false;\n    }\n\n    return new ParseContextImpl({\n      dataSource: dataSource,\n      methodName: methodName,\n      targetDoc: targetDoc,\n      path: FieldPath$1.emptyPath(),\n      arrayElement: false,\n      hasConverter: hasConverter\n    }, this.databaseId, this.serializer, this.ignoreUndefinedProperties);\n  };\n\n  return UserDataReader;\n}();\n\nfunction newUserDataReader(firestore) {\n  var settings = firestore._freezeSettings();\n\n  var serializer = newSerializer(firestore._databaseId);\n  return new UserDataReader(firestore._databaseId, !!settings.ignoreUndefinedProperties, serializer);\n}\n/** Parse document data from a set() call. */\n\n\nfunction parseSetData(userDataReader, methodName, targetDoc, input, hasConverter, options) {\n  if (options === void 0) {\n    options = {};\n  }\n\n  var context = userDataReader.createContext(options.merge || options.mergeFields ? 2\n  /* MergeSet */\n  : 0\n  /* Set */\n  , methodName, targetDoc, hasConverter);\n  validatePlainObject('Data must be an object, but it was:', context, input);\n  var updateData = parseObject(input, context);\n  var fieldMask;\n  var fieldTransforms;\n\n  if (options.merge) {\n    fieldMask = new FieldMask(context.fieldMask);\n    fieldTransforms = context.fieldTransforms;\n  } else if (options.mergeFields) {\n    var validatedFieldPaths = [];\n\n    for (var _i = 0, _d = options.mergeFields; _i < _d.length; _i++) {\n      var stringOrFieldPath = _d[_i];\n      var fieldPath = fieldPathFromArgument$1(methodName, stringOrFieldPath, targetDoc);\n\n      if (!context.contains(fieldPath)) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Field '\" + fieldPath + \"' is specified in your field mask but missing from your input data.\");\n      }\n\n      if (!fieldMaskContains(validatedFieldPaths, fieldPath)) {\n        validatedFieldPaths.push(fieldPath);\n      }\n    }\n\n    fieldMask = new FieldMask(validatedFieldPaths);\n    fieldTransforms = context.fieldTransforms.filter(function (transform) {\n      return fieldMask.covers(transform.field);\n    });\n  } else {\n    fieldMask = null;\n    fieldTransforms = context.fieldTransforms;\n  }\n\n  return new ParsedSetData(new ObjectValue(updateData), fieldMask, fieldTransforms);\n}\n\nvar DeleteFieldValueImpl =\n/** @class */\nfunction (_super) {\n  tslib.__extends(DeleteFieldValueImpl, _super);\n\n  function DeleteFieldValueImpl() {\n    return _super !== null && _super.apply(this, arguments) || this;\n  }\n\n  DeleteFieldValueImpl.prototype._toFieldTransform = function (context) {\n    if (context.dataSource === 2\n    /* MergeSet */\n    ) {\n        // No transform to add for a delete, but we need to add it to our\n        // fieldMask so it gets deleted.\n        context.fieldMask.push(context.path);\n      } else if (context.dataSource === 1\n    /* Update */\n    ) {\n        throw context.createError(this._methodName + \"() can only appear at the top level \" + 'of your update data');\n      } else {\n      // We shouldn't encounter delete sentinels for queries or non-merge set() calls.\n      throw context.createError(this._methodName + \"() cannot be used with set() unless you pass \" + '{merge:true}');\n    }\n\n    return null;\n  };\n\n  DeleteFieldValueImpl.prototype.isEqual = function (other) {\n    return other instanceof DeleteFieldValueImpl;\n  };\n\n  return DeleteFieldValueImpl;\n}(FieldValue);\n/**\r\n * Creates a child context for parsing SerializableFieldValues.\r\n *\r\n * This is different than calling `ParseContext.contextWith` because it keeps\r\n * the fieldTransforms and fieldMask separate.\r\n *\r\n * The created context has its `dataSource` set to `UserDataSource.Argument`.\r\n * Although these values are used with writes, any elements in these FieldValues\r\n * are not considered writes since they cannot contain any FieldValue sentinels,\r\n * etc.\r\n *\r\n * @param fieldValue - The sentinel FieldValue for which to create a child\r\n *     context.\r\n * @param context - The parent context.\r\n * @param arrayElement - Whether or not the FieldValue has an array.\r\n */\n\n\nfunction createSentinelChildContext(fieldValue, context, arrayElement) {\n  return new ParseContextImpl({\n    dataSource: 3\n    /* Argument */\n    ,\n    targetDoc: context.settings.targetDoc,\n    methodName: fieldValue._methodName,\n    arrayElement: arrayElement\n  }, context.databaseId, context.serializer, context.ignoreUndefinedProperties);\n}\n\nvar ServerTimestampFieldValueImpl =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ServerTimestampFieldValueImpl, _super);\n\n  function ServerTimestampFieldValueImpl() {\n    return _super !== null && _super.apply(this, arguments) || this;\n  }\n\n  ServerTimestampFieldValueImpl.prototype._toFieldTransform = function (context) {\n    return new FieldTransform(context.path, new ServerTimestampTransform());\n  };\n\n  ServerTimestampFieldValueImpl.prototype.isEqual = function (other) {\n    return other instanceof ServerTimestampFieldValueImpl;\n  };\n\n  return ServerTimestampFieldValueImpl;\n}(FieldValue);\n\nvar ArrayUnionFieldValueImpl =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ArrayUnionFieldValueImpl, _super);\n\n  function ArrayUnionFieldValueImpl(methodName, _elements) {\n    var _this = _super.call(this, methodName) || this;\n\n    _this._elements = _elements;\n    return _this;\n  }\n\n  ArrayUnionFieldValueImpl.prototype._toFieldTransform = function (context) {\n    var parseContext = createSentinelChildContext(this, context,\n    /*array=*/\n    true);\n\n    var parsedElements = this._elements.map(function (element) {\n      return parseData(element, parseContext);\n    });\n\n    var arrayUnion = new ArrayUnionTransformOperation(parsedElements);\n    return new FieldTransform(context.path, arrayUnion);\n  };\n\n  ArrayUnionFieldValueImpl.prototype.isEqual = function (other) {\n    // TODO(mrschmidt): Implement isEquals\n    return this === other;\n  };\n\n  return ArrayUnionFieldValueImpl;\n}(FieldValue);\n\nvar ArrayRemoveFieldValueImpl =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ArrayRemoveFieldValueImpl, _super);\n\n  function ArrayRemoveFieldValueImpl(methodName, _elements) {\n    var _this = _super.call(this, methodName) || this;\n\n    _this._elements = _elements;\n    return _this;\n  }\n\n  ArrayRemoveFieldValueImpl.prototype._toFieldTransform = function (context) {\n    var parseContext = createSentinelChildContext(this, context,\n    /*array=*/\n    true);\n\n    var parsedElements = this._elements.map(function (element) {\n      return parseData(element, parseContext);\n    });\n\n    var arrayUnion = new ArrayRemoveTransformOperation(parsedElements);\n    return new FieldTransform(context.path, arrayUnion);\n  };\n\n  ArrayRemoveFieldValueImpl.prototype.isEqual = function (other) {\n    // TODO(mrschmidt): Implement isEquals\n    return this === other;\n  };\n\n  return ArrayRemoveFieldValueImpl;\n}(FieldValue);\n\nvar NumericIncrementFieldValueImpl =\n/** @class */\nfunction (_super) {\n  tslib.__extends(NumericIncrementFieldValueImpl, _super);\n\n  function NumericIncrementFieldValueImpl(methodName, _operand) {\n    var _this = _super.call(this, methodName) || this;\n\n    _this._operand = _operand;\n    return _this;\n  }\n\n  NumericIncrementFieldValueImpl.prototype._toFieldTransform = function (context) {\n    var numericIncrement = new NumericIncrementTransformOperation(context.serializer, toNumber(context.serializer, this._operand));\n    return new FieldTransform(context.path, numericIncrement);\n  };\n\n  NumericIncrementFieldValueImpl.prototype.isEqual = function (other) {\n    // TODO(mrschmidt): Implement isEquals\n    return this === other;\n  };\n\n  return NumericIncrementFieldValueImpl;\n}(FieldValue);\n/** Parse update data from an update() call. */\n\n\nfunction parseUpdateData(userDataReader, methodName, targetDoc, input) {\n  var context = userDataReader.createContext(1\n  /* Update */\n  , methodName, targetDoc);\n  validatePlainObject('Data must be an object, but it was:', context, input);\n  var fieldMaskPaths = [];\n  var updateData = ObjectValue.empty();\n  forEach(input, function (key, value) {\n    var path = fieldPathFromDotSeparatedString(methodName, key, targetDoc); // For Compat types, we have to \"extract\" the underlying types before\n    // performing validation.\n\n    value = util.getModularInstance(value);\n    var childContext = context.childContextForFieldPath(path);\n\n    if (value instanceof DeleteFieldValueImpl) {\n      // Add it to the field mask, but don't add anything to updateData.\n      fieldMaskPaths.push(path);\n    } else {\n      var parsedValue = parseData(value, childContext);\n\n      if (parsedValue != null) {\n        fieldMaskPaths.push(path);\n        updateData.set(path, parsedValue);\n      }\n    }\n  });\n  var mask = new FieldMask(fieldMaskPaths);\n  return new ParsedUpdateData(updateData, mask, context.fieldTransforms);\n}\n/** Parse update data from a list of field/value arguments. */\n\n\nfunction parseUpdateVarargs(userDataReader, methodName, targetDoc, field, value, moreFieldsAndValues) {\n  var context = userDataReader.createContext(1\n  /* Update */\n  , methodName, targetDoc);\n  var keys = [fieldPathFromArgument$1(methodName, field, targetDoc)];\n  var values = [value];\n\n  if (moreFieldsAndValues.length % 2 !== 0) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Function \" + methodName + \"() needs to be called with an even number \" + 'of arguments that alternate between field names and values.');\n  }\n\n  for (var i = 0; i < moreFieldsAndValues.length; i += 2) {\n    keys.push(fieldPathFromArgument$1(methodName, moreFieldsAndValues[i]));\n    values.push(moreFieldsAndValues[i + 1]);\n  }\n\n  var fieldMaskPaths = [];\n  var updateData = ObjectValue.empty(); // We iterate in reverse order to pick the last value for a field if the\n  // user specified the field multiple times.\n\n  for (var i = keys.length - 1; i >= 0; --i) {\n    if (!fieldMaskContains(fieldMaskPaths, keys[i])) {\n      var path = keys[i];\n      var value_1 = values[i]; // For Compat types, we have to \"extract\" the underlying types before\n      // performing validation.\n\n      value_1 = util.getModularInstance(value_1);\n      var childContext = context.childContextForFieldPath(path);\n\n      if (value_1 instanceof DeleteFieldValueImpl) {\n        // Add it to the field mask, but don't add anything to updateData.\n        fieldMaskPaths.push(path);\n      } else {\n        var parsedValue = parseData(value_1, childContext);\n\n        if (parsedValue != null) {\n          fieldMaskPaths.push(path);\n          updateData.set(path, parsedValue);\n        }\n      }\n    }\n  }\n\n  var mask = new FieldMask(fieldMaskPaths);\n  return new ParsedUpdateData(updateData, mask, context.fieldTransforms);\n}\n/**\r\n * Parse a \"query value\" (e.g. value in a where filter or a value in a cursor\r\n * bound).\r\n *\r\n * @param allowArrays - Whether the query value is an array that may directly\r\n * contain additional arrays (e.g. the operand of an `in` query).\r\n */\n\n\nfunction parseQueryValue(userDataReader, methodName, input, allowArrays) {\n  if (allowArrays === void 0) {\n    allowArrays = false;\n  }\n\n  var context = userDataReader.createContext(allowArrays ? 4\n  /* ArrayArgument */\n  : 3\n  /* Argument */\n  , methodName);\n  var parsed = parseData(input, context);\n  return parsed;\n}\n/**\r\n * Parses user data to Protobuf Values.\r\n *\r\n * @param input - Data to be parsed.\r\n * @param context - A context object representing the current path being parsed,\r\n * the source of the data being parsed, etc.\r\n * @returns The parsed value, or null if the value was a FieldValue sentinel\r\n * that should not be included in the resulting parsed data.\r\n */\n\n\nfunction parseData(input, context) {\n  // Unwrap the API type from the Compat SDK. This will return the API type\n  // from firestore-exp.\n  input = util.getModularInstance(input);\n\n  if (looksLikeJsonObject(input)) {\n    validatePlainObject('Unsupported field value:', context, input);\n    return parseObject(input, context);\n  } else if (input instanceof FieldValue) {\n    // FieldValues usually parse into transforms (except FieldValue.delete())\n    // in which case we do not want to include this field in our parsed data\n    // (as doing so will overwrite the field directly prior to the transform\n    // trying to transform it). So we don't add this location to\n    // context.fieldMask and we return null as our parsing result.\n    parseSentinelFieldValue(input, context);\n    return null;\n  } else if (input === undefined && context.ignoreUndefinedProperties) {\n    // If the input is undefined it can never participate in the fieldMask, so\n    // don't handle this below. If `ignoreUndefinedProperties` is false,\n    // `parseScalarValue` will reject an undefined value.\n    return null;\n  } else {\n    // If context.path is null we are inside an array and we don't support\n    // field mask paths more granular than the top-level array.\n    if (context.path) {\n      context.fieldMask.push(context.path);\n    }\n\n    if (input instanceof Array) {\n      // TODO(b/34871131): Include the path containing the array in the error\n      // message.\n      // In the case of IN queries, the parsed data is an array (representing\n      // the set of values to be included for the IN query) that may directly\n      // contain additional arrays (each representing an individual field\n      // value), so we disable this validation.\n      if (context.settings.arrayElement && context.dataSource !== 4\n      /* ArrayArgument */\n      ) {\n          throw context.createError('Nested arrays are not supported');\n        }\n\n      return parseArray(input, context);\n    } else {\n      return parseScalarValue(input, context);\n    }\n  }\n}\n\nfunction parseObject(obj, context) {\n  var fields = {};\n\n  if (isEmpty(obj)) {\n    // If we encounter an empty object, we explicitly add it to the update\n    // mask to ensure that the server creates a map entry.\n    if (context.path && context.path.length > 0) {\n      context.fieldMask.push(context.path);\n    }\n  } else {\n    forEach(obj, function (key, val) {\n      var parsedValue = parseData(val, context.childContextForField(key));\n\n      if (parsedValue != null) {\n        fields[key] = parsedValue;\n      }\n    });\n  }\n\n  return {\n    mapValue: {\n      fields: fields\n    }\n  };\n}\n\nfunction parseArray(array, context) {\n  var values = [];\n  var entryIndex = 0;\n\n  for (var _i = 0, array_1 = array; _i < array_1.length; _i++) {\n    var entry = array_1[_i];\n    var parsedEntry = parseData(entry, context.childContextForArray(entryIndex));\n\n    if (parsedEntry == null) {\n      // Just include nulls in the array for fields being replaced with a\n      // sentinel.\n      parsedEntry = {\n        nullValue: 'NULL_VALUE'\n      };\n    }\n\n    values.push(parsedEntry);\n    entryIndex++;\n  }\n\n  return {\n    arrayValue: {\n      values: values\n    }\n  };\n}\n/**\r\n * \"Parses\" the provided FieldValueImpl, adding any necessary transforms to\r\n * context.fieldTransforms.\r\n */\n\n\nfunction parseSentinelFieldValue(value, context) {\n  // Sentinels are only supported with writes, and not within arrays.\n  if (!isWrite(context.dataSource)) {\n    throw context.createError(value._methodName + \"() can only be used with update() and set()\");\n  }\n\n  if (!context.path) {\n    throw context.createError(value._methodName + \"() is not currently supported inside arrays\");\n  }\n\n  var fieldTransform = value._toFieldTransform(context);\n\n  if (fieldTransform) {\n    context.fieldTransforms.push(fieldTransform);\n  }\n}\n/**\r\n * Helper to parse a scalar value (i.e. not an Object, Array, or FieldValue)\r\n *\r\n * @returns The parsed value\r\n */\n\n\nfunction parseScalarValue(value, context) {\n  value = util.getModularInstance(value);\n\n  if (value === null) {\n    return {\n      nullValue: 'NULL_VALUE'\n    };\n  } else if (typeof value === 'number') {\n    return toNumber(context.serializer, value);\n  } else if (typeof value === 'boolean') {\n    return {\n      booleanValue: value\n    };\n  } else if (typeof value === 'string') {\n    return {\n      stringValue: value\n    };\n  } else if (value instanceof Date) {\n    var timestamp = Timestamp.fromDate(value);\n    return {\n      timestampValue: toTimestamp(context.serializer, timestamp)\n    };\n  } else if (value instanceof Timestamp) {\n    // Firestore backend truncates precision down to microseconds. To ensure\n    // offline mode works the same with regards to truncation, perform the\n    // truncation immediately without waiting for the backend to do that.\n    var timestamp = new Timestamp(value.seconds, Math.floor(value.nanoseconds / 1000) * 1000);\n    return {\n      timestampValue: toTimestamp(context.serializer, timestamp)\n    };\n  } else if (value instanceof GeoPoint) {\n    return {\n      geoPointValue: {\n        latitude: value.latitude,\n        longitude: value.longitude\n      }\n    };\n  } else if (value instanceof Bytes) {\n    return {\n      bytesValue: toBytes(context.serializer, value._byteString)\n    };\n  } else if (value instanceof DocumentReference$1) {\n    var thisDb = context.databaseId;\n    var otherDb = value.firestore._databaseId;\n\n    if (!otherDb.isEqual(thisDb)) {\n      throw context.createError('Document reference is for database ' + (otherDb.projectId + \"/\" + otherDb.database + \" but should be \") + (\"for database \" + thisDb.projectId + \"/\" + thisDb.database));\n    }\n\n    return {\n      referenceValue: toResourceName(value.firestore._databaseId || context.databaseId, value._key.path)\n    };\n  } else {\n    throw context.createError(\"Unsupported field value: \" + valueDescription(value));\n  }\n}\n/**\r\n * Checks whether an object looks like a JSON object that should be converted\r\n * into a struct. Normal class/prototype instances are considered to look like\r\n * JSON objects since they should be converted to a struct value. Arrays, Dates,\r\n * GeoPoints, etc. are not considered to look like JSON objects since they map\r\n * to specific FieldValue types other than ObjectValue.\r\n */\n\n\nfunction looksLikeJsonObject(input) {\n  return typeof input === 'object' && input !== null && !(input instanceof Array) && !(input instanceof Date) && !(input instanceof Timestamp) && !(input instanceof GeoPoint) && !(input instanceof Bytes) && !(input instanceof DocumentReference$1) && !(input instanceof FieldValue);\n}\n\nfunction validatePlainObject(message, context, input) {\n  if (!looksLikeJsonObject(input) || !isPlainObject(input)) {\n    var description = valueDescription(input);\n\n    if (description === 'an object') {\n      // Massage the error if it was an object.\n      throw context.createError(message + ' a custom object');\n    } else {\n      throw context.createError(message + ' ' + description);\n    }\n  }\n}\n/**\r\n * Helper that calls fromDotSeparatedString() but wraps any error thrown.\r\n */\n\n\nfunction fieldPathFromArgument$1(methodName, path, targetDoc) {\n  // If required, replace the FieldPath Compat class with with the firestore-exp\n  // FieldPath.\n  path = util.getModularInstance(path);\n\n  if (path instanceof FieldPath) {\n    return path._internalPath;\n  } else if (typeof path === 'string') {\n    return fieldPathFromDotSeparatedString(methodName, path);\n  } else {\n    var message = 'Field path arguments must be of type string or FieldPath.';\n    throw createError(message, methodName,\n    /* hasConverter= */\n    false,\n    /* path= */\n    undefined, targetDoc);\n  }\n}\n/**\r\n * Matches any characters in a field path string that are reserved.\r\n */\n\n\nvar FIELD_PATH_RESERVED = new RegExp('[~\\\\*/\\\\[\\\\]]');\n/**\r\n * Wraps fromDotSeparatedString with an error message about the method that\r\n * was thrown.\r\n * @param methodName - The publicly visible method name\r\n * @param path - The dot-separated string form of a field path which will be\r\n * split on dots.\r\n * @param targetDoc - The document against which the field path will be\r\n * evaluated.\r\n */\n\nfunction fieldPathFromDotSeparatedString(methodName, path, targetDoc) {\n  var found = path.search(FIELD_PATH_RESERVED);\n\n  if (found >= 0) {\n    throw createError(\"Invalid field path (\" + path + \"). Paths must not contain \" + \"'~', '*', '/', '[', or ']'\", methodName,\n    /* hasConverter= */\n    false,\n    /* path= */\n    undefined, targetDoc);\n  }\n\n  try {\n    return new (FieldPath.bind.apply(FieldPath, tslib.__spreadArray([void 0], path.split('.'))))()._internalPath;\n  } catch (e) {\n    throw createError(\"Invalid field path (\" + path + \"). Paths must not be empty, \" + \"begin with '.', end with '.', or contain '..'\", methodName,\n    /* hasConverter= */\n    false,\n    /* path= */\n    undefined, targetDoc);\n  }\n}\n\nfunction createError(reason, methodName, hasConverter, path, targetDoc) {\n  var hasPath = path && !path.isEmpty();\n  var hasDocument = targetDoc !== undefined;\n  var message = \"Function \" + methodName + \"() called with invalid data\";\n\n  if (hasConverter) {\n    message += ' (via `toFirestore()`)';\n  }\n\n  message += '. ';\n  var description = '';\n\n  if (hasPath || hasDocument) {\n    description += ' (found';\n\n    if (hasPath) {\n      description += \" in field \" + path;\n    }\n\n    if (hasDocument) {\n      description += \" in document \" + targetDoc;\n    }\n\n    description += ')';\n  }\n\n  return new FirestoreError(Code.INVALID_ARGUMENT, message + reason + description);\n}\n/** Checks `haystack` if FieldPath `needle` is present. Runs in O(n). */\n\n\nfunction fieldMaskContains(haystack, needle) {\n  return haystack.some(function (v) {\n    return v.isEqual(needle);\n  });\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A `DocumentSnapshot` contains data read from a document in your Firestore\r\n * database. The data can be extracted with `.data()` or `.get(<field>)` to\r\n * get a specific field.\r\n *\r\n * For a `DocumentSnapshot` that points to a non-existing document, any data\r\n * access will return 'undefined'. You can use the `exists()` method to\r\n * explicitly verify a document's existence.\r\n */\n\n\nvar DocumentSnapshot$2 =\n/** @class */\nfunction () {\n  // Note: This class is stripped down version of the DocumentSnapshot in\n  // the legacy SDK. The changes are:\n  // - No support for SnapshotMetadata.\n  // - No support for SnapshotOptions.\n\n  /** @hideconstructor protected */\n  function DocumentSnapshot$2(_firestore, _userDataWriter, _key, _document, _converter) {\n    this._firestore = _firestore;\n    this._userDataWriter = _userDataWriter;\n    this._key = _key;\n    this._document = _document;\n    this._converter = _converter;\n  }\n\n  Object.defineProperty(DocumentSnapshot$2.prototype, \"id\", {\n    /** Property of the `DocumentSnapshot` that provides the document's ID. */\n    get: function () {\n      return this._key.path.lastSegment();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentSnapshot$2.prototype, \"ref\", {\n    /**\r\n     * The `DocumentReference` for the document included in the `DocumentSnapshot`.\r\n     */\n    get: function () {\n      return new DocumentReference$1(this._firestore, this._converter, this._key);\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Signals whether or not the document at the snapshot's location exists.\r\n   *\r\n   * @returns true if the document exists.\r\n   */\n\n  DocumentSnapshot$2.prototype.exists = function () {\n    return this._document !== null;\n  };\n  /**\r\n   * Retrieves all fields in the document as an `Object`. Returns `undefined` if\r\n   * the document doesn't exist.\r\n   *\r\n   * @returns An `Object` containing all fields in the document or `undefined`\r\n   * if the document doesn't exist.\r\n   */\n\n\n  DocumentSnapshot$2.prototype.data = function () {\n    if (!this._document) {\n      return undefined;\n    } else if (this._converter) {\n      // We only want to use the converter and create a new DocumentSnapshot\n      // if a converter has been provided.\n      var snapshot = new QueryDocumentSnapshot$2(this._firestore, this._userDataWriter, this._key, this._document,\n      /* converter= */\n      null);\n      return this._converter.fromFirestore(snapshot);\n    } else {\n      return this._userDataWriter.convertValue(this._document.data.value);\n    }\n  };\n  /**\r\n   * Retrieves the field specified by `fieldPath`. Returns `undefined` if the\r\n   * document or field doesn't exist.\r\n   *\r\n   * @param fieldPath - The path (for example 'foo' or 'foo.bar') to a specific\r\n   * field.\r\n   * @returns The data at the specified field location or undefined if no such\r\n   * field exists in the document.\r\n   */\n  // We are using `any` here to avoid an explicit cast by our users.\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n\n  DocumentSnapshot$2.prototype.get = function (fieldPath) {\n    if (this._document) {\n      var value = this._document.data.field(fieldPathFromArgument('DocumentSnapshot.get', fieldPath));\n\n      if (value !== null) {\n        return this._userDataWriter.convertValue(value);\n      }\n    }\n\n    return undefined;\n  };\n\n  return DocumentSnapshot$2;\n}();\n/**\r\n * A `QueryDocumentSnapshot` contains data read from a document in your\r\n * Firestore database as part of a query. The document is guaranteed to exist\r\n * and its data can be extracted with `.data()` or `.get(<field>)` to get a\r\n * specific field.\r\n *\r\n * A `QueryDocumentSnapshot` offers the same API surface as a\r\n * `DocumentSnapshot`. Since query results contain only existing documents, the\r\n * `exists` property will always be true and `data()` will never return\r\n * 'undefined'.\r\n */\n\n\nvar QueryDocumentSnapshot$2 =\n/** @class */\nfunction (_super) {\n  tslib.__extends(QueryDocumentSnapshot$2, _super);\n\n  function QueryDocumentSnapshot$2() {\n    return _super !== null && _super.apply(this, arguments) || this;\n  }\n  /**\r\n   * Retrieves all fields in the document as an `Object`.\r\n   *\r\n   * @override\r\n   * @returns An `Object` containing all fields in the document.\r\n   */\n\n\n  QueryDocumentSnapshot$2.prototype.data = function () {\n    return _super.prototype.data.call(this);\n  };\n\n  return QueryDocumentSnapshot$2;\n}(DocumentSnapshot$2);\n/**\r\n * Helper that calls fromDotSeparatedString() but wraps any error thrown.\r\n */\n\n\nfunction fieldPathFromArgument(methodName, arg) {\n  if (typeof arg === 'string') {\n    return fieldPathFromDotSeparatedString(methodName, arg);\n  } else if (arg instanceof FieldPath) {\n    return arg._internalPath;\n  } else {\n    return arg._delegate._internalPath;\n  }\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Metadata about a snapshot, describing the state of the snapshot.\r\n */\n\n\nvar SnapshotMetadata =\n/** @class */\nfunction () {\n  /** @hideconstructor */\n  function SnapshotMetadata(hasPendingWrites, fromCache) {\n    this.hasPendingWrites = hasPendingWrites;\n    this.fromCache = fromCache;\n  }\n  /**\r\n   * Returns true if this `SnapshotMetadata` is equal to the provided one.\r\n   *\r\n   * @param other - The `SnapshotMetadata` to compare against.\r\n   * @returns true if this `SnapshotMetadata` is equal to the provided one.\r\n   */\n\n\n  SnapshotMetadata.prototype.isEqual = function (other) {\n    return this.hasPendingWrites === other.hasPendingWrites && this.fromCache === other.fromCache;\n  };\n\n  return SnapshotMetadata;\n}();\n/**\r\n * A `DocumentSnapshot` contains data read from a document in your Firestore\r\n * database. The data can be extracted with `.data()` or `.get(<field>)` to\r\n * get a specific field.\r\n *\r\n * For a `DocumentSnapshot` that points to a non-existing document, any data\r\n * access will return 'undefined'. You can use the `exists()` method to\r\n * explicitly verify a document's existence.\r\n */\n\n\nvar DocumentSnapshot$1 =\n/** @class */\nfunction (_super) {\n  tslib.__extends(DocumentSnapshot$1, _super);\n  /** @hideconstructor protected */\n\n\n  function DocumentSnapshot$1(_firestore, userDataWriter, key, document, metadata, converter) {\n    var _this = _super.call(this, _firestore, userDataWriter, key, document, converter) || this;\n\n    _this._firestore = _firestore;\n    _this._firestoreImpl = _firestore;\n    _this.metadata = metadata;\n    return _this;\n  }\n  /**\r\n   * Property of the `DocumentSnapshot` that signals whether or not the data\r\n   * exists. True if the document exists.\r\n   */\n\n\n  DocumentSnapshot$1.prototype.exists = function () {\n    return _super.prototype.exists.call(this);\n  };\n  /**\r\n   * Retrieves all fields in the document as an `Object`. Returns `undefined` if\r\n   * the document doesn't exist.\r\n   *\r\n   * By default, `FieldValue.serverTimestamp()` values that have not yet been\r\n   * set to their final value will be returned as `null`. You can override\r\n   * this by passing an options object.\r\n   *\r\n   * @param options - An options object to configure how data is retrieved from\r\n   * the snapshot (for example the desired behavior for server timestamps that\r\n   * have not yet been set to their final value).\r\n   * @returns An `Object` containing all fields in the document or `undefined` if\r\n   * the document doesn't exist.\r\n   */\n\n\n  DocumentSnapshot$1.prototype.data = function (options) {\n    if (options === void 0) {\n      options = {};\n    }\n\n    if (!this._document) {\n      return undefined;\n    } else if (this._converter) {\n      // We only want to use the converter and create a new DocumentSnapshot\n      // if a converter has been provided.\n      var snapshot = new QueryDocumentSnapshot$1(this._firestore, this._userDataWriter, this._key, this._document, this.metadata,\n      /* converter= */\n      null);\n      return this._converter.fromFirestore(snapshot, options);\n    } else {\n      return this._userDataWriter.convertValue(this._document.data.value, options.serverTimestamps);\n    }\n  };\n  /**\r\n   * Retrieves the field specified by `fieldPath`. Returns `undefined` if the\r\n   * document or field doesn't exist.\r\n   *\r\n   * By default, a `FieldValue.serverTimestamp()` that has not yet been set to\r\n   * its final value will be returned as `null`. You can override this by\r\n   * passing an options object.\r\n   *\r\n   * @param fieldPath - The path (for example 'foo' or 'foo.bar') to a specific\r\n   * field.\r\n   * @param options - An options object to configure how the field is retrieved\r\n   * from the snapshot (for example the desired behavior for server timestamps\r\n   * that have not yet been set to their final value).\r\n   * @returns The data at the specified field location or undefined if no such\r\n   * field exists in the document.\r\n   */\n  // We are using `any` here to avoid an explicit cast by our users.\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n\n\n  DocumentSnapshot$1.prototype.get = function (fieldPath, options) {\n    if (options === void 0) {\n      options = {};\n    }\n\n    if (this._document) {\n      var value = this._document.data.field(fieldPathFromArgument('DocumentSnapshot.get', fieldPath));\n\n      if (value !== null) {\n        return this._userDataWriter.convertValue(value, options.serverTimestamps);\n      }\n    }\n\n    return undefined;\n  };\n\n  return DocumentSnapshot$1;\n}(DocumentSnapshot$2);\n/**\r\n * A `QueryDocumentSnapshot` contains data read from a document in your\r\n * Firestore database as part of a query. The document is guaranteed to exist\r\n * and its data can be extracted with `.data()` or `.get(<field>)` to get a\r\n * specific field.\r\n *\r\n * A `QueryDocumentSnapshot` offers the same API surface as a\r\n * `DocumentSnapshot`. Since query results contain only existing documents, the\r\n * `exists` property will always be true and `data()` will never return\r\n * 'undefined'.\r\n */\n\n\nvar QueryDocumentSnapshot$1 =\n/** @class */\nfunction (_super) {\n  tslib.__extends(QueryDocumentSnapshot$1, _super);\n\n  function QueryDocumentSnapshot$1() {\n    return _super !== null && _super.apply(this, arguments) || this;\n  }\n  /**\r\n   * Retrieves all fields in the document as an `Object`.\r\n   *\r\n   * By default, `FieldValue.serverTimestamp()` values that have not yet been\r\n   * set to their final value will be returned as `null`. You can override\r\n   * this by passing an options object.\r\n   *\r\n   * @override\r\n   * @param options - An options object to configure how data is retrieved from\r\n   * the snapshot (for example the desired behavior for server timestamps that\r\n   * have not yet been set to their final value).\r\n   * @returns An `Object` containing all fields in the document.\r\n   */\n\n\n  QueryDocumentSnapshot$1.prototype.data = function (options) {\n    if (options === void 0) {\n      options = {};\n    }\n\n    return _super.prototype.data.call(this, options);\n  };\n\n  return QueryDocumentSnapshot$1;\n}(DocumentSnapshot$1);\n/**\r\n * A `QuerySnapshot` contains zero or more `DocumentSnapshot` objects\r\n * representing the results of a query. The documents can be accessed as an\r\n * array via the `docs` property or enumerated using the `forEach` method. The\r\n * number of documents can be determined via the `empty` and `size`\r\n * properties.\r\n */\n\n\nvar QuerySnapshot$1 =\n/** @class */\nfunction () {\n  /** @hideconstructor */\n  function QuerySnapshot$1(_firestore, _userDataWriter, query, _snapshot) {\n    this._firestore = _firestore;\n    this._userDataWriter = _userDataWriter;\n    this._snapshot = _snapshot;\n    this.metadata = new SnapshotMetadata(_snapshot.hasPendingWrites, _snapshot.fromCache);\n    this.query = query;\n  }\n\n  Object.defineProperty(QuerySnapshot$1.prototype, \"docs\", {\n    /** An array of all the documents in the `QuerySnapshot`. */\n    get: function () {\n      var result = [];\n      this.forEach(function (doc) {\n        return result.push(doc);\n      });\n      return result;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(QuerySnapshot$1.prototype, \"size\", {\n    /** The number of documents in the `QuerySnapshot`. */\n    get: function () {\n      return this._snapshot.docs.size;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(QuerySnapshot$1.prototype, \"empty\", {\n    /** True if there are no documents in the `QuerySnapshot`. */\n    get: function () {\n      return this.size === 0;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Enumerates all of the documents in the `QuerySnapshot`.\r\n   *\r\n   * @param callback - A callback to be called with a `QueryDocumentSnapshot` for\r\n   * each document in the snapshot.\r\n   * @param thisArg - The `this` binding for the callback.\r\n   */\n\n  QuerySnapshot$1.prototype.forEach = function (callback, thisArg) {\n    var _this = this;\n\n    this._snapshot.docs.forEach(function (doc) {\n      callback.call(thisArg, new QueryDocumentSnapshot$1(_this._firestore, _this._userDataWriter, doc.key, doc, new SnapshotMetadata(_this._snapshot.mutatedKeys.has(doc.key), _this._snapshot.fromCache), _this.query.converter));\n    });\n  };\n  /**\r\n   * Returns an array of the documents changes since the last snapshot. If this\r\n   * is the first snapshot, all documents will be in the list as 'added'\r\n   * changes.\r\n   *\r\n   * @param options - `SnapshotListenOptions` that control whether metadata-only\r\n   * changes (i.e. only `DocumentSnapshot.metadata` changed) should trigger\r\n   * snapshot events.\r\n   */\n\n\n  QuerySnapshot$1.prototype.docChanges = function (options) {\n    if (options === void 0) {\n      options = {};\n    }\n\n    var includeMetadataChanges = !!options.includeMetadataChanges;\n\n    if (includeMetadataChanges && this._snapshot.excludesMetadataChanges) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'To include metadata changes with your document changes, you must ' + 'also pass { includeMetadataChanges:true } to onSnapshot().');\n    }\n\n    if (!this._cachedChanges || this._cachedChangesIncludeMetadataChanges !== includeMetadataChanges) {\n      this._cachedChanges = changesFromSnapshot(this, includeMetadataChanges);\n      this._cachedChangesIncludeMetadataChanges = includeMetadataChanges;\n    }\n\n    return this._cachedChanges;\n  };\n\n  return QuerySnapshot$1;\n}();\n/** Calculates the array of DocumentChanges for a given ViewSnapshot. */\n\n\nfunction changesFromSnapshot(querySnapshot, includeMetadataChanges) {\n  if (querySnapshot._snapshot.oldDocs.isEmpty()) {\n    var index_1 = 0;\n    return querySnapshot._snapshot.docChanges.map(function (change) {\n      var doc = new QueryDocumentSnapshot$1(querySnapshot._firestore, querySnapshot._userDataWriter, change.doc.key, change.doc, new SnapshotMetadata(querySnapshot._snapshot.mutatedKeys.has(change.doc.key), querySnapshot._snapshot.fromCache), querySnapshot.query.converter);\n      return {\n        type: 'added',\n        doc: doc,\n        oldIndex: -1,\n        newIndex: index_1++\n      };\n    });\n  } else {\n    // A DocumentSet that is updated incrementally as changes are applied to use\n    // to lookup the index of a document.\n    var indexTracker_1 = querySnapshot._snapshot.oldDocs;\n    return querySnapshot._snapshot.docChanges.filter(function (change) {\n      return includeMetadataChanges || change.type !== 3;\n    }\n    /* Metadata */\n    ).map(function (change) {\n      var doc = new QueryDocumentSnapshot$1(querySnapshot._firestore, querySnapshot._userDataWriter, change.doc.key, change.doc, new SnapshotMetadata(querySnapshot._snapshot.mutatedKeys.has(change.doc.key), querySnapshot._snapshot.fromCache), querySnapshot.query.converter);\n      var oldIndex = -1;\n      var newIndex = -1;\n\n      if (change.type !== 0\n      /* Added */\n      ) {\n          oldIndex = indexTracker_1.indexOf(change.doc.key);\n          indexTracker_1 = indexTracker_1.delete(change.doc.key);\n        }\n\n      if (change.type !== 1\n      /* Removed */\n      ) {\n          indexTracker_1 = indexTracker_1.add(change.doc);\n          newIndex = indexTracker_1.indexOf(change.doc.key);\n        }\n\n      return {\n        type: resultChangeType(change.type),\n        doc: doc,\n        oldIndex: oldIndex,\n        newIndex: newIndex\n      };\n    });\n  }\n}\n\nfunction resultChangeType(type) {\n  switch (type) {\n    case 0\n    /* Added */\n    :\n      return 'added';\n\n    case 2\n    /* Modified */\n    :\n    case 3\n    /* Metadata */\n    :\n      return 'modified';\n\n    case 1\n    /* Removed */\n    :\n      return 'removed';\n\n    default:\n      return fail();\n  }\n} // TODO(firestoreexp): Add tests for snapshotEqual with different snapshot\n// metadata\n\n/**\r\n * Returns true if the provided snapshots are equal.\r\n *\r\n * @param left - A snapshot to compare.\r\n * @param right - A snapshot to compare.\r\n * @returns true if the snapshots are equal.\r\n */\n\n\nfunction snapshotEqual(left, right) {\n  if (left instanceof DocumentSnapshot$1 && right instanceof DocumentSnapshot$1) {\n    return left._firestore === right._firestore && left._key.isEqual(right._key) && (left._document === null ? right._document === null : left._document.isEqual(right._document)) && left._converter === right._converter;\n  } else if (left instanceof QuerySnapshot$1 && right instanceof QuerySnapshot$1) {\n    return left._firestore === right._firestore && queryEqual(left.query, right.query) && left.metadata.isEqual(right.metadata) && left._snapshot.isEqual(right._snapshot);\n  }\n\n  return false;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction validateHasExplicitOrderByForLimitToLast(query) {\n  if (hasLimitToLast(query) && query.explicitOrderBy.length === 0) {\n    throw new FirestoreError(Code.UNIMPLEMENTED, 'limitToLast() queries require specifying at least one orderBy() clause');\n  }\n}\n/**\r\n * A `QueryConstraint` is used to narrow the set of documents returned by a\r\n * Firestore query. `QueryConstraint`s are created by invoking {@link where},\r\n * {@link orderBy}, {@link (startAt:1)}, {@link (startAfter:1)}, {@link\r\n * endBefore:1}, {@link (endAt:1)}, {@link limit} or {@link limitToLast} and\r\n * can then be passed to {@link query} to create a new query instance that\r\n * also contains this `QueryConstraint`.\r\n */\n\n\nvar QueryConstraint =\n/** @class */\nfunction () {\n  function QueryConstraint() {}\n\n  return QueryConstraint;\n}();\n/**\r\n * Creates a new immutable instance of `Query` that is extended to also include\r\n * additional query constraints.\r\n *\r\n * @param query - The Query instance to use as a base for the new constraints.\r\n * @param queryConstraints - The list of `QueryConstraint`s to apply.\r\n * @throws if any of the provided query constraints cannot be combined with the\r\n * existing or new constraints.\r\n */\n\n\nfunction query(query) {\n  var queryConstraints = [];\n\n  for (var _i = 1; _i < arguments.length; _i++) {\n    queryConstraints[_i - 1] = arguments[_i];\n  }\n\n  for (var _d = 0, queryConstraints_1 = queryConstraints; _d < queryConstraints_1.length; _d++) {\n    var constraint = queryConstraints_1[_d];\n    query = constraint._apply(query);\n  }\n\n  return query;\n}\n\nvar QueryFilterConstraint =\n/** @class */\nfunction (_super) {\n  tslib.__extends(QueryFilterConstraint, _super);\n\n  function QueryFilterConstraint(_field, _op, _value) {\n    var _this = _super.call(this) || this;\n\n    _this._field = _field;\n    _this._op = _op;\n    _this._value = _value;\n    _this.type = 'where';\n    return _this;\n  }\n\n  QueryFilterConstraint.prototype._apply = function (query) {\n    var reader = newUserDataReader(query.firestore);\n    var filter = newQueryFilter(query._query, 'where', reader, query.firestore._databaseId, this._field, this._op, this._value);\n    return new Query$1(query.firestore, query.converter, queryWithAddedFilter(query._query, filter));\n  };\n\n  return QueryFilterConstraint;\n}(QueryConstraint);\n/**\r\n * Creates a `QueryConstraint` that enforces that documents must contain the\r\n * specified field and that the value should satisfy the relation constraint\r\n * provided.\r\n *\r\n * @param fieldPath - The path to compare\r\n * @param opStr - The operation string (e.g \"&lt;\", \"&lt;=\", \"==\", \"&lt;\",\r\n *   \"&lt;=\", \"!=\").\r\n * @param value - The value for comparison\r\n * @returns The created `Query`.\r\n */\n\n\nfunction where(fieldPath, opStr, value) {\n  var op = opStr;\n  var field = fieldPathFromArgument('where', fieldPath);\n  return new QueryFilterConstraint(field, op, value);\n}\n\nvar QueryOrderByConstraint =\n/** @class */\nfunction (_super) {\n  tslib.__extends(QueryOrderByConstraint, _super);\n\n  function QueryOrderByConstraint(_field, _direction) {\n    var _this = _super.call(this) || this;\n\n    _this._field = _field;\n    _this._direction = _direction;\n    _this.type = 'orderBy';\n    return _this;\n  }\n\n  QueryOrderByConstraint.prototype._apply = function (query) {\n    var orderBy = newQueryOrderBy(query._query, this._field, this._direction);\n    return new Query$1(query.firestore, query.converter, queryWithAddedOrderBy(query._query, orderBy));\n  };\n\n  return QueryOrderByConstraint;\n}(QueryConstraint);\n/**\r\n * Creates a `QueryConstraint` that sorts the query result by the\r\n * specified field, optionally in descending order instead of ascending.\r\n *\r\n * @param fieldPath - The field to sort by.\r\n * @param directionStr - Optional direction to sort by ('asc' or 'desc'). If\r\n * not specified, order will be ascending.\r\n * @returns The created `Query`.\r\n */\n\n\nfunction orderBy(fieldPath, directionStr) {\n  if (directionStr === void 0) {\n    directionStr = 'asc';\n  }\n\n  var direction = directionStr;\n  var path = fieldPathFromArgument('orderBy', fieldPath);\n  return new QueryOrderByConstraint(path, direction);\n}\n\nvar QueryLimitConstraint =\n/** @class */\nfunction (_super) {\n  tslib.__extends(QueryLimitConstraint, _super);\n\n  function QueryLimitConstraint(type, _limit, _limitType) {\n    var _this = _super.call(this) || this;\n\n    _this.type = type;\n    _this._limit = _limit;\n    _this._limitType = _limitType;\n    return _this;\n  }\n\n  QueryLimitConstraint.prototype._apply = function (query) {\n    return new Query$1(query.firestore, query.converter, queryWithLimit(query._query, this._limit, this._limitType));\n  };\n\n  return QueryLimitConstraint;\n}(QueryConstraint);\n/**\r\n * Creates a `QueryConstraint` that only returns the first matching documents.\r\n *\r\n * @param limit - The maximum number of items to return.\r\n * @returns The created `Query`.\r\n */\n\n\nfunction limit(limit) {\n  validatePositiveNumber('limit', limit);\n  return new QueryLimitConstraint('limit', limit, \"F\"\n  /* First */\n  );\n}\n/**\r\n * Creates a `QueryConstraint` that only returns the last matching documents.\r\n *\r\n * You must specify at least one `orderBy` clause for `limitToLast` queries,\r\n * otherwise an exception will be thrown during execution.\r\n *\r\n * @param limit - The maximum number of items to return.\r\n * @returns The created `Query`.\r\n */\n\n\nfunction limitToLast(limit) {\n  validatePositiveNumber('limitToLast', limit);\n  return new QueryLimitConstraint('limitToLast', limit, \"L\"\n  /* Last */\n  );\n}\n\nvar QueryStartAtConstraint =\n/** @class */\nfunction (_super) {\n  tslib.__extends(QueryStartAtConstraint, _super);\n\n  function QueryStartAtConstraint(type, _docOrFields, _before) {\n    var _this = _super.call(this) || this;\n\n    _this.type = type;\n    _this._docOrFields = _docOrFields;\n    _this._before = _before;\n    return _this;\n  }\n\n  QueryStartAtConstraint.prototype._apply = function (query) {\n    var bound = newQueryBoundFromDocOrFields(query, this.type, this._docOrFields, this._before);\n    return new Query$1(query.firestore, query.converter, queryWithStartAt(query._query, bound));\n  };\n\n  return QueryStartAtConstraint;\n}(QueryConstraint);\n\nfunction startAt() {\n  var docOrFields = [];\n\n  for (var _i = 0; _i < arguments.length; _i++) {\n    docOrFields[_i] = arguments[_i];\n  }\n\n  return new QueryStartAtConstraint('startAt', docOrFields,\n  /*before=*/\n  true);\n}\n\nfunction startAfter() {\n  var docOrFields = [];\n\n  for (var _i = 0; _i < arguments.length; _i++) {\n    docOrFields[_i] = arguments[_i];\n  }\n\n  return new QueryStartAtConstraint('startAfter', docOrFields,\n  /*before=*/\n  false);\n}\n\nvar QueryEndAtConstraint =\n/** @class */\nfunction (_super) {\n  tslib.__extends(QueryEndAtConstraint, _super);\n\n  function QueryEndAtConstraint(type, _docOrFields, _before) {\n    var _this = _super.call(this) || this;\n\n    _this.type = type;\n    _this._docOrFields = _docOrFields;\n    _this._before = _before;\n    return _this;\n  }\n\n  QueryEndAtConstraint.prototype._apply = function (query) {\n    var bound = newQueryBoundFromDocOrFields(query, this.type, this._docOrFields, this._before);\n    return new Query$1(query.firestore, query.converter, queryWithEndAt(query._query, bound));\n  };\n\n  return QueryEndAtConstraint;\n}(QueryConstraint);\n\nfunction endBefore() {\n  var docOrFields = [];\n\n  for (var _i = 0; _i < arguments.length; _i++) {\n    docOrFields[_i] = arguments[_i];\n  }\n\n  return new QueryEndAtConstraint('endBefore', docOrFields,\n  /*before=*/\n  true);\n}\n\nfunction endAt() {\n  var docOrFields = [];\n\n  for (var _i = 0; _i < arguments.length; _i++) {\n    docOrFields[_i] = arguments[_i];\n  }\n\n  return new QueryEndAtConstraint('endAt', docOrFields,\n  /*before=*/\n  false);\n}\n/** Helper function to create a bound from a document or fields */\n\n\nfunction newQueryBoundFromDocOrFields(query, methodName, docOrFields, before) {\n  docOrFields[0] = util.getModularInstance(docOrFields[0]);\n\n  if (docOrFields[0] instanceof DocumentSnapshot$2) {\n    return newQueryBoundFromDocument(query._query, query.firestore._databaseId, methodName, docOrFields[0]._document, before);\n  } else {\n    var reader = newUserDataReader(query.firestore);\n    return newQueryBoundFromFields(query._query, query.firestore._databaseId, reader, methodName, docOrFields, before);\n  }\n}\n\nfunction newQueryFilter(query, methodName, dataReader, databaseId, fieldPath, op, value) {\n  var fieldValue;\n\n  if (fieldPath.isKeyField()) {\n    if (op === \"array-contains\"\n    /* ARRAY_CONTAINS */\n    || op === \"array-contains-any\"\n    /* ARRAY_CONTAINS_ANY */\n    ) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid Query. You can't perform '\" + op + \"' \" + 'queries on FieldPath.documentId().');\n      } else if (op === \"in\"\n    /* IN */\n    || op === \"not-in\"\n    /* NOT_IN */\n    ) {\n        validateDisjunctiveFilterElements(value, op);\n        var referenceList = [];\n\n        for (var _i = 0, value_2 = value; _i < value_2.length; _i++) {\n          var arrayValue = value_2[_i];\n          referenceList.push(parseDocumentIdValue(databaseId, query, arrayValue));\n        }\n\n        fieldValue = {\n          arrayValue: {\n            values: referenceList\n          }\n        };\n      } else {\n      fieldValue = parseDocumentIdValue(databaseId, query, value);\n    }\n  } else {\n    if (op === \"in\"\n    /* IN */\n    || op === \"not-in\"\n    /* NOT_IN */\n    || op === \"array-contains-any\"\n    /* ARRAY_CONTAINS_ANY */\n    ) {\n        validateDisjunctiveFilterElements(value, op);\n      }\n\n    fieldValue = parseQueryValue(dataReader, methodName, value,\n    /* allowArrays= */\n    op === \"in\"\n    /* IN */\n    || op === \"not-in\"\n    /* NOT_IN */\n    );\n  }\n\n  var filter = FieldFilter.create(fieldPath, op, fieldValue);\n  validateNewFilter(query, filter);\n  return filter;\n}\n\nfunction newQueryOrderBy(query, fieldPath, direction) {\n  if (query.startAt !== null) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. You must not call startAt() or startAfter() before ' + 'calling orderBy().');\n  }\n\n  if (query.endAt !== null) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. You must not call endAt() or endBefore() before ' + 'calling orderBy().');\n  }\n\n  var orderBy = new OrderBy(fieldPath, direction);\n  validateNewOrderBy(query, orderBy);\n  return orderBy;\n}\n/**\r\n * Create a Bound from a query and a document.\r\n *\r\n * Note that the Bound will always include the key of the document\r\n * and so only the provided document will compare equal to the returned\r\n * position.\r\n *\r\n * Will throw if the document does not contain all fields of the order by\r\n * of the query or if any of the fields in the order by are an uncommitted\r\n * server timestamp.\r\n */\n\n\nfunction newQueryBoundFromDocument(query, databaseId, methodName, doc, before) {\n  if (!doc) {\n    throw new FirestoreError(Code.NOT_FOUND, \"Can't use a DocumentSnapshot that doesn't exist for \" + (methodName + \"().\"));\n  }\n\n  var components = []; // Because people expect to continue/end a query at the exact document\n  // provided, we need to use the implicit sort order rather than the explicit\n  // sort order, because it's guaranteed to contain the document key. That way\n  // the position becomes unambiguous and the query continues/ends exactly at\n  // the provided document. Without the key (by using the explicit sort\n  // orders), multiple documents could match the position, yielding duplicate\n  // results.\n\n  for (var _i = 0, _d = queryOrderBy(query); _i < _d.length; _i++) {\n    var orderBy_5 = _d[_i];\n\n    if (orderBy_5.field.isKeyField()) {\n      components.push(refValue(databaseId, doc.key));\n    } else {\n      var value = doc.data.field(orderBy_5.field);\n\n      if (isServerTimestamp(value)) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. You are trying to start or end a query using a ' + 'document for which the field \"' + orderBy_5.field + '\" is an uncommitted server timestamp. (Since the value of ' + 'this field is unknown, you cannot start/end a query with it.)');\n      } else if (value !== null) {\n        components.push(value);\n      } else {\n        var field = orderBy_5.field.canonicalString();\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. You are trying to start or end a query using a \" + (\"document for which the field '\" + field + \"' (used as the \") + \"orderBy) does not exist.\");\n      }\n    }\n  }\n\n  return new Bound(components, before);\n}\n/**\r\n * Converts a list of field values to a Bound for the given query.\r\n */\n\n\nfunction newQueryBoundFromFields(query, databaseId, dataReader, methodName, values, before) {\n  // Use explicit order by's because it has to match the query the user made\n  var orderBy = query.explicitOrderBy;\n\n  if (values.length > orderBy.length) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Too many arguments provided to \" + methodName + \"(). \" + \"The number of arguments must be less than or equal to the \" + \"number of orderBy() clauses\");\n  }\n\n  var components = [];\n\n  for (var i = 0; i < values.length; i++) {\n    var rawValue = values[i];\n    var orderByComponent = orderBy[i];\n\n    if (orderByComponent.field.isKeyField()) {\n      if (typeof rawValue !== 'string') {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. Expected a string for document ID in \" + (methodName + \"(), but got a \" + typeof rawValue));\n      }\n\n      if (!isCollectionGroupQuery(query) && rawValue.indexOf('/') !== -1) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. When querying a collection and ordering by FieldPath.documentId(), \" + (\"the value passed to \" + methodName + \"() must be a plain document ID, but \") + (\"'\" + rawValue + \"' contains a slash.\"));\n      }\n\n      var path = query.path.child(ResourcePath.fromString(rawValue));\n\n      if (!DocumentKey.isDocumentKey(path)) {\n        throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. When querying a collection group and ordering by \" + (\"FieldPath.documentId(), the value passed to \" + methodName + \"() must result in a \") + (\"valid document path, but '\" + path + \"' is not because it contains an odd number \") + \"of segments.\");\n      }\n\n      var key = new DocumentKey(path);\n      components.push(refValue(databaseId, key));\n    } else {\n      var wrapped = parseQueryValue(dataReader, methodName, rawValue);\n      components.push(wrapped);\n    }\n  }\n\n  return new Bound(components, before);\n}\n/**\r\n * Parses the given documentIdValue into a ReferenceValue, throwing\r\n * appropriate errors if the value is anything other than a DocumentReference\r\n * or String, or if the string is malformed.\r\n */\n\n\nfunction parseDocumentIdValue(databaseId, query, documentIdValue) {\n  documentIdValue = util.getModularInstance(documentIdValue);\n\n  if (typeof documentIdValue === 'string') {\n    if (documentIdValue === '') {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. When querying with FieldPath.documentId(), you ' + 'must provide a valid document ID, but it was an empty string.');\n    }\n\n    if (!isCollectionGroupQuery(query) && documentIdValue.indexOf('/') !== -1) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. When querying a collection by \" + \"FieldPath.documentId(), you must provide a plain document ID, but \" + (\"'\" + documentIdValue + \"' contains a '/' character.\"));\n    }\n\n    var path = query.path.child(ResourcePath.fromString(documentIdValue));\n\n    if (!DocumentKey.isDocumentKey(path)) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. When querying a collection group by \" + \"FieldPath.documentId(), the value provided must result in a valid document path, \" + (\"but '\" + path + \"' is not because it has an odd number of segments (\" + path.length + \").\"));\n    }\n\n    return refValue(databaseId, new DocumentKey(path));\n  } else if (documentIdValue instanceof DocumentReference$1) {\n    return refValue(databaseId, documentIdValue._key);\n  } else {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. When querying with FieldPath.documentId(), you must provide a valid \" + \"string or a DocumentReference, but it was: \" + (valueDescription(documentIdValue) + \".\"));\n  }\n}\n/**\r\n * Validates that the value passed into a disjunctive filter satisfies all\r\n * array requirements.\r\n */\n\n\nfunction validateDisjunctiveFilterElements(value, operator) {\n  if (!Array.isArray(value) || value.length === 0) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid Query. A non-empty array is required for ' + (\"'\" + operator.toString() + \"' filters.\"));\n  }\n\n  if (value.length > 10) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid Query. '\" + operator.toString() + \"' filters support a \" + 'maximum of 10 elements in the value array.');\n  }\n}\n/**\r\n * Given an operator, returns the set of operators that cannot be used with it.\r\n *\r\n * Operators in a query must adhere to the following set of rules:\r\n * 1. Only one array operator is allowed.\r\n * 2. Only one disjunctive operator is allowed.\r\n * 3. NOT_EQUAL cannot be used with another NOT_EQUAL operator.\r\n * 4. NOT_IN cannot be used with array, disjunctive, or NOT_EQUAL operators.\r\n *\r\n * Array operators: ARRAY_CONTAINS, ARRAY_CONTAINS_ANY\r\n * Disjunctive operators: IN, ARRAY_CONTAINS_ANY, NOT_IN\r\n */\n\n\nfunction conflictingOps(op) {\n  switch (op) {\n    case \"!=\"\n    /* NOT_EQUAL */\n    :\n      return [\"!=\"\n      /* NOT_EQUAL */\n      , \"not-in\"\n      /* NOT_IN */\n      ];\n\n    case \"array-contains\"\n    /* ARRAY_CONTAINS */\n    :\n      return [\"array-contains\"\n      /* ARRAY_CONTAINS */\n      , \"array-contains-any\"\n      /* ARRAY_CONTAINS_ANY */\n      , \"not-in\"\n      /* NOT_IN */\n      ];\n\n    case \"in\"\n    /* IN */\n    :\n      return [\"array-contains-any\"\n      /* ARRAY_CONTAINS_ANY */\n      , \"in\"\n      /* IN */\n      , \"not-in\"\n      /* NOT_IN */\n      ];\n\n    case \"array-contains-any\"\n    /* ARRAY_CONTAINS_ANY */\n    :\n      return [\"array-contains\"\n      /* ARRAY_CONTAINS */\n      , \"array-contains-any\"\n      /* ARRAY_CONTAINS_ANY */\n      , \"in\"\n      /* IN */\n      , \"not-in\"\n      /* NOT_IN */\n      ];\n\n    case \"not-in\"\n    /* NOT_IN */\n    :\n      return [\"array-contains\"\n      /* ARRAY_CONTAINS */\n      , \"array-contains-any\"\n      /* ARRAY_CONTAINS_ANY */\n      , \"in\"\n      /* IN */\n      , \"not-in\"\n      /* NOT_IN */\n      , \"!=\"\n      /* NOT_EQUAL */\n      ];\n\n    default:\n      return [];\n  }\n}\n\nfunction validateNewFilter(query, filter) {\n  if (filter.isInequality()) {\n    var existingField = getInequalityFilterField(query);\n\n    if (existingField !== null && !existingField.isEqual(filter.field)) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. All where filters with an inequality' + ' (<, <=, !=, not-in, >, or >=) must be on the same field. But you have' + (\" inequality filters on '\" + existingField.toString() + \"'\") + (\" and '\" + filter.field.toString() + \"'\"));\n    }\n\n    var firstOrderByField = getFirstOrderByField(query);\n\n    if (firstOrderByField !== null) {\n      validateOrderByAndInequalityMatch(query, filter.field, firstOrderByField);\n    }\n  }\n\n  var conflictingOp = findFilterOperator(query, conflictingOps(filter.op));\n\n  if (conflictingOp !== null) {\n    // Special case when it's a duplicate op to give a slightly clearer error message.\n    if (conflictingOp === filter.op) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid query. You cannot use more than one ' + (\"'\" + filter.op.toString() + \"' filter.\"));\n    } else {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. You cannot use '\" + filter.op.toString() + \"' filters \" + (\"with '\" + conflictingOp.toString() + \"' filters.\"));\n    }\n  }\n}\n\nfunction validateNewOrderBy(query, orderBy) {\n  if (getFirstOrderByField(query) === null) {\n    // This is the first order by. It must match any inequality.\n    var inequalityField = getInequalityFilterField(query);\n\n    if (inequalityField !== null) {\n      validateOrderByAndInequalityMatch(query, inequalityField, orderBy.field);\n    }\n  }\n}\n\nfunction validateOrderByAndInequalityMatch(baseQuery, inequality, orderBy) {\n  if (!orderBy.isEqual(inequality)) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, \"Invalid query. You have a where filter with an inequality \" + (\"(<, <=, !=, not-in, >, or >=) on field '\" + inequality.toString() + \"' \") + (\"and so you must also use '\" + inequality.toString() + \"' \") + \"as your first argument to orderBy(), but your first orderBy() \" + (\"is on field '\" + orderBy.toString() + \"' instead.\"));\n  }\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Converts Firestore's internal types to the JavaScript types that we expose\r\n * to the user.\r\n *\r\n * @internal\r\n */\n\n\nvar AbstractUserDataWriter =\n/** @class */\nfunction () {\n  function AbstractUserDataWriter() {}\n\n  AbstractUserDataWriter.prototype.convertValue = function (value, serverTimestampBehavior) {\n    if (serverTimestampBehavior === void 0) {\n      serverTimestampBehavior = 'none';\n    }\n\n    switch (typeOrder(value)) {\n      case 0\n      /* NullValue */\n      :\n        return null;\n\n      case 1\n      /* BooleanValue */\n      :\n        return value.booleanValue;\n\n      case 2\n      /* NumberValue */\n      :\n        return normalizeNumber(value.integerValue || value.doubleValue);\n\n      case 3\n      /* TimestampValue */\n      :\n        return this.convertTimestamp(value.timestampValue);\n\n      case 4\n      /* ServerTimestampValue */\n      :\n        return this.convertServerTimestamp(value, serverTimestampBehavior);\n\n      case 5\n      /* StringValue */\n      :\n        return value.stringValue;\n\n      case 6\n      /* BlobValue */\n      :\n        return this.convertBytes(normalizeByteString(value.bytesValue));\n\n      case 7\n      /* RefValue */\n      :\n        return this.convertReference(value.referenceValue);\n\n      case 8\n      /* GeoPointValue */\n      :\n        return this.convertGeoPoint(value.geoPointValue);\n\n      case 9\n      /* ArrayValue */\n      :\n        return this.convertArray(value.arrayValue, serverTimestampBehavior);\n\n      case 10\n      /* ObjectValue */\n      :\n        return this.convertObject(value.mapValue, serverTimestampBehavior);\n\n      default:\n        throw fail();\n    }\n  };\n\n  AbstractUserDataWriter.prototype.convertObject = function (mapValue, serverTimestampBehavior) {\n    var _this = this;\n\n    var result = {};\n    forEach(mapValue.fields, function (key, value) {\n      result[key] = _this.convertValue(value, serverTimestampBehavior);\n    });\n    return result;\n  };\n\n  AbstractUserDataWriter.prototype.convertGeoPoint = function (value) {\n    return new GeoPoint(normalizeNumber(value.latitude), normalizeNumber(value.longitude));\n  };\n\n  AbstractUserDataWriter.prototype.convertArray = function (arrayValue, serverTimestampBehavior) {\n    var _this = this;\n\n    return (arrayValue.values || []).map(function (value) {\n      return _this.convertValue(value, serverTimestampBehavior);\n    });\n  };\n\n  AbstractUserDataWriter.prototype.convertServerTimestamp = function (value, serverTimestampBehavior) {\n    switch (serverTimestampBehavior) {\n      case 'previous':\n        var previousValue = getPreviousValue(value);\n\n        if (previousValue == null) {\n          return null;\n        }\n\n        return this.convertValue(previousValue, serverTimestampBehavior);\n\n      case 'estimate':\n        return this.convertTimestamp(getLocalWriteTime(value));\n\n      default:\n        return null;\n    }\n  };\n\n  AbstractUserDataWriter.prototype.convertTimestamp = function (value) {\n    var normalizedValue = normalizeTimestamp(value);\n    return new Timestamp(normalizedValue.seconds, normalizedValue.nanos);\n  };\n\n  AbstractUserDataWriter.prototype.convertDocumentKey = function (name, expectedDatabaseId) {\n    var resourcePath = ResourcePath.fromString(name);\n    hardAssert(isValidResourceName(resourcePath));\n    var databaseId = new DatabaseId(resourcePath.get(1), resourcePath.get(3));\n    var key = new DocumentKey(resourcePath.popFirst(5));\n\n    if (!databaseId.isEqual(expectedDatabaseId)) {\n      // TODO(b/64130202): Somehow support foreign references.\n      logError(\"Document \" + key + \" contains a document \" + \"reference within a different database (\" + (databaseId.projectId + \"/\" + databaseId.database + \") which is not \") + \"supported. It will be treated as a reference in the current \" + (\"database (\" + expectedDatabaseId.projectId + \"/\" + expectedDatabaseId.database + \") \") + \"instead.\");\n    }\n\n    return key;\n  };\n\n  return AbstractUserDataWriter;\n}();\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Converts custom model object of type T into DocumentData by applying the\r\n * converter if it exists.\r\n *\r\n * This function is used when converting user objects to DocumentData\r\n * because we want to provide the user with a more specific error message if\r\n * their set() or fails due to invalid data originating from a toFirestore()\r\n * call.\r\n */\n\n\nfunction applyFirestoreDataConverter(converter, value, options) {\n  var convertedValue;\n\n  if (converter) {\n    if (options && (options.merge || options.mergeFields)) {\n      // Cast to `any` in order to satisfy the union type constraint on\n      // toFirestore().\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      convertedValue = converter.toFirestore(value, options);\n    } else {\n      convertedValue = converter.toFirestore(value);\n    }\n  } else {\n    convertedValue = value;\n  }\n\n  return convertedValue;\n}\n\nvar LiteUserDataWriter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(LiteUserDataWriter, _super);\n\n  function LiteUserDataWriter(firestore) {\n    var _this = _super.call(this) || this;\n\n    _this.firestore = firestore;\n    return _this;\n  }\n\n  LiteUserDataWriter.prototype.convertBytes = function (bytes) {\n    return new Bytes(bytes);\n  };\n\n  LiteUserDataWriter.prototype.convertReference = function (name) {\n    var key = this.convertDocumentKey(name, this.firestore._databaseId);\n    return new DocumentReference$1(this.firestore,\n    /* converter= */\n    null, key);\n  };\n\n  return LiteUserDataWriter;\n}(AbstractUserDataWriter);\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A write batch, used to perform multiple writes as a single atomic unit.\r\n *\r\n * A `WriteBatch` object can be acquired by calling {@link writeBatch}. It\r\n * provides methods for adding writes to the write batch. None of the writes\r\n * will be committed (or visible locally) until {@link WriteBatch.commit} is\r\n * called.\r\n */\n\n\nvar WriteBatch$1 =\n/** @class */\nfunction () {\n  /** @hideconstructor */\n  function WriteBatch$1(_firestore, _commitHandler) {\n    this._firestore = _firestore;\n    this._commitHandler = _commitHandler;\n    this._mutations = [];\n    this._committed = false;\n    this._dataReader = newUserDataReader(_firestore);\n  }\n\n  WriteBatch$1.prototype.set = function (documentRef, data, options) {\n    this._verifyNotCommitted();\n\n    var ref = validateReference(documentRef, this._firestore);\n    var convertedValue = applyFirestoreDataConverter(ref.converter, data, options);\n    var parsed = parseSetData(this._dataReader, 'WriteBatch.set', ref._key, convertedValue, ref.converter !== null, options);\n\n    this._mutations.push(parsed.toMutation(ref._key, Precondition.none()));\n\n    return this;\n  };\n\n  WriteBatch$1.prototype.update = function (documentRef, fieldOrUpdateData, value) {\n    var moreFieldsAndValues = [];\n\n    for (var _i = 3; _i < arguments.length; _i++) {\n      moreFieldsAndValues[_i - 3] = arguments[_i];\n    }\n\n    this._verifyNotCommitted();\n\n    var ref = validateReference(documentRef, this._firestore); // For Compat types, we have to \"extract\" the underlying types before\n    // performing validation.\n\n    fieldOrUpdateData = util.getModularInstance(fieldOrUpdateData);\n    var parsed;\n\n    if (typeof fieldOrUpdateData === 'string' || fieldOrUpdateData instanceof FieldPath) {\n      parsed = parseUpdateVarargs(this._dataReader, 'WriteBatch.update', ref._key, fieldOrUpdateData, value, moreFieldsAndValues);\n    } else {\n      parsed = parseUpdateData(this._dataReader, 'WriteBatch.update', ref._key, fieldOrUpdateData);\n    }\n\n    this._mutations.push(parsed.toMutation(ref._key, Precondition.exists(true)));\n\n    return this;\n  };\n  /**\r\n   * Deletes the document referred to by the provided {@link DocumentReference}.\r\n   *\r\n   * @param documentRef - A reference to the document to be deleted.\r\n   * @returns This `WriteBatch` instance. Used for chaining method calls.\r\n   */\n\n\n  WriteBatch$1.prototype.delete = function (documentRef) {\n    this._verifyNotCommitted();\n\n    var ref = validateReference(documentRef, this._firestore);\n    this._mutations = this._mutations.concat(new DeleteMutation(ref._key, Precondition.none()));\n    return this;\n  };\n  /**\r\n   * Commits all of the writes in this write batch as a single atomic unit.\r\n   *\r\n   * The result of these writes will only be reflected in document reads that\r\n   * occur after the returned Promise resolves. If the client is offline, the\r\n   * write fails. If you would like to see local modifications or buffer writes\r\n   * until the client is online, use the full Firestore SDK.\r\n   *\r\n   * @returns A Promise resolved once all of the writes in the batch have been\r\n   * successfully written to the backend as an atomic unit (note that it won't\r\n   * resolve while you're offline).\r\n   */\n\n\n  WriteBatch$1.prototype.commit = function () {\n    this._verifyNotCommitted();\n\n    this._committed = true;\n\n    if (this._mutations.length > 0) {\n      return this._commitHandler(this._mutations);\n    }\n\n    return Promise.resolve();\n  };\n\n  WriteBatch$1.prototype._verifyNotCommitted = function () {\n    if (this._committed) {\n      throw new FirestoreError(Code.FAILED_PRECONDITION, 'A write batch can no longer be used after commit() ' + 'has been called.');\n    }\n  };\n\n  return WriteBatch$1;\n}();\n\nfunction validateReference(documentRef, firestore) {\n  documentRef = util.getModularInstance(documentRef);\n\n  if (documentRef.firestore !== firestore) {\n    throw new FirestoreError(Code.INVALID_ARGUMENT, 'Provided document reference is from a different Firestore instance.');\n  } else {\n    return documentRef;\n  }\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n// TODO(mrschmidt) Consider using `BaseTransaction` as the base class in the\n// legacy SDK.\n\n/**\r\n * A reference to a transaction.\r\n *\r\n * The `Transaction` object passed to a transaction's `updateFunction` provides\r\n * the methods to read and write data within the transaction context. See\r\n * {@link runTransaction}.\r\n */\n\n\nvar Transaction$2 =\n/** @class */\nfunction () {\n  /** @hideconstructor */\n  function Transaction$2(_firestore, _transaction) {\n    this._firestore = _firestore;\n    this._transaction = _transaction;\n    this._dataReader = newUserDataReader(_firestore);\n  }\n  /**\r\n   * Reads the document referenced by the provided {@link DocumentReference}.\r\n   *\r\n   * @param documentRef - A reference to the document to be read.\r\n   * @returns A `DocumentSnapshot` with the read data.\r\n   */\n\n\n  Transaction$2.prototype.get = function (documentRef) {\n    var _this = this;\n\n    var ref = validateReference(documentRef, this._firestore);\n    var userDataWriter = new LiteUserDataWriter(this._firestore);\n    return this._transaction.lookup([ref._key]).then(function (docs) {\n      if (!docs || docs.length !== 1) {\n        return fail();\n      }\n\n      var doc = docs[0];\n\n      if (doc.isFoundDocument()) {\n        return new DocumentSnapshot$2(_this._firestore, userDataWriter, doc.key, doc, ref.converter);\n      } else if (doc.isNoDocument()) {\n        return new DocumentSnapshot$2(_this._firestore, userDataWriter, ref._key, null, ref.converter);\n      } else {\n        throw fail();\n      }\n    });\n  };\n\n  Transaction$2.prototype.set = function (documentRef, value, options) {\n    var ref = validateReference(documentRef, this._firestore);\n    var convertedValue = applyFirestoreDataConverter(ref.converter, value, options);\n    var parsed = parseSetData(this._dataReader, 'Transaction.set', ref._key, convertedValue, ref.converter !== null, options);\n\n    this._transaction.set(ref._key, parsed);\n\n    return this;\n  };\n\n  Transaction$2.prototype.update = function (documentRef, fieldOrUpdateData, value) {\n    var moreFieldsAndValues = [];\n\n    for (var _i = 3; _i < arguments.length; _i++) {\n      moreFieldsAndValues[_i - 3] = arguments[_i];\n    }\n\n    var ref = validateReference(documentRef, this._firestore); // For Compat types, we have to \"extract\" the underlying types before\n    // performing validation.\n\n    fieldOrUpdateData = util.getModularInstance(fieldOrUpdateData);\n    var parsed;\n\n    if (typeof fieldOrUpdateData === 'string' || fieldOrUpdateData instanceof FieldPath) {\n      parsed = parseUpdateVarargs(this._dataReader, 'Transaction.update', ref._key, fieldOrUpdateData, value, moreFieldsAndValues);\n    } else {\n      parsed = parseUpdateData(this._dataReader, 'Transaction.update', ref._key, fieldOrUpdateData);\n    }\n\n    this._transaction.update(ref._key, parsed);\n\n    return this;\n  };\n  /**\r\n   * Deletes the document referred to by the provided {@link DocumentReference}.\r\n   *\r\n   * @param documentRef - A reference to the document to be deleted.\r\n   * @returns This `Transaction` instance. Used for chaining method calls.\r\n   */\n\n\n  Transaction$2.prototype.delete = function (documentRef) {\n    var ref = validateReference(documentRef, this._firestore);\n\n    this._transaction.delete(ref._key);\n\n    return this;\n  };\n\n  return Transaction$2;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n\nfunction isPartialObserver(obj) {\n  return implementsAnyMethods(obj, ['next', 'error', 'complete']);\n}\n/**\r\n * Returns true if obj is an object and contains at least one of the specified\r\n * methods.\r\n */\n\n\nfunction implementsAnyMethods(obj, methods) {\n  if (typeof obj !== 'object' || obj === null) {\n    return false;\n  }\n\n  var object = obj;\n\n  for (var _i = 0, methods_1 = methods; _i < methods_1.length; _i++) {\n    var method = methods_1[_i];\n\n    if (method in object && typeof object[method] === 'function') {\n      return true;\n    }\n  }\n\n  return false;\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * Reads the document referred to by this `DocumentReference`.\r\n *\r\n * Note: `getDoc()` attempts to provide up-to-date data when possible by waiting\r\n * for data from the server, but it may return cached data or fail if you are\r\n * offline and the server cannot be reached. To specify this behavior, invoke\r\n * {@link getDocFromCache} or {@link getDocFromServer}.\r\n *\r\n * @param reference - The reference of the document to fetch.\r\n * @returns A Promise resolved with a `DocumentSnapshot` containing the\r\n * current document contents.\r\n */\n\n\nfunction getDoc(reference) {\n  reference = cast(reference, DocumentReference$1);\n  var firestore = cast(reference.firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientGetDocumentViaSnapshotListener(client, reference._key).then(function (snapshot) {\n    return convertToDocSnapshot(firestore, reference, snapshot);\n  });\n}\n\nvar ExpUserDataWriter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(ExpUserDataWriter, _super);\n\n  function ExpUserDataWriter(firestore) {\n    var _this = _super.call(this) || this;\n\n    _this.firestore = firestore;\n    return _this;\n  }\n\n  ExpUserDataWriter.prototype.convertBytes = function (bytes) {\n    return new Bytes(bytes);\n  };\n\n  ExpUserDataWriter.prototype.convertReference = function (name) {\n    var key = this.convertDocumentKey(name, this.firestore._databaseId);\n    return new DocumentReference$1(this.firestore,\n    /* converter= */\n    null, key);\n  };\n\n  return ExpUserDataWriter;\n}(AbstractUserDataWriter);\n/**\r\n * Reads the document referred to by this `DocumentReference` from cache.\r\n * Returns an error if the document is not currently cached.\r\n *\r\n * @returns A Promise resolved with a `DocumentSnapshot` containing the\r\n * current document contents.\r\n */\n\n\nfunction getDocFromCache(reference) {\n  reference = cast(reference, DocumentReference$1);\n  var firestore = cast(reference.firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  var userDataWriter = new ExpUserDataWriter(firestore);\n  return firestoreClientGetDocumentFromLocalCache(client, reference._key).then(function (doc) {\n    return new DocumentSnapshot$1(firestore, userDataWriter, reference._key, doc, new SnapshotMetadata(doc !== null && doc.hasLocalMutations,\n    /* fromCache= */\n    true), reference.converter);\n  });\n}\n/**\r\n * Reads the document referred to by this `DocumentReference` from the server.\r\n * Returns an error if the network is not available.\r\n *\r\n * @returns A Promise resolved with a `DocumentSnapshot` containing the\r\n * current document contents.\r\n */\n\n\nfunction getDocFromServer(reference) {\n  reference = cast(reference, DocumentReference$1);\n  var firestore = cast(reference.firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientGetDocumentViaSnapshotListener(client, reference._key, {\n    source: 'server'\n  }).then(function (snapshot) {\n    return convertToDocSnapshot(firestore, reference, snapshot);\n  });\n}\n/**\r\n * Executes the query and returns the results as a `QuerySnapshot`.\r\n *\r\n * Note: `getDocs()` attempts to provide up-to-date data when possible by\r\n * waiting for data from the server, but it may return cached data or fail if\r\n * you are offline and the server cannot be reached. To specify this behavior,\r\n * invoke {@link getDocsFromCache} or {@link getDocsFromServer}.\r\n *\r\n * @returns A Promise that will be resolved with the results of the query.\r\n */\n\n\nfunction getDocs(query) {\n  query = cast(query, Query$1);\n  var firestore = cast(query.firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  var userDataWriter = new ExpUserDataWriter(firestore);\n  validateHasExplicitOrderByForLimitToLast(query._query);\n  return firestoreClientGetDocumentsViaSnapshotListener(client, query._query).then(function (snapshot) {\n    return new QuerySnapshot$1(firestore, userDataWriter, query, snapshot);\n  });\n}\n/**\r\n * Executes the query and returns the results as a `QuerySnapshot` from cache.\r\n * Returns an error if the document is not currently cached.\r\n *\r\n * @returns A Promise that will be resolved with the results of the query.\r\n */\n\n\nfunction getDocsFromCache(query) {\n  query = cast(query, Query$1);\n  var firestore = cast(query.firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  var userDataWriter = new ExpUserDataWriter(firestore);\n  return firestoreClientGetDocumentsFromLocalCache(client, query._query).then(function (snapshot) {\n    return new QuerySnapshot$1(firestore, userDataWriter, query, snapshot);\n  });\n}\n/**\r\n * Executes the query and returns the results as a `QuerySnapshot` from the\r\n * server. Returns an error if the network is not available.\r\n *\r\n * @returns A Promise that will be resolved with the results of the query.\r\n */\n\n\nfunction getDocsFromServer(query) {\n  query = cast(query, Query$1);\n  var firestore = cast(query.firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  var userDataWriter = new ExpUserDataWriter(firestore);\n  return firestoreClientGetDocumentsViaSnapshotListener(client, query._query, {\n    source: 'server'\n  }).then(function (snapshot) {\n    return new QuerySnapshot$1(firestore, userDataWriter, query, snapshot);\n  });\n}\n\nfunction setDoc(reference, data, options) {\n  reference = cast(reference, DocumentReference$1);\n  var firestore = cast(reference.firestore, Firestore$1);\n  var convertedValue = applyFirestoreDataConverter(reference.converter, data, options);\n  var dataReader = newUserDataReader(firestore);\n  var parsed = parseSetData(dataReader, 'setDoc', reference._key, convertedValue, reference.converter !== null, options);\n  var mutation = parsed.toMutation(reference._key, Precondition.none());\n  return executeWrite(firestore, [mutation]);\n}\n\nfunction updateDoc(reference, fieldOrUpdateData, value) {\n  var moreFieldsAndValues = [];\n\n  for (var _i = 3; _i < arguments.length; _i++) {\n    moreFieldsAndValues[_i - 3] = arguments[_i];\n  }\n\n  reference = cast(reference, DocumentReference$1);\n  var firestore = cast(reference.firestore, Firestore$1);\n  var dataReader = newUserDataReader(firestore); // For Compat types, we have to \"extract\" the underlying types before\n  // performing validation.\n\n  fieldOrUpdateData = util.getModularInstance(fieldOrUpdateData);\n  var parsed;\n\n  if (typeof fieldOrUpdateData === 'string' || fieldOrUpdateData instanceof FieldPath) {\n    parsed = parseUpdateVarargs(dataReader, 'updateDoc', reference._key, fieldOrUpdateData, value, moreFieldsAndValues);\n  } else {\n    parsed = parseUpdateData(dataReader, 'updateDoc', reference._key, fieldOrUpdateData);\n  }\n\n  var mutation = parsed.toMutation(reference._key, Precondition.exists(true));\n  return executeWrite(firestore, [mutation]);\n}\n/**\r\n * Deletes the document referred to by the specified `DocumentReference`.\r\n *\r\n * @param reference - A reference to the document to delete.\r\n * @returns A Promise resolved once the document has been successfully\r\n * deleted from the backend (note that it won't resolve while you're offline).\r\n */\n\n\nfunction deleteDoc(reference) {\n  var firestore = cast(reference.firestore, Firestore$1);\n  var mutations = [new DeleteMutation(reference._key, Precondition.none())];\n  return executeWrite(firestore, mutations);\n}\n/**\r\n * Add a new document to specified `CollectionReference` with the given data,\r\n * assigning it a document ID automatically.\r\n *\r\n * @param reference - A reference to the collection to add this document to.\r\n * @param data - An Object containing the data for the new document.\r\n * @returns A Promise resolved with a `DocumentReference` pointing to the\r\n * newly created document after it has been written to the backend (Note that it\r\n * won't resolve while you're offline).\r\n */\n\n\nfunction addDoc(reference, data) {\n  var firestore = cast(reference.firestore, Firestore$1);\n  var docRef = doc(reference);\n  var convertedValue = applyFirestoreDataConverter(reference.converter, data);\n  var dataReader = newUserDataReader(reference.firestore);\n  var parsed = parseSetData(dataReader, 'addDoc', docRef._key, convertedValue, reference.converter !== null, {});\n  var mutation = parsed.toMutation(docRef._key, Precondition.exists(false));\n  return executeWrite(firestore, [mutation]).then(function () {\n    return docRef;\n  });\n}\n\nfunction onSnapshot(reference) {\n  var args = [];\n\n  for (var _i = 1; _i < arguments.length; _i++) {\n    args[_i - 1] = arguments[_i];\n  }\n\n  var _a, _b, _c;\n\n  reference = util.getModularInstance(reference);\n  var options = {\n    includeMetadataChanges: false\n  };\n  var currArg = 0;\n\n  if (typeof args[currArg] === 'object' && !isPartialObserver(args[currArg])) {\n    options = args[currArg];\n    currArg++;\n  }\n\n  var internalOptions = {\n    includeMetadataChanges: options.includeMetadataChanges\n  };\n\n  if (isPartialObserver(args[currArg])) {\n    var userObserver = args[currArg];\n    args[currArg] = (_a = userObserver.next) === null || _a === void 0 ? void 0 : _a.bind(userObserver);\n    args[currArg + 1] = (_b = userObserver.error) === null || _b === void 0 ? void 0 : _b.bind(userObserver);\n    args[currArg + 2] = (_c = userObserver.complete) === null || _c === void 0 ? void 0 : _c.bind(userObserver);\n  }\n\n  var observer;\n  var firestore;\n  var internalQuery;\n\n  if (reference instanceof DocumentReference$1) {\n    firestore = cast(reference.firestore, Firestore$1);\n    internalQuery = newQueryForPath(reference._key.path);\n    observer = {\n      next: function (snapshot) {\n        if (args[currArg]) {\n          args[currArg](convertToDocSnapshot(firestore, reference, snapshot));\n        }\n      },\n      error: args[currArg + 1],\n      complete: args[currArg + 2]\n    };\n  } else {\n    var query_5 = cast(reference, Query$1);\n    firestore = cast(query_5.firestore, Firestore$1);\n    internalQuery = query_5._query;\n    var userDataWriter_1 = new ExpUserDataWriter(firestore);\n    observer = {\n      next: function (snapshot) {\n        if (args[currArg]) {\n          args[currArg](new QuerySnapshot$1(firestore, userDataWriter_1, query_5, snapshot));\n        }\n      },\n      error: args[currArg + 1],\n      complete: args[currArg + 2]\n    };\n    validateHasExplicitOrderByForLimitToLast(reference._query);\n  }\n\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientListen(client, internalQuery, internalOptions, observer);\n}\n\nfunction onSnapshotsInSync(firestore, arg) {\n  firestore = cast(firestore, Firestore$1);\n  var client = ensureFirestoreConfigured(firestore);\n  var observer = isPartialObserver(arg) ? arg : {\n    next: arg\n  };\n  return firestoreClientAddSnapshotsInSyncListener(client, observer);\n}\n/**\r\n * Locally writes `mutations` on the async queue.\r\n * @internal\r\n */\n\n\nfunction executeWrite(firestore, mutations) {\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientWrite(client, mutations);\n}\n/**\r\n * Converts a ViewSnapshot that contains the single document specified by `ref`\r\n * to a DocumentSnapshot.\r\n */\n\n\nfunction convertToDocSnapshot(firestore, ref, snapshot) {\n  var doc = snapshot.docs.get(ref._key);\n  var userDataWriter = new ExpUserDataWriter(firestore);\n  return new DocumentSnapshot$1(firestore, userDataWriter, ref._key, doc, new SnapshotMetadata(snapshot.hasPendingWrites, snapshot.fromCache), ref.converter);\n}\n/**\r\n * @license\r\n * Copyright 2020 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * A reference to a transaction.\r\n *\r\n * The `Transaction` object passed to a transaction's `updateFunction` provides\r\n * the methods to read and write data within the transaction context. See\r\n * {@link runTransaction}.\r\n */\n\n\nvar Transaction$1 =\n/** @class */\nfunction (_super) {\n  tslib.__extends(Transaction$1, _super); // This class implements the same logic as the Transaction API in the Lite SDK\n  // but is subclassed in order to return its own DocumentSnapshot types.\n\n  /** @hideconstructor */\n\n\n  function Transaction$1(_firestore, _transaction) {\n    var _this = _super.call(this, _firestore, _transaction) || this;\n\n    _this._firestore = _firestore;\n    return _this;\n  }\n  /**\r\n   * Reads the document referenced by the provided {@link DocumentReference}.\r\n   *\r\n   * @param documentRef - A reference to the document to be read.\r\n   * @returns A `DocumentSnapshot` with the read data.\r\n   */\n\n\n  Transaction$1.prototype.get = function (documentRef) {\n    var _this = this;\n\n    var ref = validateReference(documentRef, this._firestore);\n    var userDataWriter = new ExpUserDataWriter(this._firestore);\n    return _super.prototype.get.call(this, documentRef).then(function (liteDocumentSnapshot) {\n      return new DocumentSnapshot$1(_this._firestore, userDataWriter, ref._key, liteDocumentSnapshot._document, new SnapshotMetadata(\n      /* hasPendingWrites= */\n      false,\n      /* fromCache= */\n      false), ref.converter);\n    });\n  };\n\n  return Transaction$1;\n}(Transaction$2);\n/**\r\n * Executes the given `updateFunction` and then attempts to commit the changes\r\n * applied within the transaction. If any document read within the transaction\r\n * has changed, Cloud Firestore retries the `updateFunction`. If it fails to\r\n * commit after 5 attempts, the transaction fails.\r\n *\r\n * The maximum number of writes allowed in a single transaction is 500.\r\n *\r\n * @param firestore - A reference to the Firestore database to run this\r\n * transaction against.\r\n * @param updateFunction - The function to execute within the transaction\r\n * context.\r\n * @returns If the transaction completed successfully or was explicitly aborted\r\n * (the `updateFunction` returned a failed promise), the promise returned by the\r\n * `updateFunction `is returned here. Otherwise, if the transaction failed, a\r\n * rejected promise with the corresponding failure error is returned.\r\n */\n\n\nfunction runTransaction(firestore, updateFunction) {\n  var client = ensureFirestoreConfigured(firestore);\n  return firestoreClientTransaction(client, function (internalTransaction) {\n    return updateFunction(new Transaction$1(firestore, internalTransaction));\n  });\n}\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/** Helper function to assert Uint8Array is available at runtime. */\n\n\nfunction assertUint8ArrayAvailable() {\n  if (typeof Uint8Array === 'undefined') {\n    throw new FirestoreError(Code.UNIMPLEMENTED, 'Uint8Arrays are not available in this environment.');\n  }\n}\n/** Immutable class holding a blob (binary data) */\n\n\nvar Blob =\n/** @class */\nfunction () {\n  function Blob(_delegate) {\n    this._delegate = _delegate;\n  }\n\n  Blob.fromBase64String = function (base64) {\n    return new Blob(Bytes.fromBase64String(base64));\n  };\n\n  Blob.fromUint8Array = function (array) {\n    assertUint8ArrayAvailable();\n    return new Blob(Bytes.fromUint8Array(array));\n  };\n\n  Blob.prototype.toBase64 = function () {\n    return this._delegate.toBase64();\n  };\n\n  Blob.prototype.toUint8Array = function () {\n    assertUint8ArrayAvailable();\n    return this._delegate.toUint8Array();\n  };\n\n  Blob.prototype.isEqual = function (other) {\n    return this._delegate.isEqual(other._delegate);\n  };\n\n  Blob.prototype.toString = function () {\n    return 'Blob(base64: ' + this.toBase64() + ')';\n  };\n\n  return Blob;\n}();\n/**\r\n * @license\r\n * Copyright 2017 Google LLC\r\n *\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n *   http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n */\n\n/**\r\n * The persistence provider included with the full Firestore SDK.\r\n */\n\n\nvar IndexedDbPersistenceProvider =\n/** @class */\nfunction () {\n  function IndexedDbPersistenceProvider() {}\n\n  IndexedDbPersistenceProvider.prototype.enableIndexedDbPersistence = function (firestore, forceOwnership) {\n    return enableIndexedDbPersistence(firestore._delegate, {\n      forceOwnership: forceOwnership\n    });\n  };\n\n  IndexedDbPersistenceProvider.prototype.enableMultiTabIndexedDbPersistence = function (firestore) {\n    return enableMultiTabIndexedDbPersistence(firestore._delegate);\n  };\n\n  IndexedDbPersistenceProvider.prototype.clearIndexedDbPersistence = function (firestore) {\n    return clearIndexedDbPersistence(firestore._delegate);\n  };\n\n  return IndexedDbPersistenceProvider;\n}();\n/**\r\n * Compat class for Firestore. Exposes Firestore Legacy API, but delegates\r\n * to the functional API of firestore-exp.\r\n */\n\n\nvar Firestore =\n/** @class */\nfunction () {\n  function Firestore(databaseIdOrApp, _delegate, _persistenceProvider) {\n    var _this = this;\n\n    this._delegate = _delegate;\n    this._persistenceProvider = _persistenceProvider;\n    this.INTERNAL = {\n      delete: function () {\n        return _this.terminate();\n      }\n    };\n\n    if (!(databaseIdOrApp instanceof DatabaseId)) {\n      this._appCompat = databaseIdOrApp;\n    }\n  }\n\n  Object.defineProperty(Firestore.prototype, \"_databaseId\", {\n    get: function () {\n      return this._delegate._databaseId;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  Firestore.prototype.settings = function (settingsLiteral) {\n    var currentSettings = this._delegate._getSettings();\n\n    if (!settingsLiteral.merge && currentSettings.host !== settingsLiteral.host) {\n      logWarn('You are overriding the original host. If you did not intend ' + 'to override your settings, use {merge: true}.');\n    }\n\n    if (settingsLiteral.merge) {\n      settingsLiteral = Object.assign(Object.assign({}, currentSettings), settingsLiteral); // Remove the property from the settings once the merge is completed\n\n      delete settingsLiteral.merge;\n    }\n\n    this._delegate._setSettings(settingsLiteral);\n  };\n\n  Firestore.prototype.useEmulator = function (host, port, options) {\n    if (options === void 0) {\n      options = {};\n    }\n\n    connectFirestoreEmulator(this._delegate, host, port, options);\n  };\n\n  Firestore.prototype.enableNetwork = function () {\n    return enableNetwork(this._delegate);\n  };\n\n  Firestore.prototype.disableNetwork = function () {\n    return disableNetwork(this._delegate);\n  };\n\n  Firestore.prototype.enablePersistence = function (settings) {\n    var synchronizeTabs = false;\n    var experimentalForceOwningTab = false;\n\n    if (settings) {\n      synchronizeTabs = !!settings.synchronizeTabs;\n      experimentalForceOwningTab = !!settings.experimentalForceOwningTab;\n      validateIsNotUsedTogether('synchronizeTabs', synchronizeTabs, 'experimentalForceOwningTab', experimentalForceOwningTab);\n    }\n\n    return synchronizeTabs ? this._persistenceProvider.enableMultiTabIndexedDbPersistence(this) : this._persistenceProvider.enableIndexedDbPersistence(this, experimentalForceOwningTab);\n  };\n\n  Firestore.prototype.clearPersistence = function () {\n    return this._persistenceProvider.clearIndexedDbPersistence(this);\n  };\n\n  Firestore.prototype.terminate = function () {\n    if (this._appCompat) {\n      this._appCompat._removeServiceInstance('firestore');\n\n      this._appCompat._removeServiceInstance('firestore-exp');\n    }\n\n    return this._delegate._delete();\n  };\n\n  Firestore.prototype.waitForPendingWrites = function () {\n    return waitForPendingWrites(this._delegate);\n  };\n\n  Firestore.prototype.onSnapshotsInSync = function (arg) {\n    return onSnapshotsInSync(this._delegate, arg);\n  };\n\n  Object.defineProperty(Firestore.prototype, \"app\", {\n    get: function () {\n      if (!this._appCompat) {\n        throw new FirestoreError(Code.FAILED_PRECONDITION, \"Firestore was not initialized using the Firebase SDK. 'app' is \" + 'not available');\n      }\n\n      return this._appCompat;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  Firestore.prototype.collection = function (pathString) {\n    try {\n      return new CollectionReference(this, collection(this._delegate, pathString));\n    } catch (e) {\n      throw replaceFunctionName(e, 'collection()', 'Firestore.collection()');\n    }\n  };\n\n  Firestore.prototype.doc = function (pathString) {\n    try {\n      return new DocumentReference(this, doc(this._delegate, pathString));\n    } catch (e) {\n      throw replaceFunctionName(e, 'doc()', 'Firestore.doc()');\n    }\n  };\n\n  Firestore.prototype.collectionGroup = function (collectionId) {\n    try {\n      return new Query(this, collectionGroup(this._delegate, collectionId));\n    } catch (e) {\n      throw replaceFunctionName(e, 'collectionGroup()', 'Firestore.collectionGroup()');\n    }\n  };\n\n  Firestore.prototype.runTransaction = function (updateFunction) {\n    var _this = this;\n\n    return runTransaction(this._delegate, function (transaction) {\n      return updateFunction(new Transaction(_this, transaction));\n    });\n  };\n\n  Firestore.prototype.batch = function () {\n    var _this = this;\n\n    ensureFirestoreConfigured(this._delegate);\n    return new WriteBatch(new WriteBatch$1(this._delegate, function (mutations) {\n      return executeWrite(_this._delegate, mutations);\n    }));\n  };\n\n  Firestore.prototype.loadBundle = function (bundleData) {\n    throw new FirestoreError(Code.FAILED_PRECONDITION, '\"loadBundle()\" does not exist, have you imported \"firebase/firestore/bundle\"?');\n  };\n\n  Firestore.prototype.namedQuery = function (name) {\n    throw new FirestoreError(Code.FAILED_PRECONDITION, '\"namedQuery()\" does not exist, have you imported \"firebase/firestore/bundle\"?');\n  };\n\n  return Firestore;\n}();\n\nvar UserDataWriter =\n/** @class */\nfunction (_super) {\n  tslib.__extends(UserDataWriter, _super);\n\n  function UserDataWriter(firestore) {\n    var _this = _super.call(this) || this;\n\n    _this.firestore = firestore;\n    return _this;\n  }\n\n  UserDataWriter.prototype.convertBytes = function (bytes) {\n    return new Blob(new Bytes(bytes));\n  };\n\n  UserDataWriter.prototype.convertReference = function (name) {\n    var key = this.convertDocumentKey(name, this.firestore._databaseId);\n    return DocumentReference.forKey(key, this.firestore,\n    /* converter= */\n    null);\n  };\n\n  return UserDataWriter;\n}(AbstractUserDataWriter);\n\nfunction setLogLevel(level) {\n  setLogLevel$1(level);\n}\n/**\r\n * A reference to a transaction.\r\n */\n\n\nvar Transaction =\n/** @class */\nfunction () {\n  function Transaction(_firestore, _delegate) {\n    this._firestore = _firestore;\n    this._delegate = _delegate;\n    this._userDataWriter = new UserDataWriter(_firestore);\n  }\n\n  Transaction.prototype.get = function (documentRef) {\n    var _this = this;\n\n    var ref = castReference(documentRef);\n    return this._delegate.get(ref).then(function (result) {\n      return new DocumentSnapshot(_this._firestore, new DocumentSnapshot$1(_this._firestore._delegate, _this._userDataWriter, result._key, result._document, result.metadata, ref.converter));\n    });\n  };\n\n  Transaction.prototype.set = function (documentRef, data, options) {\n    var ref = castReference(documentRef);\n\n    if (options) {\n      validateSetOptions('Transaction.set', options);\n\n      this._delegate.set(ref, data, options);\n    } else {\n      this._delegate.set(ref, data);\n    }\n\n    return this;\n  };\n\n  Transaction.prototype.update = function (documentRef, dataOrField, value) {\n    var _d;\n\n    var moreFieldsAndValues = [];\n\n    for (var _i = 3; _i < arguments.length; _i++) {\n      moreFieldsAndValues[_i - 3] = arguments[_i];\n    }\n\n    var ref = castReference(documentRef);\n\n    if (arguments.length === 2) {\n      this._delegate.update(ref, dataOrField);\n    } else {\n      (_d = this._delegate).update.apply(_d, tslib.__spreadArray([ref, dataOrField, value], moreFieldsAndValues));\n    }\n\n    return this;\n  };\n\n  Transaction.prototype.delete = function (documentRef) {\n    var ref = castReference(documentRef);\n\n    this._delegate.delete(ref);\n\n    return this;\n  };\n\n  return Transaction;\n}();\n\nvar WriteBatch =\n/** @class */\nfunction () {\n  function WriteBatch(_delegate) {\n    this._delegate = _delegate;\n  }\n\n  WriteBatch.prototype.set = function (documentRef, data, options) {\n    var ref = castReference(documentRef);\n\n    if (options) {\n      validateSetOptions('WriteBatch.set', options);\n\n      this._delegate.set(ref, data, options);\n    } else {\n      this._delegate.set(ref, data);\n    }\n\n    return this;\n  };\n\n  WriteBatch.prototype.update = function (documentRef, dataOrField, value) {\n    var _d;\n\n    var moreFieldsAndValues = [];\n\n    for (var _i = 3; _i < arguments.length; _i++) {\n      moreFieldsAndValues[_i - 3] = arguments[_i];\n    }\n\n    var ref = castReference(documentRef);\n\n    if (arguments.length === 2) {\n      this._delegate.update(ref, dataOrField);\n    } else {\n      (_d = this._delegate).update.apply(_d, tslib.__spreadArray([ref, dataOrField, value], moreFieldsAndValues));\n    }\n\n    return this;\n  };\n\n  WriteBatch.prototype.delete = function (documentRef) {\n    var ref = castReference(documentRef);\n\n    this._delegate.delete(ref);\n\n    return this;\n  };\n\n  WriteBatch.prototype.commit = function () {\n    return this._delegate.commit();\n  };\n\n  return WriteBatch;\n}();\n/**\r\n * Wraps a `PublicFirestoreDataConverter` translating the types from the\r\n * experimental SDK into corresponding types from the Classic SDK before passing\r\n * them to the wrapped converter.\r\n */\n\n\nvar FirestoreDataConverter =\n/** @class */\nfunction () {\n  function FirestoreDataConverter(_firestore, _userDataWriter, _delegate) {\n    this._firestore = _firestore;\n    this._userDataWriter = _userDataWriter;\n    this._delegate = _delegate;\n  }\n\n  FirestoreDataConverter.prototype.fromFirestore = function (snapshot, options) {\n    var expSnapshot = new QueryDocumentSnapshot$1(this._firestore._delegate, this._userDataWriter, snapshot._key, snapshot._document, snapshot.metadata,\n    /* converter= */\n    null);\n    return this._delegate.fromFirestore(new QueryDocumentSnapshot(this._firestore, expSnapshot), options !== null && options !== void 0 ? options : {});\n  };\n\n  FirestoreDataConverter.prototype.toFirestore = function (modelObject, options) {\n    if (!options) {\n      return this._delegate.toFirestore(modelObject);\n    } else {\n      return this._delegate.toFirestore(modelObject, options);\n    }\n  }; // Use the same instance of `FirestoreDataConverter` for the given instances\n  // of `Firestore` and `PublicFirestoreDataConverter` so that isEqual() will\n  // compare equal for two objects created with the same converter instance.\n\n\n  FirestoreDataConverter.getInstance = function (firestore, converter) {\n    var converterMapByFirestore = FirestoreDataConverter.INSTANCES;\n    var untypedConverterByConverter = converterMapByFirestore.get(firestore);\n\n    if (!untypedConverterByConverter) {\n      untypedConverterByConverter = new WeakMap();\n      converterMapByFirestore.set(firestore, untypedConverterByConverter);\n    }\n\n    var instance = untypedConverterByConverter.get(converter);\n\n    if (!instance) {\n      instance = new FirestoreDataConverter(firestore, new UserDataWriter(firestore), converter);\n      untypedConverterByConverter.set(converter, instance);\n    }\n\n    return instance;\n  };\n\n  return FirestoreDataConverter;\n}();\n\nFirestoreDataConverter.INSTANCES = new WeakMap();\n/**\r\n * A reference to a particular document in a collection in the database.\r\n */\n\nvar DocumentReference =\n/** @class */\nfunction () {\n  function DocumentReference(firestore, _delegate) {\n    this.firestore = firestore;\n    this._delegate = _delegate;\n    this._userDataWriter = new UserDataWriter(firestore);\n  }\n\n  DocumentReference.forPath = function (path, firestore, converter) {\n    if (path.length % 2 !== 0) {\n      throw new FirestoreError(Code.INVALID_ARGUMENT, 'Invalid document reference. Document ' + 'references must have an even number of segments, but ' + (path.canonicalString() + \" has \" + path.length));\n    }\n\n    return new DocumentReference(firestore, new DocumentReference$1(firestore._delegate, converter, new DocumentKey(path)));\n  };\n\n  DocumentReference.forKey = function (key, firestore, converter) {\n    return new DocumentReference(firestore, new DocumentReference$1(firestore._delegate, converter, key));\n  };\n\n  Object.defineProperty(DocumentReference.prototype, \"id\", {\n    get: function () {\n      return this._delegate.id;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentReference.prototype, \"parent\", {\n    get: function () {\n      return new CollectionReference(this.firestore, this._delegate.parent);\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentReference.prototype, \"path\", {\n    get: function () {\n      return this._delegate.path;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  DocumentReference.prototype.collection = function (pathString) {\n    try {\n      return new CollectionReference(this.firestore, collection(this._delegate, pathString));\n    } catch (e) {\n      throw replaceFunctionName(e, 'collection()', 'DocumentReference.collection()');\n    }\n  };\n\n  DocumentReference.prototype.isEqual = function (other) {\n    other = util.getModularInstance(other);\n\n    if (!(other instanceof DocumentReference$1)) {\n      return false;\n    }\n\n    return refEqual(this._delegate, other);\n  };\n\n  DocumentReference.prototype.set = function (value, options) {\n    options = validateSetOptions('DocumentReference.set', options);\n\n    try {\n      return setDoc(this._delegate, value, options);\n    } catch (e) {\n      throw replaceFunctionName(e, 'setDoc()', 'DocumentReference.set()');\n    }\n  };\n\n  DocumentReference.prototype.update = function (fieldOrUpdateData, value) {\n    var moreFieldsAndValues = [];\n\n    for (var _i = 2; _i < arguments.length; _i++) {\n      moreFieldsAndValues[_i - 2] = arguments[_i];\n    }\n\n    try {\n      if (arguments.length === 1) {\n        return updateDoc(this._delegate, fieldOrUpdateData);\n      } else {\n        return updateDoc.apply(void 0, tslib.__spreadArray([this._delegate, fieldOrUpdateData, value], moreFieldsAndValues));\n      }\n    } catch (e) {\n      throw replaceFunctionName(e, 'updateDoc()', 'DocumentReference.update()');\n    }\n  };\n\n  DocumentReference.prototype.delete = function () {\n    return deleteDoc(this._delegate);\n  };\n\n  DocumentReference.prototype.onSnapshot = function () {\n    var _this = this;\n\n    var args = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      args[_i] = arguments[_i];\n    }\n\n    var options = extractSnapshotOptions(args);\n    var observer = wrapObserver(args, function (result) {\n      return new DocumentSnapshot(_this.firestore, new DocumentSnapshot$1(_this.firestore._delegate, _this._userDataWriter, result._key, result._document, result.metadata, _this._delegate.converter));\n    });\n    return onSnapshot(this._delegate, options, observer);\n  };\n\n  DocumentReference.prototype.get = function (options) {\n    var _this = this;\n\n    var snap;\n\n    if ((options === null || options === void 0 ? void 0 : options.source) === 'cache') {\n      snap = getDocFromCache(this._delegate);\n    } else if ((options === null || options === void 0 ? void 0 : options.source) === 'server') {\n      snap = getDocFromServer(this._delegate);\n    } else {\n      snap = getDoc(this._delegate);\n    }\n\n    return snap.then(function (result) {\n      return new DocumentSnapshot(_this.firestore, new DocumentSnapshot$1(_this.firestore._delegate, _this._userDataWriter, result._key, result._document, result.metadata, _this._delegate.converter));\n    });\n  };\n\n  DocumentReference.prototype.withConverter = function (converter) {\n    return new DocumentReference(this.firestore, converter ? this._delegate.withConverter(FirestoreDataConverter.getInstance(this.firestore, converter)) : this._delegate.withConverter(null));\n  };\n\n  return DocumentReference;\n}();\n/**\r\n * Replaces the function name in an error thrown by the firestore-exp API\r\n * with the function names used in the classic API.\r\n */\n\n\nfunction replaceFunctionName(e, original, updated) {\n  e.message = e.message.replace(original, updated);\n  return e;\n}\n/**\r\n * Iterates the list of arguments from an `onSnapshot` call and returns the\r\n * first argument that may be an `SnapshotListenOptions` object. Returns an\r\n * empty object if none is found.\r\n */\n\n\nfunction extractSnapshotOptions(args) {\n  for (var _i = 0, args_1 = args; _i < args_1.length; _i++) {\n    var arg = args_1[_i];\n\n    if (typeof arg === 'object' && !isPartialObserver(arg)) {\n      return arg;\n    }\n  }\n\n  return {};\n}\n/**\r\n * Creates an observer that can be passed to the firestore-exp SDK. The\r\n * observer converts all observed values into the format expected by the classic\r\n * SDK.\r\n *\r\n * @param args - The list of arguments from an `onSnapshot` call.\r\n * @param wrapper - The function that converts the firestore-exp type into the\r\n * type used by this shim.\r\n */\n\n\nfunction wrapObserver(args, wrapper) {\n  var _a, _b;\n\n  var userObserver;\n\n  if (isPartialObserver(args[0])) {\n    userObserver = args[0];\n  } else if (isPartialObserver(args[1])) {\n    userObserver = args[1];\n  } else if (typeof args[0] === 'function') {\n    userObserver = {\n      next: args[0],\n      error: args[1],\n      complete: args[2]\n    };\n  } else {\n    userObserver = {\n      next: args[1],\n      error: args[2],\n      complete: args[3]\n    };\n  }\n\n  return {\n    next: function (val) {\n      if (userObserver.next) {\n        userObserver.next(wrapper(val));\n      }\n    },\n    error: (_a = userObserver.error) === null || _a === void 0 ? void 0 : _a.bind(userObserver),\n    complete: (_b = userObserver.complete) === null || _b === void 0 ? void 0 : _b.bind(userObserver)\n  };\n}\n\nvar DocumentSnapshot =\n/** @class */\nfunction () {\n  function DocumentSnapshot(_firestore, _delegate) {\n    this._firestore = _firestore;\n    this._delegate = _delegate;\n  }\n\n  Object.defineProperty(DocumentSnapshot.prototype, \"ref\", {\n    get: function () {\n      return new DocumentReference(this._firestore, this._delegate.ref);\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentSnapshot.prototype, \"id\", {\n    get: function () {\n      return this._delegate.id;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentSnapshot.prototype, \"metadata\", {\n    get: function () {\n      return this._delegate.metadata;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentSnapshot.prototype, \"exists\", {\n    get: function () {\n      return this._delegate.exists();\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  DocumentSnapshot.prototype.data = function (options) {\n    return this._delegate.data(options);\n  };\n\n  DocumentSnapshot.prototype.get = function (fieldPath, options // We are using `any` here to avoid an explicit cast by our users.\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  ) {\n    return this._delegate.get(fieldPath, options);\n  };\n\n  DocumentSnapshot.prototype.isEqual = function (other) {\n    return snapshotEqual(this._delegate, other._delegate);\n  };\n\n  return DocumentSnapshot;\n}();\n\nvar QueryDocumentSnapshot =\n/** @class */\nfunction (_super) {\n  tslib.__extends(QueryDocumentSnapshot, _super);\n\n  function QueryDocumentSnapshot() {\n    return _super !== null && _super.apply(this, arguments) || this;\n  }\n\n  QueryDocumentSnapshot.prototype.data = function (options) {\n    var data = this._delegate.data(options);\n\n    return data;\n  };\n\n  return QueryDocumentSnapshot;\n}(DocumentSnapshot);\n\nvar Query =\n/** @class */\nfunction () {\n  function Query(firestore, _delegate) {\n    this.firestore = firestore;\n    this._delegate = _delegate;\n    this._userDataWriter = new UserDataWriter(firestore);\n  }\n\n  Query.prototype.where = function (fieldPath, opStr, value) {\n    try {\n      // The \"as string\" cast is a little bit of a hack. `where` accepts the\n      // FieldPath Compat type as input, but is not typed as such in order to\n      // not expose this via our public typings file.\n      return new Query(this.firestore, query(this._delegate, where(fieldPath, opStr, value)));\n    } catch (e) {\n      throw replaceFunctionName(e, /(orderBy|where)\\(\\)/, 'Query.$1()');\n    }\n  };\n\n  Query.prototype.orderBy = function (fieldPath, directionStr) {\n    try {\n      // The \"as string\" cast is a little bit of a hack. `orderBy` accepts the\n      // FieldPath Compat type as input, but is not typed as such in order to\n      // not expose this via our public typings file.\n      return new Query(this.firestore, query(this._delegate, orderBy(fieldPath, directionStr)));\n    } catch (e) {\n      throw replaceFunctionName(e, /(orderBy|where)\\(\\)/, 'Query.$1()');\n    }\n  };\n\n  Query.prototype.limit = function (n) {\n    try {\n      return new Query(this.firestore, query(this._delegate, limit(n)));\n    } catch (e) {\n      throw replaceFunctionName(e, 'limit()', 'Query.limit()');\n    }\n  };\n\n  Query.prototype.limitToLast = function (n) {\n    try {\n      return new Query(this.firestore, query(this._delegate, limitToLast(n)));\n    } catch (e) {\n      throw replaceFunctionName(e, 'limitToLast()', 'Query.limitToLast()');\n    }\n  };\n\n  Query.prototype.startAt = function () {\n    var args = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      args[_i] = arguments[_i];\n    }\n\n    try {\n      return new Query(this.firestore, query(this._delegate, startAt.apply(void 0, args)));\n    } catch (e) {\n      throw replaceFunctionName(e, 'startAt()', 'Query.startAt()');\n    }\n  };\n\n  Query.prototype.startAfter = function () {\n    var args = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      args[_i] = arguments[_i];\n    }\n\n    try {\n      return new Query(this.firestore, query(this._delegate, startAfter.apply(void 0, args)));\n    } catch (e) {\n      throw replaceFunctionName(e, 'startAfter()', 'Query.startAfter()');\n    }\n  };\n\n  Query.prototype.endBefore = function () {\n    var args = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      args[_i] = arguments[_i];\n    }\n\n    try {\n      return new Query(this.firestore, query(this._delegate, endBefore.apply(void 0, args)));\n    } catch (e) {\n      throw replaceFunctionName(e, 'endBefore()', 'Query.endBefore()');\n    }\n  };\n\n  Query.prototype.endAt = function () {\n    var args = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      args[_i] = arguments[_i];\n    }\n\n    try {\n      return new Query(this.firestore, query(this._delegate, endAt.apply(void 0, args)));\n    } catch (e) {\n      throw replaceFunctionName(e, 'endAt()', 'Query.endAt()');\n    }\n  };\n\n  Query.prototype.isEqual = function (other) {\n    return queryEqual(this._delegate, other._delegate);\n  };\n\n  Query.prototype.get = function (options) {\n    var _this = this;\n\n    var query;\n\n    if ((options === null || options === void 0 ? void 0 : options.source) === 'cache') {\n      query = getDocsFromCache(this._delegate);\n    } else if ((options === null || options === void 0 ? void 0 : options.source) === 'server') {\n      query = getDocsFromServer(this._delegate);\n    } else {\n      query = getDocs(this._delegate);\n    }\n\n    return query.then(function (result) {\n      return new QuerySnapshot(_this.firestore, new QuerySnapshot$1(_this.firestore._delegate, _this._userDataWriter, _this._delegate, result._snapshot));\n    });\n  };\n\n  Query.prototype.onSnapshot = function () {\n    var _this = this;\n\n    var args = [];\n\n    for (var _i = 0; _i < arguments.length; _i++) {\n      args[_i] = arguments[_i];\n    }\n\n    var options = extractSnapshotOptions(args);\n    var observer = wrapObserver(args, function (snap) {\n      return new QuerySnapshot(_this.firestore, new QuerySnapshot$1(_this.firestore._delegate, _this._userDataWriter, _this._delegate, snap._snapshot));\n    });\n    return onSnapshot(this._delegate, options, observer);\n  };\n\n  Query.prototype.withConverter = function (converter) {\n    return new Query(this.firestore, converter ? this._delegate.withConverter(FirestoreDataConverter.getInstance(this.firestore, converter)) : this._delegate.withConverter(null));\n  };\n\n  return Query;\n}();\n\nvar DocumentChange =\n/** @class */\nfunction () {\n  function DocumentChange(_firestore, _delegate) {\n    this._firestore = _firestore;\n    this._delegate = _delegate;\n  }\n\n  Object.defineProperty(DocumentChange.prototype, \"type\", {\n    get: function () {\n      return this._delegate.type;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentChange.prototype, \"doc\", {\n    get: function () {\n      return new QueryDocumentSnapshot(this._firestore, this._delegate.doc);\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentChange.prototype, \"oldIndex\", {\n    get: function () {\n      return this._delegate.oldIndex;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DocumentChange.prototype, \"newIndex\", {\n    get: function () {\n      return this._delegate.newIndex;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  return DocumentChange;\n}();\n\nvar QuerySnapshot =\n/** @class */\nfunction () {\n  function QuerySnapshot(_firestore, _delegate) {\n    this._firestore = _firestore;\n    this._delegate = _delegate;\n  }\n\n  Object.defineProperty(QuerySnapshot.prototype, \"query\", {\n    get: function () {\n      return new Query(this._firestore, this._delegate.query);\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(QuerySnapshot.prototype, \"metadata\", {\n    get: function () {\n      return this._delegate.metadata;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(QuerySnapshot.prototype, \"size\", {\n    get: function () {\n      return this._delegate.size;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(QuerySnapshot.prototype, \"empty\", {\n    get: function () {\n      return this._delegate.empty;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(QuerySnapshot.prototype, \"docs\", {\n    get: function () {\n      var _this = this;\n\n      return this._delegate.docs.map(function (doc) {\n        return new QueryDocumentSnapshot(_this._firestore, doc);\n      });\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  QuerySnapshot.prototype.docChanges = function (options) {\n    var _this = this;\n\n    return this._delegate.docChanges(options).map(function (docChange) {\n      return new DocumentChange(_this._firestore, docChange);\n    });\n  };\n\n  QuerySnapshot.prototype.forEach = function (callback, thisArg) {\n    var _this = this;\n\n    this._delegate.forEach(function (snapshot) {\n      callback.call(thisArg, new QueryDocumentSnapshot(_this._firestore, snapshot));\n    });\n  };\n\n  QuerySnapshot.prototype.isEqual = function (other) {\n    return snapshotEqual(this._delegate, other._delegate);\n  };\n\n  return QuerySnapshot;\n}();\n\nvar CollectionReference =\n/** @class */\nfunction (_super) {\n  tslib.__extends(CollectionReference, _super);\n\n  function CollectionReference(firestore, _delegate) {\n    var _this = _super.call(this, firestore, _delegate) || this;\n\n    _this.firestore = firestore;\n    _this._delegate = _delegate;\n    return _this;\n  }\n\n  Object.defineProperty(CollectionReference.prototype, \"id\", {\n    get: function () {\n      return this._delegate.id;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(CollectionReference.prototype, \"path\", {\n    get: function () {\n      return this._delegate.path;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(CollectionReference.prototype, \"parent\", {\n    get: function () {\n      var docRef = this._delegate.parent;\n      return docRef ? new DocumentReference(this.firestore, docRef) : null;\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  CollectionReference.prototype.doc = function (documentPath) {\n    try {\n      if (documentPath === undefined) {\n        // Call `doc` without `documentPath` if `documentPath` is `undefined`\n        // as `doc` validates the number of arguments to prevent users from\n        // accidentally passing `undefined`.\n        return new DocumentReference(this.firestore, doc(this._delegate));\n      } else {\n        return new DocumentReference(this.firestore, doc(this._delegate, documentPath));\n      }\n    } catch (e) {\n      throw replaceFunctionName(e, 'doc()', 'CollectionReference.doc()');\n    }\n  };\n\n  CollectionReference.prototype.add = function (data) {\n    var _this = this;\n\n    return addDoc(this._delegate, data).then(function (docRef) {\n      return new DocumentReference(_this.firestore, docRef);\n    });\n  };\n\n  CollectionReference.prototype.isEqual = function (other) {\n    return refEqual(this._delegate, other._delegate);\n  };\n\n  CollectionReference.prototype.withConverter = function (converter) {\n    return new CollectionReference(this.firestore, converter ? this._delegate.withConverter(FirestoreDataConverter.getInstance(this.firestore, converter)) : this._delegate.withConverter(null));\n  };\n\n  return CollectionReference;\n}(Query);\n\nfunction castReference(documentRef) {\n  return cast(documentRef, DocumentReference$1);\n}\n\nexports.ArrayRemoveFieldValueImpl = ArrayRemoveFieldValueImpl;\nexports.ArrayUnionFieldValueImpl = ArrayUnionFieldValueImpl;\nexports.Blob = Blob;\nexports.CACHE_SIZE_UNLIMITED = CACHE_SIZE_UNLIMITED;\nexports.CollectionReference = CollectionReference;\nexports.DeleteFieldValueImpl = DeleteFieldValueImpl;\nexports.DocumentReference = DocumentReference;\nexports.DocumentSnapshot = DocumentSnapshot;\nexports.FieldPath = FieldPath;\nexports.FieldPath$1 = FieldPath$1;\nexports.Firestore = Firestore;\nexports.Firestore$1 = Firestore$1;\nexports.GeoPoint = GeoPoint;\nexports.IndexedDbPersistenceProvider = IndexedDbPersistenceProvider;\nexports.NumericIncrementFieldValueImpl = NumericIncrementFieldValueImpl;\nexports.Query = Query;\nexports.QueryDocumentSnapshot = QueryDocumentSnapshot;\nexports.QuerySnapshot = QuerySnapshot;\nexports.ServerTimestampFieldValueImpl = ServerTimestampFieldValueImpl;\nexports.Timestamp = Timestamp;\nexports.Transaction = Transaction;\nexports.WriteBatch = WriteBatch;\nexports.loadBundle = loadBundle;\nexports.namedQuery = namedQuery;\nexports.setLogLevel = setLogLevel; //# sourceMappingURL=database-c96156d6-f0f0e10d.js.map","map":null,"metadata":{},"sourceType":"script"}